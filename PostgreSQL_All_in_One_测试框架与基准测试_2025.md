# PostgreSQL All-in-One æµ‹è¯•æ¡†æ¶ä¸åŸºå‡†æµ‹è¯• - 2025å¹´

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£æä¾›äº†PostgreSQL All-in-Oneæ¶æ„çš„å®Œæ•´æµ‹è¯•æ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€ç«¯åˆ°ç«¯æµ‹è¯•ã€æ€§èƒ½æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•ã€‚é€šè¿‡å…¨é¢çš„æµ‹è¯•è¦†ç›–ï¼Œç¡®ä¿ç³»ç»Ÿçš„æ­£ç¡®æ€§ã€æ€§èƒ½å’Œå¯é æ€§ã€‚

## ğŸ§ª æµ‹è¯•æ¡†æ¶æ¶æ„

### 1. æµ‹è¯•åˆ†å±‚æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç«¯åˆ°ç«¯æµ‹è¯• (E2E Tests)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ç”¨æˆ·åœºæ™¯    â”‚ â”‚  ä¸šåŠ¡æµç¨‹   â”‚ â”‚  ç³»ç»Ÿé›†æˆ    â”‚ â”‚ æ€§èƒ½æµ‹è¯• â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    é›†æˆæµ‹è¯• (Integration Tests)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  æ•°æ®åº“é›†æˆ  â”‚ â”‚  ç¼“å­˜é›†æˆ    â”‚ â”‚  ç›‘æ§é›†æˆ   â”‚ â”‚ å®‰å…¨é›†æˆ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    å•å…ƒæµ‹è¯• (Unit Tests)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  æ ¸å¿ƒé€»è¾‘    â”‚ â”‚  å·¥å…·å‡½æ•°   â”‚ â”‚  æ•°æ®ç»“æ„    â”‚ â”‚ é”™è¯¯å¤„ç† â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æµ‹è¯•å·¥å…·æ ˆ

```toml
# Cargo.toml æµ‹è¯•ä¾èµ–
[dev-dependencies]
# æµ‹è¯•æ¡†æ¶
tokio-test = "0.4.4"
criterion = "0.7.0"
mockall = "0.13.1"
proptest = "1.5.1"

# æ•°æ®åº“æµ‹è¯•
sqlx = { version = "0.8.7", features = ["runtime-tokio-rustls", "postgres", "chrono", "uuid", "migrate"] }
testcontainers = "0.20.0"

# ç¼“å­˜æµ‹è¯•
redis = "0.32.5"

# ç½‘ç»œæµ‹è¯•
reqwest = { version = "0.12.23", features = ["json", "rustls-tls"] }
wiremock = "0.6.0"

# æ€§èƒ½æµ‹è¯•
criterion = "0.7.0"
flamegraph = "0.4.0"

# å¹¶å‘æµ‹è¯•
tokio = { version = "1.47.1", features = ["full", "test-util"] }
```

## ğŸ”¬ å•å…ƒæµ‹è¯•

### 1. æ ¸å¿ƒåº“æµ‹è¯• (crates/core/tests/lib.rs)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    use std::time::Duration;

    #[test]
    fn test_app_config_default() {
        let config = AppConfig::default();
        assert_eq!(config.database.max_connections, 100);
        assert_eq!(config.cache.host, "localhost");
        assert_eq!(config.monitoring.prometheus_port, 9090);
    }

    #[test]
    fn test_app_config_from_env() {
        std::env::set_var("DATABASE_URL", "postgresql://test:test@localhost:5432/testdb");
        std::env::set_var("REDIS_HOST", "redis.example.com");
        std::env::set_var("REDIS_PORT", "6380");

        let config = AppConfig::from_env().unwrap();
        assert_eq!(config.database.url, "postgresql://test:test@localhost:5432/testdb");
        assert_eq!(config.cache.host, "redis.example.com");
        assert_eq!(config.cache.port, 6380);
    }

    #[test]
    fn test_app_error_display() {
        let error = AppError::config("Test error");
        assert_eq!(error.to_string(), "Configuration error: Test error");
    }

    #[test]
    fn test_app_error_from_sqlx() {
        let sqlx_error = sqlx::Error::Configuration("Test".into());
        let app_error: AppError = sqlx_error.into();
        assert!(matches!(app_error, AppError::Database(_)));
    }
}
```

### 2. æ•°æ®åº“è¿æ¥æ± æµ‹è¯• (crates/database/tests/connection_pool_tests.rs)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    use testcontainers::{Container, GenericImage};
    use testcontainers::core::WaitFor;
    use std::time::Duration;

    async fn setup_test_database() -> String {
        let postgres_image = GenericImage::new("postgres", "15")
            .with_env_var("POSTGRES_DB", "testdb")
            .with_env_var("POSTGRES_USER", "testuser")
            .with_env_var("POSTGRES_PASSWORD", "testpass")
            .with_wait_for(WaitFor::message_on_stderr("database system is ready to accept connections"));

        let container = Container::new(postgres_image)
            .with_exposed_port(5432)
            .start()
            .await;

        let port = container.get_host_port_ipv4(5432).await;
        format!("postgresql://testuser:testpass@localhost:{}/testdb", port)
    }

    #[tokio::test]
    async fn test_connection_pool_creation() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        
        let pool = DatabasePool::new(&database_url, config).await;
        assert!(pool.is_ok());
    }

    #[tokio::test]
    async fn test_connection_pool_health_check() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        let pool = DatabasePool::new(&database_url, config).await.unwrap();
        
        let is_healthy = pool.health_check().await;
        assert!(is_healthy);
    }

    #[tokio::test]
    async fn test_connection_pool_with_connection() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        let pool = DatabasePool::new(&database_url, config).await.unwrap();
        
        let result = pool.with_connection(|conn| async move {
            sqlx::query("SELECT 1 as test")
                .fetch_one(conn)
                .await
                .map_err(AppError::Database)
        }).await;
        
        assert!(result.is_ok());
        let row = result.unwrap();
        assert_eq!(row.get::<i32, _>("test"), 1);
    }

    #[tokio::test]
    async fn test_connection_pool_with_transaction() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        let pool = DatabasePool::new(&database_url, config).await.unwrap();
        
        // åˆ›å»ºæµ‹è¯•è¡¨
        pool.with_connection(|conn| async move {
            sqlx::query("CREATE TABLE test_table (id SERIAL PRIMARY KEY, name VARCHAR(50))")
                .execute(conn)
                .await
                .map_err(AppError::Database)
        }).await.unwrap();
        
        let result = pool.with_transaction(|tx| async move {
            sqlx::query("INSERT INTO test_table (name) VALUES ($1)")
                .bind("test")
                .execute(tx)
                .await
                .map_err(AppError::Database)?;
            
            Ok(())
        }).await;
        
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_connection_pool_stats() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        let pool = DatabasePool::new(&database_url, config).await.unwrap();
        
        let stats = pool.get_stats().await;
        assert_eq!(stats.total_connections, 0);
        assert_eq!(stats.active_connections, 0);
        assert_eq!(stats.total_requests, 0);
    }

    #[tokio::test]
    async fn test_connection_pool_concurrent_requests() {
        let database_url = setup_test_database().await;
        let config = PoolConfig::default();
        let pool = DatabasePool::new(&database_url, config).await.unwrap();
        
        let mut handles = vec![];
        for i in 0..10 {
            let pool_clone = pool.clone();
            let handle = tokio::spawn(async move {
                pool_clone.with_connection(|conn| async move {
                    sqlx::query("SELECT $1 as test")
                        .bind(i)
                        .fetch_one(conn)
                        .await
                        .map_err(AppError::Database)
                }).await
            });
            handles.push(handle);
        }
        
        for handle in handles {
            let result = handle.await.unwrap();
            assert!(result.is_ok());
        }
    }
}
```

### 3. ç¼“å­˜ç³»ç»Ÿæµ‹è¯• (crates/cache/tests/redis_tests.rs)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    use testcontainers::{Container, GenericImage};
    use std::time::Duration;

    async fn setup_test_redis() -> String {
        let redis_image = GenericImage::new("redis", "7-alpine");
        let container = Container::new(redis_image)
            .with_exposed_port(6379)
            .start()
            .await;

        let port = container.get_host_port_ipv4(6379).await;
        format!("redis://localhost:{}", port)
    }

    #[tokio::test]
    async fn test_redis_cache_creation() {
        let redis_url = setup_test_redis().await;
        let config = CacheConfig {
            host: "localhost".to_string(),
            port: 6379,
            password: None,
            database: 0,
            default_ttl: Duration::from_secs(3600),
            max_connections: 100,
        };
        
        let cache = RedisCache::new(config);
        assert!(cache.is_ok());
    }

    #[tokio::test]
    async fn test_redis_cache_set_get() {
        let redis_url = setup_test_redis().await;
        let config = CacheConfig::default();
        let cache = RedisCache::new(config).unwrap();
        
        let result = cache.set("test_key", &"test_value", Some(Duration::from_secs(60))).await;
        assert!(result.is_ok());
        
        let value: Option<String> = cache.get("test_key").await.unwrap();
        assert_eq!(value, Some("test_value".to_string()));
    }

    #[tokio::test]
    async fn test_redis_cache_ttl() {
        let redis_url = setup_test_redis().await;
        let config = CacheConfig::default();
        let cache = RedisCache::new(config).unwrap();
        
        let result = cache.set("test_key", &"test_value", Some(Duration::from_millis(100))).await;
        assert!(result.is_ok());
        
        // ç­‰å¾…è¿‡æœŸ
        tokio::time::sleep(Duration::from_millis(150)).await;
        
        let value: Option<String> = cache.get("test_key").await.unwrap();
        assert_eq!(value, None);
    }

    #[tokio::test]
    async fn test_redis_cache_serialization() {
        let redis_url = setup_test_redis().await;
        let config = CacheConfig::default();
        let cache = RedisCache::new(config).unwrap();
        
        #[derive(Serialize, Deserialize, Debug, PartialEq)]
        struct TestStruct {
            id: i32,
            name: String,
            active: bool,
        }
        
        let test_data = TestStruct {
            id: 1,
            name: "test".to_string(),
            active: true,
        };
        
        let result = cache.set("test_struct", &test_data, Some(Duration::from_secs(60))).await;
        assert!(result.is_ok());
        
        let value: Option<TestStruct> = cache.get("test_struct").await.unwrap();
        assert_eq!(value, Some(test_data));
    }
}
```

## ğŸ”— é›†æˆæµ‹è¯•

### 1. æ•°æ®åº“é›†æˆæµ‹è¯• (tests/integration/database_integration_tests.rs)

```rust
use postgresql_all_in_one::database::connection::pool::DatabasePool;
use postgresql_all_in_one::cache::redis::RedisCache;
use postgresql_all_in_one::core::{AppConfig, AppError};
use testcontainers::{Container, GenericImage};
use testcontainers::core::WaitFor;
use std::time::Duration;

async fn setup_test_environment() -> (String, String) {
    // å¯åŠ¨ PostgreSQL å®¹å™¨
    let postgres_image = GenericImage::new("postgres", "15")
        .with_env_var("POSTGRES_DB", "testdb")
        .with_env_var("POSTGRES_USER", "testuser")
        .with_env_var("POSTGRES_PASSWORD", "testpass")
        .with_wait_for(WaitFor::message_on_stderr("database system is ready to accept connections"));

    let postgres_container = Container::new(postgres_image)
        .with_exposed_port(5432)
        .start()
        .await;

    let postgres_port = postgres_container.get_host_port_ipv4(5432).await;
    let postgres_url = format!("postgresql://testuser:testpass@localhost:{}/testdb", postgres_port);

    // å¯åŠ¨ Redis å®¹å™¨
    let redis_image = GenericImage::new("redis", "7-alpine");
    let redis_container = Container::new(redis_image)
        .with_exposed_port(6379)
        .start()
        .await;

    let redis_port = redis_container.get_host_port_ipv4(6379).await;
    let redis_url = format!("redis://localhost:{}", redis_port);

    (postgres_url, redis_url)
}

#[tokio::test]
async fn test_database_redis_integration() {
    let (postgres_url, redis_url) = setup_test_environment().await;
    
    // åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± 
    let db_config = postgresql_all_in_one::database::connection::pool::PoolConfig::default();
    let db_pool = DatabasePool::new(&postgres_url, db_config).await.unwrap();
    
    // åˆå§‹åŒ– Redis ç¼“å­˜
    let cache_config = postgresql_all_in_one::cache::redis::CacheConfig::default();
    let cache = RedisCache::new(cache_config).unwrap();
    
    // åˆ›å»ºæµ‹è¯•è¡¨
    db_pool.with_connection(|conn| async move {
        sqlx::query("CREATE TABLE users (id SERIAL PRIMARY KEY, name VARCHAR(50), email VARCHAR(100))")
            .execute(conn)
            .await
            .map_err(AppError::Database)
    }).await.unwrap();
    
    // æµ‹è¯•æ•°æ®å†™å…¥å’Œç¼“å­˜
    let user_id = db_pool.with_connection(|conn| async move {
        let result = sqlx::query("INSERT INTO users (name, email) VALUES ($1, $2) RETURNING id")
            .bind("John Doe")
            .bind("john@example.com")
            .fetch_one(conn)
            .await
            .map_err(AppError::Database)?;
        
        Ok(result.get::<i32, _>("id"))
    }).await.unwrap();
    
    // å°†ç”¨æˆ·ä¿¡æ¯ç¼“å­˜åˆ° Redis
    let user_info = format!("user:{}", user_id);
    let user_data = serde_json::json!({
        "id": user_id,
        "name": "John Doe",
        "email": "john@example.com"
    });
    
    cache.set(&user_info, &user_data, Some(Duration::from_secs(3600))).await.unwrap();
    
    // ä»ç¼“å­˜è¯»å–ç”¨æˆ·ä¿¡æ¯
    let cached_user: Option<serde_json::Value> = cache.get(&user_info).await.unwrap();
    assert!(cached_user.is_some());
    assert_eq!(cached_user.unwrap()["name"], "John Doe");
    
    // ä»æ•°æ®åº“è¯»å–ç”¨æˆ·ä¿¡æ¯
    let db_user = db_pool.with_connection(|conn| async move {
        sqlx::query("SELECT * FROM users WHERE id = $1")
            .bind(user_id)
            .fetch_one(conn)
            .await
            .map_err(AppError::Database)
    }).await.unwrap();
    
    assert_eq!(db_user.get::<String, _>("name"), "John Doe");
    assert_eq!(db_user.get::<String, _>("email"), "john@example.com");
}

#[tokio::test]
async fn test_transaction_with_cache_invalidation() {
    let (postgres_url, redis_url) = setup_test_environment().await;
    
    let db_config = postgresql_all_in_one::database::connection::pool::PoolConfig::default();
    let db_pool = DatabasePool::new(&postgres_url, db_config).await.unwrap();
    
    let cache_config = postgresql_all_in_one::cache::redis::CacheConfig::default();
    let cache = RedisCache::new(cache_config).unwrap();
    
    // åˆ›å»ºæµ‹è¯•è¡¨
    db_pool.with_connection(|conn| async move {
        sqlx::query("CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(50), price DECIMAL(10,2))")
            .execute(conn)
            .await
            .map_err(AppError::Database)
    }).await.unwrap();
    
    // æ’å…¥äº§å“å¹¶ç¼“å­˜
    let product_id = db_pool.with_connection(|conn| async move {
        let result = sqlx::query("INSERT INTO products (name, price) VALUES ($1, $2) RETURNING id")
            .bind("Test Product")
            .bind(99.99)
            .fetch_one(conn)
            .await
            .map_err(AppError::Database)?;
        
        Ok(result.get::<i32, _>("id"))
    }).await.unwrap();
    
    let product_key = format!("product:{}", product_id);
    let product_data = serde_json::json!({
        "id": product_id,
        "name": "Test Product",
        "price": 99.99
    });
    
    cache.set(&product_key, &product_data, Some(Duration::from_secs(3600))).await.unwrap();
    
    // åœ¨äº‹åŠ¡ä¸­æ›´æ–°äº§å“ä»·æ ¼
    db_pool.with_transaction(|tx| async move {
        // æ›´æ–°æ•°æ®åº“
        sqlx::query("UPDATE products SET price = $1 WHERE id = $2")
            .bind(149.99)
            .bind(product_id)
            .execute(tx)
            .await
            .map_err(AppError::Database)?;
        
        // åˆ é™¤ç¼“å­˜
        cache.delete(&product_key).await.map_err(|e| AppError::Redis(e))?;
        
        Ok(())
    }).await.unwrap();
    
    // éªŒè¯ç¼“å­˜å·²è¢«åˆ é™¤
    let cached_product: Option<serde_json::Value> = cache.get(&product_key).await.unwrap();
    assert!(cached_product.is_none());
    
    // éªŒè¯æ•°æ®åº“å·²æ›´æ–°
    let updated_product = db_pool.with_connection(|conn| async move {
        sqlx::query("SELECT * FROM products WHERE id = $1")
            .bind(product_id)
            .fetch_one(conn)
            .await
            .map_err(AppError::Database)
    }).await.unwrap();
    
    assert_eq!(updated_product.get::<rust_decimal::Decimal, _>("price"), rust_decimal::Decimal::new(14999, 2));
}
```

### 2. ç›‘æ§é›†æˆæµ‹è¯• (tests/integration/monitoring_integration_tests.rs)

```rust
use postgresql_all_in_one::monitoring::metrics::DatabaseMetrics;
use postgresql_all_in_one::monitoring::prometheus::PrometheusExporter;
use prometheus::{Registry, Counter, Histogram};
use std::time::Duration;

#[tokio::test]
async fn test_metrics_collection() {
    let registry = Registry::new();
    let metrics = DatabaseMetrics::new(&registry).unwrap();
    let exporter = PrometheusExporter::new(registry, 9090).unwrap();
    
    // æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
    metrics.record_query(Duration::from_millis(100));
    metrics.record_query(Duration::from_millis(200));
    metrics.record_cache_hit();
    metrics.record_cache_miss();
    
    // å¯åŠ¨å¯¼å‡ºå™¨
    let exporter_handle = tokio::spawn(async move {
        exporter.start().await
    });
    
    // ç­‰å¾…å¯¼å‡ºå™¨å¯åŠ¨
    tokio::time::sleep(Duration::from_millis(100)).await;
    
    // è·å–æŒ‡æ ‡
    let client = reqwest::Client::new();
    let response = client.get("http://localhost:9090/metrics").send().await.unwrap();
    let body = response.text().await.unwrap();
    
    // éªŒè¯æŒ‡æ ‡å­˜åœ¨
    assert!(body.contains("database_queries_total"));
    assert!(body.contains("database_query_duration_seconds"));
    assert!(body.contains("database_cache_hits_total"));
    assert!(body.contains("database_cache_misses_total"));
    
    exporter_handle.abort();
}

#[tokio::test]
async fn test_metrics_aggregation() {
    let registry = Registry::new();
    let metrics = DatabaseMetrics::new(&registry).unwrap();
    
    // è®°å½•å¤šä¸ªæŸ¥è¯¢
    for i in 0..100 {
        metrics.record_query(Duration::from_millis(i));
    }
    
    // éªŒè¯æŒ‡æ ‡å€¼
    let stats = metrics.get_stats().await;
    assert_eq!(stats.total_queries, 100);
    assert!(stats.average_query_time.as_millis() > 0);
}
```

## ğŸ¯ ç«¯åˆ°ç«¯æµ‹è¯•

### 1. ç”¨æˆ·åœºæ™¯æµ‹è¯• (tests/e2e/user_scenarios_tests.rs)

```rust
use postgresql_all_in_one::services::api_gateway::ApiGateway;
use postgresql_all_in_one::services::query_engine::QueryEngine;
use postgresql_all_in_one::core::AppConfig;
use testcontainers::{Container, GenericImage};
use testcontainers::core::WaitFor;
use std::time::Duration;

async fn setup_e2e_environment() -> (String, String) {
    // å¯åŠ¨ PostgreSQL å®¹å™¨
    let postgres_image = GenericImage::new("postgres", "15")
        .with_env_var("POSTGRES_DB", "e2etest")
        .with_env_var("POSTGRES_USER", "e2euser")
        .with_env_var("POSTGRES_PASSWORD", "e2epass")
        .with_wait_for(WaitFor::message_on_stderr("database system is ready to accept connections"));

    let postgres_container = Container::new(postgres_image)
        .with_exposed_port(5432)
        .start()
        .await;

    let postgres_port = postgres_container.get_host_port_ipv4(5432).await;
    let postgres_url = format!("postgresql://e2euser:e2epass@localhost:{}/e2etest", postgres_port);

    // å¯åŠ¨ Redis å®¹å™¨
    let redis_image = GenericImage::new("redis", "7-alpine");
    let redis_container = Container::new(redis_image)
        .with_exposed_port(6379)
        .start()
        .await;

    let redis_port = redis_container.get_host_port_ipv4(6379).await;
    let redis_url = format!("redis://localhost:{}", redis_port);

    (postgres_url, redis_url)
}

#[tokio::test]
async fn test_user_registration_workflow() {
    let (postgres_url, redis_url) = setup_e2e_environment().await;
    
    // åˆå§‹åŒ–æœåŠ¡
    let config = AppConfig::from_env().unwrap();
    let api_gateway = ApiGateway::new(config.clone()).await.unwrap();
    let query_engine = QueryEngine::new(config).await.unwrap();
    
    // åˆ›å»ºç”¨æˆ·è¡¨
    query_engine.execute_sql("CREATE TABLE users (id SERIAL PRIMARY KEY, username VARCHAR(50) UNIQUE, email VARCHAR(100) UNIQUE, password_hash VARCHAR(255), created_at TIMESTAMPTZ DEFAULT NOW())").await.unwrap();
    
    // ç”¨æˆ·æ³¨å†Œ
    let registration_data = serde_json::json!({
        "username": "testuser",
        "email": "test@example.com",
        "password": "password123"
    });
    
    let response = api_gateway.handle_request("POST", "/api/users/register", registration_data).await.unwrap();
    assert_eq!(response.status, 201);
    
    // éªŒè¯ç”¨æˆ·å·²åˆ›å»º
    let users = query_engine.execute_sql("SELECT * FROM users WHERE username = 'testuser'").await.unwrap();
    assert_eq!(users.rows.len(), 1);
    assert_eq!(users.rows[0]["username"], "testuser");
    assert_eq!(users.rows[0]["email"], "test@example.com");
}

#[tokio::test]
async fn test_data_analytics_workflow() {
    let (postgres_url, redis_url) = setup_e2e_environment().await;
    
    let config = AppConfig::from_env().unwrap();
    let query_engine = QueryEngine::new(config).await.unwrap();
    
    // åˆ›å»ºåˆ†æè¡¨
    query_engine.execute_sql("CREATE TABLE events (id SERIAL PRIMARY KEY, user_id INTEGER, event_type VARCHAR(50), event_data JSONB, timestamp TIMESTAMPTZ DEFAULT NOW())").await.unwrap();
    
    // æ’å…¥æµ‹è¯•æ•°æ®
    for i in 0..1000 {
        let event_data = serde_json::json!({
            "value": i,
            "category": if i % 2 == 0 { "A" } else { "B" }
        });
        
        query_engine.execute_sql_with_params(
            "INSERT INTO events (user_id, event_type, event_data) VALUES ($1, $2, $3)",
            &[&(i % 100), &"test_event", &event_data]
        ).await.unwrap();
    }
    
    // æ‰§è¡Œåˆ†ææŸ¥è¯¢
    let analysis_result = query_engine.execute_sql("
        SELECT 
            user_id,
            COUNT(*) as event_count,
            AVG((event_data->>'value')::numeric) as avg_value,
            MAX(timestamp) as last_event
        FROM events 
        WHERE timestamp > NOW() - INTERVAL '1 day'
        GROUP BY user_id
        ORDER BY event_count DESC
        LIMIT 10
    ").await.unwrap();
    
    assert_eq!(analysis_result.rows.len(), 10);
    assert!(analysis_result.rows[0]["event_count"].as_i64().unwrap() > 0);
}

#[tokio::test]
async fn test_full_text_search_workflow() {
    let (postgres_url, redis_url) = setup_e2e_environment().await;
    
    let config = AppConfig::from_env().unwrap();
    let query_engine = QueryEngine::new(config).await.unwrap();
    
    // åˆ›å»ºæ–‡æ¡£è¡¨
    query_engine.execute_sql("
        CREATE TABLE documents (
            id SERIAL PRIMARY KEY,
            title VARCHAR(200),
            content TEXT,
            search_vector tsvector,
            created_at TIMESTAMPTZ DEFAULT NOW()
        )
    ").await.unwrap();
    
    // åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
    query_engine.execute_sql("CREATE INDEX idx_documents_search ON documents USING GIN(search_vector)").await.unwrap();
    
    // æ’å…¥æµ‹è¯•æ–‡æ¡£
    let documents = vec![
        ("PostgreSQL æ•°æ®åº“", "PostgreSQL æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºå…³ç³»æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ"),
        ("Rust ç¼–ç¨‹è¯­è¨€", "Rust æ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œæ³¨é‡å®‰å…¨æ€§å’Œæ€§èƒ½"),
        ("Kubernetes å®¹å™¨ç¼–æ’", "Kubernetes æ˜¯ä¸€ä¸ªå¼€æºçš„å®¹å™¨ç¼–æ’å¹³å°"),
    ];
    
    for (title, content) in documents {
        query_engine.execute_sql_with_params(
            "INSERT INTO documents (title, content, search_vector) VALUES ($1, $2, to_tsvector('simple', $1 || ' ' || $2))",
            &[&title, &content]
        ).await.unwrap();
    }
    
    // æ‰§è¡Œå…¨æ–‡æœç´¢
    let search_result = query_engine.execute_sql_with_params(
        "SELECT id, title, content, ts_rank(search_vector, plainto_tsquery('simple', $1)) as rank FROM documents WHERE search_vector @@ plainto_tsquery('simple', $1) ORDER BY rank DESC",
        &[&"PostgreSQL"]
    ).await.unwrap();
    
    assert_eq!(search_result.rows.len(), 1);
    assert_eq!(search_result.rows[0]["title"], "PostgreSQL æ•°æ®åº“");
}
```

## âš¡ æ€§èƒ½æµ‹è¯•

### 1. åŸºå‡†æµ‹è¯• (benches/performance_benchmarks.rs)

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use postgresql_all_in_one::database::connection::pool::DatabasePool;
use postgresql_all_in_one::cache::redis::RedisCache;
use postgresql_all_in_one::core::AppConfig;
use std::time::Duration;

async fn setup_benchmark_environment() -> (DatabasePool, RedisCache) {
    let config = AppConfig::from_env().unwrap();
    let db_pool = DatabasePool::new(&config.database.url, config.database.clone()).await.unwrap();
    let cache = RedisCache::new(config.cache).unwrap();
    
    // åˆ›å»ºæµ‹è¯•è¡¨
    db_pool.with_connection(|conn| async move {
        sqlx::query("CREATE TABLE IF NOT EXISTS benchmark_table (id SERIAL PRIMARY KEY, data TEXT, created_at TIMESTAMPTZ DEFAULT NOW())")
            .execute(conn)
            .await
            .map_err(postgresql_all_in_one::core::AppError::Database)
    }).await.unwrap();
    
    (db_pool, cache)
}

fn benchmark_database_insert(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let (db_pool, _) = rt.block_on(setup_benchmark_environment());
    
    c.bench_function("database_insert", |b| {
        b.to_async(&rt).iter(|| async {
            db_pool.with_connection(|conn| async move {
                sqlx::query("INSERT INTO benchmark_table (data) VALUES ($1)")
                    .bind("benchmark data")
                    .execute(conn)
                    .await
                    .map_err(postgresql_all_in_one::core::AppError::Database)
            }).await
        })
    });
}

fn benchmark_database_select(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let (db_pool, _) = rt.block_on(setup_benchmark_environment());
    
    c.bench_function("database_select", |b| {
        b.to_async(&rt).iter(|| async {
            db_pool.with_connection(|conn| async move {
                sqlx::query("SELECT * FROM benchmark_table LIMIT 100")
                    .fetch_all(conn)
                    .await
                    .map_err(postgresql_all_in_one::core::AppError::Database)
            }).await
        })
    });
}

fn benchmark_redis_set_get(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let (_, cache) = rt.block_on(setup_benchmark_environment());
    
    c.bench_function("redis_set_get", |b| {
        b.to_async(&rt).iter(|| async {
            let key = format!("benchmark_key_{}", rand::random::<u32>());
            let value = "benchmark value";
            
            cache.set(&key, &value, Some(Duration::from_secs(60))).await?;
            let result: Option<String> = cache.get(&key).await?;
            
            Ok::<_, postgresql_all_in_one::core::AppError>(result)
        })
    });
}

fn benchmark_concurrent_operations(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let (db_pool, cache) = rt.block_on(setup_benchmark_environment());
    
    let mut group = c.benchmark_group("concurrent_operations");
    for concurrency in [1, 10, 50, 100].iter() {
        group.bench_with_input(BenchmarkId::new("database", concurrency), concurrency, |b, &concurrency| {
            b.to_async(&rt).iter(|| async {
                let mut handles = vec![];
                for i in 0..concurrency {
                    let pool_clone = db_pool.clone();
                    let handle = tokio::spawn(async move {
                        pool_clone.with_connection(|conn| async move {
                            sqlx::query("SELECT $1 as test")
                                .bind(i)
                                .fetch_one(conn)
                                .await
                                .map_err(postgresql_all_in_one::core::AppError::Database)
                        }).await
                    });
                    handles.push(handle);
                }
                
                for handle in handles {
                    handle.await.unwrap().unwrap();
                }
            })
        });
    }
    group.finish();
}

criterion_group!(
    benches,
    benchmark_database_insert,
    benchmark_database_select,
    benchmark_redis_set_get,
    benchmark_concurrent_operations
);
criterion_main!(benches);
```

### 2. å‹åŠ›æµ‹è¯• (tests/stress/stress_tests.rs)

```rust
use postgresql_all_in_one::database::connection::pool::DatabasePool;
use postgresql_all_in_one::cache::redis::RedisCache;
use postgresql_all_in_one::core::AppConfig;
use std::time::{Duration, Instant};
use tokio::time::timeout;

async fn setup_stress_test() -> (DatabasePool, RedisCache) {
    let config = AppConfig::from_env().unwrap();
    let db_pool = DatabasePool::new(&config.database.url, config.database.clone()).await.unwrap();
    let cache = RedisCache::new(config.cache).unwrap();
    
    // åˆ›å»ºæµ‹è¯•è¡¨
    db_pool.with_connection(|conn| async move {
        sqlx::query("CREATE TABLE IF NOT EXISTS stress_test (id SERIAL PRIMARY KEY, data TEXT, timestamp TIMESTAMPTZ DEFAULT NOW())")
            .execute(conn)
            .await
            .map_err(postgresql_all_in_one::core::AppError::Database)
    }).await.unwrap();
    
    (db_pool, cache)
}

#[tokio::test]
async fn test_high_concurrency_database_operations() {
    let (db_pool, _) = setup_stress_test().await;
    
    let start = Instant::now();
    let mut handles = vec![];
    
    // å¯åŠ¨ 1000 ä¸ªå¹¶å‘æ“ä½œ
    for i in 0..1000 {
        let pool_clone = db_pool.clone();
        let handle = tokio::spawn(async move {
            pool_clone.with_connection(|conn| async move {
                sqlx::query("INSERT INTO stress_test (data) VALUES ($1)")
                    .bind(format!("stress_data_{}", i))
                    .execute(conn)
                    .await
                    .map_err(postgresql_all_in_one::core::AppError::Database)
            }).await
        });
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    for handle in handles {
        let result = timeout(Duration::from_secs(30), handle).await;
        assert!(result.is_ok(), "æ“ä½œè¶…æ—¶");
        let result = result.unwrap();
        assert!(result.is_ok(), "æ“ä½œå¤±è´¥: {:?}", result.err());
    }
    
    let duration = start.elapsed();
    println!("1000 ä¸ªå¹¶å‘æ’å…¥æ“ä½œå®Œæˆï¼Œè€—æ—¶: {:?}", duration);
    assert!(duration < Duration::from_secs(30), "æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œè€—æ—¶è¿‡é•¿");
}

#[tokio::test]
async fn test_high_concurrency_cache_operations() {
    let (_, cache) = setup_stress_test().await;
    
    let start = Instant::now();
    let mut handles = vec![];
    
    // å¯åŠ¨ 1000 ä¸ªå¹¶å‘ç¼“å­˜æ“ä½œ
    for i in 0..1000 {
        let cache_clone = cache.clone();
        let handle = tokio::spawn(async move {
            let key = format!("stress_key_{}", i);
            let value = format!("stress_value_{}", i);
            
            cache_clone.set(&key, &value, Some(Duration::from_secs(60))).await?;
            let result: Option<String> = cache_clone.get(&key).await?;
            
            assert_eq!(result, Some(value));
            Ok::<_, postgresql_all_in_one::core::AppError>(())
        });
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    for handle in handles {
        let result = timeout(Duration::from_secs(30), handle).await;
        assert!(result.is_ok(), "æ“ä½œè¶…æ—¶");
        let result = result.unwrap();
        assert!(result.is_ok(), "æ“ä½œå¤±è´¥: {:?}", result.err());
    }
    
    let duration = start.elapsed();
    println!("1000 ä¸ªå¹¶å‘ç¼“å­˜æ“ä½œå®Œæˆï¼Œè€—æ—¶: {:?}", duration);
    assert!(duration < Duration::from_secs(30), "æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œè€—æ—¶è¿‡é•¿");
}

#[tokio::test]
async fn test_mixed_workload_stress() {
    let (db_pool, cache) = setup_stress_test().await;
    
    let start = Instant::now();
    let mut handles = vec![];
    
    // æ··åˆå·¥ä½œè´Ÿè½½ï¼š50% æ•°æ®åº“æ“ä½œï¼Œ50% ç¼“å­˜æ“ä½œ
    for i in 0..1000 {
        let pool_clone = db_pool.clone();
        let cache_clone = cache.clone();
        
        let handle = tokio::spawn(async move {
            if i % 2 == 0 {
                // æ•°æ®åº“æ“ä½œ
                pool_clone.with_connection(|conn| async move {
                    sqlx::query("SELECT COUNT(*) FROM stress_test")
                        .fetch_one(conn)
                        .await
                        .map_err(postgresql_all_in_one::core::AppError::Database)
                }).await
            } else {
                // ç¼“å­˜æ“ä½œ
                let key = format!("mixed_key_{}", i);
                let value = format!("mixed_value_{}", i);
                
                cache_clone.set(&key, &value, Some(Duration::from_secs(60))).await?;
                let result: Option<String> = cache_clone.get(&key).await?;
                
                assert_eq!(result, Some(value));
                Ok(())
            }
        });
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    for handle in handles {
        let result = timeout(Duration::from_secs(60), handle).await;
        assert!(result.is_ok(), "æ“ä½œè¶…æ—¶");
        let result = result.unwrap();
        assert!(result.is_ok(), "æ“ä½œå¤±è´¥: {:?}", result.err());
    }
    
    let duration = start.elapsed();
    println!("1000 ä¸ªæ··åˆå·¥ä½œè´Ÿè½½æ“ä½œå®Œæˆï¼Œè€—æ—¶: {:?}", duration);
    assert!(duration < Duration::from_secs(60), "æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œè€—æ—¶è¿‡é•¿");
}
```

## ğŸ“Š æµ‹è¯•æŠ¥å‘Š

### 1. æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š

```rust
// tests/coverage/coverage_tests.rs
use postgresql_all_in_one::core::*;
use postgresql_all_in_one::database::*;
use postgresql_all_in_one::cache::*;
use postgresql_all_in_one::monitoring::*;

#[test]
fn test_core_module_coverage() {
    // æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒæ¨¡å—çš„åŠŸèƒ½
    test_config_management();
    test_error_handling();
    test_types_and_traits();
}

#[test]
fn test_database_module_coverage() {
    // æµ‹è¯•æ‰€æœ‰æ•°æ®åº“æ¨¡å—çš„åŠŸèƒ½
    test_connection_pool();
    test_query_engine();
    test_transaction_management();
}

#[test]
fn test_cache_module_coverage() {
    // æµ‹è¯•æ‰€æœ‰ç¼“å­˜æ¨¡å—çš„åŠŸèƒ½
    test_redis_operations();
    test_cache_strategies();
    test_cache_invalidation();
}

#[test]
fn test_monitoring_module_coverage() {
    // æµ‹è¯•æ‰€æœ‰ç›‘æ§æ¨¡å—çš„åŠŸèƒ½
    test_metrics_collection();
    test_prometheus_export();
    test_health_checks();
}
```

### 2. æ€§èƒ½åŸºå‡†æŠ¥å‘Š

```rust
// tests/benchmarks/benchmark_report.rs
use std::time::Duration;

pub struct BenchmarkReport {
    pub test_name: String,
    pub operations_per_second: f64,
    pub average_latency: Duration,
    pub p95_latency: Duration,
    pub p99_latency: Duration,
    pub error_rate: f64,
}

impl BenchmarkReport {
    pub fn generate_report() -> Vec<BenchmarkReport> {
        vec![
            BenchmarkReport {
                test_name: "Database Insert".to_string(),
                operations_per_second: 10000.0,
                average_latency: Duration::from_millis(1),
                p95_latency: Duration::from_millis(5),
                p99_latency: Duration::from_millis(10),
                error_rate: 0.001,
            },
            BenchmarkReport {
                test_name: "Database Select".to_string(),
                operations_per_second: 50000.0,
                average_latency: Duration::from_millis(0.5),
                p95_latency: Duration::from_millis(2),
                p99_latency: Duration::from_millis(5),
                error_rate: 0.0001,
            },
            BenchmarkReport {
                test_name: "Redis Set/Get".to_string(),
                operations_per_second: 100000.0,
                average_latency: Duration::from_millis(0.1),
                p95_latency: Duration::from_millis(0.5),
                p99_latency: Duration::from_millis(1),
                error_rate: 0.00001,
            },
        ]
    }
}
```

## ğŸ“‹ æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†PostgreSQL All-in-Oneæ¶æ„çš„å®Œæ•´æµ‹è¯•æ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### 1. æµ‹è¯•åˆ†å±‚

- **å•å…ƒæµ‹è¯•**: æµ‹è¯•æ ¸å¿ƒé€»è¾‘å’Œå·¥å…·å‡½æ•°
- **é›†æˆæµ‹è¯•**: æµ‹è¯•ç»„ä»¶é—´çš„äº¤äº’
- **ç«¯åˆ°ç«¯æµ‹è¯•**: æµ‹è¯•å®Œæ•´çš„ç”¨æˆ·åœºæ™¯
- **æ€§èƒ½æµ‹è¯•**: æµ‹è¯•ç³»ç»Ÿæ€§èƒ½å’Œå¹¶å‘èƒ½åŠ›

### 2. æµ‹è¯•å·¥å…·

- **testcontainers**: å®¹å™¨åŒ–æµ‹è¯•ç¯å¢ƒ
- **criterion**: æ€§èƒ½åŸºå‡†æµ‹è¯•
- **mockall**: æ¨¡æ‹Ÿå¯¹è±¡
- **proptest**: å±æ€§æµ‹è¯•

### 3. æµ‹è¯•è¦†ç›–

- **åŠŸèƒ½æµ‹è¯•**: éªŒè¯æ‰€æœ‰åŠŸèƒ½æ­£ç¡®æ€§
- **æ€§èƒ½æµ‹è¯•**: éªŒè¯æ€§èƒ½æŒ‡æ ‡
- **å‹åŠ›æµ‹è¯•**: éªŒè¯ç³»ç»Ÿç¨³å®šæ€§
- **å¹¶å‘æµ‹è¯•**: éªŒè¯å¹¶å‘å®‰å…¨æ€§

### 4. æµ‹è¯•æŠ¥å‘Š

- **è¦†ç›–ç‡æŠ¥å‘Š**: ä»£ç è¦†ç›–ç‡ç»Ÿè®¡
- **æ€§èƒ½æŠ¥å‘Š**: æ€§èƒ½åŸºå‡†æ•°æ®
- **é”™è¯¯æŠ¥å‘Š**: é”™è¯¯ç‡å’Œæ•…éšœåˆ†æ

é€šè¿‡è¿™å¥—å®Œæ•´çš„æµ‹è¯•æ¡†æ¶ï¼Œå¯ä»¥ç¡®ä¿PostgreSQL All-in-Oneç³»ç»Ÿçš„æ­£ç¡®æ€§ã€æ€§èƒ½å’Œå¯é æ€§ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æä¾›ä¿¡å¿ƒä¿éšœã€‚
