# Rustå®ç°æŒ‡å—

## ğŸ“‹ ç›®å½•

- [Rustå®ç°æŒ‡å—](#rustå®ç°æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
  - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
    - [1. æ•´ä½“æ¶æ„](#1-æ•´ä½“æ¶æ„)
    - [2. æ¨¡å—åŒ–è®¾è®¡](#2-æ¨¡å—åŒ–è®¾è®¡)
  - [æ ¸å¿ƒç»„ä»¶å®ç°](#æ ¸å¿ƒç»„ä»¶å®ç°)
    - [1. æ•°æ®æ”¶é›†å™¨](#1-æ•°æ®æ”¶é›†å™¨)
    - [2. æ•°æ®å¤„ç†å™¨](#2-æ•°æ®å¤„ç†å™¨)
    - [3. æ•°æ®å¯¼å‡ºå™¨](#3-æ•°æ®å¯¼å‡ºå™¨)
  - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
    - [1. å†…å­˜ä¼˜åŒ–](#1-å†…å­˜ä¼˜åŒ–)
    - [2. å¹¶å‘ä¼˜åŒ–](#2-å¹¶å‘ä¼˜åŒ–)
    - [3. ç½‘ç»œä¼˜åŒ–](#3-ç½‘ç»œä¼˜åŒ–)
  - [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
    - [1. é”™è¯¯ç±»å‹å®šä¹‰](#1-é”™è¯¯ç±»å‹å®šä¹‰)
    - [2. é”™è¯¯æ¢å¤æœºåˆ¶](#2-é”™è¯¯æ¢å¤æœºåˆ¶)
  - [æµ‹è¯•ç­–ç•¥](#æµ‹è¯•ç­–ç•¥)
    - [1. å•å…ƒæµ‹è¯•](#1-å•å…ƒæµ‹è¯•)
    - [2. é›†æˆæµ‹è¯•](#2-é›†æˆæµ‹è¯•)
    - [3. åŸºå‡†æµ‹è¯•](#3-åŸºå‡†æµ‹è¯•)
  - [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
    - [1. é…ç½®ç»“æ„](#1-é…ç½®ç»“æ„)
  - [æ€»ç»“](#æ€»ç»“)

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›OTLPé¡¹ç›®çš„Rustå®ç°æŒ‡å—ï¼ŒåŒ…æ‹¬æ¶æ„è®¾è®¡ã€æ ¸å¿ƒç»„ä»¶å®ç°ã€æ€§èƒ½ä¼˜åŒ–ã€æµ‹è¯•ç­–ç•¥ç­‰å…³é”®æŠ€æœ¯è¦ç‚¹ï¼Œä¸ºå¼€å‘è€…æä¾›è¯¦ç»†çš„å®ç°å‚è€ƒã€‚

## æ¶æ„è®¾è®¡

### 1. æ•´ä½“æ¶æ„

```rust
// æ ¸å¿ƒæ¶æ„ç»„ä»¶
pub struct OTLPCore {
    pub collector: DataCollector,
    pub processor: DataProcessor,
    pub exporter: DataExporter,
    pub config_manager: ConfigManager,
    pub metrics_registry: MetricsRegistry,
}

pub struct DataCollector {
    pub trace_collector: TraceCollector,
    pub metric_collector: MetricCollector,
    pub log_collector: LogCollector,
    pub resource_detector: ResourceDetector,
}

pub struct DataProcessor {
    pub batch_processor: BatchProcessor,
    pub attribute_processor: AttributeProcessor,
    pub sampling_processor: SamplingProcessor,
    pub filter_processor: FilterProcessor,
}

pub struct DataExporter {
    pub otlp_exporter: OTLPExporter,
    pub jaeger_exporter: JaegerExporter,
    pub prometheus_exporter: PrometheusExporter,
    pub console_exporter: ConsoleExporter,
}
```

### 2. æ¨¡å—åŒ–è®¾è®¡

```rust
// æ¨¡å—åŒ–æ¶æ„
pub mod core {
    pub mod collector;
    pub mod processor;
    pub mod exporter;
    pub mod resource;
}

pub mod protocols {
    pub mod otlp;
    pub mod jaeger;
    pub mod prometheus;
    pub mod zipkin;
}

pub mod utils {
    pub mod config;
    pub mod metrics;
    pub mod logging;
    pub mod error;
}

pub mod extensions {
    pub mod sampling;
    pub mod filtering;
    pub mod transformation;
    pub mod enrichment;
}
```

## æ ¸å¿ƒç»„ä»¶å®ç°

### 1. æ•°æ®æ”¶é›†å™¨

```rust
use tokio::sync::{mpsc, RwLock};
use std::sync::Arc;
use std::time::{Duration, Instant};

pub struct TraceCollector {
    pub spans: Arc<RwLock<Vec<Span>>>,
    pub sender: mpsc::UnboundedSender<Span>,
    pub receiver: Arc<RwLock<mpsc::UnboundedReceiver<Span>>>,
    pub config: CollectorConfig,
}

impl TraceCollector {
    pub fn new(config: CollectorConfig) -> Self {
        let (sender, receiver) = mpsc::unbounded_channel();
        
        Self {
            spans: Arc::new(RwLock::new(Vec::new())),
            sender,
            receiver: Arc::new(RwLock::new(receiver)),
            config,
        }
    }
    
    pub async fn collect_span(&self, span: Span) -> Result<(), CollectionError> {
        // éªŒè¯spanæ•°æ®
        self.validate_span(&span)?;
        
        // å‘é€åˆ°å¤„ç†é˜Ÿåˆ—
        self.sender.send(span).map_err(|e| {
            CollectionError::SendError(e.to_string())
        })?;
        
        Ok(())
    }
    
    pub async fn start_collection(&self) -> Result<(), CollectionError> {
        let receiver = self.receiver.clone();
        let spans = self.spans.clone();
        let config = self.config.clone();
        
        tokio::spawn(async move {
            let mut receiver = receiver.write().await;
            let mut batch = Vec::new();
            let mut last_flush = Instant::now();
            
            while let Some(span) = receiver.recv().await {
                batch.push(span);
                
                // æ£€æŸ¥æ‰¹é‡å¤§å°æˆ–æ—¶é—´é—´éš”
                if batch.len() >= config.batch_size 
                   || last_flush.elapsed() >= config.flush_interval {
                    
                    // æ‰¹é‡å¤„ç†spans
                    let mut spans_guard = spans.write().await;
                    spans_guard.extend(batch.drain(..));
                    drop(spans_guard);
                    
                    last_flush = Instant::now();
                }
            }
        });
        
        Ok(())
    }
    
    fn validate_span(&self, span: &Span) -> Result<(), ValidationError> {
        if span.trace_id.is_empty() {
            return Err(ValidationError::MissingTraceId);
        }
        
        if span.span_id.is_empty() {
            return Err(ValidationError::MissingSpanId);
        }
        
        if span.name.is_empty() {
            return Err(ValidationError::MissingSpanName);
        }
        
        Ok(())
    }
}
```

### 2. æ•°æ®å¤„ç†å™¨

```rust
use async_trait::async_trait;

#[async_trait]
pub trait Processor: Send + Sync {
    async fn process(&self, data: &mut TelemetryData) -> Result<(), ProcessingError>;
    async fn shutdown(&self) -> Result<(), ProcessingError>;
}

pub struct BatchProcessor {
    pub batch_size: usize,
    pub timeout: Duration,
    pub buffer: Arc<RwLock<Vec<TelemetryData>>>,
    pub sender: mpsc::UnboundedSender<Vec<TelemetryData>>,
}

#[async_trait]
impl Processor for BatchProcessor {
    async fn process(&self, data: &mut TelemetryData) -> Result<(), ProcessingError> {
        let mut buffer = self.buffer.write().await;
        buffer.push(data.clone());
        
        if buffer.len() >= self.batch_size {
            let batch = buffer.drain(..).collect();
            self.sender.send(batch).map_err(|e| {
                ProcessingError::SendError(e.to_string())
            })?;
        }
        
        Ok(())
    }
    
    async fn shutdown(&self) -> Result<(), ProcessingError> {
        let mut buffer = self.buffer.write().await;
        if !buffer.is_empty() {
            let batch = buffer.drain(..).collect();
            self.sender.send(batch).map_err(|e| {
                ProcessingError::SendError(e.to_string())
            })?;
        }
        
        Ok(())
    }
}

pub struct AttributeProcessor {
    pub actions: Vec<AttributeAction>,
}

#[async_trait]
impl Processor for AttributeProcessor {
    async fn process(&self, data: &mut TelemetryData) -> Result<(), ProcessingError> {
        for action in &self.actions {
            match action {
                AttributeAction::Insert { key, value } => {
                    data.attributes.insert(key.clone(), value.clone());
                },
                AttributeAction::Update { key, value } => {
                    if data.attributes.contains_key(key) {
                        data.attributes.insert(key.clone(), value.clone());
                    }
                },
                AttributeAction::Upsert { key, value } => {
                    data.attributes.insert(key.clone(), value.clone());
                },
                AttributeAction::Delete { key } => {
                    data.attributes.remove(key);
                },
                AttributeAction::Hash { key } => {
                    if let Some(value) = data.attributes.get(key) {
                        let hashed = self.hash_value(value);
                        data.attributes.insert(key.clone(), hashed);
                    }
                },
            }
        }
        
        Ok(())
    }
    
    async fn shutdown(&self) -> Result<(), ProcessingError> {
        Ok(())
    }
}

impl AttributeProcessor {
    fn hash_value(&self, value: &AttributeValue) -> AttributeValue {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        value.hash(&mut hasher);
        let hash = hasher.finish();
        
        AttributeValue::String(format!("hash_{}", hash))
    }
}
```

### 3. æ•°æ®å¯¼å‡ºå™¨

```rust
use reqwest::Client;
use prost::Message;

pub struct OTLPExporter {
    pub client: Client,
    pub endpoint: String,
    pub headers: HashMap<String, String>,
    pub timeout: Duration,
    pub compression: CompressionType,
}

impl OTLPExporter {
    pub fn new(config: ExporterConfig) -> Self {
        let client = Client::builder()
            .timeout(config.timeout)
            .build()
            .expect("Failed to create HTTP client");
        
        Self {
            client,
            endpoint: config.endpoint,
            headers: config.headers,
            timeout: config.timeout,
            compression: config.compression,
        }
    }
    
    pub async fn export_traces(&self, spans: Vec<Span>) -> Result<(), ExportError> {
        // è½¬æ¢ä¸ºOTLPæ ¼å¼
        let otlp_spans = self.convert_to_otlp_spans(spans)?;
        
        // åºåˆ—åŒ–
        let mut buffer = Vec::new();
        otlp_spans.encode(&mut buffer).map_err(|e| {
            ExportError::SerializationError(e.to_string())
        })?;
        
        // å‹ç¼©
        let compressed_data = self.compress_data(&buffer)?;
        
        // å‘é€HTTPè¯·æ±‚
        let mut request = self.client
            .post(&format!("{}/v1/traces", self.endpoint))
            .body(compressed_data);
        
        for (key, value) in &self.headers {
            request = request.header(key, value);
        }
        
        match self.compression {
            CompressionType::Gzip => {
                request = request.header("Content-Encoding", "gzip");
            },
            CompressionType::None => {},
        }
        
        let response = request.send().await.map_err(|e| {
            ExportError::NetworkError(e.to_string())
        })?;
        
        if !response.status().is_success() {
            return Err(ExportError::HttpError(response.status().as_u16()));
        }
        
        Ok(())
    }
    
    fn convert_to_otlp_spans(&self, spans: Vec<Span>) -> Result<otlp::TracesData, ConversionError> {
        let mut resource_spans = HashMap::new();
        
        for span in spans {
            let resource_key = self.get_resource_key(&span.resource);
            let resource_span_list = resource_spans
                .entry(resource_key)
                .or_insert_with(Vec::new);
            
            resource_span_list.push(self.convert_span_to_otlp(span)?);
        }
        
        let mut traces_data = otlp::TracesData::default();
        
        for (resource, spans) in resource_spans {
            let mut resource_spans = otlp::ResourceSpans::default();
            resource_spans.resource = Some(resource);
            
            let mut scope_spans = otlp::ScopeSpans::default();
            scope_spans.spans = spans;
            
            resource_spans.scope_spans = vec![scope_spans];
            traces_data.resource_spans.push(resource_spans);
        }
        
        Ok(traces_data)
    }
    
    fn compress_data(&self, data: &[u8]) -> Result<Vec<u8>, CompressionError> {
        match self.compression {
            CompressionType::Gzip => {
                use flate2::write::GzEncoder;
                use flate2::Compression;
                use std::io::Write;
                
                let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
                encoder.write_all(data).map_err(|e| {
                    CompressionError::CompressionFailed(e.to_string())
                })?;
                
                encoder.finish().map_err(|e| {
                    CompressionError::CompressionFailed(e.to_string())
                })
            },
            CompressionType::None => Ok(data.to_vec()),
        }
    }
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–

```rust
use std::sync::Arc;
use parking_lot::RwLock;
use crossbeam::queue::SegQueue;

pub struct MemoryOptimizedCollector {
    pub span_pool: Arc<SpanPool>,
    pub buffer_pool: Arc<BufferPool>,
    pub queue: Arc<SegQueue<Arc<Span>>>,
}

pub struct SpanPool {
    pub pool: SegQueue<Box<Span>>,
    pub max_size: usize,
    pub current_size: AtomicUsize,
}

impl SpanPool {
    pub fn new(max_size: usize) -> Self {
        Self {
            pool: SegQueue::new(),
            max_size,
            current_size: AtomicUsize::new(0),
        }
    }
    
    pub fn get_span(&self) -> Box<Span> {
        if let Some(span) = self.pool.pop() {
            // é‡ç½®spanæ•°æ®
            self.reset_span(&mut *span);
            span
        } else {
            Box::new(Span::default())
        }
    }
    
    pub fn return_span(&self, mut span: Box<Span>) {
        if self.current_size.load(Ordering::Relaxed) < self.max_size {
            // æ¸…ç†spanæ•°æ®
            self.clear_span(&mut *span);
            self.pool.push(span);
        }
        // å¦‚æœæ± å·²æ»¡ï¼Œè®©spanè‡ªåŠ¨é‡Šæ”¾
    }
    
    fn reset_span(&self, span: &mut Span) {
        span.trace_id.clear();
        span.span_id.clear();
        span.name.clear();
        span.attributes.clear();
        span.events.clear();
        span.links.clear();
    }
    
    fn clear_span(&self, span: &mut Span) {
        span.trace_id.clear();
        span.span_id.clear();
        span.name.clear();
        span.attributes.clear();
        span.events.clear();
        span.links.clear();
    }
}
```

### 2. å¹¶å‘ä¼˜åŒ–

```rust
use tokio::sync::Semaphore;
use std::sync::atomic::{AtomicU64, Ordering};

pub struct ConcurrentProcessor {
    pub semaphore: Arc<Semaphore>,
    pub worker_count: usize,
    pub processed_count: AtomicU64,
    pub error_count: AtomicU64,
}

impl ConcurrentProcessor {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
            worker_count: max_concurrent,
            processed_count: AtomicU64::new(0),
            error_count: AtomicU64::new(0),
        }
    }
    
    pub async fn process_batch(&self, batch: Vec<TelemetryData>) -> Result<(), ProcessingError> {
        let chunk_size = (batch.len() + self.worker_count - 1) / self.worker_count;
        let chunks: Vec<_> = batch.chunks(chunk_size).collect();
        
        let mut tasks = Vec::new();
        
        for chunk in chunks {
            let chunk = chunk.to_vec();
            let semaphore = self.semaphore.clone();
            let processed_count = &self.processed_count;
            let error_count = &self.error_count;
            
            let task = tokio::spawn(async move {
                let _permit = semaphore.acquire().await.unwrap();
                
                for data in chunk {
                    match Self::process_single_data(data).await {
                        Ok(_) => {
                            processed_count.fetch_add(1, Ordering::Relaxed);
                        },
                        Err(_) => {
                            error_count.fetch_add(1, Ordering::Relaxed);
                        }
                    }
                }
            });
            
            tasks.push(task);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for task in tasks {
            task.await.map_err(|e| {
                ProcessingError::TaskError(e.to_string())
            })?;
        }
        
        Ok(())
    }
    
    async fn process_single_data(data: TelemetryData) -> Result<(), ProcessingError> {
        // å¤„ç†å•ä¸ªæ•°æ®é¡¹
        tokio::time::sleep(Duration::from_millis(1)).await;
        Ok(())
    }
}
```

### 3. ç½‘ç»œä¼˜åŒ–

```rust
use tokio::net::TcpStream;
use tokio_util::codec::{Framed, LengthDelimitedCodec};
use futures::{SinkExt, StreamExt};

pub struct OptimizedNetworkExporter {
    pub connection_pool: ConnectionPool,
    pub retry_policy: RetryPolicy,
    pub circuit_breaker: CircuitBreaker,
}

pub struct ConnectionPool {
    pub connections: Arc<RwLock<Vec<Connection>>>,
    pub max_connections: usize,
    pub idle_timeout: Duration,
}

impl ConnectionPool {
    pub async fn get_connection(&self, endpoint: &str) -> Result<Connection, NetworkError> {
        // å°è¯•è·å–ç©ºé—²è¿æ¥
        {
            let mut connections = self.connections.write().await;
            for (i, conn) in connections.iter().enumerate() {
                if conn.endpoint == endpoint && conn.is_idle() {
                    return Ok(connections.remove(i));
                }
            }
        }
        
        // åˆ›å»ºæ–°è¿æ¥
        self.create_connection(endpoint).await
    }
    
    pub async fn return_connection(&self, connection: Connection) {
        let mut connections = self.connections.write().await;
        if connections.len() < self.max_connections {
            connections.push(connection);
        }
        // å¦‚æœæ± å·²æ»¡ï¼Œè¿æ¥ä¼šè‡ªåŠ¨å…³é—­
    }
    
    async fn create_connection(&self, endpoint: &str) -> Result<Connection, NetworkError> {
        let stream = TcpStream::connect(endpoint).await.map_err(|e| {
            NetworkError::ConnectionFailed(e.to_string())
        })?;
        
        let framed = Framed::new(stream, LengthDelimitedCodec::new());
        
        Ok(Connection {
            endpoint: endpoint.to_string(),
            framed: Arc::new(RwLock::new(framed)),
            last_used: Instant::now(),
        })
    }
}

pub struct Connection {
    pub endpoint: String,
    pub framed: Arc<RwLock<Framed<TcpStream, LengthDelimitedCodec>>>,
    pub last_used: Instant,
}

impl Connection {
    pub fn is_idle(&self) -> bool {
        self.last_used.elapsed() < Duration::from_secs(30)
    }
    
    pub async fn send_data(&mut self, data: &[u8]) -> Result<(), NetworkError> {
        let mut framed = self.framed.write().await;
        framed.send(data.into()).await.map_err(|e| {
            NetworkError::SendFailed(e.to_string())
        })?;
        
        self.last_used = Instant::now();
        Ok(())
    }
}
```

## é”™è¯¯å¤„ç†

### 1. é”™è¯¯ç±»å‹å®šä¹‰

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum OTLPError {
    #[error("Collection error: {0}")]
    Collection(#[from] CollectionError),
    
    #[error("Processing error: {0}")]
    Processing(#[from] ProcessingError),
    
    #[error("Export error: {0}")]
    Export(#[from] ExportError),
    
    #[error("Configuration error: {0}")]
    Configuration(#[from] ConfigurationError),
    
    #[error("Network error: {0}")]
    Network(#[from] NetworkError),
}

#[derive(Error, Debug)]
pub enum CollectionError {
    #[error("Validation failed: {0}")]
    Validation(#[from] ValidationError),
    
    #[error("Send error: {0}")]
    SendError(String),
    
    #[error("Buffer overflow")]
    BufferOverflow,
    
    #[error("Resource detection failed: {0}")]
    ResourceDetection(String),
}

#[derive(Error, Debug)]
pub enum ProcessingError {
    #[error("Transformation failed: {0}")]
    Transformation(String),
    
    #[error("Filtering failed: {0}")]
    Filtering(String),
    
    #[error("Batching failed: {0}")]
    Batching(String),
    
    #[error("Task error: {0}")]
    TaskError(String),
}

#[derive(Error, Debug)]
pub enum ExportError {
    #[error("Serialization error: {0}")]
    SerializationError(String),
    
    #[error("Compression error: {0}")]
    CompressionError(String),
    
    #[error("Network error: {0}")]
    NetworkError(String),
    
    #[error("HTTP error: {0}")]
    HttpError(u16),
    
    #[error("Authentication failed")]
    AuthenticationFailed,
}
```

### 2. é”™è¯¯æ¢å¤æœºåˆ¶

```rust
use std::sync::atomic::{AtomicU32, Ordering};

pub struct ErrorRecoveryManager {
    pub retry_policy: RetryPolicy,
    pub circuit_breaker: CircuitBreaker,
    pub fallback_exporter: Option<Box<dyn Exporter>>,
    pub error_metrics: ErrorMetrics,
}

pub struct RetryPolicy {
    pub max_attempts: u32,
    pub base_delay: Duration,
    pub max_delay: Duration,
    pub backoff_multiplier: f64,
}

impl RetryPolicy {
    pub async fn execute_with_retry<F, T, E>(&self, mut operation: F) -> Result<T, E>
    where
        F: FnMut() -> Result<T, E>,
        E: std::fmt::Debug,
    {
        let mut attempt = 0;
        let mut delay = self.base_delay;
        
        loop {
            attempt += 1;
            
            match operation() {
                Ok(result) => return Ok(result),
                Err(error) => {
                    if attempt >= self.max_attempts {
                        return Err(error);
                    }
                    
                    // ç­‰å¾…é‡è¯•
                    tokio::time::sleep(delay).await;
                    
                    // è®¡ç®—ä¸‹æ¬¡é‡è¯•å»¶è¿Ÿ
                    delay = std::cmp::min(
                        Duration::from_millis(
                            (delay.as_millis() as f64 * self.backoff_multiplier) as u64
                        ),
                        self.max_delay
                    );
                }
            }
        }
    }
}

pub struct CircuitBreaker {
    pub failure_threshold: u32,
    pub recovery_timeout: Duration,
    pub failure_count: AtomicU32,
    pub last_failure_time: Arc<RwLock<Option<Instant>>>,
    pub state: Arc<RwLock<CircuitBreakerState>>,
}

#[derive(Debug, Clone, PartialEq)]
pub enum CircuitBreakerState {
    Closed,
    Open,
    HalfOpen,
}

impl CircuitBreaker {
    pub async fn execute<F, T, E>(&self, operation: F) -> Result<T, CircuitBreakerError<E>>
    where
        F: FnOnce() -> Result<T, E>,
    {
        // æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
        let state = {
            let state_guard = self.state.read().await;
            state_guard.clone()
        };
        
        match state {
            CircuitBreakerState::Open => {
                // æ£€æŸ¥æ˜¯å¦å¯ä»¥å°è¯•æ¢å¤
                let last_failure = self.last_failure_time.read().await;
                if let Some(last_failure_time) = *last_failure {
                    if last_failure_time.elapsed() >= self.recovery_timeout {
                        // è½¬æ¢åˆ°åŠå¼€çŠ¶æ€
                        *self.state.write().await = CircuitBreakerState::HalfOpen;
                    } else {
                        return Err(CircuitBreakerError::CircuitOpen);
                    }
                }
            },
            CircuitBreakerState::HalfOpen => {
                // åŠå¼€çŠ¶æ€ï¼Œå…è®¸ä¸€æ¬¡å°è¯•
            },
            CircuitBreakerState::Closed => {
                // æ­£å¸¸çŠ¶æ€
            },
        }
        
        // æ‰§è¡Œæ“ä½œ
        match operation() {
            Ok(result) => {
                // æ“ä½œæˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                self.failure_count.store(0, Ordering::Relaxed);
                *self.state.write().await = CircuitBreakerState::Closed;
                Ok(result)
            },
            Err(error) => {
                // æ“ä½œå¤±è´¥ï¼Œå¢åŠ å¤±è´¥è®¡æ•°
                let failures = self.failure_count.fetch_add(1, Ordering::Relaxed) + 1;
                *self.last_failure_time.write().await = Some(Instant::now());
                
                if failures >= self.failure_threshold {
                    *self.state.write().await = CircuitBreakerState::Open;
                }
                
                Err(CircuitBreakerError::OperationFailed(error))
            }
        }
    }
}

#[derive(Error, Debug)]
pub enum CircuitBreakerError<E> {
    #[error("Circuit breaker is open")]
    CircuitOpen,
    
    #[error("Operation failed: {0:?}")]
    OperationFailed(E),
}
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    
    #[tokio::test]
    async fn test_trace_collector_basic_functionality() {
        let config = CollectorConfig::default();
        let collector = TraceCollector::new(config);
        
        let span = Span {
            trace_id: "test_trace_id".to_string(),
            span_id: "test_span_id".to_string(),
            name: "test_span".to_string(),
            ..Default::default()
        };
        
        let result = collector.collect_span(span).await;
        assert!(result.is_ok());
    }
    
    #[tokio::test]
    async fn test_batch_processor_batching() {
        let processor = BatchProcessor {
            batch_size: 3,
            timeout: Duration::from_secs(1),
            buffer: Arc::new(RwLock::new(Vec::new())),
            sender: mpsc::unbounded_channel().0,
        };
        
        // æ·»åŠ æ•°æ®åˆ°æ‰¹å¤„ç†å™¨
        for i in 0..5 {
            let mut data = TelemetryData::default();
            data.attributes.insert("index".to_string(), AttributeValue::Int(i));
            
            let result = processor.process(&mut data).await;
            assert!(result.is_ok());
        }
        
        // éªŒè¯æ‰¹å¤„ç†è¡Œä¸º
        let buffer = processor.buffer.read().await;
        assert_eq!(buffer.len(), 2); // 3ä¸ªå·²å‘é€ï¼Œ2ä¸ªåœ¨ç¼“å†²åŒº
    }
    
    #[tokio::test]
    async fn test_otlp_exporter_serialization() {
        let config = ExporterConfig {
            endpoint: "http://localhost:4317".to_string(),
            timeout: Duration::from_secs(10),
            compression: CompressionType::None,
            headers: HashMap::new(),
        };
        
        let exporter = OTLPExporter::new(config);
        
        let spans = vec![
            Span {
                trace_id: "trace1".to_string(),
                span_id: "span1".to_string(),
                name: "test_span".to_string(),
                ..Default::default()
            }
        ];
        
        let otlp_spans = exporter.convert_to_otlp_spans(spans);
        assert!(otlp_spans.is_ok());
        
        let otlp_data = otlp_spans.unwrap();
        assert_eq!(otlp_data.resource_spans.len(), 1);
    }
}
```

### 2. é›†æˆæµ‹è¯•

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;
    use testcontainers::*;
    
    #[tokio::test]
    async fn test_end_to_end_trace_flow() {
        // å¯åŠ¨æµ‹è¯•å®¹å™¨
        let docker = clients::Cli::default();
        let jaeger = docker.run(images::generic::GenericImage::new("jaegertracing/all-in-one", "latest"));
        
        let jaeger_port = jaeger.get_host_port_ipv4(14268);
        
        // é…ç½®OTLPç³»ç»Ÿ
        let config = OTLPConfig {
            collector: CollectorConfig::default(),
            processor: ProcessorConfig::default(),
            exporter: ExporterConfig {
                endpoint: format!("http://localhost:{}", jaeger_port),
                timeout: Duration::from_secs(10),
                compression: CompressionType::None,
                headers: HashMap::new(),
            },
        };
        
        let otlp_core = OTLPCore::new(config).await.unwrap();
        
        // åˆ›å»ºæµ‹è¯•span
        let span = Span {
            trace_id: "integration_test_trace".to_string(),
            span_id: "integration_test_span".to_string(),
            name: "integration_test".to_string(),
            start_time: SystemTime::now(),
            end_time: SystemTime::now() + Duration::from_millis(100),
            ..Default::default()
        };
        
        // å‘é€span
        otlp_core.collector.collect_span(span).await.unwrap();
        
        // ç­‰å¾…å¤„ç†å®Œæˆ
        tokio::time::sleep(Duration::from_secs(2)).await;
        
        // éªŒè¯æ•°æ®å·²å‘é€åˆ°Jaeger
        // è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹Jaeger APIçš„æŸ¥è¯¢æ¥éªŒè¯æ•°æ®
    }
    
    #[tokio::test]
    async fn test_high_throughput_performance() {
        let config = OTLPConfig::default();
        let otlp_core = OTLPCore::new(config).await.unwrap();
        
        let start_time = Instant::now();
        let span_count = 10000;
        
        // å¹¶å‘å‘é€å¤§é‡span
        let mut tasks = Vec::new();
        for i in 0..span_count {
            let collector = otlp_core.collector.clone();
            let task = tokio::spawn(async move {
                let span = Span {
                    trace_id: format!("trace_{}", i),
                    span_id: format!("span_{}", i),
                    name: format!("test_span_{}", i),
                    ..Default::default()
                };
                
                collector.collect_span(span).await
            });
            tasks.push(task);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for task in tasks {
            task.await.unwrap().unwrap();
        }
        
        let elapsed = start_time.elapsed();
        let throughput = span_count as f64 / elapsed.as_secs_f64();
        
        println!("Processed {} spans in {:?}, throughput: {:.2} spans/sec", 
                 span_count, elapsed, throughput);
        
        // éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert!(throughput > 1000.0, "Throughput should be > 1000 spans/sec");
    }
}
```

### 3. åŸºå‡†æµ‹è¯•

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_span_creation(c: &mut Criterion) {
    c.bench_function("span_creation", |b| {
        b.iter(|| {
            let span = Span {
                trace_id: black_box("test_trace_id".to_string()),
                span_id: black_box("test_span_id".to_string()),
                name: black_box("test_span".to_string()),
                ..Default::default()
            };
            black_box(span)
        })
    });
}

fn benchmark_attribute_processing(c: &mut Criterion) {
    let processor = AttributeProcessor {
        actions: vec![
            AttributeAction::Insert {
                key: "test_key".to_string(),
                value: AttributeValue::String("test_value".to_string()),
            },
            AttributeAction::Hash {
                key: "sensitive_data".to_string(),
            },
        ],
    };
    
    c.bench_function("attribute_processing", |b| {
        b.iter(|| {
            let mut data = TelemetryData {
                attributes: {
                    let mut attrs = HashMap::new();
                    attrs.insert("sensitive_data".to_string(), 
                               AttributeValue::String("secret_value".to_string()));
                    attrs
                },
                ..Default::default()
            };
            
            tokio_test::block_on(async {
                processor.process(black_box(&mut data)).await
            })
        })
    });
}

fn benchmark_batch_processing(c: &mut Criterion) {
    let (sender, _receiver) = mpsc::unbounded_channel();
    let processor = BatchProcessor {
        batch_size: 100,
        timeout: Duration::from_secs(1),
        buffer: Arc::new(RwLock::new(Vec::new())),
        sender,
    };
    
    c.bench_function("batch_processing", |b| {
        b.iter(|| {
            let mut data = TelemetryData::default();
            tokio_test::block_on(async {
                processor.process(black_box(&mut data)).await
            })
        })
    });
}

criterion_group!(benches, 
    benchmark_span_creation,
    benchmark_attribute_processing,
    benchmark_batch_processing
);
criterion_main!(benches);
```

## é…ç½®ç®¡ç†

### 1. é…ç½®ç»“æ„

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OTLPConfig {
    pub collector: CollectorConfig,
    pub processor: ProcessorConfig,
    pub exporter: ExporterConfig,
    pub resource: ResourceConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollectorConfig {
    pub batch_size: usize,
    pub flush_interval: Duration,
    pub max_queue_size: usize,
    pub timeout: Duration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessorConfig {
    pub processors: Vec<ProcessorType>,
    pub batch_processor: BatchProcessorConfig,
    pub attribute_processor: AttributeProcessorConfig,
    pub sampling_processor: SamplingProcessorConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExporterConfig {
    pub endpoint: String,
    pub timeout: Duration,
    pub compression: CompressionType,
    pub headers: HashMap<String, String>,
    pub retry_policy: RetryPolicyConfig,
}

impl Default for OTLPConfig {
    fn default() -> Self {
        Self {
            collector: CollectorConfig::default(),
            processor: ProcessorConfig::default(),
            exporter: ExporterConfig::default(),
            resource: ResourceConfig::default(),
            logging: LoggingConfig::default(),
        }
    }
}

impl OTLPConfig {
    pub fn from_file(path: &str) -> Result<Self, ConfigError> {
        let content = std::fs::read_to_string(path)
            .map_err(|e| ConfigError::FileReadError(e.to_string()))?;
        
        let config: OTLPConfig = toml::from_str(&content)
            .map_err(|e| ConfigError::ParseError(e.to_string()))?;
        
        config.validate()?;
        Ok(config)
    }
    
    pub fn from_env() -> Result<Self, ConfigError> {
        let mut config = Self::default();
        
        if let Ok(endpoint) = std::env::var("OTLP_EXPORTER_ENDPOINT") {
            config.exporter.endpoint = endpoint;
        }
        
        if let Ok(timeout) = std::env::var("OTLP_EXPORTER_TIMEOUT") {
            let timeout_secs: u64 = timeout.parse()
                .map_err(|e| ConfigError::ParseError(e.to_string()))?;
            config.exporter.timeout = Duration::from_secs(timeout_secs);
        }
        
        if let Ok(batch_size) = std::env::var("OTLP_BATCH_SIZE") {
            config.collector.batch_size = batch_size.parse()
                .map_err(|e| ConfigError::ParseError(e.to_string()))?;
        }
        
        config.validate()?;
        Ok(config)
    }
    
    fn validate(&self) -> Result<(), ConfigError> {
        if self.collector.batch_size == 0 {
            return Err(ConfigError::ValidationError(
                "Batch size must be greater than 0".to_string()
            ));
        }
        
        if self.exporter.endpoint.is_empty() {
            return Err(ConfigError::ValidationError(
                "Exporter endpoint cannot be empty".to_string()
            ));
        }
        
        if self.exporter.timeout.as_secs() == 0 {
            return Err(ConfigError::ValidationError(
                "Exporter timeout must be greater than 0".to_string()
            ));
        }
        
        Ok(())
    }
}
```

## æ€»ç»“

æœ¬Rustå®ç°æŒ‡å—æä¾›äº†OTLPé¡¹ç›®çš„å®Œæ•´å®ç°æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼š

1. **æ¶æ„è®¾è®¡**: æ¨¡å—åŒ–ã€å¯æ‰©å±•çš„ç³»ç»Ÿæ¶æ„
2. **æ ¸å¿ƒç»„ä»¶**: æ•°æ®æ”¶é›†ã€å¤„ç†ã€å¯¼å‡ºçš„å®Œæ•´å®ç°
3. **æ€§èƒ½ä¼˜åŒ–**: å†…å­˜ã€å¹¶å‘ã€ç½‘ç»œç­‰å¤šæ–¹é¢ä¼˜åŒ–
4. **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯ç±»å‹å’Œæ¢å¤æœºåˆ¶
5. **æµ‹è¯•ç­–ç•¥**: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€åŸºå‡†æµ‹è¯•
6. **é…ç½®ç®¡ç†**: çµæ´»çš„é…ç½®ç³»ç»Ÿ

è¿™äº›å®ç°ä¸ºå¼€å‘é«˜æ€§èƒ½ã€å¯é çš„OTLPç³»ç»Ÿæä¾›äº†åšå®çš„åŸºç¡€ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„ç¨³å®šè¿è¡Œã€‚
