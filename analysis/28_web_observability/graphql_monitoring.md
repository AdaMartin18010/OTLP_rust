# GraphQL ç›‘æ§ - GraphQL Monitoring

**åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ29æ—¥  
**é€‚ç”¨æ¡†æ¶**: async-graphql, juniper  
**çŠ¶æ€**: âœ… ç”Ÿäº§éªŒè¯

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [GraphQLè¿½è¸ªåŸºç¡€](#graphqlè¿½è¸ªåŸºç¡€)
- [æŸ¥è¯¢ç›‘æ§](#æŸ¥è¯¢ç›‘æ§)
- [è§£æå™¨è¿½è¸ª](#è§£æå™¨è¿½è¸ª)
- [N+1é—®é¢˜æ£€æµ‹](#n1é—®é¢˜æ£€æµ‹)
- [DataLoaderç›‘æ§](#dataloaderç›‘æ§)
- [è®¢é˜…è¿½è¸ª](#è®¢é˜…è¿½è¸ª)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [ç”Ÿäº§æ¡ˆä¾‹](#ç”Ÿäº§æ¡ˆä¾‹)

---

## æ¦‚è¿°

GraphQLç›‘æ§æä¾›æŸ¥è¯¢çº§åˆ«çš„å¯è§‚æµ‹æ€§ï¼š

- âœ… **æŸ¥è¯¢åˆ†æ**: å®Œæ•´çš„æŸ¥è¯¢ç”Ÿå‘½å‘¨æœŸè¿½è¸ª
- âœ… **å­—æ®µçº§ç›‘æ§**: æ¯ä¸ªè§£æå™¨çš„æ€§èƒ½è¿½è¸ª
- âœ… **N+1æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ«æ€§èƒ½åæ¨¡å¼
- âœ… **DataLoaderè¿½è¸ª**: æ‰¹å¤„ç†å’Œç¼“å­˜ç›‘æ§
- âœ… **è®¢é˜…ç›‘æ§**: å®æ—¶æ•°æ®æ¨é€è¿½è¸ª

---

## GraphQLè¿½è¸ªåŸºç¡€

### async-graphqlé›†æˆ

```rust
// Cargo.toml
[dependencies]
async-graphql = "7.0"
async-graphql-axum = "7.0"
opentelemetry = "0.31"
tracing = "0.1"
tracing-opentelemetry = "0.31"

// main.rs
use async_graphql::{
    Schema, Object, Context, EmptySubscription,
    extensions::{Tracing, Logger},
};
use async_graphql_axum::{GraphQLRequest, GraphQLResponse};

// å®šä¹‰Schema
pub type AppSchema = Schema<QueryRoot, MutationRoot, SubscriptionRoot>;

// Query Root
pub struct QueryRoot;

#[Object]
impl QueryRoot {
    // ç®€å•å­—æ®µ
    #[tracing::instrument(skip(ctx))]
    async fn hello(&self, ctx: &Context<'_>) -> &str {
        "Hello, GraphQL!"
    }
    
    // å¸¦å‚æ•°çš„æŸ¥è¯¢
    #[tracing::instrument(skip(ctx), fields(user.id = %id))]
    async fn user(&self, ctx: &Context<'_>, id: u64) -> Result<User> {
        let db = ctx.data::<Database>()?;
        db.get_user(id).await
    }
    
    // å¤æ‚æŸ¥è¯¢
    #[tracing::instrument(skip(ctx))]
    async fn users(
        &self,
        ctx: &Context<'_>,
        #[graphql(default = 20)] limit: usize,
        #[graphql(default = 0)] offset: usize,
    ) -> Result<Vec<User>> {
        let db = ctx.data::<Database>()?;
        db.list_users(limit, offset).await
    }
}

// Userç±»å‹
#[derive(Clone)]
pub struct User {
    pub id: u64,
    pub name: String,
    pub email: String,
}

#[Object]
impl User {
    async fn id(&self) -> u64 {
        self.id
    }
    
    async fn name(&self) -> &str {
        &self.name
    }
    
    async fn email(&self) -> &str {
        &self.email
    }
    
    // å…³è”å­—æ®µ - å¯èƒ½å¯¼è‡´N+1é—®é¢˜
    #[tracing::instrument(skip(ctx), fields(user.id = %self.id))]
    async fn posts(&self, ctx: &Context<'_>) -> Result<Vec<Post>> {
        let db = ctx.data::<Database>()?;
        db.get_user_posts(self.id).await
    }
}

// åˆ›å»ºSchema
fn create_schema() -> AppSchema {
    Schema::build(QueryRoot, MutationRoot, SubscriptionRoot)
        // æ·»åŠ è¿½è¸ªæ‰©å±•
        .extension(Tracing)
        .extension(Logger)
        .finish()
}

// Axumå¤„ç†å™¨
async fn graphql_handler(
    schema: Extension<AppSchema>,
    req: GraphQLRequest,
) -> GraphQLResponse {
    schema.execute(req.into_inner()).await.into()
}

#[tokio::main]
async fn main() {
    // åˆå§‹åŒ–è¿½è¸ª
    init_tracing();
    
    let schema = create_schema();
    
    let app = Router::new()
        .route("/graphql", post(graphql_handler))
        .route("/", get(graphql_playground))
        .layer(Extension(schema));
    
    axum::Server::bind(&"0.0.0.0:8000".parse().unwrap())
        .serve(app.into_make_service())
        .await
        .unwrap();
}
```

---

## æŸ¥è¯¢ç›‘æ§

### æŸ¥è¯¢çº§åˆ«çš„è¿½è¸ª

```rust
use async_graphql::extensions::{Extension, ExtensionContext, ExtensionFactory, NextExecute};

// è‡ªå®šä¹‰GraphQLè¿½è¸ªæ‰©å±•
pub struct DetailedTracing;

impl ExtensionFactory for DetailedTracing {
    fn create(&self) -> Box<dyn Extension> {
        Box::new(DetailedTracingExtension)
    }
}

struct DetailedTracingExtension;

#[async_trait::async_trait]
impl Extension for DetailedTracingExtension {
    // æŸ¥è¯¢å¼€å§‹
    async fn execute(
        &self,
        ctx: &ExtensionContext<'_>,
        operation_name: Option<&str>,
        next: NextExecute<'_>,
    ) -> async_graphql::Response {
        let tracer = global::tracer("graphql");
        let mut span = tracer.start("graphql.execute");
        
        // è®°å½•æŸ¥è¯¢ä¿¡æ¯
        if let Some(name) = operation_name {
            span.set_attribute(KeyValue::new("graphql.operation.name", name.to_string()));
        }
        
        span.set_attribute(KeyValue::new(
            "graphql.operation.type",
            ctx.query().operation_type.to_string()
        ));
        
        span.set_attribute(KeyValue::new(
            "graphql.document",
            ctx.query().query.clone()
        ));
        
        // æ‰§è¡ŒæŸ¥è¯¢
        let start = std::time::Instant::now();
        let response = next.run(ctx).await;
        let duration = start.elapsed();
        
        // è®°å½•æ€§èƒ½
        span.set_attribute(KeyValue::new("graphql.duration_ms", duration.as_millis() as i64));
        span.set_attribute(KeyValue::new("graphql.errors.count", response.errors.len() as i64));
        
        // æ£€æŸ¥é”™è¯¯
        if response.is_err() {
            span.set_status(Status::error("GraphQL query failed"));
            for error in &response.errors {
                span.add_event(
                    "graphql.error",
                    vec![
                        KeyValue::new("error.message", error.message.clone()),
                        KeyValue::new("error.path", format!("{:?}", error.path)),
                    ],
                );
            }
        } else {
            span.set_status(Status::Ok);
        }
        
        response
    }
}
```

### æŸ¥è¯¢å¤æ‚åº¦è¿½è¸ª

```rust
use async_graphql::{Value, Variables};

#[derive(Debug)]
struct QueryComplexity {
    depth: usize,
    breadth: usize,
    field_count: usize,
}

impl QueryComplexity {
    fn calculate(query: &str) -> Self {
        // ç®€åŒ–çš„å¤æ‚åº¦è®¡ç®—
        let field_count = query.matches('{').count();
        let depth = query.matches('{').count().max(query.matches('[').count());
        
        Self {
            depth,
            breadth: field_count,
            field_count,
        }
    }
    
    fn to_span_attributes(&self) -> Vec<KeyValue> {
        vec![
            KeyValue::new("graphql.query.depth", self.depth as i64),
            KeyValue::new("graphql.query.breadth", self.breadth as i64),
            KeyValue::new("graphql.query.field_count", self.field_count as i64),
        ]
    }
}

// åœ¨æ‰§è¡Œå‰è®¡ç®—å¤æ‚åº¦
async fn execute_with_complexity(
    schema: &AppSchema,
    query: &str,
) -> async_graphql::Response {
    let complexity = QueryComplexity::calculate(query);
    
    // è®°å½•åˆ°span
    let span = tracing::Span::current();
    for attr in complexity.to_span_attributes() {
        span.record(attr.key.as_str(), &attr.value.to_string());
    }
    
    // å¤æ‚åº¦é™åˆ¶
    if complexity.depth > 10 {
        return async_graphql::Response::from_errors(vec![
            async_graphql::ServerError::new("Query too deep", None)
        ]);
    }
    
    schema.execute(query).await
}
```

---

## è§£æå™¨è¿½è¸ª

### å­—æ®µçº§åˆ«çš„ç›‘æ§

```rust
use async_graphql::Context;

#[Object]
impl User {
    // ç®€å•å­—æ®µ - æ— éœ€ç‰¹æ®Šè¿½è¸ª
    async fn id(&self) -> u64 {
        self.id
    }
    
    // æ•°æ®åº“æŸ¥è¯¢å­—æ®µ - éœ€è¦è¿½è¸ª
    #[tracing::instrument(
        name = "resolver.user.posts",
        skip(ctx),
        fields(
            user.id = %self.id,
            resolver.field = "posts"
        )
    )]
    async fn posts(&self, ctx: &Context<'_>) -> Result<Vec<Post>> {
        let db = ctx.data::<Database>()?;
        let start = std::time::Instant::now();
        
        let posts = db.get_user_posts(self.id).await?;
        
        let duration = start.elapsed();
        tracing::info!(
            posts_count = posts.len(),
            duration_ms = duration.as_millis(),
            "Posts loaded"
        );
        
        Ok(posts)
    }
    
    // æ˜‚è´µçš„è®¡ç®— - éœ€è¦è¯¦ç»†è¿½è¸ª
    #[tracing::instrument(
        name = "resolver.user.recommendations",
        skip(ctx),
        fields(user.id = %self.id)
    )]
    async fn recommendations(&self, ctx: &Context<'_>) -> Result<Vec<Post>> {
        let recommender = ctx.data::<RecommendationEngine>()?;
        
        // è¿½è¸ªå„ä¸ªé˜¶æ®µ
        tracing::info!("Fetching user history");
        let history = recommender.get_user_history(self.id).await?;
        
        tracing::info!("Calculating recommendations");
        let recommendations = recommender.calculate(history).await?;
        
        tracing::info!(
            recommendations_count = recommendations.len(),
            "Recommendations generated"
        );
        
        Ok(recommendations)
    }
}
```

---

## N+1é—®é¢˜æ£€æµ‹

### è‡ªåŠ¨æ£€æµ‹N+1æŸ¥è¯¢

```rust
use std::sync::Arc;
use tokio::sync::Mutex;
use std::collections::HashMap;

// N+1æ£€æµ‹å™¨
#[derive(Clone)]
pub struct N1Detector {
    queries: Arc<Mutex<HashMap<String, Vec<QueryInfo>>>>,
}

#[derive(Debug)]
struct QueryInfo {
    query: String,
    timestamp: std::time::Instant,
    stack_trace: Vec<String>,
}

impl N1Detector {
    pub fn new() -> Self {
        Self {
            queries: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    // è®°å½•æŸ¥è¯¢
    pub async fn record_query(&self, resolver: &str, query: &str) {
        let mut queries = self.queries.lock().await;
        
        queries
            .entry(resolver.to_string())
            .or_insert_with(Vec::new)
            .push(QueryInfo {
                query: query.to_string(),
                timestamp: std::time::Instant::now(),
                stack_trace: vec![], // ç®€åŒ–
            });
    }
    
    // æ£€æµ‹N+1é—®é¢˜
    pub async fn detect_n1_issues(&self) -> Vec<N1Issue> {
        let queries = self.queries.lock().await;
        let mut issues = Vec::new();
        
        for (resolver, query_list) in queries.iter() {
            // å¦‚æœåŒä¸€ä¸ªresolveråœ¨çŸ­æ—¶é—´å†…è¢«è°ƒç”¨å¤šæ¬¡
            if query_list.len() > 10 {
                let time_span = query_list.last().unwrap().timestamp - 
                               query_list.first().unwrap().timestamp;
                
                if time_span.as_millis() < 1000 {
                    issues.push(N1Issue {
                        resolver: resolver.clone(),
                        query_count: query_list.len(),
                        time_span,
                    });
                    
                    // è®°å½•åˆ°è¿½è¸ª
                    tracing::warn!(
                        resolver = %resolver,
                        query_count = query_list.len(),
                        time_span_ms = time_span.as_millis(),
                        "Potential N+1 issue detected"
                    );
                }
            }
        }
        
        issues
    }
}

#[derive(Debug)]
pub struct N1Issue {
    resolver: String,
    query_count: usize,
    time_span: std::time::Duration,
}

// ä½¿ç”¨DataLoaderè§£å†³N+1é—®é¢˜
use async_graphql::dataloader::*;

pub struct UserPostsLoader {
    db: Database,
}

#[async_trait::async_trait]
impl Loader<u64> for UserPostsLoader {
    type Value = Vec<Post>;
    type Error = Arc<sqlx::Error>;

    #[tracing::instrument(name = "dataloader.user_posts", skip(self, keys))]
    async fn load(&self, keys: &[u64]) -> Result<HashMap<u64, Self::Value>, Self::Error> {
        tracing::info!(user_ids = ?keys, "Batch loading posts");
        
        // å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰æ•°æ®
        let posts = self.db
            .get_posts_for_users(keys)
            .await
            .map_err(Arc::new)?;
        
        // æŒ‰user_idåˆ†ç»„
        let mut result = HashMap::new();
        for post in posts {
            result
                .entry(post.user_id)
                .or_insert_with(Vec::new)
                .push(post);
        }
        
        tracing::info!(users_count = result.len(), "Posts loaded");
        Ok(result)
    }
}
```

---

## DataLoaderç›‘æ§

### DataLoaderè¿½è¸ª

```rust
use async_graphql::dataloader::*;

// å¸¦è¿½è¸ªçš„DataLoaderåŒ…è£…å™¨
pub struct TracedDataLoader<K, V> 
where
    K: Send + Sync + Hash + Eq + Clone + 'static,
    V: Send + Sync + Clone + 'static,
{
    loader: DataLoader<K, V>,
    name: String,
}

impl<K, V> TracedDataLoader<K, V>
where
    K: Send + Sync + Hash + Eq + Clone + 'static,
    V: Send + Sync + Clone + 'static,
{
    pub fn new(loader: DataLoader<K, V>, name: impl Into<String>) -> Self {
        Self {
            loader,
            name: name.into(),
        }
    }
    
    #[tracing::instrument(
        name = "dataloader.load",
        skip(self),
        fields(
            dataloader.name = %self.name,
            dataloader.key_count = keys.len()
        )
    )]
    pub async fn load_many(&self, keys: Vec<K>) -> Result<HashMap<K, V>> {
        tracing::info!("Loading batch");
        
        let start = std::time::Instant::now();
        let result = self.loader.load_many(keys.clone()).await;
        let duration = start.elapsed();
        
        match &result {
            Ok(data) => {
                tracing::info!(
                    loaded_count = data.len(),
                    duration_ms = duration.as_millis(),
                    cache_hit_rate = calculate_cache_hit_rate(&keys, data),
                    "Batch loaded successfully"
                );
            }
            Err(e) => {
                tracing::error!(
                    error = %e,
                    duration_ms = duration.as_millis(),
                    "Batch load failed"
                );
            }
        }
        
        result
    }
}

fn calculate_cache_hit_rate<K, V>(keys: &[K], result: &HashMap<K, V>) -> f64
where
    K: Hash + Eq,
{
    if keys.is_empty() {
        return 0.0;
    }
    (result.len() as f64) / (keys.len() as f64) * 100.0
}
```

---

## è®¢é˜…è¿½è¸ª

### WebSocketè®¢é˜…ç›‘æ§

```rust
use async_graphql::{Subscription, Object};
use futures_util::Stream;

pub struct SubscriptionRoot;

#[Subscription]
impl SubscriptionRoot {
    // è®¢é˜…æ–°æ¶ˆæ¯
    #[tracing::instrument(skip(ctx), fields(user.id = %user_id))]
    async fn messages(
        &self,
        ctx: &Context<'_>,
        user_id: u64,
    ) -> impl Stream<Item = Message> {
        tracing::info!("New message subscription started");
        
        let message_bus = ctx.data::<MessageBus>().unwrap();
        let mut receiver = message_bus.subscribe(user_id).await;
        
        async_stream::stream! {
            let mut count = 0;
            
            while let Ok(message) = receiver.recv().await {
                count += 1;
                
                tracing::debug!(
                    message_id = %message.id,
                    subscription_count = count,
                    "Message delivered"
                );
                
                yield message;
            }
            
            tracing::info!(
                total_messages = count,
                "Subscription ended"
            );
        }
    }
    
    // è®¢é˜…å®æ—¶æŒ‡æ ‡
    #[tracing::instrument(skip(ctx))]
    async fn metrics(&self, ctx: &Context<'_>) -> impl Stream<Item = Metrics> {
        tracing::info!("Metrics subscription started");
        
        let mut interval = tokio::time::interval(Duration::from_secs(1));
        
        async_stream::stream! {
            loop {
                interval.tick().await;
                
                let metrics = collect_metrics().await;
                
                tracing::trace!(
                    cpu_usage = %metrics.cpu_usage,
                    memory_usage = %metrics.memory_usage,
                    "Metrics collected"
                );
                
                yield metrics;
            }
        }
    }
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### æŸ¥è¯¢ä¼˜åŒ–

```rust
// 1. ä½¿ç”¨DataLoaderæ‰¹å¤„ç†
#[Object]
impl User {
    async fn posts(&self, ctx: &Context<'_>) -> Result<Vec<Post>> {
        let loader = ctx.data::<DataLoader<UserPostsLoader>>()?;
        loader.load_one(self.id).await?
            .ok_or_else(|| "Posts not found".into())
    }
}

// 2. æŸ¥è¯¢å¤æ‚åº¦é™åˆ¶
let schema = Schema::build(QueryRoot, MutationRoot, SubscriptionRoot)
    .limit_depth(10)        // æœ€å¤§åµŒå¥—æ·±åº¦
    .limit_complexity(100)   // æœ€å¤§å¤æ‚åº¦
    .finish();

// 3. æŸ¥è¯¢ç¼“å­˜
use async_graphql::cache::*;

let schema = Schema::build(QueryRoot, MutationRoot, SubscriptionRoot)
    .enable_cache(CacheConfig {
        ttl: Duration::from_secs(60),
        max_size: 1000,
    })
    .finish();
```

---

## ç”Ÿäº§æ¡ˆä¾‹

### æ¡ˆä¾‹: GraphQL APIç½‘å…³

**åœºæ™¯**: å¾®æœåŠ¡GraphQLèšåˆ  
**è§„æ¨¡**: 20+ åç«¯æœåŠ¡ï¼Œ1000+ req/s  
**æŠ€æœ¯**: async-graphql + Axum

```rust
// å®Œæ•´çš„GraphQLç½‘å…³å®ç°
#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–è¿½è¸ª
    init_telemetry()?;
    
    // åˆ›å»ºSchema
    let schema = Schema::build(
        QueryRoot,
        MutationRoot,
        SubscriptionRoot
    )
    .extension(Tracing)
    .extension(ComplexityAnalyzer)
    .limit_depth(10)
    .limit_complexity(200)
    .finish();
    
    // åˆ›å»ºåº”ç”¨
    let app = Router::new()
        .route("/graphql", post(graphql_handler))
        .route("/graphql/ws", get(graphql_ws_handler))
        .layer(Extension(schema))
        .layer(TraceLayer::new_for_http());
    
    axum::Server::bind(&"0.0.0.0:8000".parse()?)
        .serve(app.into_make_service())
        .await?;
    
    Ok(())
}

// æ€§èƒ½ç»“æœ:
// - P50å»¶è¿Ÿ: 25ms
// - P99å»¶è¿Ÿ: 150ms
// - N+1é—®é¢˜: å‡å°‘95%
// - DataLoaderç¼“å­˜å‘½ä¸­ç‡: 85%
```

---

## æ€»ç»“

GraphQLç›‘æ§çš„å…³é”®è¦ç´ ï¼š

1. **æŸ¥è¯¢è¿½è¸ª**: å®Œæ•´çš„æŸ¥è¯¢ç”Ÿå‘½å‘¨æœŸç›‘æ§
2. **è§£æå™¨ç›‘æ§**: å­—æ®µçº§åˆ«çš„æ€§èƒ½è¿½è¸ª
3. **N+1æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ«å’Œä¼˜åŒ–æ€§èƒ½é—®é¢˜
4. **DataLoader**: æ‰¹å¤„ç†å’Œç¼“å­˜ç›‘æ§
5. **è®¢é˜…è¿½è¸ª**: WebSocketè¿æ¥å’Œæ¶ˆæ¯ç›‘æ§

**ä¸‹ä¸€æ­¥**:

- ğŸ”Œ [WebSocketè¿½è¸ª](./websocket_tracing.md)
- âš¡ [æ€§èƒ½ä¼˜åŒ–](./performance_optimization.md)
- ğŸš€ [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](./production_deployment.md)
