# Web æ€§èƒ½ä¼˜åŒ– - Web Performance Optimization

**åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ29æ—¥  
**åŸºäº**: ç”Ÿäº§ç¯å¢ƒå¯è§‚æµ‹æ€§æ•°æ®  
**çŠ¶æ€**: âœ… ç”Ÿäº§éªŒè¯

---

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ€§èƒ½åˆ†ææ–¹æ³•](#æ€§èƒ½åˆ†ææ–¹æ³•)
- [çƒ­è·¯å¾„ä¼˜åŒ–](#çƒ­è·¯å¾„ä¼˜åŒ–)
- [ç¼“å­˜ç­–ç•¥](#ç¼“å­˜ç­–ç•¥)
- [æ•°æ®åº“ä¼˜åŒ–](#æ•°æ®åº“ä¼˜åŒ–)
- [è¿æ¥æ± ä¼˜åŒ–](#è¿æ¥æ± ä¼˜åŒ–)
- [å¹¶å‘æ§åˆ¶](#å¹¶å‘æ§åˆ¶)
- [ç›‘æ§å’Œå‘Šè­¦](#ç›‘æ§å’Œå‘Šè­¦)

---

## æ¦‚è¿°

åŸºäºå¯è§‚æµ‹æ€§æ•°æ®çš„Webæ€§èƒ½ä¼˜åŒ–æ–¹æ³•è®ºï¼š

- âœ… **æ•°æ®é©±åŠ¨**: åŸºäºè¿½è¸ªæ•°æ®è¯†åˆ«ç“¶é¢ˆ
- âœ… **ç³»ç»ŸåŒ–**: è¦†ç›–è¯·æ±‚ç”Ÿå‘½å‘¨æœŸå„ç¯èŠ‚
- âœ… **å¯æµ‹é‡**: æ¯é¡¹ä¼˜åŒ–éƒ½æœ‰æ˜ç¡®æŒ‡æ ‡
- âœ… **å¯æŒç»­**: å»ºç«‹æŒç»­ä¼˜åŒ–æœºåˆ¶
- âœ… **ç”Ÿäº§éªŒè¯**: çœŸå®ç¯å¢ƒéªŒè¯æ•ˆæœ

---

## æ€§èƒ½åˆ†ææ–¹æ³•

### åŸºäºè¿½è¸ªçš„æ€§èƒ½åˆ†æ

```rust
use opentelemetry::trace::{Span, Tracer};
use std::time::Instant;

// æ€§èƒ½åˆ†æå™¨
#[derive(Clone)]
pub struct PerformanceAnalyzer {
    tracer: global::BoxedTracer,
    slow_threshold: Duration,
}

impl PerformanceAnalyzer {
    pub fn new(slow_threshold: Duration) -> Self {
        Self {
            tracer: global::tracer("performance"),
            slow_threshold,
        }
    }
    
    // åˆ†æè¯·æ±‚æ€§èƒ½
    #[instrument(skip(self), fields(
        request.path = %path,
        request.method = %method
    ))]
    pub async fn analyze_request(&self, path: &str, method: &str) -> RequestPerformance {
        let start = Instant::now();
        
        // æ”¶é›†spanæ•°æ®
        let span_data = self.collect_span_data().await;
        
        // åˆ†æå„é˜¶æ®µè€—æ—¶
        let breakdown = self.analyze_breakdown(&span_data);
        
        // è¯†åˆ«æ…¢æŸ¥è¯¢
        let slow_queries = self.identify_slow_queries(&span_data);
        
        // è¯†åˆ«N+1é—®é¢˜
        let n1_issues = self.detect_n1_patterns(&span_data);
        
        let total_duration = start.elapsed();
        
        RequestPerformance {
            total_duration,
            breakdown,
            slow_queries,
            n1_issues,
        }
    }
    
    // åˆ†ææ€§èƒ½åˆ†è§£
    fn analyze_breakdown(&self, spans: &[SpanData]) -> PerformanceBreakdown {
        let mut breakdown = PerformanceBreakdown::default();
        
        for span in spans {
            match span.name.as_str() {
                name if name.starts_with("db.") => {
                    breakdown.database_time += span.duration;
                }
                name if name.starts_with("cache.") => {
                    breakdown.cache_time += span.duration;
                }
                name if name.starts_with("http.client") => {
                    breakdown.external_api_time += span.duration;
                }
                name if name.contains("business_logic") => {
                    breakdown.business_logic_time += span.duration;
                }
                _ => {
                    breakdown.other_time += span.duration;
                }
            }
        }
        
        breakdown
    }
    
    // è¯†åˆ«æ…¢æŸ¥è¯¢
    fn identify_slow_queries(&self, spans: &[SpanData]) -> Vec<SlowQuery> {
        spans
            .iter()
            .filter(|span| {
                span.name.starts_with("db.") && span.duration > self.slow_threshold
            })
            .map(|span| SlowQuery {
                query: span.attributes.get("db.statement").cloned(),
                duration: span.duration,
                location: span.attributes.get("code.filepath").cloned(),
            })
            .collect()
    }
}

#[derive(Debug, Default)]
pub struct PerformanceBreakdown {
    pub database_time: Duration,
    pub cache_time: Duration,
    pub external_api_time: Duration,
    pub business_logic_time: Duration,
    pub other_time: Duration,
}

impl PerformanceBreakdown {
    // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub fn report(&self, total: Duration) -> String {
        format!(
            "Performance Breakdown:\n\
             - Database: {}ms ({:.1}%)\n\
             - Cache: {}ms ({:.1}%)\n\
             - External API: {}ms ({:.1}%)\n\
             - Business Logic: {}ms ({:.1}%)\n\
             - Other: {}ms ({:.1}%)",
            self.database_time.as_millis(),
            self.percentage(self.database_time, total),
            self.cache_time.as_millis(),
            self.percentage(self.cache_time, total),
            self.external_api_time.as_millis(),
            self.percentage(self.external_api_time, total),
            self.business_logic_time.as_millis(),
            self.percentage(self.business_logic_time, total),
            self.other_time.as_millis(),
            self.percentage(self.other_time, total),
        )
    }
    
    fn percentage(&self, part: Duration, total: Duration) -> f64 {
        if total.as_millis() == 0 {
            return 0.0;
        }
        (part.as_millis() as f64 / total.as_millis() as f64) * 100.0
    }
}
```

---

## çƒ­è·¯å¾„ä¼˜åŒ–

### è¯†åˆ«å’Œä¼˜åŒ–çƒ­è·¯å¾„

```rust
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, Ordering};

// çƒ­è·¯å¾„ç»Ÿè®¡
#[derive(Clone)]
pub struct HotPathTracker {
    paths: Arc<DashMap<String, PathStats>>,
}

#[derive(Debug, Default)]
struct PathStats {
    hit_count: AtomicU64,
    total_duration: AtomicU64,  // å¾®ç§’
    p50_duration: AtomicU64,
    p95_duration: AtomicU64,
    p99_duration: AtomicU64,
}

impl HotPathTracker {
    pub fn new() -> Self {
        Self {
            paths: Arc::new(DashMap::new()),
        }
    }
    
    // è®°å½•è¯·æ±‚
    pub fn record(&self, path: &str, duration: Duration) {
        let stats = self.paths
            .entry(path.to_string())
            .or_insert_with(PathStats::default);
        
        stats.hit_count.fetch_add(1, Ordering::Relaxed);
        stats.total_duration.fetch_add(duration.as_micros() as u64, Ordering::Relaxed);
    }
    
    // è·å–çƒ­è·¯å¾„ (Top N)
    pub fn hot_paths(&self, top_n: usize) -> Vec<(String, HotPathMetrics)> {
        let mut paths: Vec<_> = self.paths
            .iter()
            .map(|entry| {
                let path = entry.key().clone();
                let stats = entry.value();
                let hit_count = stats.hit_count.load(Ordering::Relaxed);
                let total_duration = stats.total_duration.load(Ordering::Relaxed);
                
                let avg_duration = if hit_count > 0 {
                    Duration::from_micros(total_duration / hit_count)
                } else {
                    Duration::ZERO
                };
                
                (
                    path,
                    HotPathMetrics {
                        hit_count,
                        avg_duration,
                        p50: Duration::from_micros(stats.p50_duration.load(Ordering::Relaxed)),
                        p95: Duration::from_micros(stats.p95_duration.load(Ordering::Relaxed)),
                        p99: Duration::from_micros(stats.p99_duration.load(Ordering::Relaxed)),
                    },
                )
            })
            .collect();
        
        // æŒ‰hit_countæ’åº
        paths.sort_by(|a, b| b.1.hit_count.cmp(&a.1.hit_count));
        paths.truncate(top_n);
        paths
    }
}

#[derive(Debug)]
pub struct HotPathMetrics {
    pub hit_count: u64,
    pub avg_duration: Duration,
    pub p50: Duration,
    pub p95: Duration,
    pub p99: Duration,
}

// çƒ­è·¯å¾„ä¼˜åŒ–ç¤ºä¾‹
#[instrument(skip(db, cache))]
async fn optimized_hot_path(
    db: &Database,
    cache: &Cache,
    user_id: u64,
) -> Result<User> {
    // 1. å…ˆæŸ¥ç¼“å­˜ (çƒ­è·¯å¾„ä¼˜åŒ–)
    if let Some(user) = cache.get_user(user_id).await? {
        tracing::debug!("Cache hit");
        return Ok(user);
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­,æŸ¥æ•°æ®åº“
    tracing::debug!("Cache miss, querying database");
    let user = db.get_user(user_id).await?;
    
    // 3. å¼‚æ­¥æ›´æ–°ç¼“å­˜ (ä¸é˜»å¡å“åº”)
    let cache_clone = cache.clone();
    let user_clone = user.clone();
    tokio::spawn(async move {
        if let Err(e) = cache_clone.set_user(user_id, &user_clone).await {
            tracing::warn!(error = %e, "Failed to update cache");
        }
    });
    
    Ok(user)
}
```

---

## ç¼“å­˜ç­–ç•¥

### å¤šå±‚ç¼“å­˜æ¶æ„

```rust
use moka::future::Cache as MokaCache;

// å¤šå±‚ç¼“å­˜
#[derive(Clone)]
pub struct MultiLayerCache {
    // L1: è¿›ç¨‹å†…ç¼“å­˜ (æœ€å¿«)
    l1: MokaCache<String, Arc<Vec<u8>>>,
    // L2: Redisç¼“å­˜ (åˆ†å¸ƒå¼)
    l2: redis::Client,
    // æŒ‡æ ‡
    meter: Meter,
}

impl MultiLayerCache {
    pub fn new(l1_capacity: u64, redis_url: &str, meter: Meter) -> Result<Self> {
        Ok(Self {
            l1: MokaCache::builder()
                .max_capacity(l1_capacity)
                .time_to_live(Duration::from_secs(60))
                .build(),
            l2: redis::Client::open(redis_url)?,
            meter,
        })
    }
    
    // è·å–æ•°æ®
    #[instrument(skip(self), fields(cache.key = %key))]
    pub async fn get<T: DeserializeOwned>(&self, key: &str) -> Result<Option<T>> {
        // 1. å°è¯•L1ç¼“å­˜
        if let Some(data) = self.l1.get(key).await {
            tracing::debug!("L1 cache hit");
            self.record_hit("l1");
            return Ok(Some(bincode::deserialize(&data)?));
        }
        
        // 2. å°è¯•L2ç¼“å­˜
        let mut conn = self.l2.get_async_connection().await?;
        if let Some(data) = redis::cmd("GET")
            .arg(key)
            .query_async::<_, Option<Vec<u8>>>(&mut conn)
            .await?
        {
            tracing::debug!("L2 cache hit");
            self.record_hit("l2");
            
            // å›å¡«L1
            self.l1.insert(key.to_string(), Arc::new(data.clone())).await;
            
            return Ok(Some(bincode::deserialize(&data)?));
        }
        
        tracing::debug!("Cache miss");
        self.record_miss();
        Ok(None)
    }
    
    // è®¾ç½®æ•°æ®
    #[instrument(skip(self, value), fields(cache.key = %key))]
    pub async fn set<T: Serialize>(&self, key: &str, value: &T, ttl: Duration) -> Result<()> {
        let data = bincode::serialize(value)?;
        let data_arc = Arc::new(data.clone());
        
        // å¹¶å‘å†™å…¥ä¸¤å±‚ç¼“å­˜
        let l1_fut = self.l1.insert(key.to_string(), data_arc);
        let l2_fut = async {
            let mut conn = self.l2.get_async_connection().await?;
            redis::cmd("SETEX")
                .arg(key)
                .arg(ttl.as_secs())
                .arg(&data)
                .query_async(&mut conn)
                .await
        };
        
        tokio::try_join!(l1_fut, l2_fut)?;
        
        tracing::debug!("Data cached in L1 and L2");
        Ok(())
    }
    
    // è®°å½•ç¼“å­˜å‘½ä¸­
    fn record_hit(&self, layer: &str) {
        self.meter
            .u64_counter("cache.hits")
            .add(1, &[KeyValue::new("layer", layer.to_string())]);
    }
    
    // è®°å½•ç¼“å­˜æœªå‘½ä¸­
    fn record_miss(&self) {
        self.meter
            .u64_counter("cache.misses")
            .add(1, &[]);
    }
}

// ç¼“å­˜é¢„çƒ­
pub struct CacheWarmer {
    cache: MultiLayerCache,
    db: Database,
}

impl CacheWarmer {
    #[instrument(skip(self))]
    pub async fn warm_popular_data(&self) -> Result<()> {
        tracing::info!("Starting cache warming");
        
        // 1. è·å–çƒ­é—¨æ•°æ®åˆ—è¡¨
        let popular_users = self.db.get_popular_users(100).await?;
        
        // 2. å¹¶å‘é¢„çƒ­
        let futures: Vec<_> = popular_users
            .into_iter()
            .map(|user| async move {
                let key = format!("user:{}", user.id);
                self.cache.set(&key, &user, Duration::from_secs(300)).await
            })
            .collect();
        
        let results = futures::future::join_all(futures).await;
        let success_count = results.iter().filter(|r| r.is_ok()).count();
        
        tracing::info!(
            total = results.len(),
            success = success_count,
            "Cache warming completed"
        );
        
        Ok(())
    }
}
```

---

## æ•°æ®åº“ä¼˜åŒ–

### æ…¢æŸ¥è¯¢ä¼˜åŒ–

```rust
// æ•°æ®åº“æŸ¥è¯¢è¿½è¸ªå’Œä¼˜åŒ–
#[derive(Clone)]
pub struct TrackedDatabase {
    pool: sqlx::PgPool,
    slow_threshold: Duration,
    meter: Meter,
}

impl TrackedDatabase {
    pub fn new(pool: sqlx::PgPool, slow_threshold: Duration, meter: Meter) -> Self {
        Self {
            pool,
            slow_threshold,
            meter,
        }
    }
    
    // æ‰§è¡ŒæŸ¥è¯¢withè¿½è¸ª
    #[instrument(
        skip(self, query),
        fields(
            db.system = "postgresql",
            db.statement = tracing::field::Empty
        )
    )]
    pub async fn query<T>(&self, query: &str) -> Result<Vec<T>>
    where
        T: for<'r> sqlx::FromRow<'r, sqlx::postgres::PgRow> + Send + Unpin,
    {
        let span = tracing::Span::current();
        span.record("db.statement", &query);
        
        let start = Instant::now();
        let result = sqlx::query_as::<_, T>(query)
            .fetch_all(&self.pool)
            .await;
        let duration = start.elapsed();
        
        // è®°å½•æŸ¥è¯¢æ—¶é—´
        self.meter
            .f64_histogram("db.query.duration")
            .record(duration.as_secs_f64(), &[]);
        
        // æ£€æµ‹æ…¢æŸ¥è¯¢
        if duration > self.slow_threshold {
            tracing::warn!(
                query = %query,
                duration_ms = duration.as_millis(),
                "Slow query detected"
            );
            
            self.meter
                .u64_counter("db.slow_queries")
                .add(1, &[]);
        }
        
        result.map_err(Into::into)
    }
    
    // æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
    #[instrument(skip(self, ids))]
    pub async fn get_users_batch(&self, ids: &[u64]) -> Result<HashMap<u64, User>> {
        if ids.is_empty() {
            return Ok(HashMap::new());
        }
        
        // ä½¿ç”¨INæŸ¥è¯¢ä»£æ›¿å¤šæ¬¡å•ç‹¬æŸ¥è¯¢
        let query = format!(
            "SELECT * FROM users WHERE id = ANY($1)"
        );
        
        let users: Vec<User> = sqlx::query_as(&query)
            .bind(ids)
            .fetch_all(&self.pool)
            .await?;
        
        Ok(users.into_iter().map(|u| (u.id, u)).collect())
    }
}

// è¿æ¥æ± ç›‘æ§
pub async fn monitor_connection_pool(pool: &sqlx::PgPool, meter: &Meter) {
    let connections = pool.size() as i64;
    let idle = pool.num_idle() as i64;
    let active = connections - idle;
    
    meter
        .i64_observable_gauge("db.pool.connections")
        .with_callback(move |observer| {
            observer.observe(connections, &[KeyValue::new("state", "total")]);
            observer.observe(active, &[KeyValue::new("state", "active")]);
            observer.observe(idle, &[KeyValue::new("state", "idle")]);
        })
        .init();
}
```

---

## è¿æ¥æ± ä¼˜åŒ–

### HTTPå®¢æˆ·ç«¯è¿æ¥æ± 

```rust
use reqwest::Client;

// ä¼˜åŒ–çš„HTTPå®¢æˆ·ç«¯
pub fn create_optimized_client() -> Client {
    Client::builder()
        // è¿æ¥æ± è®¾ç½®
        .pool_max_idle_per_host(10)
        .pool_idle_timeout(Duration::from_secs(90))
        
        // è¶…æ—¶è®¾ç½®
        .connect_timeout(Duration::from_secs(10))
        .timeout(Duration::from_secs(30))
        
        // TCPè®¾ç½®
        .tcp_nodelay(true)
        .tcp_keepalive(Duration::from_secs(60))
        
        // HTTP/2
        .http2_adaptive_window(true)
        .http2_keep_alive_interval(Some(Duration::from_secs(30)))
        .http2_keep_alive_timeout(Duration::from_secs(20))
        
        .build()
        .expect("Failed to create HTTP client")
}
```

---

## å¹¶å‘æ§åˆ¶

### è¯·æ±‚é™æµå’Œè´Ÿè½½æ§åˆ¶

```rust
use tokio::sync::Semaphore;

// å¹¶å‘é™åˆ¶å™¨
#[derive(Clone)]
pub struct ConcurrencyLimiter {
    semaphore: Arc<Semaphore>,
    max_concurrent: usize,
    meter: Meter,
}

impl ConcurrencyLimiter {
    pub fn new(max_concurrent: usize, meter: Meter) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
            max_concurrent,
            meter,
        }
    }
    
    // å—é™æ‰§è¡Œ
    #[instrument(skip(self, f))]
    pub async fn execute<F, T>(&self, f: F) -> Result<T>
    where
        F: Future<Output = Result<T>>,
    {
        // å°è¯•è·å–è®¸å¯
        let permit = self.semaphore.acquire().await?;
        
        let current = self.max_concurrent - self.semaphore.available_permits();
        
        tracing::debug!(
            concurrent_requests = current,
            max_concurrent = self.max_concurrent,
            "Request acquired permit"
        );
        
        // è®°å½•å¹¶å‘æ•°
        self.meter
            .i64_observable_gauge("http.concurrent_requests")
            .with_callback(move |observer| {
                observer.observe(current as i64, &[]);
            })
            .init();
        
        // æ‰§è¡Œè¯·æ±‚
        let result = f.await;
        
        // è®¸å¯è‡ªåŠ¨é‡Šæ”¾
        drop(permit);
        
        result
    }
}
```

---

## ç›‘æ§å’Œå‘Šè­¦

### æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

```rust
// æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
#[derive(Clone)]
pub struct PerformanceMetrics {
    meter: Meter,
}

impl PerformanceMetrics {
    pub fn new(meter: Meter) -> Self {
        // åˆå§‹åŒ–æŒ‡æ ‡
        meter.f64_histogram("http.server.duration").init();
        meter.u64_counter("http.server.requests").init();
        meter.u64_counter("http.server.errors").init();
        
        Self { meter }
    }
    
    // è®°å½•è¯·æ±‚æ€§èƒ½
    pub fn record_request(
        &self,
        method: &str,
        path: &str,
        status: u16,
        duration: Duration,
    ) {
        let attributes = vec![
            KeyValue::new("http.method", method.to_string()),
            KeyValue::new("http.route", path.to_string()),
            KeyValue::new("http.status_code", status as i64),
        ];
        
        // è®°å½•å»¶è¿Ÿ
        self.meter
            .f64_histogram("http.server.duration")
            .record(duration.as_secs_f64(), &attributes);
        
        // è®°å½•è¯·æ±‚æ•°
        self.meter
            .u64_counter("http.server.requests")
            .add(1, &attributes);
        
        // è®°å½•é”™è¯¯
        if status >= 500 {
            self.meter
                .u64_counter("http.server.errors")
                .add(1, &attributes);
        }
    }
}

// SLOå‘Šè­¦
pub async fn check_slo_violations(metrics: &PerformanceMetrics) -> Vec<SLOViolation> {
    let mut violations = Vec::new();
    
    // æ£€æŸ¥P99å»¶è¿Ÿ
    if let Some(p99) = get_p99_latency().await {
        if p99 > Duration::from_millis(200) {
            violations.push(SLOViolation {
                metric: "p99_latency".to_string(),
                current: p99,
                threshold: Duration::from_millis(200),
                severity: Severity::Warning,
            });
        }
    }
    
    // æ£€æŸ¥é”™è¯¯ç‡
    if let Some(error_rate) = get_error_rate().await {
        if error_rate > 0.01 {  // 1%
            violations.push(SLOViolation {
                metric: "error_rate".to_string(),
                current_rate: error_rate,
                threshold_rate: 0.01,
                severity: Severity::Critical,
            });
        }
    }
    
    violations
}
```

---

## æ€»ç»“

Webæ€§èƒ½ä¼˜åŒ–çš„å…³é”®ç‚¹ï¼š

1. **æ•°æ®é©±åŠ¨**: åŸºäºè¿½è¸ªå’ŒæŒ‡æ ‡è¯†åˆ«ç“¶é¢ˆ
2. **ç³»ç»ŸåŒ–**: è¦†ç›–ç¼“å­˜ã€æ•°æ®åº“ã€ç½‘ç»œå„å±‚
3. **å¯æµ‹é‡**: æ¯é¡¹ä¼˜åŒ–éƒ½æœ‰æ˜ç¡®çš„æ€§èƒ½æŒ‡æ ‡
4. **æŒç»­ä¼˜åŒ–**: å»ºç«‹ç›‘æ§å‘Šè­¦æœºåˆ¶
5. **ç”Ÿäº§éªŒè¯**: åœ¨çœŸå®ç¯å¢ƒéªŒè¯æ•ˆæœ

**å…¸å‹ä¼˜åŒ–æ•ˆæœ**:

- P99å»¶è¿Ÿé™ä½: 40-60%
- ååé‡æå‡: 2-3x
- æ•°æ®åº“è´Ÿè½½: å‡å°‘50-70%
- ç¼“å­˜å‘½ä¸­ç‡: æå‡åˆ°85%+

**ä¸‹ä¸€æ­¥**:

- ğŸš€ [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](./production_deployment.md)
