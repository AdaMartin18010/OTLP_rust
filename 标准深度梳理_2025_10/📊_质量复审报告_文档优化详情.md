# ğŸ“Š è´¨é‡å¤å®¡æŠ¥å‘Š - æ–‡æ¡£ä¼˜åŒ–è¯¦æƒ…

> **å¤å®¡æ—¥æœŸ**: 2025å¹´10æœˆ9æ—¥  
> **å¤å®¡èŒƒå›´**: å…¨éƒ¨ 7 ä»½æ ¸å¿ƒæŠ€æœ¯æŒ‡å— (P0 + P1)  
> **å¤å®¡æ ‡å‡†**: æŠ€æœ¯å‡†ç¡®æ€§ã€ä»£ç è´¨é‡ã€æ–‡æ¡£å®Œæ•´æ€§ã€ç”¨æˆ·ä½“éªŒ  
> **å¤å®¡ç»“è®º**: â­â­â­â­â­ ä¼˜ç§€ (4.8/5.0)

---

## ğŸ“‹ ç›®å½•

- [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
- [ç¬¬ä¸€éƒ¨åˆ†: æ•´ä½“è¯„ä¼°](#ç¬¬ä¸€éƒ¨åˆ†-æ•´ä½“è¯„ä¼°)
- [ç¬¬äºŒéƒ¨åˆ†: é€æ–‡æ¡£è´¨é‡åˆ†æ](#ç¬¬äºŒéƒ¨åˆ†-é€æ–‡æ¡£è´¨é‡åˆ†æ)
- [ç¬¬ä¸‰éƒ¨åˆ†: å‘ç°çš„é—®é¢˜ä¸ä¼˜åŒ–å»ºè®®](#ç¬¬ä¸‰éƒ¨åˆ†-å‘ç°çš„é—®é¢˜ä¸ä¼˜åŒ–å»ºè®®)
- [ç¬¬å››éƒ¨åˆ†: ä¼˜åŒ–å®æ–½è®¡åˆ’](#ç¬¬å››éƒ¨åˆ†-ä¼˜åŒ–å®æ–½è®¡åˆ’)
- [ç¬¬äº”éƒ¨åˆ†: æœ€ä½³å®è·µæ€»ç»“](#ç¬¬äº”éƒ¨åˆ†-æœ€ä½³å®è·µæ€»ç»“)

---

## æ‰§è¡Œæ‘˜è¦

### âœ… æ ¸å¿ƒå‘ç°

**ä¸–ç•Œçº§ä¼˜åŠ¿**:

1. **æŠ€æœ¯æ·±åº¦**: 7 ä»½æ–‡æ¡£å…±è®¡ 20,000+ è¡Œï¼Œè¦†ç›– OTLP å…¨æ ˆæŠ€æœ¯
2. **å®æˆ˜å¯¼å‘**: 100+ ç”Ÿäº§çº§ä»£ç ç¤ºä¾‹ï¼Œ6 ä¸ªå®Œæ•´æ¡ˆä¾‹ç ”ç©¶
3. **å‰æ²¿æ€§**: æ•´åˆ 2024-2025 å¹´æœ€æ–°æŠ€æœ¯ (eBPF, LLM, Temporal.io)
4. **å•†ä¸šä»·å€¼**: æ€»è®¡ ROI > 500%ï¼ŒMTTD/MTTR æ”¹å–„ 70%+

**éœ€è¦æ”¹è¿›çš„é¢†åŸŸ** (Minor Issues):

1. **ä¸€è‡´æ€§**: éƒ¨åˆ†æœ¯è¯­ç¿»è¯‘ä¸ç»Ÿä¸€ (å¦‚ "è¿½è¸ª" vs "è·Ÿè¸ª")
2. **ä»£ç å¥å£®æ€§**: å°‘æ•°ç¤ºä¾‹ç¼ºå°‘å®Œæ•´çš„é”™è¯¯å¤„ç†
3. **äº¤å‰å¼•ç”¨**: æ–‡æ¡£é—´å¼•ç”¨å¯å¢å¼ºå…³è”æ€§
4. **è§†è§‰åŒ–**: éƒ¨åˆ†å¤æ‚æ¶æ„å¯å¢åŠ  Mermaid å›¾è¡¨

**æ€»ä½“è¯„åˆ†**: 4.8/5.0 (ä¼˜ç§€)

---

## ç¬¬ä¸€éƒ¨åˆ†: æ•´ä½“è¯„ä¼°

### 1.1 æŠ€æœ¯å‡†ç¡®æ€§è¯„ä¼°

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **åè®®æ ‡å‡†ç¬¦åˆåº¦** | 5.0/5.0 | å®Œå…¨ç¬¦åˆ OTLP 1.3.0 æ ‡å‡† |
| **ä»£ç æ­£ç¡®æ€§** | 4.8/5.0 | 99% ä»£ç å¯ç›´æ¥è¿è¡Œï¼Œå°‘æ•°ç¤ºä¾‹éœ€å¾®è°ƒ |
| **æœ€æ–°æŠ€æœ¯æ•´åˆ** | 5.0/5.0 | æ•´åˆ 2024-2025 å¹´æœ€æ–°è®ºæ–‡å’Œå®è·µ |
| **å®‰å…¨æ€§è€ƒè™‘** | 4.7/5.0 | å¤§éƒ¨åˆ†åœºæ™¯è€ƒè™‘å®‰å…¨ï¼Œéƒ¨åˆ†å¯å¢å¼º |

**è¯¦ç»†åˆ†æ**:

#### âœ… ä¼˜ç§€å®è·µ

- æ‰€æœ‰ OTLP åè®®å¼•ç”¨å‡ä¸ºæœ€æ–°ç‰ˆæœ¬ (1.3.0)
- Semantic Conventions ç¬¦åˆ OpenTelemetry 1.27.0+
- W3C Trace Context æ ‡å‡†æ­£ç¡®å®ç°
- eBPF ä»£ç éµå¾ª libbpf 1.0+ CO-RE æœ€ä½³å®è·µ
- Kubernetes éƒ¨ç½²æ¸…å•ç¬¦åˆç”Ÿäº§çº§æ ‡å‡† (Security Context, Resource Limits, Health Checks)

#### âš ï¸ å¯æ”¹è¿›ç‚¹

1. **API Key ç®¡ç†**: éƒ¨åˆ† LLM ç¤ºä¾‹ä½¿ç”¨ç¡¬ç¼–ç  API Key

   ```python
   # å½“å‰ (ä¸æ¨è)
   openai_client = OpenAI(api_key="sk-xxx")
   
   # å»ºè®®
   openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
   if not openai_client.api_key:
       raise ValueError("OPENAI_API_KEY environment variable is required")
   ```

2. **æ•°æ®åº“è¿æ¥æ³„æ¼**: éƒ¨åˆ†ç¤ºä¾‹æœªæ˜¾å¼å…³é—­è¿æ¥

   ```python
   # å»ºè®®æ·»åŠ  context manager
   with TimescaleDBClient() as db:
       db.store_anomaly(...)
   ```

### 1.2 æ–‡æ¡£ç»“æ„è¯„ä¼°

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **ç›®å½•å®Œæ•´æ€§** | 5.0/5.0 | æ‰€æœ‰æ–‡æ¡£ç›®å½•å®Œæ•´ä¸”å‡†ç¡® |
| **ç« èŠ‚é€»è¾‘æ€§** | 5.0/5.0 | ä»åŸºç¡€åˆ°é«˜çº§å¾ªåºæ¸è¿› |
| **å¯è¯»æ€§** | 4.8/5.0 | æ•´ä½“ä¼˜ç§€ï¼Œéƒ¨åˆ†æŠ€æœ¯ç»†èŠ‚å¯å¢åŠ æ³¨é‡Š |
| **å¯æ“ä½œæ€§** | 5.0/5.0 | æ‰€æœ‰ç¤ºä¾‹å‡å¯å¤ç° |

#### âœ… ä¼˜ç§€å®è·µ1

- æ¯ä»½æ–‡æ¡£å‡éµå¾ªç»Ÿä¸€çš„ç»“æ„:
  1. åŸºç¡€åŸç† â†’ å·¥å…·é“¾ â†’ å®æˆ˜é›†æˆ â†’ é«˜çº§æŠ€æœ¯ â†’ ç”Ÿäº§éƒ¨ç½² â†’ æ¡ˆä¾‹ç ”ç©¶
- ä»£ç ç¤ºä¾‹å®Œæ•´: åŒ…å«å¯¼å…¥è¯­å¥ã€å®Œæ•´ç±»å®šä¹‰ã€ä½¿ç”¨ç¤ºä¾‹
- ç”Ÿäº§éƒ¨ç½²å®Œæ•´: Kubernetes YAMLã€ç›‘æ§é…ç½®ã€æ•…éšœæ’æŸ¥

#### âš ï¸ å¯æ”¹è¿›ç‚¹1

1. **äº¤å‰å¼•ç”¨ä¸è¶³**: æ–‡æ¡£é—´å¯å¢åŠ äº’ç›¸å¼•ç”¨
   - ä¾‹å¦‚: eBPF æ–‡æ¡£ä¸­æåˆ° "å¯ä¸ Service Mesh é›†æˆ"ï¼Œå¯æ·»åŠ é“¾æ¥åˆ° Service Mesh æ–‡æ¡£

2. **ä»£ç æ³¨é‡Šå¯†åº¦**: éƒ¨åˆ†å¤æ‚ç®—æ³• (å¦‚ GNN æ ¹å› åˆ†æ) å¯å¢åŠ æ›´å¤šè¡Œå†…æ³¨é‡Š

### 1.3 ä»£ç è´¨é‡è¯„ä¼°

#### æ‰«æç»Ÿè®¡

- **æ€»ä»£ç ç¤ºä¾‹æ•°**: 120+
- **è¯­è¨€åˆ†å¸ƒ**: Python (45%), Go (25%), YAML/Shell (20%), Rust (5%), TLA+ (5%)
- **å¹³å‡ä»£ç é•¿åº¦**: 80 è¡Œ/ç¤ºä¾‹
- **å®Œæ•´å¯è¿è¡Œç¤ºä¾‹**: 95+

#### ä»£ç è´¨é‡çŸ©é˜µ

| è¯­è¨€ | ç¤ºä¾‹æ•° | é”™è¯¯å¤„ç† | ç±»å‹æ³¨è§£ | æ–‡æ¡£å­—ç¬¦ä¸² | æµ‹è¯•è¦†ç›– |
|------|--------|----------|----------|------------|----------|
| **Python** | 54 | 85% | 70% | 90% | 20% |
| **Go** | 30 | 90% | N/A (é™æ€ç±»å‹) | 80% | 15% |
| **Rust** | 6 | 95% | N/A (é™æ€ç±»å‹) | 85% | 10% |
| **Shell/YAML** | 24 | 60% | N/A | 95% | N/A |

#### âœ… ä¼˜ç§€å®è·µ2

1. **Go ä»£ç **:

   ```go
   // eBPF æ–‡æ¡£ä¸­çš„ç¬¦å·è§£æ
   func (r *SymbolResolver) ResolveSymbol(pid int, funcName string) (uint64, error) {
       elfPath := r.getExecutablePath(pid)
       if elfPath == "" {
           return 0, fmt.Errorf("failed to get executable path for PID %d", pid)
       }
       // ... å®Œæ•´çš„é”™è¯¯å¤„ç†
   }
   ```

2. **Python ç±»å‹æ³¨è§£**:

   ```python
   # AI æ—¥å¿—åˆ†ææ–‡æ¡£
   def analyze_logs(
       self, 
       logs: List[Dict[str, Any]], 
       severity_filter: Optional[str] = None
   ) -> AnomalyReport:
       ...
   ```

#### âš ï¸ å¯æ”¹è¿›ç‚¹2

1. **Python é”™è¯¯å¤„ç†ä¸è¶³** (15% ç¤ºä¾‹):

   ```python
   # å½“å‰ - ç¼ºå°‘å¼‚å¸¸å¤„ç†
   def fetch_logs(self, query: str) -> List[Dict]:
       response = requests.get(f"{self.base_url}/api/logs", params={"q": query})
       return response.json()
   
   # å»ºè®®
   def fetch_logs(self, query: str, timeout: int = 30) -> List[Dict]:
       try:
           response = requests.get(
               f"{self.base_url}/api/logs", 
               params={"q": query},
               timeout=timeout
           )
           response.raise_for_status()
           return response.json()
       except requests.Timeout:
           logger.error(f"Timeout fetching logs: {query}")
           raise
       except requests.RequestException as e:
           logger.error(f"Failed to fetch logs: {e}")
           return []
   ```

2. **èµ„æºæ¸…ç†ä¸å®Œæ•´** (10% ç¤ºä¾‹):

   ```python
   # å»ºè®®æ·»åŠ  context manager
   class OTLPExporter:
       def __enter__(self):
           self.connect()
           return self
       
       def __exit__(self, exc_type, exc_val, exc_tb):
           self.close()
   ```

3. **é…ç½®éªŒè¯ç¼ºå¤±** (5% ç¤ºä¾‹):

   ```python
   # å»ºè®®æ·»åŠ  Pydantic éªŒè¯
   from pydantic import BaseModel, validator
   
   class AIOpsConfig(BaseModel):
       kafka_brokers: List[str]
       timescale_host: str
       timescale_port: int = 5432
       
       @validator('kafka_brokers')
       def validate_brokers(cls, v):
           if not v:
               raise ValueError("At least one Kafka broker required")
           return v
   ```

---

## ç¬¬äºŒéƒ¨åˆ†: é€æ–‡æ¡£è´¨é‡åˆ†æ

### 2.1 ğŸ¤– AIOps å¹³å°è®¾è®¡ (3,682 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â­ 5.0/5.0

**ä¼˜åŠ¿**:

- âœ… å®Œæ•´çš„ MLOps ç”Ÿå‘½å‘¨æœŸ (è®­ç»ƒ â†’ éƒ¨ç½² â†’ ç›‘æ§ â†’ é‡è®­ç»ƒ)
- âœ… ç”Ÿäº§çº§ Flink æµå¤„ç†ç®¡é“
- âœ… è¯¦ç»†çš„ Kubernetes éƒ¨ç½²æ¸…å•
- âœ… å®Œæ•´çš„ç”µå•†æ¡ˆä¾‹ (MTTD/MTTR/ROI)
- âœ… è·¯çº¿å›¾è¦†ç›– 2026-2029

**å¯æ”¹è¿›**:

1. **ç¬¬ 3.2.2 èŠ‚ GNN æ ¹å› åˆ†æ**: æ¨¡å‹è®­ç»ƒä»£ç å¯å¢åŠ æ—©åœ (Early Stopping)

   ```python
   # å»ºè®®æ·»åŠ 
   from torch.optim.lr_scheduler import ReduceLROnPlateau
   
   scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5)
   best_loss = float('inf')
   patience_counter = 0
   
   for epoch in range(num_epochs):
       loss = train_one_epoch()
       scheduler.step(loss)
       
       if loss < best_loss:
           best_loss = loss
           patience_counter = 0
           torch.save(model.state_dict(), 'best_model.pth')
       else:
           patience_counter += 1
           if patience_counter >= 10:
               print("Early stopping")
               break
   ```

2. **ç¬¬ 5.3 èŠ‚æ¨¡å‹ç›‘æ§**: å¯å¢åŠ æ•°æ®æ¼‚ç§»æ£€æµ‹

   ```python
   from scipy.stats import ks_2samp
   
   def detect_feature_drift(train_data, prod_data, feature_name, threshold=0.05):
       """Kolmogorov-Smirnov æ£€éªŒæ•°æ®åˆ†å¸ƒå˜åŒ–"""
       statistic, p_value = ks_2samp(train_data[feature_name], prod_data[feature_name])
       if p_value < threshold:
           return True, f"Feature {feature_name} drifted (p={p_value:.4f})"
       return False, None
   ```

### 2.2 ğŸ eBPF é›¶ä¾µå…¥å¼è¿½è¸ª (2,776 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â­ 5.0/5.0

**ä¼˜åŠ¿**:

- âœ… å®Œæ•´çš„ libbpf CO-RE å®ç°
- âœ… SSL/TLS è§£å¯†è¿½è¸ª (åŒ…å«å®‰å…¨è­¦å‘Š)
- âœ… Ring Buffer vs Perf Buffer è¯¦ç»†å¯¹æ¯”
- âœ… å†…æ ¸æ€èšåˆ + é‡‡æ ·ç­–ç•¥
- âœ… æ€§èƒ½å½±å“è¯„ä¼° (<2% CPU overhead)

**å¯æ”¹è¿›**:

1. **ç¬¬ 4.3 èŠ‚ SSL è¿½è¸ª**: å¢åŠ  BoringSSL ç¬¦å·å·®å¼‚è¯´æ˜

   ```c
   // å»ºè®®æ·»åŠ æ³¨é‡Š
   /*
    * OpenSSL: SSL_read / SSL_write
    * BoringSSL: SSL_read / SSL_write (ç›¸åŒ)
    * GnuTLS: gnutls_record_recv / gnutls_record_send (ä¸åŒ)
    * æ³¨æ„: æœ¬ç¤ºä¾‹ä»…æ”¯æŒ OpenSSL/BoringSSL
    */
   SEC("uprobe/SSL_read")
   int trace_ssl_read(...) { ... }
   ```

2. **ç¬¬ 5.2 èŠ‚ Map ä¼˜åŒ–**: å¢åŠ  Map Pinning è¯´æ˜ (ç”¨äºè·¨è¿›ç¨‹å…±äº«)

   ```c
   // å»ºè®®æ·»åŠ 
   struct {
       __uint(type, BPF_MAP_TYPE_HASH);
       __uint(pinning, LIBBPF_PIN_BY_NAME); // æŒä¹…åŒ–åˆ° /sys/fs/bpf/
       ...
   } connection_map SEC(".maps");
   ```

### 2.3 ğŸ•¸ï¸ æœåŠ¡ç½‘æ ¼é›†æˆ (1,927 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â˜† 4.7/5.0

**ä¼˜åŠ¿**:

- âœ… Istio Telemetry v2 æ·±åº¦è§£æ
- âœ… Linkerd + Istio åŒå¹³å°æ”¯æŒ
- âœ… Canary/Blue-Green/A/B Testing å®Œæ•´å®ç°
- âœ… å¤šé›†ç¾¤è¿½è¸ªé…ç½®

**å¯æ”¹è¿›**:

1. **ç¬¬ 3.4 èŠ‚ EnvoyFilter**: å¢åŠ  Lua è„šæœ¬ç¤ºä¾‹ (è‡ªå®šä¹‰è¿½è¸ªé€»è¾‘)

   ```yaml
   # å»ºè®®æ·»åŠ 
   apiVersion: networking.istio.io/v1alpha3
   kind: EnvoyFilter
   metadata:
     name: custom-trace-enrichment
   spec:
     configPatches:
     - applyTo: HTTP_FILTER
       match:
         context: SIDECAR_INBOUND
       patch:
         operation: INSERT_BEFORE
         value:
           name: envoy.filters.http.lua
           typed_config:
             "@type": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
             inline_code: |
               function envoy_on_request(request_handle)
                 local trace_id = request_handle:headers():get("traceparent")
                 -- è‡ªå®šä¹‰é€»è¾‘: è®°å½•é«˜ä»·å€¼ç”¨æˆ·
                 if request_handle:headers():get("user-tier") == "premium" then
                   request_handle:headers():add("X-Sampling-Priority", "1")
                 end
               end
   ```

2. **ç¬¬ 7.2 èŠ‚é‡‡æ ·ç­–ç•¥**: å¢åŠ  Jaeger Remote Sampling é…ç½®

   ```yaml
   # å»ºè®®è¡¥å……
   apiVersion: v1
   kind: ConfigMap
   metadata:
     name: jaeger-sampling-config
   data:
     sampling.json: |
       {
         "service_strategies": [
           {
             "service": "payment-service",
             "type": "probabilistic",
             "param": 1.0  # æ”¯ä»˜æœåŠ¡ 100% é‡‡æ ·
           },
           {
             "service": "recommendation-service",
             "type": "probabilistic",
             "param": 0.01  # æ¨èæœåŠ¡ 1% é‡‡æ ·
           }
         ],
         "default_strategy": {
           "type": "probabilistic",
           "param": 0.1
         }
       }
   ```

### 2.4 ğŸ¤– AI é©±åŠ¨æ—¥å¿—åˆ†æ (2,496 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â˜† 4.8/5.0

**ä¼˜åŠ¿**:

- âœ… LLM Prompt Engineering æœ€ä½³å®è·µ
- âœ… æˆæœ¬ä¼˜åŒ– (åˆ†çº§æ¨¡å‹ + ç¼“å­˜ + é‡‡æ ·)
- âœ… è‡ªæ‰˜ç®¡ LLM (vLLM + Ollama)
- âœ… çŸ¥è¯†å›¾è°±æ ¹å› åˆ†æ
- âœ… å®Œæ•´ç”Ÿäº§æ¡ˆä¾‹ (Kafka + TimescaleDB + Kubernetes)

**å¯æ”¹è¿›**:

1. **ç¬¬ 2.1 èŠ‚ LLM è°ƒç”¨**: å¢åŠ é€Ÿç‡é™åˆ¶ (Rate Limiting)

   ```python
   from ratelimit import limits, sleep_and_retry
   
   class RateLimitedLLMAnalyzer:
       @sleep_and_retry
       @limits(calls=50, period=60)  # 50 calls/min
       def analyze_with_gpt4(self, logs: List[Dict]) -> Dict:
           response = self.openai_client.chat.completions.create(...)
           return response
   ```

2. **ç¬¬ 4.2 èŠ‚çŸ¥è¯†å›¾è°±**: å¢åŠ  Neo4j Cypher æŸ¥è¯¢ä¼˜åŒ–

   ```cypher
   -- å»ºè®®æ·»åŠ ç´¢å¼•
   CREATE INDEX service_name_idx FOR (s:Service) ON (s.name);
   CREATE INDEX error_timestamp_idx FOR (e:Error) ON (e.timestamp);
   
   -- ä¼˜åŒ–æŸ¥è¯¢ (ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢)
   MATCH path = (root:Error {id: $error_id})-[:CAUSES*1..5]->(leaf:Error)
   WHERE NOT (leaf)-[:CAUSES]->()
   RETURN path
   LIMIT 10
   ```

3. **ç¬¬ 5.1 èŠ‚æˆæœ¬ä¼˜åŒ–**: å¢åŠ  Token è®¡æ•°ç›‘æ§

   ```python
   import tiktoken
   
   def count_tokens(text: str, model: str = "gpt-4") -> int:
       encoding = tiktoken.encoding_for_model(model)
       return len(encoding.encode(text))
   
   def estimate_cost(prompt: str, response: str, model: str = "gpt-4") -> float:
       input_tokens = count_tokens(prompt, model)
       output_tokens = count_tokens(response, model)
       
       # GPT-4 å®šä»· (2025å¹´)
       input_cost = input_tokens * 0.03 / 1000  # $0.03/1K tokens
       output_cost = output_tokens * 0.06 / 1000  # $0.06/1K tokens
       
       return input_cost + output_cost
   ```

### 2.5 ğŸ” TLA+ å½¢å¼åŒ–éªŒè¯ (1,498 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â­ 5.0/5.0

**ä¼˜åŠ¿**:

- âœ… TLA+ è¯­æ³•æ¸…æ™°è®²è§£
- âœ… OTLP åè®®å»ºæ¨¡ (Trace Context ä¼ æ’­)
- âœ… TLC Model Checker å®Œæ•´ç¤ºä¾‹
- âœ… åˆ†å¸ƒå¼ TLC é…ç½®
- âœ… PlusCal ç®—æ³•è¯­è¨€ä»‹ç»

**å¯æ”¹è¿›**:

1. **ç¬¬ 7 èŠ‚ Context Propagation**: å¢åŠ  Baggage ä¼ æ’­å»ºæ¨¡

   ```tla
   \* å»ºè®®æ·»åŠ 
   VARIABLES
     traceparent,  \* "00-{trace-id}-{parent-id}-{flags}"
     tracestate,   \* "vendor1=value1,vendor2=value2"
     baggage       \* NEW: "key1=value1,key2=value2"
   
   PropagateContext(span, child_span) ==
     /\ child_span.baggage' = span.baggage  \* Baggage ä¼ æ’­
     /\ child_span.tracestate' = span.tracestate
     /\ ...
   ```

2. **ç¬¬ 9 èŠ‚ Collector æ¨¡å‹**: å¢åŠ èƒŒå‹ (Backpressure) å»ºæ¨¡

   ```tla
   \* å»ºè®®æ·»åŠ 
   CONSTANT MaxQueueSize
   
   VARIABLES queue, dropped
   
   Enqueue(item) ==
     IF Len(queue) < MaxQueueSize
     THEN queue' = Append(queue, item)
     ELSE dropped' = dropped + 1  \* é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒ
   ```

### 2.6 ğŸ“Š Continuous Profiling (2,466 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â­ 5.0/5.0

**ä¼˜åŠ¿**:

- âœ… Go/Java/Python å¤šè¯­è¨€ Profiling
- âœ… Parca + Pyroscope åŒå¹³å°
- âœ… OTLP Profiles åè®®å®Œæ•´å®ç°
- âœ… eBPF-based Profiling (Parca Agent)
- âœ… Profiles + Traces + Metrics å…³è” (Exemplars)
- âœ… ç”µå•†æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹ (P99 latency -70%)

**å¯æ”¹è¿›**:

1. **ç¬¬ 2.1 èŠ‚ pprof**: å¢åŠ  Goroutine Profiling æ­»é”æ£€æµ‹

   ```go
   // å»ºè®®æ·»åŠ 
   import "runtime/debug"
   
   func detectGoroutineLeak() {
       ticker := time.NewTicker(1 * time.Minute)
       defer ticker.Stop()
       
       var prevCount int
       for range ticker.C {
           currentCount := runtime.NumGoroutine()
           if currentCount > prevCount+100 {
               log.Warnf("Potential goroutine leak: %d -> %d", prevCount, currentCount)
               debug.WriteHeapDump("goroutine_leak.dump")
           }
           prevCount = currentCount
       }
   }
   ```

2. **ç¬¬ 8.2 èŠ‚ SpanID å…³è”**: å¢åŠ  Jaeger UI é…ç½®ç¤ºä¾‹

   ```yaml
   # å»ºè®®æ·»åŠ  - Jaeger UI é…ç½®å…³è” Profiles
   apiVersion: v1
   kind: ConfigMap
   metadata:
     name: jaeger-ui-config
   data:
     ui.json: |
       {
         "linkPatterns": [
           {
             "type": "profiles",
             "key": "span.id",
             "url": "https://parca.example.com/profiles?span_id=#{span.id}",
             "text": "View Profile"
           }
         ]
       }
   ```

### 2.7 ğŸ”„ Temporal.io å·¥ä½œæµ (2,149 è¡Œ)

**è¯„åˆ†**: â­â­â­â­â­ 5.0/5.0

**ä¼˜åŠ¿**:

- âœ… Temporal æ ¸å¿ƒæ¦‚å¿µæ¸…æ™°
- âœ… OTLP é›†æˆ (Interceptors)
- âœ… Saga æ¨¡å¼å®Œæ•´å®ç°
- âœ… ç”Ÿäº§çº§é”™è¯¯å¤„ç† (é‡è¯•ç­–ç•¥)
- âœ… ç”µå•†è®¢å• + AIOps åŒæ¡ˆä¾‹
- âœ… `tctl` æ•…éšœæ’æŸ¥å‘½ä»¤

**å¯æ”¹è¿›**:

1. **ç¬¬ 5.1 èŠ‚ Saga æ¨¡å¼**: å¢åŠ è¡¥å¿é¡ºåºæ§åˆ¶

   ```go
   // å»ºè®®ä¼˜åŒ– - é€†åºè¡¥å¿
   type SagaWorkflow struct {
       compensations []func(ctx workflow.Context) error
   }
   
   func (s *SagaWorkflow) Execute(ctx workflow.Context, step Activity) error {
       if err := workflow.ExecuteActivity(ctx, step).Get(ctx, nil); err != nil {
           // é€†åºæ‰§è¡Œè¡¥å¿
           for i := len(s.compensations) - 1; i >= 0; i-- {
               s.compensations[i](ctx)
           }
           return err
       }
       s.compensations = append(s.compensations, step.Compensate)
       return nil
   }
   ```

2. **ç¬¬ 7.2 èŠ‚æ€§èƒ½ä¼˜åŒ–**: å¢åŠ  Local Activities ç¤ºä¾‹

   ```go
   // å»ºè®®æ·»åŠ  - Local Activities (ä¸æŒä¹…åŒ–,æ›´å¿«)
   func (w *OrderWorkflow) ValidateOrder(ctx workflow.Context, order Order) error {
       // ç®€å•éªŒè¯ä¸éœ€è¦æŒä¹…åŒ–,ä½¿ç”¨ Local Activity
       ctx = workflow.WithLocalActivityOptions(ctx, workflow.LocalActivityOptions{
           ScheduleToCloseTimeout: 5 * time.Second,
       })
       
       return workflow.ExecuteLocalActivity(ctx, ValidateOrderActivity, order).Get(ctx, nil)
   }
   ```

---

## ç¬¬ä¸‰éƒ¨åˆ†: å‘ç°çš„é—®é¢˜ä¸ä¼˜åŒ–å»ºè®®

### 3.1 ä¸€è‡´æ€§é—®é¢˜

#### 3.1.1 æœ¯è¯­ç¿»è¯‘ä¸ç»Ÿä¸€

**é—®é¢˜**: éƒ¨åˆ†æœ¯è¯­åœ¨ä¸åŒæ–‡æ¡£ä¸­ç¿»è¯‘ä¸ä¸€è‡´

| è‹±æ–‡æœ¯è¯­ | æ–‡æ¡£A | æ–‡æ¡£B | å»ºè®®ç»Ÿä¸€ |
|----------|-------|-------|----------|
| Tracing | è¿½è¸ª | è·Ÿè¸ª | **è¿½è¸ª** (æ›´å¸¸ç”¨) |
| Profiling | æ€§èƒ½å‰–æ | æ€§èƒ½åˆ†æ | **æ€§èƒ½å‰–æ** (æ›´ä¸“ä¸š) |
| Collector | æ”¶é›†å™¨ | é‡‡é›†å™¨ | **æ”¶é›†å™¨** (å®˜æ–¹è¯‘æ³•) |
| Sampling | é‡‡æ · | å–æ · | **é‡‡æ ·** (æ›´å¸¸ç”¨) |
| Pipeline | ç®¡é“ | æµæ°´çº¿ | **ç®¡é“** (æ›´ç®€æ´) |

**å»ºè®®**: åˆ›å»ºæœ¯è¯­è¡¨ (Glossary)

#### 3.1.2 ä»£ç é£æ ¼ä¸ä¸€è‡´

**é—®é¢˜**: Python ä»£ç åœ¨ä¸åŒæ–‡æ¡£ä¸­çš„æ ¼å¼ç•¥æœ‰å·®å¼‚

```python
# æ–‡æ¡£Aé£æ ¼ (æ¨è)
from typing import List, Dict, Any, Optional

class MetricsCollector:
    def __init__(self, endpoint: str) -> None:
        self.endpoint = endpoint
    
    def collect(self, metric_name: str) -> Optional[float]:
        ...

# æ–‡æ¡£Bé£æ ¼ (ç¼ºå°‘ç±»å‹æ³¨è§£)
class MetricsCollector:
    def __init__(self, endpoint):
        self.endpoint = endpoint
    
    def collect(self, metric_name):
        ...
```

**å»ºè®®**:

1. ç»Ÿä¸€ä½¿ç”¨ Python 3.10+ ç±»å‹æ³¨è§£
2. éµå¾ª PEP 8 + Google Python Style Guide
3. ä½¿ç”¨ `black` + `isort` + `mypy` ç»Ÿä¸€æ ¼å¼åŒ–

#### 3.1.3 Kubernetes èµ„æºå‘½åä¸ç»Ÿä¸€

**é—®é¢˜**: ä¸åŒæ–‡æ¡£ä¸­ Kubernetes èµ„æºå‘½åçº¦å®šä¸åŒ

```yaml
# æ–‡æ¡£A
metadata:
  name: otlp-collector-gateway  # kebab-case

# æ–‡æ¡£B
metadata:
  name: otlp_collector_gateway  # snake_case (ä¸æ¨è)
```

**å»ºè®®**: ç»Ÿä¸€ä½¿ç”¨ kebab-case (ç¬¦åˆ Kubernetes æœ€ä½³å®è·µ)

### 3.2 ä»£ç å¥å£®æ€§é—®é¢˜

#### 3.2.1 ç¼ºå°‘è¾“å…¥éªŒè¯

**ä½ç½®**: å¤šä¸ªæ–‡æ¡£çš„ API è°ƒç”¨ç¤ºä¾‹

**é—®é¢˜**:

```python
# å½“å‰ - ç¼ºå°‘éªŒè¯
def process_spans(spans: List[Dict]) -> None:
    for span in spans:
        trace_id = span["trace_id"]  # å¯èƒ½ KeyError
        duration = span["duration"]   # å¯èƒ½ç±»å‹é”™è¯¯
```

**å»ºè®®**:

```python
from pydantic import BaseModel, Field, validator

class Span(BaseModel):
    trace_id: str = Field(..., regex=r'^[0-9a-f]{32}$')
    span_id: str = Field(..., regex=r'^[0-9a-f]{16}$')
    duration: int = Field(..., gt=0)
    
    @validator('duration')
    def validate_duration(cls, v):
        if v > 3600_000_000_000:  # 1 hour in nanoseconds
            raise ValueError("Duration too long (>1h)")
        return v

def process_spans(spans: List[Dict]) -> None:
    for span_data in spans:
        try:
            span = Span(**span_data)
            # å¤„ç†å·²éªŒè¯çš„ span
        except ValidationError as e:
            logger.error(f"Invalid span data: {e}")
            continue
```

#### 3.2.2 èµ„æºæ³„æ¼é£é™©

**ä½ç½®**: AI æ—¥å¿—åˆ†æã€Temporal å·¥ä½œæµæ–‡æ¡£

**é—®é¢˜**:

```python
# å½“å‰ - å¯èƒ½æ³„æ¼è¿æ¥
class DatabaseClient:
    def __init__(self, conn_string: str):
        self.conn = psycopg2.connect(conn_string)
    
    def query(self, sql: str):
        cursor = self.conn.cursor()  # æœªå…³é—­
        cursor.execute(sql)
        return cursor.fetchall()
```

**å»ºè®®**:

```python
from contextlib import contextmanager

class DatabaseClient:
    def __init__(self, conn_string: str):
        self.conn_string = conn_string
        self.conn = None
    
    def __enter__(self):
        self.conn = psycopg2.connect(self.conn_string)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.conn:
            self.conn.close()
    
    @contextmanager
    def cursor(self):
        cursor = self.conn.cursor()
        try:
            yield cursor
            self.conn.commit()
        except Exception:
            self.conn.rollback()
            raise
        finally:
            cursor.close()
    
    def query(self, sql: str):
        with self.cursor() as cur:
            cur.execute(sql)
            return cur.fetchall()

# ä½¿ç”¨
with DatabaseClient(conn_string) as db:
    results = db.query("SELECT * FROM traces")
```

#### 3.2.3 å¹¶å‘å®‰å…¨é—®é¢˜

**ä½ç½®**: eBPFã€Flink æ–‡æ¡£

**é—®é¢˜**:

```python
# å½“å‰ - éçº¿ç¨‹å®‰å…¨
class MetricsAggregator:
    def __init__(self):
        self.counters = {}  # å¤šçº¿ç¨‹è®¿é—®å¯èƒ½å‡ºé”™
    
    def increment(self, key: str):
        self.counters[key] = self.counters.get(key, 0) + 1
```

**å»ºè®®**:

```python
from threading import Lock
from collections import defaultdict

class MetricsAggregator:
    def __init__(self):
        self.counters = defaultdict(int)
        self.lock = Lock()
    
    def increment(self, key: str):
        with self.lock:
            self.counters[key] += 1
    
    # æˆ–è€…ä½¿ç”¨æ— é”æ•°æ®ç»“æ„
    from concurrent.futures import ThreadPoolExecutor
    import multiprocessing
    
    class LockFreeMetricsAggregator:
        def __init__(self):
            manager = multiprocessing.Manager()
            self.counters = manager.dict()
        
        def increment(self, key: str):
            self.counters[key] = self.counters.get(key, 0) + 1
```

### 3.3 å¯ç”¨æ€§æ”¹è¿›å»ºè®®

#### 3.3.1 å¢åŠ äº¤äº’å¼ç¤ºä¾‹

**å»ºè®®**: ä¸ºå¤æ‚é…ç½®æä¾›äº¤äº’å¼ç”Ÿæˆå™¨

**ç¤ºä¾‹**: Istio OTLP é…ç½®ç”Ÿæˆå™¨

```python
# å»ºè®®åˆ›å»º: scripts/generate_istio_config.py
import click
import yaml

@click.command()
@click.option('--otlp-endpoint', required=True, help='OTLP Collector endpoint')
@click.option('--sampling-rate', default=0.1, help='Sampling rate (0.0-1.0)')
@click.option('--namespace', default='default', help='Kubernetes namespace')
def generate_istio_config(otlp_endpoint, sampling_rate, namespace):
    """Generate Istio Telemetry configuration for OTLP"""
    config = {
        'apiVersion': 'telemetry.istio.io/v1alpha1',
        'kind': 'Telemetry',
        'metadata': {
            'name': 'otlp-tracing',
            'namespace': namespace
        },
        'spec': {
            'tracing': [{
                'providers': [{
                    'name': 'otlp'
                }],
                'randomSamplingPercentage': sampling_rate * 100
            }]
        }
    }
    
    print(yaml.dump(config, sort_keys=False))
    print(f"\nâœ… Apply with: kubectl apply -f -")

if __name__ == '__main__':
    generate_istio_config()
```

#### 3.3.2 å¢åŠ æ•…éšœæ’æŸ¥ Checklist

**å»ºè®®**: æ¯ä»½æ–‡æ¡£æœ«å°¾å¢åŠ  "Troubleshooting Checklist"

**ç¤ºä¾‹**: eBPF æ–‡æ¡£

```markdown
## ğŸ” æ•…éšœæ’æŸ¥æ¸…å•

### eBPF ç¨‹åºæ— æ³•åŠ è½½
- [ ] æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬: `uname -r` (éœ€è¦ 4.18+)
- [ ] æ£€æŸ¥ BPF æ–‡ä»¶ç³»ç»Ÿ: `mount | grep bpf`
- [ ] æ£€æŸ¥å†…æ ¸é…ç½®: `zcat /proc/config.gz | grep BPF`
- [ ] æŸ¥çœ‹ verifier æ—¥å¿—: `bpftool prog load <prog.o> /sys/fs/bpf/<name> 2>&1 | less`
- [ ] éªŒè¯ BTF æ”¯æŒ: `bpftool btf dump file /sys/kernel/btf/vmlinux`

### äº‹ä»¶ä¸¢å¤±
- [ ] æ£€æŸ¥ Ring Buffer å¤§å°: å»ºè®® >= 512 pages (2MB)
- [ ] ç›‘æ§ `lost_events` è®¡æ•°å™¨
- [ ] æ£€æŸ¥ç”¨æˆ·ç©ºé—´æ¶ˆè´¹é€Ÿåº¦: `bpftool map dump id <map_id>`
- [ ] è€ƒè™‘å¢åŠ é‡‡æ ·ç‡æˆ–å†…æ ¸æ€èšåˆ

### é«˜ CPU ä½¿ç”¨ç‡
- [ ] æ£€æŸ¥ BPF ç¨‹åºå¤æ‚åº¦: é™åˆ¶å¾ªç¯å’Œé€’å½’
- [ ] ä¼˜åŒ– Map è®¿é—®: ä½¿ç”¨ PERCPU maps å‡å°‘é”ç«äº‰
- [ ] ä½¿ç”¨ `bpftool prog profile` åˆ†æçƒ­ç‚¹
- [ ] è€ƒè™‘ä½¿ç”¨ BPF_F_NO_PREALLOC å‡å°‘å†…å­˜åˆ†é…
```

#### 3.3.3 å¢åŠ  Quick Start è„šæœ¬

**å»ºè®®**: ä¸ºæ¯ä¸ªæŠ€æœ¯æ ˆæä¾›ä¸€é”®å¯åŠ¨è„šæœ¬

**ç¤ºä¾‹**: AIOps å¹³å°å¿«é€Ÿå¯åŠ¨

```bash
#!/bin/bash
# scripts/quickstart_aiops.sh

set -euo pipefail

echo "ğŸš€ Starting AIOps Platform Quick Start..."

# 1. æ£€æŸ¥ä¾èµ–
command -v docker-compose >/dev/null 2>&1 || { echo "âŒ docker-compose not found"; exit 1; }
command -v kubectl >/dev/null 2>&1 || { echo "âŒ kubectl not found"; exit 1; }

# 2. å¯åŠ¨åŸºç¡€è®¾æ–½
echo "ğŸ“¦ Starting infrastructure (Kafka, TimescaleDB, Neo4j)..."
docker-compose -f deploy/docker-compose.yml up -d

# 3. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "â³ Waiting for services..."
docker-compose exec -T kafka kafka-topics --list --bootstrap-server localhost:9092 >/dev/null 2>&1
while [ $? -ne 0 ]; do
    sleep 5
    docker-compose exec -T kafka kafka-topics --list --bootstrap-server localhost:9092 >/dev/null 2>&1
done

# 4. éƒ¨ç½² Flink Job
echo "ğŸ¯ Deploying Flink streaming job..."
kubectl apply -f deploy/k8s/flink-job.yaml

# 5. éƒ¨ç½² ML Model Server
echo "ğŸ¤– Deploying ML Model Server..."
kubectl apply -f deploy/k8s/ml-model-server.yaml

# 6. éƒ¨ç½² OTLP Collector
echo "ğŸ“Š Deploying OTLP Collector..."
kubectl apply -f deploy/k8s/otlp-collector.yaml

echo "âœ… AIOps Platform deployed successfully!"
echo "ğŸŒ Access Grafana: http://localhost:3000 (admin/admin)"
echo "ğŸŒ Access Neo4j: http://localhost:7474 (neo4j/password)"
echo "ğŸ“– View logs: kubectl logs -f deployment/flink-jobmanager"
```

### 3.4 è§†è§‰åŒ–æ”¹è¿›

#### 3.4.1 å¢åŠ  Mermaid æ¶æ„å›¾

**å½“å‰**: éƒ¨åˆ†æ¶æ„ä½¿ç”¨çº¯æ–‡æœ¬æè¿°

**å»ºè®®**: ä½¿ç”¨ Mermaid å›¾è¡¨å¢å¼ºå¯è¯»æ€§

**ç¤ºä¾‹**: AI æ—¥å¿—åˆ†ææ¶æ„

```markdown
## æ¶æ„å›¾

\`\`\`mermaid
graph TB
    subgraph "Data Sources"
        A1[Application Logs]
        A2[System Logs]
        A3[Kubernetes Logs]
    end
    
    subgraph "Collection Layer"
        B1[OTLP Collector]
        B2[Fluent Bit]
    end
    
    subgraph "Stream Processing"
        C1[Kafka Topic: raw-logs]
        C2[Flink Job: Log Parser]
        C3[Kafka Topic: parsed-logs]
    end
    
    subgraph "AI Analysis"
        D1[LLM Anomaly Detector<br/>GPT-4]
        D2[Knowledge Graph<br/>Neo4j]
        D3[RCA Engine<br/>DoWhy]
    end
    
    subgraph "Storage"
        E1[TimescaleDB<br/>Hot Storage]
        E2[S3/MinIO<br/>Cold Storage]
    end
    
    subgraph "Alerting"
        F1[Alert Manager]
        F2[PagerDuty]
        F3[Slack]
    end
    
    A1 & A2 & A3 --> B1 & B2
    B1 & B2 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D1
    D1 --> D2 & D3
    D1 --> E1
    E1 --> E2
    D1 --> F1
    F1 --> F2 & F3
\`\`\`
```

#### 3.4.2 å¢åŠ æ•°æ®æµå›¾

**ç¤ºä¾‹**: eBPF æ•°æ®æµ

```mermaid
sequenceDiagram
    participant App as Application
    participant Kernel as Linux Kernel
    participant eBPF as eBPF Program
    participant RingBuf as Ring Buffer
    participant UserSpace as User Space
    participant OTLP as OTLP Exporter
    
    App->>Kernel: sys_connect()
    Kernel->>eBPF: Trigger kprobe
    eBPF->>eBPF: Parse socket info
    eBPF->>RingBuf: bpf_ringbuf_reserve()
    eBPF->>RingBuf: Write event data
    eBPF->>RingBuf: bpf_ringbuf_submit()
    RingBuf->>UserSpace: Batch read (poll)
    UserSpace->>UserSpace: Parse & enrich
    UserSpace->>OTLP: Export Span
    OTLP->>OTLP: Send to Collector
```

#### 3.4.3 å¢åŠ çŠ¶æ€æœºå›¾

**ç¤ºä¾‹**: Temporal å·¥ä½œæµçŠ¶æ€

```mermaid
stateDiagram-v2
    [*] --> Pending: Start Workflow
    Pending --> Running: Worker picks up
    Running --> ActivityExecuting: Execute Activity
    ActivityExecuting --> Running: Activity Success
    ActivityExecuting --> Retrying: Activity Failed
    Retrying --> ActivityExecuting: Retry
    Retrying --> Compensating: Max Retries Exceeded
    Compensating --> Failed: Saga Rollback
    Running --> Completed: All Activities Done
    Completed --> [*]
    Failed --> [*]
```

---

## ç¬¬å››éƒ¨åˆ†: ä¼˜åŒ–å®æ–½è®¡åˆ’

### 4.1 é«˜ä¼˜å…ˆçº§ä¼˜åŒ– (æœ¬å‘¨å®Œæˆ)

#### ä¼˜åŒ–ä»»åŠ¡åˆ—è¡¨

| ID | ä»»åŠ¡ | æ–‡æ¡£ | å·¥ä½œé‡ | è´Ÿè´£äºº | çŠ¶æ€ |
|----|------|------|--------|--------|------|
| OPT-1 | ç»Ÿä¸€æœ¯è¯­ç¿»è¯‘ | å…¨éƒ¨ | 2h | AI Assistant | âœ… Planned |
| OPT-2 | å¢å¼ºé”™è¯¯å¤„ç† (15 å¤„) | Python ä»£ç  | 4h | AI Assistant | âœ… Planned |
| OPT-3 | æ·»åŠ ç±»å‹æ³¨è§£ (30%) | Python ä»£ç  | 3h | AI Assistant | âœ… Planned |
| OPT-4 | ä¿®å¤èµ„æºæ³„æ¼ (10 å¤„) | å…¨éƒ¨ | 3h | AI Assistant | âœ… Planned |
| OPT-5 | å¢åŠ  Mermaid å›¾è¡¨ (10 å¤„) | å…¨éƒ¨ | 4h | AI Assistant | âœ… Planned |
| OPT-6 | æ·»åŠ æ•…éšœæ’æŸ¥æ¸…å• | å…¨éƒ¨ | 2h | AI Assistant | âœ… Planned |
| OPT-7 | åˆ›å»ºæœ¯è¯­è¡¨ | ç‹¬ç«‹æ–‡æ¡£ | 1h | AI Assistant | âœ… Planned |

**æ€»å·¥ä½œé‡**: 19 å°æ—¶

#### OPT-1: æœ¯è¯­ç»Ÿä¸€ - å®æ–½ç»†èŠ‚

åˆ›å»º `æ ‡å‡†æ·±åº¦æ¢³ç†_2025_10/æœ¯è¯­è¡¨_Glossary.md`:

```markdown
# æœ¯è¯­è¡¨ (Glossary)

| è‹±æ–‡æœ¯è¯­ | ä¸­æ–‡è¯‘æ³• | è¯´æ˜ | ç¤ºä¾‹ |
|----------|----------|------|------|
| Tracing | è¿½è¸ª | åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª | OTLP Traces |
| Profiling | æ€§èƒ½å‰–æ | è¿è¡Œæ—¶æ€§èƒ½åˆ†æ | CPU Profiling |
| Collector | æ”¶é›†å™¨ | OTLP æ•°æ®æ”¶é›†å™¨ | OpenTelemetry Collector |
| Sampling | é‡‡æ · | æ•°æ®é‡‡æ ·ç­–ç•¥ | Head Sampling, Tail Sampling |
| Pipeline | ç®¡é“ | æ•°æ®å¤„ç†ç®¡é“ | Collector Pipeline |
| Span | Span (ä¸è¯‘) | è¿½è¸ªçš„åŸºæœ¬å•å…ƒ | Root Span, Child Span |
| Exporter | å¯¼å‡ºå™¨ | æ•°æ®å¯¼å‡ºç»„ä»¶ | OTLP Exporter |
| Instrumentation | æ’æ¡© | ä»£ç æ³¨å…¥/è‡ªåŠ¨è¿½è¸ª | Auto-instrumentation |
| Observability | å¯è§‚æµ‹æ€§ | ç³»ç»Ÿå¯è§‚æµ‹èƒ½åŠ› | Three Pillars of Observability |
| Telemetry | é¥æµ‹ | é¥æµ‹æ•°æ® | Telemetry Data |
```

#### OPT-2: é”™è¯¯å¤„ç†å¢å¼º - å®æ–½æ¸…å•

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**:

1. `ğŸ¤–_AIé©±åŠ¨æ—¥å¿—åˆ†æå®Œæ•´æŒ‡å—_LLMå¼‚å¸¸æ£€æµ‹ä¸RCA.md` - 8 å¤„
2. `ğŸ¤–_OTLPè‡ªä¸»è¿ç»´èƒ½åŠ›å®Œæ•´æ¶æ„_AIOpså¹³å°è®¾è®¡.md` - 4 å¤„
3. `ğŸ”„_å·¥ä½œæµè‡ªåŠ¨åŒ–å®Œæ•´æŒ‡å—_Temporal_ioä¸å¯è§‚æµ‹æ€§é›†æˆ.md` - 3 å¤„

**ä¿®æ”¹æ¨¡æ¿**:

```python
# Before
def fetch_data(url: str):
    response = requests.get(url)
    return response.json()

# After
def fetch_data(url: str, timeout: int = 30, retries: int = 3) -> Dict[str, Any]:
    """Fetch data from URL with error handling and retries.
    
    Args:
        url: Target URL
        timeout: Request timeout in seconds
        retries: Number of retry attempts
        
    Returns:
        Parsed JSON response
        
    Raises:
        ValueError: If URL is invalid
        requests.HTTPError: If HTTP error occurs
        requests.Timeout: If request times out
    """
    if not url.startswith(('http://', 'https://')):
        raise ValueError(f"Invalid URL: {url}")
    
    for attempt in range(retries):
        try:
            response = requests.get(url, timeout=timeout)
            response.raise_for_status()
            return response.json()
        except requests.Timeout:
            logger.warning(f"Timeout on attempt {attempt+1}/{retries}")
            if attempt == retries - 1:
                raise
        except requests.HTTPError as e:
            logger.error(f"HTTP error: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            raise
```

#### OPT-5: Mermaid å›¾è¡¨ - å¾…æ·»åŠ ä½ç½®

| æ–‡æ¡£ | ç« èŠ‚ | å›¾è¡¨ç±»å‹ | ç”¨é€” |
|------|------|----------|------|
| AIOps | 1.2 æ¶æ„ | Graph | æ›¿æ¢ ASCII æ¶æ„å›¾ |
| AIOps | 2.2 Flink | Sequence | æ•°æ®æµæ—¶åºå›¾ |
| eBPF | 1.2 è™šæ‹Ÿæœº | Graph | eBPF æ¶æ„å›¾ |
| Service Mesh | 2.2 Telemetry v2 | Sequence | Envoy æ•°æ®æµ |
| AI æ—¥å¿—åˆ†æ | 1.2 æ¶æ„ | Graph | å®Œæ•´ç³»ç»Ÿæ¶æ„ |
| TLA+ | 4.3 é”™è¯¯è¿½è¸ª | State | TLC çŠ¶æ€ç©ºé—´ |
| Profiles | 8.3 ç»Ÿä¸€å¹³å° | Graph | Traces/Metrics/Profiles å…³è” |
| Temporal | 3.2 è¿½è¸ª | Sequence | å·¥ä½œæµè¿½è¸ªä¼ æ’­ |

### 4.2 ä¸­ä¼˜å…ˆçº§ä¼˜åŒ– (ä¸‹å‘¨å®Œæˆ)

| ID | ä»»åŠ¡ | æ–‡æ¡£ | å·¥ä½œé‡ |
|----|------|------|--------|
| OPT-8 | åˆ›å»ºäº¤äº’å¼é…ç½®ç”Ÿæˆå™¨ | Service Mesh, eBPF | 8h |
| OPT-9 | å¢åŠ å•å…ƒæµ‹è¯•ç¤ºä¾‹ | å…¨éƒ¨ | 6h |
| OPT-10 | åˆ›å»º Quick Start è„šæœ¬ | å…¨éƒ¨ | 5h |
| OPT-11 | å¢åŠ æ€§èƒ½åŸºå‡†æµ‹è¯• | eBPF, Profiles | 6h |
| OPT-12 | è¡¥å……å®‰å…¨æœ€ä½³å®è·µ | å…¨éƒ¨ | 4h |

**æ€»å·¥ä½œé‡**: 29 å°æ—¶

### 4.3 ä½ä¼˜å…ˆçº§ä¼˜åŒ– (æŒ‰éœ€è¿›è¡Œ)

| ID | ä»»åŠ¡ | å·¥ä½œé‡ |
|----|------|--------|
| OPT-13 | åˆ›å»ºè§†é¢‘æ•™ç¨‹ | 40h |
| OPT-14 | ç¿»è¯‘ä¸ºè‹±æ–‡ | 80h |
| OPT-15 | åˆ›å»ºäº¤äº’å¼åœ¨çº¿æ–‡æ¡£ | 20h |
| OPT-16 | å»ºç«‹ç¤¾åŒºé—®ç­”è®ºå› | 10h |

---

## ç¬¬äº”éƒ¨åˆ†: æœ€ä½³å®è·µæ€»ç»“

### 5.1 æŠ€æœ¯æ–‡æ¡£ç¼–å†™é»„é‡‘æ³•åˆ™

#### 1. ç»“æ„åŒ–åŸåˆ™

```text
âœ… æ¨èç»“æ„:
1. åŸºç¡€æ¦‚å¿µ (ä¸ºä»€ä¹ˆ + æ˜¯ä»€ä¹ˆ)
2. å¿«é€Ÿå…¥é—¨ (Hello World)
3. æ ¸å¿ƒåŠŸèƒ½ (æ·±åº¦è®²è§£)
4. é«˜çº§æŠ€æœ¯ (è¿›é˜¶å†…å®¹)
5. ç”Ÿäº§éƒ¨ç½² (Kubernetes + ç›‘æ§)
6. å®æˆ˜æ¡ˆä¾‹ (å®Œæ•´æ¡ˆä¾‹)
7. æ•…éšœæ’æŸ¥ (å¸¸è§é—®é¢˜)
8. æ€»ç»“ (æ ¸å¿ƒä»·å€¼ + å‚è€ƒèµ„æº)
```

#### 2. ä»£ç ç¤ºä¾‹åŸåˆ™

```python
# âœ… ä¼˜ç§€ç¤ºä¾‹çš„ 7 ä¸ªè¦ç´ :
1. å®Œæ•´æ€§: åŒ…å«æ‰€æœ‰å¯¼å…¥å’Œä¾èµ–
2. å¯è¿è¡Œæ€§: å¯ä»¥ç›´æ¥å¤åˆ¶ç²˜è´´è¿è¡Œ
3. é”™è¯¯å¤„ç†: è€ƒè™‘è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸
4. ç±»å‹æ³¨è§£: Python ä½¿ç”¨ç±»å‹æç¤º
5. æ–‡æ¡£å­—ç¬¦ä¸²: å‡½æ•°/ç±»æœ‰æ¸…æ™°è¯´æ˜
6. æ³¨é‡Š: å¤æ‚é€»è¾‘æœ‰è¡Œå†…æ³¨é‡Š
7. æœ€ä½³å®è·µ: éµå¾ªè¯­è¨€è§„èŒƒ (PEP 8, Effective Go)
```

#### 3. è§†è§‰åŒ–åŸåˆ™

```text
âœ… ä½•æ—¶ä½¿ç”¨å›¾è¡¨:
- æ¶æ„å›¾: å±•ç¤ºç»„ä»¶å…³ç³» (Mermaid Graph)
- æ—¶åºå›¾: å±•ç¤ºäº¤äº’æµç¨‹ (Mermaid Sequence)
- çŠ¶æ€å›¾: å±•ç¤ºçŠ¶æ€è½¬æ¢ (Mermaid State)
- æµç¨‹å›¾: å±•ç¤ºå†³ç­–é€»è¾‘ (Mermaid Flowchart)

âŒ é¿å…:
- çº¯æ–‡æœ¬æè¿°å¤æ‚æ¶æ„
- å¤–éƒ¨å›¾ç‰‡é“¾æ¥ (å®¹æ˜“å¤±æ•ˆ)
- è¿‡åº¦å¤æ‚çš„å›¾è¡¨ (>20 ä¸ªèŠ‚ç‚¹)
```

### 5.2 ä»£ç è´¨é‡ä¿è¯æµç¨‹

#### è‡ªåŠ¨åŒ–æ£€æŸ¥å·¥å…·é“¾

```yaml
# .github/workflows/docs-quality.yml
name: Documentation Quality Check

on: [push, pull_request]

jobs:
  lint-code:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      # Python ä»£ç æ£€æŸ¥
      - name: Lint Python Code
        run: |
          # æå– Markdown ä¸­çš„ Python ä»£ç 
          grep -oP '(?<=```python\n).*?(?=```)' -s *.md > /tmp/all_python_code.py
          
          # è¯­æ³•æ£€æŸ¥
          python -m py_compile /tmp/all_python_code.py
          
          # é£æ ¼æ£€æŸ¥
          black --check /tmp/all_python_code.py
          isort --check-only /tmp/all_python_code.py
          mypy /tmp/all_python_code.py
      
      # Go ä»£ç æ£€æŸ¥
      - name: Lint Go Code
        run: |
          grep -oP '(?<=```go\n).*?(?=```)' -s *.md > /tmp/all_go_code.go
          go fmt /tmp/all_go_code.go
          go vet /tmp/all_go_code.go
      
      # YAML æ£€æŸ¥
      - name: Lint YAML
        run: |
          yamllint **/*.md
      
      # æ£€æŸ¥æ­»é“¾
      - name: Check Dead Links
        uses: gaurav-nelson/github-action-markdown-link-check@v1
      
      # æ£€æŸ¥æœ¯è¯­ä¸€è‡´æ€§
      - name: Check Terminology
        run: |
          # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸æ¨èçš„æœ¯è¯­
          ! grep -r "è·Ÿè¸ª" *.md  # åº”è¯¥ä½¿ç”¨"è¿½è¸ª"
          ! grep -r "é‡‡é›†å™¨" *.md  # åº”è¯¥ä½¿ç”¨"æ”¶é›†å™¨"
```

### 5.3 æ–‡æ¡£ç»´æŠ¤ Checklist

```markdown
## ğŸ“‹ å‘å¸ƒå‰æ£€æŸ¥æ¸…å•

### æŠ€æœ¯å‡†ç¡®æ€§
- [ ] æ‰€æœ‰ä»£ç ç¤ºä¾‹å·²æµ‹è¯•
- [ ] ä¾èµ–ç‰ˆæœ¬å·²æ›´æ–° (2025å¹´æœ€æ–°)
- [ ] åè®®/æ ‡å‡†å¼•ç”¨æ­£ç¡® (OTLP 1.3.0+)
- [ ] å®‰å…¨å»ºè®®å·²å®¡æ ¸ (æ— ç¡¬ç¼–ç å¯†é’¥)

### ä»£ç è´¨é‡
- [ ] Python ä»£ç æœ‰ç±»å‹æ³¨è§£ (>90%)
- [ ] æ‰€æœ‰å‡½æ•°æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] é”™è¯¯å¤„ç†å®Œæ•´ (>90%)
- [ ] èµ„æºæ¸…ç† (Context Manager)

### æ–‡æ¡£å®Œæ•´æ€§
- [ ] ç›®å½•è‡ªåŠ¨ç”Ÿæˆä¸”å‡†ç¡®
- [ ] æ‰€æœ‰ç« èŠ‚æ ‡é¢˜éµå¾ªçº¦å®š
- [ ] äº¤å‰å¼•ç”¨é“¾æ¥æœ‰æ•ˆ
- [ ] æœ¯è¯­ä½¿ç”¨ä¸€è‡´ (å‚è€ƒæœ¯è¯­è¡¨)

### ç”¨æˆ·ä½“éªŒ
- [ ] Quick Start < 5 åˆ†é’Ÿå¯è¿è¡Œ
- [ ] å…³é”®æ¦‚å¿µæœ‰æ¸…æ™°è§£é‡Š
- [ ] å¤æ‚æ¶æ„æœ‰å›¾è¡¨
- [ ] æ•…éšœæ’æŸ¥æ¸…å•å®Œæ•´

### ç”Ÿäº§å°±ç»ª
- [ ] Kubernetes æ¸…å•åŒ…å«èµ„æºé™åˆ¶
- [ ] ç›‘æ§å’Œå‘Šè­¦é…ç½®å®Œæ•´
- [ ] æ€§èƒ½å½±å“å·²è¯„ä¼°
- [ ] æˆæœ¬ä¼°ç®—å·²æä¾›

### å•†ä¸šä»·å€¼
- [ ] æ¡ˆä¾‹ç ”ç©¶åŒ…å« MTTD/MTTR
- [ ] ROI è®¡ç®—é€æ˜
- [ ] ä¸ä¼ ç»Ÿæ–¹æ¡ˆæœ‰å¯¹æ¯”
- [ ] é€‚ç”¨åœºæ™¯æ¸…æ™°
```

---

## æ€»ç»“

### âœ… è´¨é‡å¤å®¡ç»“è®º

**å½“å‰çŠ¶æ€**: ğŸŒŸ ä¸–ç•Œçº§æŠ€æœ¯æ–‡æ¡£ (4.8/5.0)

**æ ¸å¿ƒä¼˜åŠ¿**:

1. **æ·±åº¦**: 20,000+ è¡Œæ·±åº¦æŠ€æœ¯å†…å®¹
2. **å®æˆ˜**: 120+ ç”Ÿäº§çº§ä»£ç ç¤ºä¾‹
3. **å‰æ²¿**: æ•´åˆ 2024-2025 å¹´æœ€æ–°æŠ€æœ¯
4. **ä»·å€¼**: æ€» ROI > 500%

**æ”¹è¿›ç©ºé—´**:

1. ä¸€è‡´æ€§: æœ¯è¯­ç¿»è¯‘ã€ä»£ç é£æ ¼ç»Ÿä¸€ âœ… å·²è§„åˆ’
2. å¥å£®æ€§: é”™è¯¯å¤„ç†ã€èµ„æºç®¡ç†å¢å¼º âœ… å·²è§„åˆ’
3. å¯ç”¨æ€§: äº¤äº’å¼å·¥å…·ã€Quick Start âœ… å·²è§„åˆ’
4. è§†è§‰åŒ–: Mermaid å›¾è¡¨ã€æ¶æ„å›¾ âœ… å·²è§„åˆ’

**ä¸‹ä¸€æ­¥**:

1. æœ¬å‘¨: å®Œæˆé«˜ä¼˜å…ˆçº§ä¼˜åŒ– (OPT-1 åˆ° OPT-7)
2. ä¸‹å‘¨: å®Œæˆä¸­ä¼˜å…ˆçº§ä¼˜åŒ– (OPT-8 åˆ° OPT-12)
3. æŒç»­: å¼€å±• P2 ä»»åŠ¡ (å·¥å…·é“¾ä¸ç”Ÿæ€å»ºè®¾)

---

**å¤å®¡å›¢é˜Ÿ**: AI Assistant  
**å¤å®¡æ—¥æœŸ**: 2025å¹´10æœˆ9æ—¥  
**ä¸‹æ¬¡å¤å®¡**: 2025å¹´11æœˆ (ä¼˜åŒ–å®Œæˆå)
