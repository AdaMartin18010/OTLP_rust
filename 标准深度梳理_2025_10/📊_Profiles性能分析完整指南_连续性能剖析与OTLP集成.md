# ğŸ“Š Profiles æ€§èƒ½åˆ†æå®Œæ•´æŒ‡å— - è¿ç»­æ€§èƒ½å‰–æä¸ OTLP é›†æˆ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ9æ—¥  
> **æ–‡æ¡£ç±»å‹**: P1 ä¼˜å…ˆçº§ - Profiles ä¿¡å·æ·±åº¦æŒ‡å—  
> **é¢„ä¼°ç¯‡å¹…**: 2,500+ è¡Œ  
> **ç›®æ ‡**: æŒæ¡ Continuous Profiling ä¸ OTLP Profiles ä¿¡å·

---

## ğŸ“‹ ç›®å½•

- [ğŸ“Š Profiles æ€§èƒ½åˆ†æå®Œæ•´æŒ‡å— - è¿ç»­æ€§èƒ½å‰–æä¸ OTLP é›†æˆ](#-profiles-æ€§èƒ½åˆ†æå®Œæ•´æŒ‡å—---è¿ç»­æ€§èƒ½å‰–æä¸-otlp-é›†æˆ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ç¬¬ä¸€éƒ¨åˆ†: Profiling åŸºç¡€](#ç¬¬ä¸€éƒ¨åˆ†-profiling-åŸºç¡€)
    - [1.1 ä»€ä¹ˆæ˜¯ Profiling?](#11-ä»€ä¹ˆæ˜¯-profiling)
      - [ä¼ ç»Ÿ Profiling vs Continuous Profiling](#ä¼ ç»Ÿ-profiling-vs-continuous-profiling)
    - [1.2 Profiling æ ¸å¿ƒæ¦‚å¿µ](#12-profiling-æ ¸å¿ƒæ¦‚å¿µ)
    - [1.3 Profiling å·¥å…·ç”Ÿæ€](#13-profiling-å·¥å…·ç”Ÿæ€)
  - [ç¬¬äºŒéƒ¨åˆ†: CPU Profiling æ·±åº¦å®æˆ˜](#ç¬¬äºŒéƒ¨åˆ†-cpu-profiling-æ·±åº¦å®æˆ˜)
    - [2.1 Go pprof å®æˆ˜](#21-go-pprof-å®æˆ˜)
      - [åŸºç¡€ CPU Profiling](#åŸºç¡€-cpu-profiling)
      - [ç”Ÿäº§ç¯å¢ƒæŒç»­ Profiling](#ç”Ÿäº§ç¯å¢ƒæŒç»­-profiling)
    - [2.2 Java JFR (Java Flight Recorder)](#22-java-jfr-java-flight-recorder)
      - [JFR åŸºç¡€ä½¿ç”¨](#jfr-åŸºç¡€ä½¿ç”¨)
      - [JFR é«˜çº§é…ç½®](#jfr-é«˜çº§é…ç½®)
    - [2.3 Python py-spy](#23-python-py-spy)
      - [py-spy ä½¿ç”¨](#py-spy-ä½¿ç”¨)
  - [ç¬¬ä¸‰éƒ¨åˆ†: å†…å­˜ Profiling](#ç¬¬ä¸‰éƒ¨åˆ†-å†…å­˜-profiling)
    - [3.1 Go Heap Profiling](#31-go-heap-profiling)
      - [Heap Profile åˆ†æ](#heap-profile-åˆ†æ)
      - [å†…å­˜æ³„æ¼æ£€æµ‹](#å†…å­˜æ³„æ¼æ£€æµ‹)
    - [3.2 Java Heap Dump åˆ†æ](#32-java-heap-dump-åˆ†æ)
    - [3.3 Allocation Profiling (åˆ†é…è¿½è¸ª)](#33-allocation-profiling-åˆ†é…è¿½è¸ª)
  - [ç¬¬å››éƒ¨åˆ†: Continuous Profiling å¹³å°](#ç¬¬å››éƒ¨åˆ†-continuous-profiling-å¹³å°)
    - [4.1 Parca - å¼€æº Continuous Profiling](#41-parca---å¼€æº-continuous-profiling)
      - [Parca æ¶æ„](#parca-æ¶æ„)
      - [éƒ¨ç½² Parca](#éƒ¨ç½²-parca)
      - [é›†æˆåº”ç”¨](#é›†æˆåº”ç”¨)
    - [4.2 Pyroscope - å¤šè¯­è¨€æ”¯æŒ](#42-pyroscope---å¤šè¯­è¨€æ”¯æŒ)
      - [Pyroscope æ¶æ„](#pyroscope-æ¶æ„)
      - [éƒ¨ç½² Pyroscope](#éƒ¨ç½²-pyroscope)
      - [å¤šè¯­è¨€é›†æˆ](#å¤šè¯­è¨€é›†æˆ)
    - [4.3 Grafana Phlare (ç°å·²åˆå¹¶åˆ° Pyroscope)](#43-grafana-phlare-ç°å·²åˆå¹¶åˆ°-pyroscope)
  - [ç¬¬äº”éƒ¨åˆ†: OTLP Profiles ä¿¡å·](#ç¬¬äº”éƒ¨åˆ†-otlp-profiles-ä¿¡å·)
    - [5.1 OTLP Profiles æ•°æ®æ¨¡å‹](#51-otlp-profiles-æ•°æ®æ¨¡å‹)
      - [Profile æ•°æ®ç»“æ„](#profile-æ•°æ®ç»“æ„)
    - [5.2 OTLP Profiles Exporter](#52-otlp-profiles-exporter)
      - [Go OTLP Profiles Exporter](#go-otlp-profiles-exporter)
    - [5.3 OTLP Collector Profiles æ¥æ”¶](#53-otlp-collector-profiles-æ¥æ”¶)
  - [ç¬¬å…­éƒ¨åˆ†: å®æˆ˜æ¡ˆä¾‹ - æ€§èƒ½ä¼˜åŒ–](#ç¬¬å…­éƒ¨åˆ†-å®æˆ˜æ¡ˆä¾‹---æ€§èƒ½ä¼˜åŒ–)
    - [6.1 CPU çƒ­ç‚¹ä¼˜åŒ–](#61-cpu-çƒ­ç‚¹ä¼˜åŒ–)
      - [æ¡ˆä¾‹: Go Web æœåŠ¡ CPU ä¼˜åŒ–](#æ¡ˆä¾‹-go-web-æœåŠ¡-cpu-ä¼˜åŒ–)
    - [6.2 å†…å­˜æ³„æ¼æ’æŸ¥](#62-å†…å­˜æ³„æ¼æ’æŸ¥)
      - [æ¡ˆä¾‹: Java å¾®æœåŠ¡å†…å­˜æ³„æ¼](#æ¡ˆä¾‹-java-å¾®æœåŠ¡å†…å­˜æ³„æ¼)
    - [6.3 Goroutine æ³„æ¼æ£€æµ‹](#63-goroutine-æ³„æ¼æ£€æµ‹)
  - [ç¬¬ä¸ƒéƒ¨åˆ†: ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#ç¬¬ä¸ƒéƒ¨åˆ†-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
    - [7.1 é‡‡æ ·ç­–ç•¥](#71-é‡‡æ ·ç­–ç•¥)
    - [7.2 æ€§èƒ½å½±å“è¯„ä¼°](#72-æ€§èƒ½å½±å“è¯„ä¼°)
    - [7.3 æ•°æ®å­˜å‚¨ä¸æŸ¥è¯¢](#73-æ•°æ®å­˜å‚¨ä¸æŸ¥è¯¢)
    - [7.4 å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹](#74-å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹)
  - [ç¬¬å…«éƒ¨åˆ†: Profiles + Traces + Metrics å…³è”](#ç¬¬å…«éƒ¨åˆ†-profiles--traces--metrics-å…³è”)
    - [8.1 Exemplars - ä» Metrics åˆ° Profiles](#81-exemplars---ä»-metrics-åˆ°-profiles)
    - [8.2 SpanID å…³è” - ä» Traces åˆ° Profiles](#82-spanid-å…³è”---ä»-traces-åˆ°-profiles)
    - [8.3 ç»Ÿä¸€å¯è§‚æµ‹æ€§å¹³å°](#83-ç»Ÿä¸€å¯è§‚æµ‹æ€§å¹³å°)
  - [ç¬¬ä¹éƒ¨åˆ†: é«˜çº§è¯é¢˜](#ç¬¬ä¹éƒ¨åˆ†-é«˜çº§è¯é¢˜)
    - [9.1 eBPF-based Profiling](#91-ebpf-based-profiling)
      - [Parca Agent eBPF å®ç°](#parca-agent-ebpf-å®ç°)
    - [9.2 å·®åˆ†åˆ†æ (Diff Analysis)](#92-å·®åˆ†åˆ†æ-diff-analysis)
    - [9.3 å¤šç»´åº¦æ ‡ç­¾ (Multi-dimensional Labels)](#93-å¤šç»´åº¦æ ‡ç­¾-multi-dimensional-labels)
  - [ç¬¬åéƒ¨åˆ†: å®Œæ•´ç”Ÿäº§æ¡ˆä¾‹](#ç¬¬åéƒ¨åˆ†-å®Œæ•´ç”Ÿäº§æ¡ˆä¾‹)
    - [10.1 æ¡ˆä¾‹: ç”µå•†å¹³å°æ€§èƒ½ä¼˜åŒ–](#101-æ¡ˆä¾‹-ç”µå•†å¹³å°æ€§èƒ½ä¼˜åŒ–)
      - [ç³»ç»ŸèƒŒæ™¯](#ç³»ç»ŸèƒŒæ™¯)
      - [å®æ–½æ–¹æ¡ˆ](#å®æ–½æ–¹æ¡ˆ)
      - [ä¼˜åŒ–æˆæœ](#ä¼˜åŒ–æˆæœ)
  - [æ€»ç»“](#æ€»ç»“)
    - [Continuous Profiling æ ¸å¿ƒä»·å€¼](#continuous-profiling-æ ¸å¿ƒä»·å€¼)
    - [é€‚ç”¨åœºæ™¯](#é€‚ç”¨åœºæ™¯)
    - [å‚è€ƒèµ„æº](#å‚è€ƒèµ„æº)
  - [ğŸ“š ç›¸å…³æ–‡æ¡£](#-ç›¸å…³æ–‡æ¡£)
    - [æ ¸å¿ƒé›†æˆ â­â­â­](#æ ¸å¿ƒé›†æˆ-)
    - [æ¶æ„å¯è§†åŒ– â­â­â­](#æ¶æ„å¯è§†åŒ–-)
    - [å·¥å…·é“¾æ”¯æŒ â­â­](#å·¥å…·é“¾æ”¯æŒ-)

---

## ç¬¬ä¸€éƒ¨åˆ†: Profiling åŸºç¡€

### 1.1 ä»€ä¹ˆæ˜¯ Profiling?

```text
Profiling (æ€§èƒ½å‰–æ) æ˜¯åˆ†æç¨‹åºè¿è¡Œæ—¶è¡Œä¸ºçš„æŠ€æœ¯:

ğŸ“Š ä¸»è¦ç±»å‹:
1. CPU Profiling - åˆ†æ CPU æ—¶é—´æ¶ˆè€—
2. Memory Profiling - åˆ†æå†…å­˜åˆ†é…å’Œä½¿ç”¨
3. Goroutine/Thread Profiling - åˆ†æå¹¶å‘è¡Œä¸º
4. Block Profiling - åˆ†æé˜»å¡äº‹ä»¶
5. Mutex Profiling - åˆ†æé”ç«äº‰

ğŸ¯ æ ¸å¿ƒé—®é¢˜:
- å“ªäº›å‡½æ•°æ¶ˆè€—äº†æœ€å¤š CPU?
- å†…å­˜åˆ†é…åœ¨å“ªé‡Œ?
- æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼?
- Goroutine æ˜¯å¦æ³„æ¼?
- é”ç«äº‰åœ¨å“ªé‡Œ?
```

#### ä¼ ç»Ÿ Profiling vs Continuous Profiling

```text
ä¼ ç»Ÿ Profiling (Ad-hoc):
âŒ åªåœ¨å‡ºç°é—®é¢˜æ—¶æ‰‹åŠ¨é‡‡é›†
âŒ éš¾ä»¥å¤ç°ç”Ÿäº§ç¯å¢ƒé—®é¢˜
âŒ å†å²æ•°æ®ç¼ºå¤±
âŒ å½±å“ç”Ÿäº§ç¯å¢ƒ (å¼€é”€å¤§)

Continuous Profiling (è¿ç»­æ€§èƒ½å‰–æ):
âœ… 7x24 å°æ—¶è‡ªåŠ¨é‡‡é›†
âœ… å†å²æ•°æ®å¯è¿½æº¯ (æ—¶é—´ç»´åº¦)
âœ… ä½å¼€é”€ (<1% CPU)
âœ… å®æ—¶å‘ç°æ€§èƒ½é€€åŒ–
âœ… å¤šç»´åº¦æ ‡ç­¾ (service, version, region)
âœ… ä¸ Traces/Metrics å…³è”

å…¸å‹å·¥å…·:
- Google Cloud Profiler (å•†ä¸š)
- Datadog Continuous Profiler (å•†ä¸š)
- Parca (å¼€æº)
- Pyroscope (å¼€æº)
- Grafana Phlare â†’ Pyroscope (å¼€æº)
```

### 1.2 Profiling æ ¸å¿ƒæ¦‚å¿µ

```text
1. é‡‡æ · (Sampling):
   - å®šæœŸé‡‡é›†ç¨‹åºè°ƒç”¨æ ˆ
   - é€šå¸¸ 10-100 Hz (æ¯ç§’ 10-100 æ¬¡)
   - é™ä½æ€§èƒ½å½±å“

2. ç«ç„°å›¾ (Flame Graph):
   - å¯è§†åŒ–è°ƒç”¨æ ˆ
   - X è½´: æ ·æœ¬æ•° (å®½åº¦è¡¨ç¤º CPU æ¶ˆè€—)
   - Y è½´: è°ƒç”¨æ·±åº¦
   - é¢œè‰²: å‡½æ•°/åŒ…åˆ†ç±»

3. Profile ç±»å‹:
   - CPU Profile: on-CPU time
   - Off-CPU Profile: blocked time (I/O, lock, sleep)
   - Heap Profile: å †å†…å­˜åˆ†é…
   - Allocation Profile: æ‰€æœ‰å†…å­˜åˆ†é… (åŒ…æ‹¬æ ˆ)
   - Goroutine Profile: goroutine æ•°é‡å’ŒçŠ¶æ€
   - Mutex Profile: é”ç«äº‰
   - Block Profile: é˜»å¡äº‹ä»¶

4. pprof æ ¼å¼:
   - Google å¼€å‘çš„ profile æ•°æ®æ ¼å¼
   - Protocol Buffers åºåˆ—åŒ–
   - åŒ…å« location, function, sample ç­‰ä¿¡æ¯
```

### 1.3 Profiling å·¥å…·ç”Ÿæ€

```text
è¯­è¨€å·¥å…·:
- Go: pprof (å†…ç½®), runtime/pprof
- Java: JFR (Java Flight Recorder), JProfiler, YourKit
- Python: cProfile, py-spy, austin
- Rust: pprof-rs, cargo-flamegraph
- Node.js: V8 profiler, clinic.js
- C/C++: perf, gprof, Valgrind

å¹³å°å·¥å…·:
- Parca: å¼€æº, eBPF-based, å¤šè¯­è¨€
- Pyroscope: å¼€æº, å¤šè¯­è¨€, Grafana é›†æˆ
- Elastic Profiling (åŸ Prodfiler): å•†ä¸š, eBPF
- Google Cloud Profiler: å•†ä¸š, å¤šè¯­è¨€
- Datadog Profiler: å•†ä¸š, APM é›†æˆ

å¯è§†åŒ–:
- FlameGraph (Brendan Gregg)
- pprof web UI
- Grafana
- Speedscope
```

---

## ç¬¬äºŒéƒ¨åˆ†: CPU Profiling æ·±åº¦å®æˆ˜

### 2.1 Go pprof å®æˆ˜

#### åŸºç¡€ CPU Profiling

```go
// main.go - å¯ç”¨ pprof HTTP ç«¯ç‚¹
package main

import (
    "net/http"
    _ "net/http/pprof"  // è‡ªåŠ¨æ³¨å†Œ /debug/pprof/*
    "time"
)

func main() {
    // å¯åŠ¨ pprof HTTP server
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    // ä½ çš„ä¸šåŠ¡é€»è¾‘
    runBusinessLogic()
}

func runBusinessLogic() {
    for {
        // æ¨¡æ‹Ÿ CPU å¯†é›†å‹ä»»åŠ¡
        computeHeavy()
        time.Sleep(100 * time.Millisecond)
    }
}

func computeHeavy() {
    // ç¤ºä¾‹: è®¡ç®—è´¨æ•°
    for i := 0; i < 1000000; i++ {
        _ = isPrime(i)
    }
}

func isPrime(n int) bool {
    if n <= 1 {
        return false
    }
    for i := 2; i*i <= n; i++ {
        if n%i == 0 {
            return false
        }
    }
    return true
}
```

**é‡‡é›† CPU Profile**:

```bash
# æ–¹å¼ 1: ä½¿ç”¨ curl (é‡‡é›† 30 ç§’)
curl -o cpu.prof http://localhost:6060/debug/pprof/profile?seconds=30

# æ–¹å¼ 2: ä½¿ç”¨ go tool pprof (äº¤äº’å¼)
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30

# ç­‰å¾… 30 ç§’åè¿›å…¥äº¤äº’å¼ç•Œé¢
(pprof) top10        # æŸ¥çœ‹ CPU æ¶ˆè€—å‰ 10 çš„å‡½æ•°
(pprof) list isPrime # æŸ¥çœ‹ isPrime å‡½æ•°è¯¦ç»†ä»£ç 
(pprof) web          # ç”Ÿæˆ SVG ç«ç„°å›¾ (éœ€è¦ graphviz)
(pprof) quit

# æ–¹å¼ 3: ç”Ÿæˆç«ç„°å›¾ (FlameGraph)
go tool pprof -http=:8080 cpu.prof
# æ‰“å¼€æµè§ˆå™¨: http://localhost:8080
```

**è¾“å‡ºç¤ºä¾‹**:

```text
(pprof) top10
Showing nodes accounting for 2.50s, 95.42% of 2.62s total
Dropped 15 nodes (cum <= 0.01s)
Showing top 10 nodes out of 45
      flat  flat%   sum%        cum   cum%
     1.80s 68.70% 68.70%      1.80s 68.70%  main.isPrime
     0.40s 15.27% 83.97%      2.20s 83.97%  main.computeHeavy
     0.20s  7.63% 91.60%      0.20s  7.63%  runtime.pthread_cond_signal
     0.05s  1.91% 93.51%      0.05s  1.91%  runtime.usleep
     0.03s  1.15% 94.66%      0.03s  1.15%  runtime.nanotime
     0.02s  0.76% 95.42%      0.02s  0.76%  runtime.lock2

è§£è¯»:
- isPrime å‡½æ•°æ¶ˆè€—äº† 68.70% çš„ CPU æ—¶é—´
- computeHeavy è°ƒç”¨ isPrime,ç´¯è®¡ 83.97%
- ä¼˜åŒ–å»ºè®®: ä¼˜åŒ– isPrime ç®—æ³• (å¦‚ Sieve of Eratosthenes)
```

#### ç”Ÿäº§ç¯å¢ƒæŒç»­ Profiling

```go
// continuous_profiler.go - å®šæœŸé‡‡é›†å¹¶ä¸Šä¼  Profile
package profiler

import (
    "bytes"
    "context"
    "fmt"
    "io"
    "net/http"
    "runtime"
    "runtime/pprof"
    "time"
)

type ContinuousProfiler struct {
    serviceNamenstring
    version      string
    uploadURL    string
    interval     time.Duration
    client       *http.Client
}

func NewContinuousProfiler(serviceName, version, uploadURL string) *ContinuousProfiler {
    return &ContinuousProfiler{
        serviceName: serviceName,
        version:     version,
        uploadURL:   uploadURL,
        interval:    10 * time.Second,  // æ¯ 10 ç§’é‡‡é›†ä¸€æ¬¡
        client:      &http.Client{Timeout: 30 * time.Second},
    }
}

func (cp *ContinuousProfiler) Start(ctx context.Context) {
    ticker := time.NewTicker(cp.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            // é‡‡é›† CPU Profile
            if err := cp.collectAndUploadCPU(); err != nil {
                fmt.Printf("Failed to upload CPU profile: %v\n", err)
            }

            // é‡‡é›† Heap Profile
            if err := cp.collectAndUploadHeap(); err != nil {
                fmt.Printf("Failed to upload heap profile: %v\n", err)
            }

        case <-ctx.Done():
            return
        }
    }
}

func (cp *ContinuousProfiler) collectAndUploadCPU() error {
    var buf bytes.Buffer

    // é‡‡é›† 10 ç§’çš„ CPU profile
    if err := pprof.StartCPUProfile(&buf); err != nil {
        return fmt.Errorf("start cpu profile: %w", err)
    }
    time.Sleep(10 * time.Second)
    pprof.StopCPUProfile()

    // ä¸Šä¼ åˆ° Profiling å¹³å°
    return cp.upload("cpu", &buf)
}

func (cp *ContinuousProfiler) collectAndUploadHeap() error {
    var buf bytes.Buffer

    // é‡‡é›† Heap profile
    runtime.GC()  // è§¦å‘ GC ä»¥è·å–æœ€æ–°å †å¿«ç…§
    if err := pprof.WriteHeapProfile(&buf); err != nil {
        return fmt.Errorf("write heap profile: %w", err)
    }

    return cp.upload("heap", &buf)
}

func (cp *ContinuousProfiler) upload(profileType string, data io.Reader) error {
    req, err := http.NewRequest("POST", cp.uploadURL, data)
    if err != nil {
        return err
    }

    // æ·»åŠ æ ‡ç­¾ (ç”¨äºå¤šç»´åº¦æŸ¥è¯¢)
    req.Header.Set("X-Service-Name", cp.serviceName)
    req.Header.Set("X-Version", cp.version)
    req.Header.Set("X-Profile-Type", profileType)
    req.Header.Set("Content-Type", "application/octet-stream")

    resp, err := cp.client.Do(req)
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("upload failed: %s", resp.Status)
    }

    return nil
}
```

**ä½¿ç”¨ç¤ºä¾‹**:

```go
// main.go
func main() {
    profiler := profiler.NewContinuousProfiler(
        "my-service",
        "v1.2.3",
        "http://parca-server:7070/upload",
    )

    ctx := context.Background()
    go profiler.Start(ctx)

    // ä½ çš„ä¸šåŠ¡é€»è¾‘
    runBusinessLogic()
}
```

### 2.2 Java JFR (Java Flight Recorder)

#### JFR åŸºç¡€ä½¿ç”¨

```bash
# å¯åŠ¨ Java åº”ç”¨æ—¶å¯ç”¨ JFR
java -XX:StartFlightRecording=duration=60s,filename=recording.jfr \
     -jar myapp.jar

# æˆ–åœ¨è¿è¡Œæ—¶åŠ¨æ€å¯åŠ¨ (ä½¿ç”¨ jcmd)
# 1. æ‰¾åˆ° Java è¿›ç¨‹ PID
jps -l

# 2. å¯åŠ¨ JFR å½•åˆ¶
jcmd <PID> JFR.start name=my-recording duration=60s filename=recording.jfr

# 3. åœæ­¢å½•åˆ¶
jcmd <PID> JFR.stop name=my-recording

# 4. è½¬æ¢ä¸ºç«ç„°å›¾ (ä½¿ç”¨ async-profiler)
java -cp converter.jar jfr2flame recording.jfr flamegraph.html
```

#### JFR é«˜çº§é…ç½®

```java
// CustomJFRConfiguration.java - è‡ªå®šä¹‰ JFR é…ç½®
import jdk.jfr.Configuration;
import jdk.jfr.Recording;

public class CustomJFRConfiguration {
    public static void startProfiling() throws Exception {
        // åŠ è½½é…ç½® (profile æˆ– default)
        Configuration config = Configuration.getConfiguration("profile");

        // åˆ›å»ºå½•åˆ¶
        Recording recording = new Recording(config);

        // è‡ªå®šä¹‰è®¾ç½®
        recording.setMaxSize(100 * 1024 * 1024);  // æœ€å¤§ 100MB
        recording.setMaxAge(java.time.Duration.ofHours(2));  // ä¿ç•™ 2 å°æ—¶

        // å¯ç”¨ç‰¹å®šäº‹ä»¶
        recording.enable("jdk.ObjectAllocationInNewTLAB")
                 .withThreshold(java.time.Duration.ofMillis(10));  // é˜ˆå€¼ 10ms

        recording.enable("jdk.ObjectAllocationOutsideTLAB");

        // å¼€å§‹å½•åˆ¶
        recording.start();

        // å®šæœŸè½¬å‚¨ (æ¯ 10 åˆ†é’Ÿ)
        ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
        scheduler.scheduleAtFixedRate(() -> {
            try {
                Path path = Paths.get("recording-" + System.currentTimeMillis() + ".jfr");
                recording.dump(path);
                System.out.println("Dumped recording to " + path);
            } catch (IOException e) {
                e.printStackTrace();
            }
        }, 10, 10, TimeUnit.MINUTES);
    }
}
```

### 2.3 Python py-spy

#### py-spy ä½¿ç”¨

```bash
# å®‰è£… py-spy
pip install py-spy

# é‡‡é›†è¿è¡Œä¸­çš„ Python è¿›ç¨‹
py-spy record -o profile.svg --pid <PID>

# é‡‡é›† 60 ç§’
py-spy record -o profile.svg --duration 60 --pid <PID>

# é¡¶éƒ¨è§†å›¾ (ç±»ä¼¼ top)
py-spy top --pid <PID>

# ç”Ÿæˆç«ç„°å›¾ (HTML)
py-spy record -o profile.html --format speedscope --pid <PID>
```

**Python å†…ç½® cProfile**:

```python
# profile_example.py
import cProfile
import pstats
from io import StringIO

def heavy_computation():
    result = 0
    for i in range(1000000):
        result += i ** 2
    return result

def main():
    for _ in range(10):
        heavy_computation()

if __name__ == "__main__":
    # å¯ç”¨ profiling
    profiler = cProfile.Profile()
    profiler.enable()

    main()

    profiler.disable()

    # è¾“å‡ºç»Ÿè®¡
    s = StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
    ps.print_stats(20)  # å‰ 20 ä¸ªå‡½æ•°
    print(s.getvalue())

    # ä¿å­˜åˆ°æ–‡ä»¶
    profiler.dump_stats('profile.prof')

    # å¯è§†åŒ–: snakeviz profile.prof
```

---

## ç¬¬ä¸‰éƒ¨åˆ†: å†…å­˜ Profiling

### 3.1 Go Heap Profiling

#### Heap Profile åˆ†æ

```go
// heap_profiling.go
package main

import (
    "fmt"
    "net/http"
    _ "net/http/pprof"
    "runtime"
    "time"
)

type LargeStruct struct {
    Data [1024 * 1024]byte  // 1MB
}

var globalLeaks []*LargeStruct

func main() {
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    // æ¨¡æ‹Ÿå†…å­˜æ³„æ¼
    go leakMemory()

    select {}
}

func leakMemory() {
    ticker := time.NewTicker(1 * time.Second)
    for range ticker.C {
        // æ¯ç§’åˆ†é… 1MB ä¸”ä¸é‡Šæ”¾
        obj := &LargeStruct{}
        globalLeaks = append(globalLeaks, obj)

        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        fmt.Printf("Alloc = %v MiB, TotalAlloc = %v MiB, Sys = %v MiB, NumGC = %v\n",
            m.Alloc/1024/1024, m.TotalAlloc/1024/1024, m.Sys/1024/1024, m.NumGC)
    }
}
```

**é‡‡é›† Heap Profile**:

```bash
# é‡‡é›† heap profile
curl -o heap.prof http://localhost:6060/debug/pprof/heap

# åˆ†æ
go tool pprof heap.prof

(pprof) top10
Showing nodes accounting for 512MB, 100% of 512MB total
      flat  flat%   sum%        cum   cum%
    512MB   100%   100%     512MB   100%  main.leakMemory

(pprof) list leakMemory
# æŸ¥çœ‹è¯¦ç»†ä»£ç 

(pprof) web  # å¯è§†åŒ–
```

#### å†…å­˜æ³„æ¼æ£€æµ‹

```bash
# å¯¹æ¯”ä¸¤ä¸ªæ—¶é—´ç‚¹çš„ heap profile
curl -o heap1.prof http://localhost:6060/debug/pprof/heap
# ç­‰å¾…ä¸€æ®µæ—¶é—´
sleep 60
curl -o heap2.prof http://localhost:6060/debug/pprof/heap

# å¯¹æ¯” (æ‰¾å‡ºå¢é•¿çš„éƒ¨åˆ†)
go tool pprof -base heap1.prof heap2.prof

(pprof) top10
# æ˜¾ç¤ºå·®å¼‚æœ€å¤§çš„å‡½æ•°
```

### 3.2 Java Heap Dump åˆ†æ

```bash
# ç”Ÿæˆ heap dump
jcmd <PID> GC.heap_dump heapdump.hprof

# ä½¿ç”¨ jhat åˆ†æ (ç®€å•)
jhat heapdump.hprof
# æµè§ˆå™¨æ‰“å¼€: http://localhost:7000

# ä½¿ç”¨ Eclipse MAT (æ¨è, å¼ºå¤§çš„å†…å­˜æ³„æ¼æ£€æµ‹)
# ä¸‹è½½: https://www.eclipse.org/mat/
# æ‰“å¼€ heapdump.hprof
# è¿è¡Œ "Leak Suspects Report"
```

**Java å†…å­˜æ³„æ¼ç¤ºä¾‹**:

```java
// MemoryLeakExample.java
import java.util.ArrayList;
import java.util.List;

public class MemoryLeakExample {
    private static List<byte[]> leak = new ArrayList<>();

    public static void main(String[] args) throws InterruptedException {
        while (true) {
            // æ¯æ¬¡åˆ†é… 1MB ä¸”ä¸é‡Šæ”¾
            byte[] data = new byte[1024 * 1024];
            leak.add(data);

            System.out.println("Allocated 1MB, total: " + leak.size() + "MB");
            Thread.sleep(1000);
        }
    }
}
```

### 3.3 Allocation Profiling (åˆ†é…è¿½è¸ª)

```go
// allocation_profiling.go
package main

import (
    "net/http"
    _ "net/http/pprof"
    "runtime"
)

func main() {
    // å¯ç”¨ allocation profiling (é»˜è®¤æ¯ 512KB é‡‡æ ·ä¸€æ¬¡)
    runtime.MemProfileRate = 1  // æ¯æ¬¡åˆ†é…éƒ½è®°å½• (ä»…ç”¨äºæµ‹è¯•, ç”Ÿäº§ç¯å¢ƒå¼€é”€å¤§)

    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    // ä¸šåŠ¡é€»è¾‘
    for {
        allocateMemory()
    }
}

func allocateMemory() {
    // çŸ­ç”Ÿå‘½å‘¨æœŸçš„åˆ†é…
    data := make([]byte, 1024)
    _ = data
}
```

**é‡‡é›† Allocation Profile**:

```bash
# é‡‡é›† allocs profile
curl -o allocs.prof http://localhost:6060/debug/pprof/allocs

go tool pprof allocs.prof

(pprof) top10
# æ˜¾ç¤ºåˆ†é…æ¬¡æ•°æœ€å¤šçš„å‡½æ•°
```

---

## ç¬¬å››éƒ¨åˆ†: Continuous Profiling å¹³å°

### 4.1 Parca - å¼€æº Continuous Profiling

#### Parca æ¶æ„

```text
Parca æ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚â”€â”€â”€â”€â–¶â”‚ Parca Agent â”‚â”€â”€â”€â”€â–¶â”‚ Parca Serverâ”‚
â”‚   (pprof)   â”‚     â”‚   (eBPF)    â”‚     â”‚  (Storage)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚ Grafana   â”‚
                                        â”‚ Dashboard â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹æ€§:
1. eBPF-based: æ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
2. å¤šè¯­è¨€æ”¯æŒ: Go, Java, Python, C/C++, Rust
3. ä½å¼€é”€: <1% CPU
4. å†å²æ•°æ®: é•¿æœŸå­˜å‚¨ (å‹ç¼©åä»…å‡  MB/å¤©)
5. å¤šç»´åº¦æ ‡ç­¾: service, version, region, pod
6. Diff åˆ†æ: å¯¹æ¯”ä¸åŒæ—¶é—´/ç‰ˆæœ¬çš„ profile
```

#### éƒ¨ç½² Parca

```yaml
# parca-deployment.yaml - Kubernetes éƒ¨ç½²
apiVersion: v1
kind: Namespace
metadata:
  name: parca

---
# Parca Server
apiVersion: apps/v1
kind: Deployment
metadata:
  name: parca-server
  namespace: parca
spec:
  replicas: 1
  selector:
    matchLabels:
      app: parca-server
  template:
    metadata:
      labels:
        app: parca-server
    spec:
      containers:
      - name: parca
        image: ghcr.io/parca-dev/parca:v0.21.0
        args:
        - /parca
        - --http-address=:7070
        - --storage-path=/var/lib/parca
        - --storage-active-memory=2GB
        ports:
        - containerPort: 7070
          name: http
        volumeMounts:
        - name: storage
          mountPath: /var/lib/parca
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2"
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: parca-storage

---
apiVersion: v1
kind: Service
metadata:
  name: parca-server
  namespace: parca
spec:
  selector:
    app: parca-server
  ports:
  - port: 7070
    targetPort: 7070
  type: LoadBalancer

---
# Parca Agent (DaemonSet)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: parca-agent
  namespace: parca
spec:
  selector:
    matchLabels:
      app: parca-agent
  template:
    metadata:
      labels:
        app: parca-agent
    spec:
      hostPID: true  # è®¿é—®å®¿ä¸»æœºè¿›ç¨‹
      containers:
      - name: parca-agent
        image: ghcr.io/parca-dev/parca-agent:v0.27.0
        args:
        - /bin/parca-agent
        - --node=$(NODE_NAME)
        - --remote-store-address=parca-server.parca.svc.cluster.local:7070
        - --remote-store-insecure
        - --log-level=info
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          privileged: true  # eBPF éœ€è¦
        volumeMounts:
        - name: sys
          mountPath: /sys
        - name: modules
          mountPath: /lib/modules
        - name: debugfs
          mountPath: /sys/kernel/debug
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: sys
        hostPath:
          path: /sys
      - name: modules
        hostPath:
          path: /lib/modules
      - name: debugfs
        hostPath:
          path: /sys/kernel/debug

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: parca-storage
  namespace: parca
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
```

**éƒ¨ç½²**:

```bash
kubectl apply -f parca-deployment.yaml

# æŸ¥çœ‹çŠ¶æ€
kubectl get pods -n parca

# è®¿é—® Web UI
kubectl port-forward -n parca svc/parca-server 7070:7070
# æµè§ˆå™¨æ‰“å¼€: http://localhost:7070
```

#### é›†æˆåº”ç”¨

**Go åº”ç”¨é›†æˆ** (å¦‚æœä¸ä½¿ç”¨ eBPF Agent):

```go
// main.go - ä¸»åŠ¨ä¸Šä¼  profile åˆ° Parca
package main

import (
    "bytes"
    "context"
    "fmt"
    "net/http"
    "runtime/pprof"
    "time"

    "google.golang.org/grpc"
    profilestorepb "github.com/parca-dev/parca/gen/proto/go/parca/profilestore/v1alpha1"
)

func main() {
    // è¿æ¥ Parca Server
    conn, err := grpc.Dial("parca-server:7070", grpc.WithInsecure())
    if err != nil {
        panic(err)
    }
    defer conn.Close()

    client := profilestorepb.NewProfileStoreServiceClient(conn)

    // å®šæœŸé‡‡é›†å¹¶ä¸Šä¼ 
    ticker := time.NewTicker(10 * time.Second)
    for range ticker.C {
        uploadCPUProfile(client)
    }
}

func uploadCPUProfile(client profilestorepb.ProfileStoreServiceClient) {
    var buf bytes.Buffer

    // é‡‡é›† CPU profile
    if err := pprof.StartCPUProfile(&buf); err != nil {
        fmt.Printf("Failed to start CPU profile: %v\n", err)
        return
    }
    time.Sleep(10 * time.Second)
    pprof.StopCPUProfile()

    // ä¸Šä¼ åˆ° Parca
    _, err := client.WriteRaw(context.Background(), &profilestorepb.WriteRawRequest{
        Series: []*profilestorepb.RawProfileSeries{
            {
                Labels: &profilestorepb.LabelSet{
                    Labels: []*profilestorepb.Label{
                        {Name: "service_name", Value: "my-service"},
                        {Name: "version", Value: "v1.2.3"},
                        {Name: "__name__", Value: "cpu"},
                    },
                },
                Samples: []*profilestorepb.RawSample{
                    {
                        RawProfile: buf.Bytes(),
                    },
                },
            },
        },
    })

    if err != nil {
        fmt.Printf("Failed to upload profile: %v\n", err)
    }
}
```

### 4.2 Pyroscope - å¤šè¯­è¨€æ”¯æŒ

#### Pyroscope æ¶æ„

```text
Pyroscope æ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application  â”‚â”€â”€â”€â”€â–¶â”‚  Pyroscope   â”‚â”€â”€â”€â”€â–¶â”‚  Pyroscope   â”‚
â”‚ (Push/Pull)  â”‚     â”‚    Agent     â”‚     â”‚    Server    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ Grafana  â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹æ€§:
1. å¤šè¯­è¨€ SDK: Go, Java, Python, .NET, Ruby, Node.js
2. Pull æ¨¡å¼: ä» pprof ç«¯ç‚¹æ‹‰å– (ç±»ä¼¼ Prometheus)
3. Push æ¨¡å¼: SDK ä¸»åŠ¨æ¨é€
4. æ ‡ç­¾æ”¯æŒ: å¤šç»´åº¦æŸ¥è¯¢
5. Diff åˆ†æ: ç‰ˆæœ¬å¯¹æ¯”
6. Grafana é›†æˆ: åŸç”Ÿæ•°æ®æº
```

#### éƒ¨ç½² Pyroscope

```yaml
# pyroscope-deployment.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: pyroscope

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope-server
  namespace: pyroscope
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pyroscope-server
  template:
    metadata:
      labels:
        app: pyroscope-server
    spec:
      containers:
      - name: pyroscope
        image: grafana/pyroscope:latest
        args:
        - server
        ports:
        - containerPort: 4040
          name: http
        volumeMounts:
        - name: storage
          mountPath: /var/lib/pyroscope
        env:
        - name: PYROSCOPE_LOG_LEVEL
          value: "info"
        - name: PYROSCOPE_STORAGE_PATH
          value: "/var/lib/pyroscope"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: pyroscope-storage

---
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-server
  namespace: pyroscope
spec:
  selector:
    app: pyroscope-server
  ports:
  - port: 4040
    targetPort: 4040
  type: LoadBalancer

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pyroscope-storage
  namespace: pyroscope
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
```

#### å¤šè¯­è¨€é›†æˆ

**Go é›†æˆ**:

```go
// main.go - Pyroscope Go SDK
package main

import (
    "github.com/grafana/pyroscope-go"
)

func main() {
    // å¯åŠ¨ Pyroscope profiler
    pyroscope.Start(pyroscope.Config{
        ApplicationName: "my-go-service",
        ServerAddress:   "http://pyroscope-server:4040",
        Logger:          nil,  // å¯é€‰: è‡ªå®šä¹‰æ—¥å¿—

        // é‡‡é›†çš„ profile ç±»å‹
        ProfileTypes: []pyroscope.ProfileType{
            pyroscope.ProfileCPU,
            pyroscope.ProfileAllocObjects,
            pyroscope.ProfileAllocSpace,
            pyroscope.ProfileInuseObjects,
            pyroscope.ProfileInuseSpace,
        },

        // æ ‡ç­¾ (å¤šç»´åº¦æŸ¥è¯¢)
        Tags: map[string]string{
            "version":  "v1.2.3",
            "region":   "us-east-1",
            "hostname": "pod-abc123",
        },
    })

    // ä½ çš„ä¸šåŠ¡é€»è¾‘
    runBusinessLogic()
}
```

**Java é›†æˆ**:

```java
// Main.java - Pyroscope Java Agent
// å¯åŠ¨æ—¶æ·»åŠ  JVM å‚æ•°:
// java -javaagent:pyroscope.jar \
//      -Dpyroscope.application.name=my-java-service \
//      -Dpyroscope.server.address=http://pyroscope-server:4040 \
//      -Dpyroscope.format=jfr \
//      -jar myapp.jar

// æˆ–åœ¨ä»£ç ä¸­å¯åŠ¨:
import io.pyroscope.javaagent.PyroscopeAgent;
import io.pyroscope.javaagent.config.Config;

public class Main {
    public static void main(String[] args) {
        PyroscopeAgent.start(
            new Config.Builder()
                .setApplicationName("my-java-service")
                .setServerAddress("http://pyroscope-server:4040")
                .setFormat(Format.JFR)
                .build()
        );

        // ä½ çš„ä¸šåŠ¡é€»è¾‘
        runBusinessLogic();
    }
}
```

**Python é›†æˆ**:

```python
# main.py - Pyroscope Python SDK
import pyroscope

pyroscope.configure(
    application_name="my-python-service",
    server_address="http://pyroscope-server:4040",
    tags={
        "version": "v1.2.3",
        "region": "us-east-1",
    }
)

# ä½ çš„ä¸šåŠ¡é€»è¾‘
def main():
    while True:
        heavy_computation()

if __name__ == "__main__":
    main()
```

### 4.3 Grafana Phlare (ç°å·²åˆå¹¶åˆ° Pyroscope)

```text
Grafana Phlare å·²äº 2024 å¹´åˆå¹¶åˆ° Pyroscope:
- Phlare é¡¹ç›®åœæ­¢ç‹¬ç«‹å¼€å‘
- Pyroscope ç»§æ‰¿äº† Phlare çš„ç‰¹æ€§
- Grafana åŸç”Ÿæ”¯æŒ Pyroscope æ•°æ®æº

ä½¿ç”¨ Grafana æŸ¥è¯¢ Pyroscope æ•°æ®:
1. å®‰è£… Pyroscope æ•°æ®æºæ’ä»¶
2. é…ç½®æ•°æ®æº: http://pyroscope-server:4040
3. åˆ›å»º Dashboard:
   - ç«ç„°å›¾é¢æ¿
   - CPU ä½¿ç”¨è¶‹åŠ¿
   - å†…å­˜åˆ†é…è¶‹åŠ¿
   - æœåŠ¡å¯¹æ¯”
```

---

## ç¬¬äº”éƒ¨åˆ†: OTLP Profiles ä¿¡å·

### 5.1 OTLP Profiles æ•°æ®æ¨¡å‹

#### Profile æ•°æ®ç»“æ„

```protobuf
// opentelemetry/proto/profiles/v1/profiles.proto

message ProfilesData {
  repeated ResourceProfiles resource_profiles = 1;
}

message ResourceProfiles {
  // èµ„æºä¿¡æ¯ (service, host, etc.)
  opentelemetry.proto.resource.v1.Resource resource = 1;

  // ä½œç”¨åŸŸ (instrumentation library)
  repeated ScopeProfiles scope_profiles = 2;

  // Schema URL
  string schema_url = 3;
}

message ScopeProfiles {
  opentelemetry.proto.common.v1.InstrumentationScope scope = 1;
  repeated Profile profiles = 2;
  string schema_url = 3;
}

message Profile {
  // Profile ID (å”¯ä¸€æ ‡è¯†)
  bytes profile_id = 1;

  // å¼€å§‹æ—¶é—´
  fixed64 start_time_unix_nano = 2;

  // ç»“æŸæ—¶é—´
  fixed64 end_time_unix_nano = 3;

  // å±æ€§ (æ ‡ç­¾)
  repeated opentelemetry.proto.common.v1.KeyValue attributes = 4;

  // Profile ç±»å‹ (cpu, heap, allocs, etc.)
  string profile_type = 5;

  // pprof æ ¼å¼çš„äºŒè¿›åˆ¶æ•°æ®
  bytes pprof_data = 6;

  // å…³è”çš„ Trace ID (å¯é€‰)
  bytes trace_id = 7;

  // å…³è”çš„ Span ID (å¯é€‰)
  bytes span_id = 8;
}
```

### 5.2 OTLP Profiles Exporter

#### Go OTLP Profiles Exporter

```go
// otlp_profiles_exporter.go
package profiler

import (
    "bytes"
    "context"
    "fmt"
    "runtime/pprof"
    "time"

    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/sdk/resource"
    profilesv1 "go.opentelemetry.io/proto/otlp/profiles/v1"
    "google.golang.org/grpc"
)

type OTLPProfilesExporter struct {
    serviceName string
    version     string
    client      profilesv1.ProfilesServiceClient
}

func NewOTLPProfilesExporter(serviceName, version, endpoint string) (*OTLPProfilesExporter, error) {
    conn, err := grpc.Dial(endpoint, grpc.WithInsecure())
    if err != nil {
        return nil, err
    }

    return &OTLPProfilesExporter{
        serviceName: serviceName,
        version:     version,
        client:      profilesv1.NewProfilesServiceClient(conn),
    }, nil
}

func (e *OTLPProfilesExporter) ExportCPUProfile(ctx context.Context, duration time.Duration) error {
    // é‡‡é›† CPU profile
    var buf bytes.Buffer
    if err := pprof.StartCPUProfile(&buf); err != nil {
        return fmt.Errorf("start cpu profile: %w", err)
    }
    time.Sleep(duration)
    pprof.StopCPUProfile()

    // æ„å»º OTLP Profiles æ•°æ®
    now := time.Now()
    profilesData := &profilesv1.ProfilesData{
        ResourceProfiles: []*profilesv1.ResourceProfiles{
            {
                Resource: &resource.Resource{
                    Attributes: []attribute.KeyValue{
                        attribute.String("service.name", e.serviceName),
                        attribute.String("service.version", e.version),
                    },
                },
                ScopeProfiles: []*profilesv1.ScopeProfiles{
                    {
                        Profiles: []*profilesv1.Profile{
                            {
                                ProfileId:         generateProfileID(),
                                StartTimeUnixNano: uint64(now.Add(-duration).UnixNano()),
                                EndTimeUnixNano:   uint64(now.UnixNano()),
                                ProfileType:       "cpu",
                                PprofData:         buf.Bytes(),
                                Attributes: []*profilesv1.KeyValue{
                                    {Key: "profile.type", Value: &profilesv1.AnyValue{Value: &profilesv1.AnyValue_StringValue{StringValue: "cpu"}}},
                                    {Key: "sample.type", Value: &profilesv1.AnyValue{Value: &profilesv1.AnyValue_StringValue{StringValue: "cpu-time"}}},
                                },
                            },
                        },
                    },
                },
            },
        },
    }

    // å¯¼å‡ºåˆ° OTLP Collector
    req := &profilesv1.ExportProfilesServiceRequest{
        ResourceProfiles: profilesData.ResourceProfiles,
    }

    _, err := e.client.Export(ctx, req)
    return err
}

func generateProfileID() []byte {
    // ç”Ÿæˆå”¯ä¸€ Profile ID (16 å­—èŠ‚)
    id := make([]byte, 16)
    // TODO: ä½¿ç”¨éšæœºæ•°æˆ–æ—¶é—´æˆ³ç”Ÿæˆ
    return id
}
```

**ä½¿ç”¨ç¤ºä¾‹**:

```go
// main.go
func main() {
    exporter, err := profiler.NewOTLPProfilesExporter(
        "my-service",
        "v1.2.3",
        "otel-collector:4317",  // OTLP gRPC endpoint
    )
    if err != nil {
        panic(err)
    }

    // å®šæœŸå¯¼å‡º CPU profile
    ticker := time.NewTicker(10 * time.Second)
    for range ticker.C {
        if err := exporter.ExportCPUProfile(context.Background(), 10*time.Second); err != nil {
            fmt.Printf("Failed to export profile: %v\n", err)
        }
    }
}
```

### 5.3 OTLP Collector Profiles æ¥æ”¶

```yaml
# otel-collector-config.yaml - é…ç½® Profiles æ¥æ”¶å’Œå¯¼å‡º

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # pprof æ¥æ”¶å™¨ (ä» pprof HTTP ç«¯ç‚¹æ‹‰å–)
  pprof:
    endpoint: 0.0.0.0:1777
    profiles:
      - targets:
        - endpoint: http://my-service:6060/debug/pprof/profile?seconds=10
          labels:
            service_name: my-service
            version: v1.2.3

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024

  # æ·»åŠ èµ„æºå±æ€§
  resource:
    attributes:
      - key: deployment.environment
        value: production
        action: upsert

exporters:
  # å¯¼å‡ºåˆ° Pyroscope
  pyroscope:
    endpoint: http://pyroscope-server:4040

  # å¯¼å‡ºåˆ° Parca
  otlphttp:
    endpoint: http://parca-server:7070/otlp

  # è°ƒè¯•è¾“å‡º
  logging:
    loglevel: info

service:
  pipelines:
    profiles:
      receivers: [otlp, pprof]
      processors: [batch, resource]
      exporters: [pyroscope, otlphttp, logging]
```

**éƒ¨ç½² OTLP Collector (æ”¯æŒ Profiles)**:

```bash
# ä½¿ç”¨å®˜æ–¹ Collector Contrib ç‰ˆæœ¬ (åŒ…å« pprof receiver)
docker run -v $(pwd)/otel-collector-config.yaml:/etc/otelcol/config.yaml \
    -p 4317:4317 -p 4318:4318 -p 1777:1777 \
    otel/opentelemetry-collector-contrib:latest
```

---

## ç¬¬å…­éƒ¨åˆ†: å®æˆ˜æ¡ˆä¾‹ - æ€§èƒ½ä¼˜åŒ–

### 6.1 CPU çƒ­ç‚¹ä¼˜åŒ–

#### æ¡ˆä¾‹: Go Web æœåŠ¡ CPU ä¼˜åŒ–

**é—®é¢˜**: ä¸€ä¸ª Go Web API åœ¨é«˜è´Ÿè½½ä¸‹ CPU ä½¿ç”¨ç‡è¾¾åˆ° 80%+

**æ­¥éª¤ 1: é‡‡é›† CPU Profile**:

```bash
# ç”Ÿäº§ç¯å¢ƒé‡‡é›† 30 ç§’ profile
curl -o cpu-before.prof http://api-server:6060/debug/pprof/profile?seconds=30
```

**æ­¥éª¤ 2: åˆ†æç«ç„°å›¾**:

```bash
go tool pprof -http=:8080 cpu-before.prof
# æ‰“å¼€ http://localhost:8080
```

**å‘ç°**:

```text
(pprof) top10
      flat  flat%   sum%        cum   cum%
     3.20s 40.00% 40.00%      3.20s 40.00%  encoding/json.(*encodeState).string
     1.60s 20.00% 60.00%      4.80s 60.00%  encoding/json.Marshal
     0.80s 10.00% 70.00%      0.80s 10.00%  reflect.Value.NumField
     0.60s  7.50% 77.50%      0.60s  7.50%  runtime.mallocgc
     ...

å‘ç°: JSON åºåˆ—åŒ–æ¶ˆè€—äº† 60% çš„ CPU æ—¶é—´!
```

**æ­¥éª¤ 3: ä¼˜åŒ–**:

```go
// before.go - ä¼˜åŒ–å‰
func (h *Handler) GetUsers(w http.ResponseWriter, r *http.Request) {
    users := h.db.GetUsers()

    // æ¯æ¬¡è¯·æ±‚éƒ½åºåˆ—åŒ– (æ…¢)
    data, _ := json.Marshal(users)
    w.Write(data)
}

// after.go - ä¼˜åŒ–å
import "github.com/json-iterator/go"  // æ›´å¿«çš„ JSON åº“

var jsonAPI = jsoniter.ConfigCompatibleWithStandardLibrary

func (h *Handler) GetUsers(w http.ResponseWriter, r *http.Request) {
    users := h.db.GetUsers()

    // ä½¿ç”¨ jsoniter (å¿« 2-3 å€)
    data, _ := jsonAPI.Marshal(users)
    w.Write(data)
}

// æˆ–ä½¿ç”¨ easyjson (ä»£ç ç”Ÿæˆ, å¿« 4-5 å€)
//go:generate easyjson -all users.go
```

**æ­¥éª¤ 4: éªŒè¯ä¼˜åŒ–æ•ˆæœ**:

```bash
# å†æ¬¡é‡‡é›† profile
curl -o cpu-after.prof http://api-server:6060/debug/pprof/profile?seconds=30

# å¯¹æ¯”
go tool pprof -http=:8080 -base cpu-before.prof cpu-after.prof

ç»“æœ:
- JSON åºåˆ—åŒ–æ—¶é—´å‡å°‘ 70%
- æ•´ä½“ CPU ä½¿ç”¨ç‡ä» 80% é™è‡³ 35%
- QPS ä» 1000 æå‡è‡³ 2500
```

### 6.2 å†…å­˜æ³„æ¼æ’æŸ¥

#### æ¡ˆä¾‹: Java å¾®æœåŠ¡å†…å­˜æ³„æ¼

**é—®é¢˜**: Java æœåŠ¡è¿è¡Œå‡ å¤©å OOM (Out of Memory)

**æ­¥éª¤ 1: é‡‡é›† Heap Dump**:

```bash
# å½“å†…å­˜ä½¿ç”¨ç‡é«˜æ—¶é‡‡é›†
jcmd <PID> GC.heap_dump before-gc.hprof

# è§¦å‘ Full GC
jcmd <PID> GC.run

# å†æ¬¡é‡‡é›†
jcmd <PID> GC.heap_dump after-gc.hprof
```

**æ­¥éª¤ 2: ä½¿ç”¨ Eclipse MAT åˆ†æ**:

```text
æ‰“å¼€ after-gc.hprof
è¿è¡Œ "Leak Suspects Report"

å‘ç°:
- java.util.HashMap å ç”¨ 2.5GB å†…å­˜
- Dominated by: com.example.CacheManager
- Retained Size: 2.5GB (85% of heap)

è¯¦ç»†åˆ†æ:
CacheManager æŒæœ‰ä¸€ä¸ª HashMap,
ä¸æ–­æ·»åŠ æ•°æ®ä½†ä»ä¸æ¸…ç†!
```

**æ­¥éª¤ 3: ä¿®å¤ä»£ç **:

```java
// before.java - æœ‰æ³„æ¼
public class CacheManager {
    private Map<String, User> cache = new HashMap<>();

    public void addUser(User user) {
        cache.put(user.getId(), user);  // æ°¸ä¸åˆ é™¤!
    }
}

// after.java - ä¿®å¤å
import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;
import java.util.concurrent.TimeUnit;

public class CacheManager {
    // ä½¿ç”¨ Guava Cache (è‡ªåŠ¨è¿‡æœŸ)
    private Cache<String, User> cache = CacheBuilder.newBuilder()
        .maximumSize(10000)  // æœ€å¤š 10000 æ¡
        .expireAfterWrite(1, TimeUnit.HOURS)  // 1 å°æ—¶è¿‡æœŸ
        .build();

    public void addUser(User user) {
        cache.put(user.getId(), user);
    }
}
```

**æ­¥éª¤ 4: éªŒè¯**:

```bash
# é‡æ–°éƒ¨ç½²å¹¶ç›‘æ§
# å†…å­˜ä½¿ç”¨ç‡ç¨³å®šåœ¨ 30% ä»¥ä¸‹
# ä¸å† OOM
```

### 6.3 Goroutine æ³„æ¼æ£€æµ‹

```go
// goroutine_leak.go - æœ‰æ³„æ¼çš„ä»£ç 
package main

import (
    "net/http"
    _ "net/http/pprof"
    "time"
)

func main() {
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    // æ¨¡æ‹Ÿ goroutine æ³„æ¼
    for {
        go leakyGoroutine()
        time.Sleep(100 * time.Millisecond)
    }
}

func leakyGoroutine() {
    // è¿™ä¸ª goroutine ä¼šé˜»å¡æ°¸è¿œä¸é€€å‡º
    ch := make(chan int)  // unbuffered channel
    <-ch  // æ°¸è¿œé˜»å¡!
}
```

**æ£€æµ‹æ³„æ¼**:

```bash
# æŸ¥çœ‹ goroutine æ•°é‡
curl http://localhost:6060/debug/pprof/goroutine?debug=1

goroutine profile: total 1234
1234 @ 0x...
#   0x... main.leakyGoroutine+0x40    /path/to/goroutine_leak.go:23

å‘ç°: æœ‰ 1234 ä¸ª goroutine é˜»å¡åœ¨ leakyGoroutine!
```

**ä¿®å¤**:

```go
// fixed.go
func fixedGoroutine(ctx context.Context) {
    ch := make(chan int)

    select {
    case <-ch:
        // æ­£å¸¸å¤„ç†
    case <-ctx.Done():
        // è¶…æ—¶æˆ–å–æ¶ˆ,goroutine é€€å‡º
        return
    }
}

func main() {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()

    for {
        go fixedGoroutine(ctx)
        time.Sleep(100 * time.Millisecond)
    }
}
```

---

## ç¬¬ä¸ƒéƒ¨åˆ†: ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 7.1 é‡‡æ ·ç­–ç•¥

```text
é‡‡æ ·ç­–ç•¥æƒè¡¡:

1. é‡‡æ ·ç‡ (Sampling Rate):
   - 10 Hz (æ¯ç§’ 10 æ¬¡): ä½å¼€é”€, å¯èƒ½ä¸¢å¤±çŸ­ç”Ÿå‘½å‘¨æœŸå‡½æ•°
   - 100 Hz: å¹³è¡¡ (æ¨èç”Ÿäº§ç¯å¢ƒ)
   - 1000 Hz: é«˜å¼€é”€, ä»…ç”¨äºè°ƒè¯•

2. é‡‡é›†æ—¶é•¿:
   - CPU Profile: 10-30 ç§’ (æ¨è 10 ç§’)
   - Heap Profile: ç¬æ—¶å¿«ç…§
   - Allocation Profile: 30-60 ç§’

3. é‡‡é›†é¢‘ç‡:
   - Continuous Profiling: æ¯ 10-60 ç§’
   - æŒ‰éœ€é‡‡é›†: ä»…åœ¨æ€§èƒ½é—®é¢˜æ—¶

4. æ•°æ®ä¿ç•™:
   - åŸå§‹ Profile: 7-30 å¤©
   - èšåˆæ•°æ®: æ°¸ä¹…
```

**Go é‡‡æ ·é…ç½®**:

```go
// sampling_config.go
import "runtime"

func init() {
    // CPU Profile é‡‡æ ·ç‡ (é»˜è®¤ 100 Hz)
    runtime.SetCPUProfileRate(100)

    // Memory Profile é‡‡æ ·ç‡ (é»˜è®¤æ¯ 512KB é‡‡æ ·ä¸€æ¬¡)
    runtime.MemProfileRate = 512 * 1024  // 512KB

    // Block Profile é‡‡æ ·ç‡ (é»˜è®¤ 0, å³ç¦ç”¨)
    runtime.SetBlockProfileRate(1000000)  // 1ms ä»¥ä¸Šçš„é˜»å¡æ‰è®°å½•

    // Mutex Profile é‡‡æ ·ç‡ (é»˜è®¤ 0, å³ç¦ç”¨)
    runtime.SetMutexProfileFraction(1000)  // 1/1000 çš„é”ç«äº‰è¢«è®°å½•
}
```

### 7.2 æ€§èƒ½å½±å“è¯„ä¼°

```text
Profiling æ€§èƒ½å¼€é”€:

æ–¹å¼                    CPU å¼€é”€    å†…å­˜å¼€é”€    ç”Ÿäº§å¯ç”¨
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€
Go pprof (100 Hz)       <1%         ~10MB      âœ…
Java JFR (default)      <1%         ~20MB      âœ…
Python cProfile         10-30%      ~50MB      âŒ (ä»…å¼€å‘)
py-spy (sampling)       <1%         ~5MB       âœ…
eBPF (Parca/Pyroscope)  <0.5%       ~5MB       âœ…
Instrumentation         5-20%       é«˜         âŒ (ä»…æµ‹è¯•)

æ¨èç”Ÿäº§ç¯å¢ƒ:
1. eBPF-based (æœ€ä½å¼€é”€)
2. Go pprof + Continuous Profiling
3. Java JFR
```

### 7.3 æ•°æ®å­˜å‚¨ä¸æŸ¥è¯¢

```text
Profile æ•°æ®å­˜å‚¨:

1. æ•°æ®é‡ä¼°ç®—:
   - å•ä¸ª CPU Profile: ~500KB (æœªå‹ç¼©)
   - å‹ç¼©å: ~50KB (gzip)
   - èšåˆå: ~5KB/å¤© (ä»…ä¿ç•™ top N å‡½æ•°)

   ç¤ºä¾‹: 100 ä¸ªæœåŠ¡, æ¯ä¸ªæ¯ 10 ç§’é‡‡é›†ä¸€æ¬¡
   - æ¯å¤©: 100 * 8640 * 50KB = 43GB (æœªå‹ç¼©)
   - å‹ç¼©å: 4.3GB/å¤©
   - èšåˆå: 0.5GB/å¤©

2. å­˜å‚¨æ–¹æ¡ˆ:
   - Parca: è‡ªæœ‰æ ¼å¼, é«˜åº¦å‹ç¼©
   - Pyroscope: Parquet æ ¼å¼
   - å¯¹è±¡å­˜å‚¨: S3/GCS (é•¿æœŸå­˜å‚¨)

3. æŸ¥è¯¢ä¼˜åŒ–:
   - æ ‡ç­¾ç´¢å¼• (service, version, region)
   - æ—¶é—´åˆ†ç‰‡ (æŒ‰å°æ—¶/å¤©)
   - é¢„èšåˆ (top functions)
```

### 7.4 å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹

```yaml
# prometheus-rules.yaml - Profile ç›¸å…³å‘Šè­¦

groups:
- name: profiling_alerts
  rules:
  # CPU çƒ­ç‚¹å‡½æ•°å æ¯”å¼‚å¸¸å¢åŠ 
  - alert: CPUHotspotIncreased
    expr: |
      (
        sum by (service, function) (rate(cpu_profile_samples[5m]))
        /
        sum by (service) (rate(cpu_profile_samples[5m]))
      ) > 0.3  # å•ä¸ªå‡½æ•°å æ¯”è¶…è¿‡ 30%
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "CPU hotspot detected in {{ $labels.service }}"
      description: "Function {{ $labels.function }} is using {{ $value | humanizePercentage }} of CPU time"

  # å†…å­˜åˆ†é…é€Ÿç‡å¼‚å¸¸
  - alert: HighAllocationRate
    expr: rate(go_memstats_alloc_bytes_total[5m]) > 100 * 1024 * 1024  # 100MB/s
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory allocation rate in {{ $labels.service }}"
      description: "Allocation rate: {{ $value | humanize }}B/s"

  # Goroutine æ³„æ¼
  - alert: GoroutineLeakSuspected
    expr: go_goroutines > 10000 and rate(go_goroutines[30m]) > 100
    for: 15m
    labels:
      severity: critical
    annotations:
      summary: "Possible goroutine leak in {{ $labels.service }}"
      description: "Goroutine count: {{ $value }}, increasing rapidly"
```

---

## ç¬¬å…«éƒ¨åˆ†: Profiles + Traces + Metrics å…³è”

### 8.1 Exemplars - ä» Metrics åˆ° Profiles

```text
Exemplars æ˜¯ Prometheus çš„ç‰¹æ€§,
å¯ä»¥å°† Metrics ä¸ Traces/Profiles å…³è”:

Metrics (èšåˆæ•°æ®)  â”€â”€â”€â”
                       â”œâ”€â”€â–¶ Exemplar â”€â”€â–¶ Trace/Profile (è¯¦ç»†æ•°æ®)
Histogram/Summary  â”€â”€â”€â”˜

ç¤ºä¾‹:
http_request_duration_seconds_bucket{le="0.5"} 1000
# å…¶ä¸­æŸä¸ªè¯·æ±‚çš„ exemplar:
http_request_duration_seconds_bucket{le="0.5"} 1000 # {trace_id="abc123",profile_id="xyz789"} 0.123 1633024800
```

**Go å®ç° (Prometheus + Exemplars)**:

```go
// exemplars.go
package main

import (
    "context"
    "math/rand"
    "net/http"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/trace"
)

var (
    // æ”¯æŒ Exemplars çš„ Histogram
    httpDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "path"},
    )
)

func handler(w http.ResponseWriter, r *http.Request) {
    start := time.Now()

    // å¼€å§‹ Trace
    ctx := r.Context()
    tracer := otel.Tracer("my-service")
    ctx, span := tracer.Start(ctx, "handleRequest")
    defer span.End()

    // ä¸šåŠ¡é€»è¾‘
    time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)

    // è®°å½• Metrics + Exemplar (åŒ…å« trace_id)
    duration := time.Since(start).Seconds()
    traceID := span.SpanContext().TraceID().String()

    httpDuration.WithLabelValues("GET", "/api").
        ObserveWithExemplar(duration, prometheus.Labels{
            "trace_id": traceID,
        })

    w.WriteHeader(http.StatusOK)
}

func main() {
    http.HandleFunc("/api", handler)
    http.Handle("/metrics", promhttp.Handler())
    http.ListenAndServe(":8080", nil)
}
```

**Grafana æŸ¥è¯¢ (ä» Metrics è·³è½¬åˆ° Trace)**:

```promql
# æŸ¥è¯¢æ…¢è¯·æ±‚çš„ trace_id
topk(10, histogram_quantile(0.99,
  rate(http_request_duration_seconds_bucket[5m])
)) by (trace_id)

# ç‚¹å‡» Exemplar å›¾æ ‡ â†’ è‡ªåŠ¨è·³è½¬åˆ° Jaeger/Tempo
```

### 8.2 SpanID å…³è” - ä» Traces åˆ° Profiles

```go
// span_profile_link.go
package main

import (
    "bytes"
    "context"
    "runtime/pprof"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/trace"
)

func slowOperation(ctx context.Context) {
    tracer := otel.Tracer("my-service")
    ctx, span := tracer.Start(ctx, "slowOperation")
    defer span.End()

    // é‡‡é›†è¿™ä¸ª Span çš„ CPU Profile
    var buf bytes.Buffer
    pprof.StartCPUProfile(&buf)
    
    // æ‰§è¡Œè€—æ—¶æ“ä½œ
    time.Sleep(2 * time.Second)
    heavyComputation()
    
    pprof.StopCPUProfile()

    // å°† Profile ä¸ Span å…³è”
    profileID := uploadProfile(buf.Bytes())
    span.SetAttributes(attribute.String("profile.id", profileID))

    // åœ¨ Trace UI ä¸­å¯ä»¥çœ‹åˆ° profile.id å±æ€§
    // ç‚¹å‡»å¯è·³è½¬åˆ° Profile æŸ¥çœ‹å™¨
}

func uploadProfile(data []byte) string {
    // ä¸Šä¼  Profile åˆ° Parca/Pyroscope
    // è¿”å› Profile ID
    return "profile-abc123"
}
```

### 8.3 ç»Ÿä¸€å¯è§‚æµ‹æ€§å¹³å°

```text
å®Œæ•´çš„å¯è§‚æµ‹æ€§å…³è”:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Grafana Dashboard                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚       â”‚              â”‚             â”‚
    â–¼       â–¼       â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Metrics â”‚ â”‚Logsâ”‚ â”‚ Traces  â”‚ â”‚Profilesâ”‚ â”‚ Events   â”‚
â”‚Prometheus Loki â”‚ â”‚ Tempo   â”‚ â”‚Pyroscopeâ”‚ â”‚Alertmgr â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚          â”‚            â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                 Correlation
              (trace_id, span_id,
               profile_id, labels)

å·¥ä½œæµç¤ºä¾‹:
1. Metrics æ˜¾ç¤º P99 å»¶è¿Ÿå¢åŠ  â†’ ç‚¹å‡» Exemplar â†’ è·³è½¬åˆ° Trace
2. Trace æ˜¾ç¤ºæŸä¸ª Span æ…¢ â†’ æŸ¥çœ‹ profile.id â†’ è·³è½¬åˆ° Profile
3. Profile æ˜¾ç¤º CPU çƒ­ç‚¹å‡½æ•° â†’ æŸ¥çœ‹å‡½æ•°ä»£ç  â†’ ä¼˜åŒ–
4. ä¼˜åŒ–å â†’ Metrics æ˜¾ç¤ºå»¶è¿Ÿé™ä½ â†’ éªŒè¯æˆåŠŸ
```

---

## ç¬¬ä¹éƒ¨åˆ†: é«˜çº§è¯é¢˜

### 9.1 eBPF-based Profiling

#### Parca Agent eBPF å®ç°

```text
eBPF-based Profiling ä¼˜åŠ¿:
1. æ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
2. æ— éœ€é‡å¯åº”ç”¨
3. æ”¯æŒæ‰€æœ‰è¯­è¨€ (åŒ…æ‹¬ native code)
4. æä½å¼€é”€ (<0.5% CPU)
5. å†…æ ¸çº§é‡‡æ ·,æ›´ç²¾ç¡®

å·¥ä½œåŸç†:
1. eBPF ç¨‹åº attach åˆ° perf_event (timer)
2. æ¯ 10ms é‡‡é›†ä¸€æ¬¡ CPU è°ƒç”¨æ ˆ
3. è§£æç¬¦å·è¡¨ (DWARF, symbol table)
4. èšåˆå¹¶ä¸Šä¼ åˆ° Parca Server

æŒ‘æˆ˜:
1. ç¬¦å·è§£æ (éœ€è¦ debug symbols æˆ– DWARF)
2. å®¹å™¨åŒ–ç¯å¢ƒ (éœ€è¦è®¿é—®å®¿ä¸»æœº /proc)
3. JIT ä»£ç  (Java, Node.js éœ€è¦é¢å¤–æ”¯æŒ)
```

**Parca Agent æ ¸å¿ƒ eBPF ç¨‹åº** (ç®€åŒ–ç‰ˆ):

```c
// parca_agent.bpf.c
#include <linux/bpf.h>
#include <bpf/bpf_helpers.h>

#define MAX_STACK_DEPTH 127

struct {
    __uint(type, BPF_MAP_TYPE_STACK_TRACE);
    __uint(max_entries, 10000);
    __uint(key_size, sizeof(__u32));
    __uint(value_size, MAX_STACK_DEPTH * sizeof(__u64));
} stack_traces SEC(".maps");

struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 10000);
    __type(key, __u32);  // stack_id
    __type(value, __u64);  // count
} counts SEC(".maps");

SEC("perf_event")
int profile_cpu(struct bpf_perf_event_data *ctx) {
    __u32 pid = bpf_get_current_pid_tgid() >> 32;

    // é‡‡é›†è°ƒç”¨æ ˆ
    __u32 stack_id = bpf_get_stackid(ctx, &stack_traces, 0);
    if (stack_id < 0)
        return 0;

    // å¢åŠ è®¡æ•°
    __u64 *count = bpf_map_lookup_elem(&counts, &stack_id);
    if (count) {
        __sync_fetch_and_add(count, 1);
    } else {
        __u64 one = 1;
        bpf_map_update_elem(&counts, &stack_id, &one, BPF_NOEXIST);
    }

    return 0;
}

char LICENSE[] SEC("license") = "GPL";
```

**ç”¨æˆ·æ€ç¨‹åº** (Go):

```go
// parca_agent.go
package main

import (
    "fmt"
    "time"

    "github.com/cilium/ebpf"
    "github.com/cilium/ebpf/link"
    "github.com/cilium/ebpf/perf"
)

func main() {
    // åŠ è½½ eBPF ç¨‹åº
    spec, err := ebpf.LoadCollectionSpec("parca_agent.bpf.o")
    if err != nil {
        panic(err)
    }

    coll, err := ebpf.NewCollection(spec)
    if err != nil {
        panic(err)
    }
    defer coll.Close()

    // Attach åˆ° perf_event (CPU clock, 100 Hz)
    prog := coll.Programs["profile_cpu"]
    link, err := link.AttachPerfEvent(link.PerfEventOptions{
        Program:  prog,
        PerfType: perf.EventTypeHardware,
        Config:   perf.ConfigHardwareCPUCycles,
        SamplePeriod: 10000000,  // 100 Hz
    })
    if err != nil {
        panic(err)
    }
    defer link.Close()

    // å®šæœŸè¯»å– counts map
    ticker := time.NewTicker(10 * time.Second)
    for range ticker.C {
        processProfiles(coll)
    }
}

func processProfiles(coll *ebpf.Collection) {
    stackTraces := coll.Maps["stack_traces"]
    counts := coll.Maps["counts"]

    // éå† counts
    var stackID uint32
    var count uint64
    iter := counts.Iterate()
    for iter.Next(&stackID, &count) {
        // è·å–è°ƒç”¨æ ˆ
        var stack []uint64
        if err := stackTraces.Lookup(stackID, &stack); err != nil {
            continue
        }

        // è§£æç¬¦å· (ç®€åŒ–, å®é™…éœ€è¦è¯»å– /proc/[pid]/maps å’Œ ELF)
        for _, addr := range stack {
            symbol := resolveSymbol(addr)
            fmt.Printf("  %s\n", symbol)
        }
        fmt.Printf("  count: %d\n\n", count)
    }

    // æ¸…ç©º counts (å¼€å§‹æ–°çš„é‡‡æ ·å‘¨æœŸ)
    counts.Close()
}

func resolveSymbol(addr uint64) string {
    // TODO: è§£æç¬¦å·è¡¨
    return fmt.Sprintf("0x%x", addr)
}
```

### 9.2 å·®åˆ†åˆ†æ (Diff Analysis)

```bash
# å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„ Profile (æ‰¾å‡ºæ€§èƒ½é€€åŒ–)

# é‡‡é›† v1.0 çš„ profile
curl -o v1.0.prof http://service-v1:6060/debug/pprof/profile?seconds=30

# éƒ¨ç½² v1.1
# é‡‡é›† v1.1 çš„ profile
curl -o v1.1.prof http://service-v1:6060/debug/pprof/profile?seconds=30

# å¯¹æ¯”
go tool pprof -http=:8080 -base v1.0.prof v1.1.prof

# æˆ–ä½¿ç”¨ Parca/Pyroscope Web UI:
# 1. é€‰æ‹© v1.0 ä½œä¸º baseline
# 2. é€‰æ‹© v1.1 ä½œä¸º comparison
# 3. æŸ¥çœ‹å·®å¼‚ç«ç„°å›¾ (Diff Flame Graph)
#    - çº¢è‰²: æ€§èƒ½å˜å·® (CPU æ—¶é—´å¢åŠ )
#    - ç»¿è‰²: æ€§èƒ½æ”¹å–„ (CPU æ—¶é—´å‡å°‘)
#    - ç°è‰²: æ— å˜åŒ–
```

**Parca Web UI Diff æŸ¥è¯¢**:

```text
# Parca Query Language (PQL)

# æŸ¥è¯¢ v1.1 ç›¸æ¯” v1.0 çš„å·®å¼‚
profile_cpu{service="my-service", version="v1.1"}
-
profile_cpu{service="my-service", version="v1.0"}

# ç»“æœ: æ˜¾ç¤ºæ¯ä¸ªå‡½æ•°çš„ CPU æ—¶é—´å˜åŒ–
main.processRequest: +50ms (+25%)  # æ€§èƒ½é€€åŒ–
main.parseJSON: -20ms (-40%)       # æ€§èƒ½æ”¹å–„
```

### 9.3 å¤šç»´åº¦æ ‡ç­¾ (Multi-dimensional Labels)

```go
// multi_dimensional_labels.go
package main

import (
    "github.com/grafana/pyroscope-go"
)

func main() {
    pyroscope.Start(pyroscope.Config{
        ApplicationName: "my-service",
        ServerAddress:   "http://pyroscope:4040",

        // é™æ€æ ‡ç­¾ (åœ¨è¿›ç¨‹å¯åŠ¨æ—¶ç¡®å®š)
        Tags: map[string]string{
            "service":  "my-service",
            "version":  "v1.2.3",
            "region":   "us-east-1",
            "env":      "production",
            "hostname": "pod-abc123",
        },
    })

    // åŠ¨æ€æ ‡ç­¾ (åœ¨è¿è¡Œæ—¶æ ¹æ®ä¸Šä¸‹æ–‡æ·»åŠ )
    pyroscope.TagWrapper(context.Background(), pyroscope.Labels(
        "endpoint", "/api/users",
        "user_tier", "premium",
    ), func(ctx context.Context) {
        // è¿™ä¸ªä»£ç å—çš„ profile ä¼šåŒ…å«ä¸Šè¿°æ ‡ç­¾
        handleRequest(ctx)
    })
}

func handleRequest(ctx context.Context) {
    // æ ¹æ®ç”¨æˆ·ç±»å‹æ·»åŠ ä¸åŒæ ‡ç­¾
    userID := getUserID(ctx)
    userTier := getUserTier(userID)

    pyroscope.TagWrapper(ctx, pyroscope.Labels(
        "user_id", userID,
        "user_tier", userTier,
    ), func(ctx context.Context) {
        // å®é™…ä¸šåŠ¡é€»è¾‘
        processUserRequest(ctx)
    })
}
```

**æŸ¥è¯¢å¤šç»´åº¦ Profile**:

```text
# Pyroscope Query

# æŸ¥è¯¢æ‰€æœ‰ Premium ç”¨æˆ·çš„ CPU profile
profile_cpu{service="my-service", user_tier="premium"}

# æŸ¥è¯¢ç‰¹å®š endpoint çš„ profile
profile_cpu{service="my-service", endpoint="/api/users"}

# å¯¹æ¯”ä¸åŒ region çš„æ€§èƒ½
profile_cpu{service="my-service", region="us-east-1"}
vs
profile_cpu{service="my-service", region="eu-west-1"}
```

---

## ç¬¬åéƒ¨åˆ†: å®Œæ•´ç”Ÿäº§æ¡ˆä¾‹

### 10.1 æ¡ˆä¾‹: ç”µå•†å¹³å°æ€§èƒ½ä¼˜åŒ–

#### ç³»ç»ŸèƒŒæ™¯

```text
ç³»ç»Ÿ: å¤§å‹ç”µå•†å¹³å°è®¢å•æœåŠ¡
è§„æ¨¡: 10,000 QPS, 100+ å¾®æœåŠ¡
é—®é¢˜: P99 å»¶è¿Ÿä» 200ms å¢åŠ åˆ° 1.5s (è¿‡å» 2 å‘¨)
å½±å“: ç”¨æˆ·æŠ•è¯‰å¢åŠ , è®¢å•è½¬åŒ–ç‡ä¸‹é™ 5%
```

#### å®æ–½æ–¹æ¡ˆ

**æ­¥éª¤ 1: éƒ¨ç½² Continuous Profiling**:

```yaml
# éƒ¨ç½² Parca
kubectl apply -f parca-deployment.yaml

# ä¸ºæ‰€æœ‰æœåŠ¡å¯ç”¨ pprof (Go æœåŠ¡)
# main.go
import _ "net/http/pprof"

func main() {
    go func() {
        http.ListenAndServe(":6060", nil)
    }()
    // ...
}

# é…ç½® Parca Agent æ‹‰å– profiles
# parca-agent-config.yaml
scrape_configs:
  - job_name: "order-service"
    scrape_interval: "10s"
    static_configs:
      - targets:
        - "order-service-1:6060"
        - "order-service-2:6060"
        - "order-service-3:6060"
        labels:
          service: "order-service"
          version: "v2.3.5"
```

**æ­¥éª¤ 2: åˆ†ææ€§èƒ½é€€åŒ–**:

```bash
# å¯¹æ¯” 2 å‘¨å‰çš„ profile
# Parca UI: é€‰æ‹©æ—¶é—´èŒƒå›´å¯¹æ¯”

å‘ç°:
1. database.(*Client).Query ä» 10% â†’ 45% (CPU æ—¶é—´)
2. æ–°å¢çš„å‡½æ•° validateOrder å ç”¨ 15%
3. json.Marshal å ç”¨ 20% (ä¹‹å‰ 5%)
```

**æ­¥éª¤ 3: æ·±å…¥åˆ†æ**:

```text
1. database.(*Client).Query å¢åŠ :
   - æŸ¥çœ‹ä»£ç  git blame
   - å‘ç° 2 å‘¨å‰æ·»åŠ äº†æ–°çš„æŸ¥è¯¢: SELECT * FROM order_items WHERE order_id = ?
   - é—®é¢˜: N+1 æŸ¥è¯¢! æ¯ä¸ªè®¢å•éƒ½æŸ¥è¯¢ä¸€æ¬¡
   
2. validateOrder å‡½æ•°:
   - æ–°å¢çš„ä¸šåŠ¡é€»è¾‘
   - åŒ…å«å¤šæ¬¡æ•°æ®åº“æŸ¥è¯¢å’Œå¤–éƒ¨ API è°ƒç”¨
   - ä¼˜åŒ–ç©ºé—´å¤§

3. json.Marshal å¢åŠ :
   - å“åº”ä½“å˜å¤§ (æ–°å¢äº†å¤§é‡å­—æ®µ)
   - æ²¡æœ‰å¤ç”¨åºåˆ—åŒ–ç»“æœ
```

**æ­¥éª¤ 4: ä¼˜åŒ–**:

```go
// ä¼˜åŒ– 1: ä¿®å¤ N+1 æŸ¥è¯¢
// before.go
func GetOrder(orderID string) (*Order, error) {
    order := &Order{}
    db.Get(order, "SELECT * FROM orders WHERE id = ?", orderID)

    // N+1 æŸ¥è¯¢!
    for _, item := range order.Items {
        db.Get(&item, "SELECT * FROM order_items WHERE order_id = ?", orderID)
    }
    return order, nil
}

// after.go
func GetOrder(orderID string) (*Order, error) {
    order := &Order{}
    db.Get(order, "SELECT * FROM orders WHERE id = ?", orderID)

    // æ‰¹é‡æŸ¥è¯¢
    db.Select(&order.Items, "SELECT * FROM order_items WHERE order_id = ?", orderID)
    return order, nil
}

// ä¼˜åŒ– 2: å¹¶è¡ŒåŒ– validateOrder
// before.go
func validateOrder(order *Order) error {
    if err := checkInventory(order); err != nil {  // 500ms
        return err
    }
    if err := checkCredit(order.UserID); err != nil {  // 300ms
        return err
    }
    if err := checkAddress(order.Address); err != nil {  // 200ms
        return err
    }
    return nil  // æ€»è®¡: 1000ms
}

// after.go
func validateOrder(order *Order) error {
    var g errgroup.Group

    g.Go(func() error {
        return checkInventory(order)  // å¹¶è¡Œ
    })
    g.Go(func() error {
        return checkCredit(order.UserID)  // å¹¶è¡Œ
    })
    g.Go(func() error {
        return checkAddress(order.Address)  // å¹¶è¡Œ
    })

    return g.Wait()  // æ€»è®¡: 500ms (æœ€æ…¢çš„é‚£ä¸ª)
}

// ä¼˜åŒ– 3: ç¼“å­˜ JSON åºåˆ—åŒ–ç»“æœ
var jsonCache = cache.New(5*time.Minute, 10*time.Minute)

func serializeOrder(order *Order) ([]byte, error) {
    cacheKey := fmt.Sprintf("order_json_%s_%d", order.ID, order.UpdatedAt.Unix())

    if cached, found := jsonCache.Get(cacheKey); found {
        return cached.([]byte), nil  // å‘½ä¸­ç¼“å­˜
    }

    data, err := json.Marshal(order)
    if err != nil {
        return nil, err
    }

    jsonCache.Set(cacheKey, data, cache.DefaultExpiration)
    return data, nil
}
```

**æ­¥éª¤ 5: éªŒè¯ä¼˜åŒ–æ•ˆæœ**:

```bash
# éƒ¨ç½²ä¼˜åŒ–åçš„ç‰ˆæœ¬ v2.3.6
kubectl set image deployment/order-service order-service=order-service:v2.3.6

# å¯¹æ¯” Profile
# Parca UI: é€‰æ‹© v2.3.5 vs v2.3.6

ç»“æœ:
- database.(*Client).Query: 45% â†’ 8% (å‡å°‘ 82%)
- validateOrder: 15% â†’ 5% (å‡å°‘ 67%)
- json.Marshal: 20% â†’ 3% (å‡å°‘ 85%)
```

#### ä¼˜åŒ–æˆæœ

```text
æ€§èƒ½æŒ‡æ ‡:
- P50 å»¶è¿Ÿ: 50ms â†’ 45ms (æ”¹å–„ 10%)
- P99 å»¶è¿Ÿ: 1.5s â†’ 180ms (æ”¹å–„ 88%)
- P999 å»¶è¿Ÿ: 3s â†’ 500ms (æ”¹å–„ 83%)
- QPS: 10,000 â†’ 15,000 (æå‡ 50%)

èµ„æºä½¿ç”¨:
- CPU ä½¿ç”¨ç‡: 75% â†’ 35% (å‡å°‘ 53%)
- å†…å­˜ä½¿ç”¨: 8GB â†’ 6GB (å‡å°‘ 25%)
- æ•°æ®åº“è¿æ¥æ•°: 500 â†’ 100 (å‡å°‘ 80%)

ä¸šåŠ¡æŒ‡æ ‡:
- è®¢å•è½¬åŒ–ç‡: æ¢å¤å¹¶æå‡ 8%
- ç”¨æˆ·æŠ•è¯‰: å‡å°‘ 90%
- æˆæœ¬èŠ‚çº¦: å‡å°‘ 15 å°æœåŠ¡å™¨ (èŠ‚çœ $5,000/æœˆ)

ROI:
- ä¼˜åŒ–æŠ•å…¥: 40 å·¥æ—¶ (çº¦ $8,000)
- æœˆåº¦æ”¶ç›Š: $5,000 (æˆæœ¬) + $50,000 (ä¸šåŠ¡å¢é•¿)
- ROI: 687% (é¦–æœˆ)
```

---

## æ€»ç»“

### Continuous Profiling æ ¸å¿ƒä»·å€¼

âœ… **æå‰å‘ç°æ€§èƒ½é—®é¢˜**: åœ¨ç”¨æˆ·æŠ•è¯‰ä¹‹å‰å‘ç°  
âœ… **å¿«é€Ÿå®šä½æ ¹å› **: ä» Metrics â†’ Traces â†’ Profiles â†’ ä»£ç   
âœ… **å†å²æ•°æ®è¿½æº¯**: å›ç­”"ä»€ä¹ˆæ—¶å€™å¼€å§‹å˜æ…¢çš„"  
âœ… **ä¼˜åŒ–æ•ˆæœéªŒè¯**: é‡åŒ–ä¼˜åŒ–å‰åçš„æ€§èƒ½å·®å¼‚  
âœ… **æˆæœ¬ä¼˜åŒ–**: å‘ç°èµ„æºæµªè´¹ (CPU, å†…å­˜, ç½‘ç»œ)  
âœ… **ä½å¼€é”€**: <1% CPU, å¯ 7x24 è¿è¡Œ

### é€‚ç”¨åœºæ™¯

1. **å¾®æœåŠ¡æ¶æ„** - å®šä½è·¨æœåŠ¡æ€§èƒ½ç“¶é¢ˆ
2. **é«˜å¹¶å‘ç³»ç»Ÿ** - CPU/å†…å­˜ä¼˜åŒ–
3. **SaaS å¹³å°** - å¤šç§Ÿæˆ·æ€§èƒ½éš”ç¦»
4. **é‡‘èäº¤æ˜“** - ä½å»¶è¿Ÿä¼˜åŒ–
5. **å¤§æ•°æ®å¤„ç†** - è®¡ç®—å¯†é›†å‹ä¼˜åŒ–

### å‚è€ƒèµ„æº

- ğŸ“š [Google Cloud Profiler æ–‡æ¡£](https://cloud.google.com/profiler/docs)
- ğŸ“š [Parca å®˜æ–¹ç½‘ç«™](https://www.parca.dev/)
- ğŸ“š [Pyroscope æ–‡æ¡£](https://grafana.com/docs/pyroscope/latest/)
- ğŸ“š [Go pprof æ–‡æ¡£](https://pkg.go.dev/net/http/pprof)
- ğŸ“š [Java Flight Recorder æŒ‡å—](https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm)
- ğŸ“š [Brendan Gregg's Flame Graphs](https://www.brendangregg.com/flamegraphs.html)
- ğŸ“š [eBPF Profiling åŸç†](https://www.polarsignals.com/blog/posts/2022/11/29/profiling-at-the-speed-of-light-with-ebpf/)
- ğŸ“„ [è®ºæ–‡: Continuous Profiling at Google](https://research.google/pubs/pub36575/)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

### æ ¸å¿ƒé›†æˆ â­â­â­

- **ğŸ¤– AIOpså¹³å°è®¾è®¡**: [æŸ¥çœ‹æ–‡æ¡£](./ğŸ¤–_OTLPè‡ªä¸»è¿ç»´èƒ½åŠ›å®Œæ•´æ¶æ„_AIOpså¹³å°è®¾è®¡.md)
  - ä½¿ç”¨åœºæ™¯: Profilingæ•°æ®æ¥å…¥AIOps,è‡ªåŠ¨æ£€æµ‹æ€§èƒ½å¼‚å¸¸
  - å…³é”®ç« èŠ‚: [æ€§èƒ½ç“¶é¢ˆæ£€æµ‹](./ğŸ¤–_OTLPè‡ªä¸»è¿ç»´èƒ½åŠ›å®Œæ•´æ¶æ„_AIOpså¹³å°è®¾è®¡.md#ç¬¬ä¸‰éƒ¨åˆ†-æœºå™¨å­¦ä¹ æ¨¡å‹)
  - ä»·å€¼: æ€§èƒ½é—®é¢˜å‘ç°æ—¶é—´ä»3å¤©é™è‡³30åˆ†é’Ÿ

- **ğŸ eBPFé›¶ä¾µå…¥è¿½è¸ª**: [æŸ¥çœ‹æ–‡æ¡£](./ğŸ_eBPFå¯è§‚æµ‹æ€§æ·±åº¦æŠ€æœ¯æŒ‡å—_é›¶ä¾µå…¥å¼è¿½è¸ª.md)
  - ä½¿ç”¨åœºæ™¯: åŸºäºeBPFçš„æŒç»­æ€§èƒ½å‰–æ,æ— éœ€ä¿®æ”¹åº”ç”¨
  - å…³é”®ç« èŠ‚: [eBPF Profiling](./ğŸ_eBPFå¯è§‚æµ‹æ€§æ·±åº¦æŠ€æœ¯æŒ‡å—_é›¶ä¾µå…¥å¼è¿½è¸ª.md#æ€§èƒ½åˆ†æ)
  - ä»·å€¼: é›¶ä¾µå…¥,å¼€é”€<1%,ç”Ÿäº§ç¯å¢ƒ7x24è¿è¡Œ

- **ğŸ•¸ï¸ Service Meshé›†æˆ**: [æŸ¥çœ‹æ–‡æ¡£](./ğŸ•¸ï¸_æœåŠ¡ç½‘æ ¼å¯è§‚æµ‹æ€§å®Œæ•´æŒ‡å—_Istio_Linkerdæ·±åº¦é›†æˆ.md)
  - ä½¿ç”¨åœºæ™¯: Envoy Sidecaræ€§èƒ½å‰–æ,ä¼˜åŒ–Service Meshå¼€é”€
  - å…³é”®ç« èŠ‚: [Envoyæ€§èƒ½ä¼˜åŒ–](./ğŸ•¸ï¸_æœåŠ¡ç½‘æ ¼å¯è§‚æµ‹æ€§å®Œæ•´æŒ‡å—_Istio_Linkerdæ·±åº¦é›†æˆ.md#ç¬¬äº”éƒ¨åˆ†-ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹)
  - ä»·å€¼: Sidecarå¼€é”€ä»15%é™è‡³3%

### æ¶æ„å¯è§†åŒ– â­â­â­

- **ğŸ“Š æ¶æ„å›¾è¡¨æŒ‡å—**: [æŸ¥çœ‹æ–‡æ¡£](./ğŸ“Š_æ¶æ„å›¾è¡¨ä¸å¯è§†åŒ–æŒ‡å—_Mermaidå®Œæ•´ç‰ˆ.md)
  - æ¨èå›¾è¡¨:
    - [Profilingæ¶æ„](./ğŸ“Š_æ¶æ„å›¾è¡¨ä¸å¯è§†åŒ–æŒ‡å—_Mermaidå®Œæ•´ç‰ˆ.md#6-continuous-profiling)
    - [Profilingä¸Tracingå…³è”](./ğŸ“Š_æ¶æ„å›¾è¡¨ä¸å¯è§†åŒ–æŒ‡å—_Mermaidå®Œæ•´ç‰ˆ.md#62-profiling-ä¸-tracing-å…³è”)
  - ä»·å€¼: Trace â†’ Profileè·³è½¬æµç¨‹ä¸€ç›®äº†ç„¶

### å·¥å…·é“¾æ”¯æŒ â­â­

- **ğŸ“š SDKæœ€ä½³å®è·µ**: [æŸ¥çœ‹æ–‡æ¡£](./ğŸ“š_OTLP_SDKæœ€ä½³å®è·µæŒ‡å—_å¤šè¯­è¨€å…¨æ ˆå®ç°.md)
  - ä½¿ç”¨åœºæ™¯: SDKé›†æˆProfiling,å®ç°Trace-Profileå…³è”
  - å…³é”®ç« èŠ‚: [Exemplarsé›†æˆ](./ğŸ“š_OTLP_SDKæœ€ä½³å®è·µæŒ‡å—_å¤šè¯­è¨€å…¨æ ˆå®ç°.md#ç¬¬ä¸‰éƒ¨åˆ†-ç”Ÿäº§çº§ä¼˜åŒ–)
  - ä»·å€¼: ä»æ…¢è¯·æ±‚ç›´æ¥è·³è½¬åˆ°ç«ç„°å›¾

---

**æ–‡æ¡£å®Œæˆæ—¶é—´**: 2025å¹´10æœˆ9æ—¥  
**æ–‡æ¡£çŠ¶æ€**: å®Œæ•´ç‰ˆ (2,500+ è¡Œ)  
**æ¨èå­¦ä¹ æ—¶é•¿**: 3-5 å¤© (å«å®è·µ)

---

*"Performance is not a sprint, it's a marathon with Continuous Profiling!"*-
