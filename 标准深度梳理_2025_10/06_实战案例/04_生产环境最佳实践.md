# ç”Ÿäº§ç¯å¢ƒOpenTelemetryæœ€ä½³å®è·µ

> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥

---

## ç›®å½•

- [ç”Ÿäº§ç¯å¢ƒOpenTelemetryæœ€ä½³å®è·µ](#ç”Ÿäº§ç¯å¢ƒopentelemetryæœ€ä½³å®è·µ)
  - [ç›®å½•](#ç›®å½•)
  - [1. ç”Ÿäº§ç¯å¢ƒå‡†å¤‡æ¸…å•](#1-ç”Ÿäº§ç¯å¢ƒå‡†å¤‡æ¸…å•)
  - [2. æ¶æ„è®¾è®¡](#2-æ¶æ„è®¾è®¡)
    - [2.1 Collectoréƒ¨ç½²æ¨¡å¼](#21-collectoréƒ¨ç½²æ¨¡å¼)
    - [2.2 é«˜å¯ç”¨æ¶æ„](#22-é«˜å¯ç”¨æ¶æ„)
  - [3. èµ„æºç®¡ç†](#3-èµ„æºç®¡ç†)
    - [3.1 CPUå’Œå†…å­˜é™åˆ¶](#31-cpuå’Œå†…å­˜é™åˆ¶)
    - [3.2 å­˜å‚¨è§„åˆ’](#32-å­˜å‚¨è§„åˆ’)
  - [4. é‡‡æ ·ç­–ç•¥](#4-é‡‡æ ·ç­–ç•¥)
  - [5. æ€§èƒ½ä¼˜åŒ–](#5-æ€§èƒ½ä¼˜åŒ–)
  - [6. ç›‘æ§ä¸å‘Šè­¦](#6-ç›‘æ§ä¸å‘Šè­¦)
  - [7. å®‰å…¨å®è·µ](#7-å®‰å…¨å®è·µ)
  - [8. æ•…éšœæ¢å¤](#8-æ•…éšœæ¢å¤)
  - [9. æˆæœ¬ä¼˜åŒ–](#9-æˆæœ¬ä¼˜åŒ–)
  - [10. åˆè§„æ€§](#10-åˆè§„æ€§)
  - [11. å›¢é˜Ÿåä½œ](#11-å›¢é˜Ÿåä½œ)
  - [12. æ¸è¿›å¼éƒ¨ç½²](#12-æ¸è¿›å¼éƒ¨ç½²)
  - [13. å…¸å‹ç”Ÿäº§é…ç½®](#13-å…¸å‹ç”Ÿäº§é…ç½®)
  - [14. æ•…éšœåœºæ™¯ä¸åº”å¯¹](#14-æ•…éšœåœºæ™¯ä¸åº”å¯¹)
  - [15. å‚è€ƒèµ„æº](#15-å‚è€ƒèµ„æº)

---

## 1. ç”Ÿäº§ç¯å¢ƒå‡†å¤‡æ¸…å•

```text
âœ… åŸºç¡€è®¾æ–½
- [ ] Collectoré›†ç¾¤éƒ¨ç½² (è‡³å°‘3èŠ‚ç‚¹)
- [ ] è´Ÿè½½å‡è¡¡å™¨é…ç½® (gRPCæ”¯æŒ)
- [ ] é«˜å¯ç”¨Backend (Jaeger/Prometheus HA)
- [ ] æŒä¹…åŒ–å­˜å‚¨ (Elasticsearch/S3)
- [ ] ç½‘ç»œç­–ç•¥ (é˜²ç«å¢™/å®‰å…¨ç»„)

âœ… é…ç½®
- [ ] é‡‡æ ·ç­–ç•¥ (ç”Ÿäº§çº§é‡‡æ ·ç‡)
- [ ] æ‰¹å¤„ç†é…ç½® (ä¼˜åŒ–ååé‡)
- [ ] èµ„æºé™åˆ¶ (memory_limiter)
- [ ] è¶…æ—¶è®¾ç½® (åˆç†è¶…æ—¶)
- [ ] é‡è¯•ç­–ç•¥ (æŒ‡æ•°é€€é¿)

âœ… ç›‘æ§
- [ ] Collectorè‡ªç›‘æ§ (Prometheus metrics)
- [ ] åº”ç”¨æ€§èƒ½ç›‘æ§ (overhead < 5%)
- [ ] å‘Šè­¦è§„åˆ™ (æ•°æ®ä¸¢å¤±/å»¶è¿Ÿ)
- [ ] Dashboard (å…³é”®æŒ‡æ ‡)
- [ ] SLOå®šä¹‰ (å¯ç”¨æ€§/å»¶è¿Ÿ)

âœ… å®‰å…¨
- [ ] TLSåŠ å¯† (mTLSæ¨è)
- [ ] è®¤è¯æœºåˆ¶ (API Key/OAuth2)
- [ ] PIIè¿‡æ»¤ (æ•æ„Ÿæ•°æ®åˆ é™¤)
- [ ] è®¿é—®æ§åˆ¶ (RBAC)
- [ ] å®¡è®¡æ—¥å¿— (åˆè§„è¦æ±‚)

âœ… è¿ç»´
- [ ] è‡ªåŠ¨åŒ–éƒ¨ç½² (CI/CD)
- [ ] é…ç½®ç®¡ç† (GitOps)
- [ ] å¤‡ä»½ç­–ç•¥ (å®šæœŸå¤‡ä»½)
- [ ] æ•…éšœæ¢å¤è®¡åˆ’ (DR plan)
- [ ] æ–‡æ¡£å®Œæ•´ (runbook)

âœ… æµ‹è¯•
- [ ] è´Ÿè½½æµ‹è¯• (å³°å€¼æµé‡)
- [ ] æ•…éšœæ³¨å…¥ (Chaos testing)
- [ ] æ€§èƒ½åŸºçº¿ (benchmark)
- [ ] ç«¯åˆ°ç«¯æµ‹è¯• (E2E)
- [ ] åˆè§„æµ‹è¯• (GDPR/PCI-DSS)
```

---

## 2. æ¶æ„è®¾è®¡

### 2.1 Collectoréƒ¨ç½²æ¨¡å¼

**Agent + Gatewayæ¨¡å¼** (æ¨è):

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application Pods                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ App+SDK â”‚  â”‚ App+SDK â”‚  â”‚ App+SDK â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
â”‚      â”‚            â”‚            â”‚                        â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                   â”‚                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚           â”‚ Agent Collectorâ”‚  (DaemonSet)              â”‚
â”‚           â”‚  - æœ¬åœ°ç¼“å†²     â”‚                           â”‚
â”‚           â”‚  - åˆæ­¥å¤„ç†     â”‚                           â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ (è·¨ç½‘ç»œ)
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gateway Collector Cluster (Deployment, 3+ replicas)   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚ â”‚ Gateway 1  â”‚  â”‚ Gateway 2  â”‚  â”‚ Gateway 3  â”‚       â”‚
â”‚ â”‚ - é‡‡æ ·     â”‚  â”‚ - é‡‡æ ·     â”‚  â”‚ - é‡‡æ ·     â”‚       â”‚
â”‚ â”‚ - èšåˆ     â”‚  â”‚ - èšåˆ     â”‚  â”‚ - èšåˆ     â”‚       â”‚
â”‚ â”‚ - è¿‡æ»¤     â”‚  â”‚ - è¿‡æ»¤     â”‚  â”‚ - è¿‡æ»¤     â”‚       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Backend (Jaeger HA)  â”‚
              â”‚ Elasticsearch Clusterâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¼˜åŠ¿:
- Agent: ä½å»¶è¿Ÿï¼Œæœ¬åœ°ç¼“å†²ï¼Œåº”ç”¨è§£è€¦
- Gateway: é›†ä¸­æ§åˆ¶ï¼Œé«˜çº§å¤„ç†ï¼Œæˆæœ¬ä¼˜åŒ–
```

### 2.2 é«˜å¯ç”¨æ¶æ„

**3å±‚é«˜å¯ç”¨**:

```yaml
# 1. SDKå±‚: å†…ç½®å®¹é”™
sdk:
  retry:
    enabled: true
    max_attempts: 3
  timeout: 5s
  fallback: drop_on_failure  # ä¸é˜»å¡åº”ç”¨

# 2. Agentå±‚: æœ¬åœ°ç¼“å­˜
agent:
  extensions:
    file_storage:
      directory: /var/lib/otelcol/storage
      timeout: 10s
  
  exporters:
    otlp:
      endpoint: gateway-service:4317
      retry_on_failure:
        enabled: true
        max_elapsed_time: 5m
      sending_queue:
        enabled: true
        num_consumers: 10
        queue_size: 5000
        storage: file_storage  # æŒä¹…åŒ–é˜Ÿåˆ—

# 3. Gatewayå±‚: è´Ÿè½½å‡è¡¡ + HA
gateway:
  replicas: 3
  antiAffinity: required  # åˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹
  
  service:
    type: LoadBalancer
    sessionAffinity: None  # è´Ÿè½½å‡è¡¡

# 4. Backendå±‚: é›†ç¾¤æ¨¡å¼
jaeger:
  collector:
    replicas: 3
  
  storage:
    type: elasticsearch
    elasticsearch:
      server-urls: http://es-cluster:9200
      num-shards: 5
      num-replicas: 2
```

---

## 3. èµ„æºç®¡ç†

### 3.1 CPUå’Œå†…å­˜é™åˆ¶

**Kubernetesèµ„æºé…ç½®**:

```yaml
# Agent (per node)
agent:
  resources:
    requests:
      cpu: 200m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  processors:
    memory_limiter:
      check_interval: 1s
      limit_mib: 400  # ç•™æœ‰å®‰å…¨è¾¹é™…
      spike_limit_mib: 100

# Gateway (per replica)
gateway:
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 2000m
      memory: 4Gi

  processors:
    memory_limiter:
      check_interval: 1s
      limit_mib: 3500  # 4GBçš„87.5%
      spike_limit_mib: 500
```

**èµ„æºè§„åˆ’å…¬å¼**:

```text
å†…å­˜ä¼°ç®—:
Memory = Queue_Size * Avg_Batch_Size * Num_Consumers + Overhead

ç¤ºä¾‹ (Gateway):
- Queue: 10000 batches
- Avg_Batch: 100KB
- Consumers: 10
- Memory â‰ˆ 10000 * 100KB * 10 = 10GB (peak)
- å®é™…: 2-4GB (normal) + 2GB (buffer)

CPUä¼°ç®—:
CPU âˆ Throughput * Processing_Complexity

ç¤ºä¾‹:
- 10K spans/s
- Tail sampling (å¤æ‚)
- CPU: 1-2 cores (normal), 4 cores (peak)
```

### 3.2 å­˜å‚¨è§„åˆ’

**å­˜å‚¨å®¹é‡è®¡ç®—**:

```text
Traceså­˜å‚¨:
Daily_Volume = Spans_Per_Day * Avg_Span_Size * (1 - Sampling_Rate)

ç¤ºä¾‹:
- 100M requests/day
- 10 spans/request = 1B spans/day
- 2KB/span (compressed)
- Sampling rate: 1%
- Daily: 1B * 2KB * 1% = 20GB/day
- 30å¤©ä¿ç•™: 600GB

ç´¢å¼•å¤§å°:
Index_Size â‰ˆ 30% * Data_Size
- 600GB data â†’ ~180GB index
- æ€»è®¡: 780GB

å‰¯æœ¬:
With 2 replicas:
- 780GB * 3 = 2.34TB

æ¨èé…ç½®:
- SSD: 3TB
- IOPS: 10K+
- Throughput: 500MB/s+
```

---

## 4. é‡‡æ ·ç­–ç•¥

**ç”Ÿäº§é‡‡æ ·é…ç½®**:

```yaml
# Head-based sampling (SDK)
sdk:
  sampler:
    # å¼€å‘ç¯å¢ƒ: AlwaysOn
    # ç”Ÿäº§ç¯å¢ƒ: TraceIdRatioBased
    type: traceidratiobased
    ratio: 0.01  # 1% (æ ¹æ®æµé‡è°ƒæ•´)

# Tail-based sampling (Collector Gateway)
collector:
  processors:
    tail_sampling:
      decision_wait: 10s
      num_traces: 50000
      expected_new_traces_per_sec: 1000
      
      policies:
        # ç­–ç•¥1: æ‰€æœ‰é”™è¯¯
        - name: errors
          type: status_code
          status_code:
            status_codes: [ERROR]
        
        # ç­–ç•¥2: æ…¢è¯·æ±‚ (p99)
        - name: slow_requests
          type: latency
          latency:
            threshold_ms: 1000
        
        # ç­–ç•¥3: ç‰¹å®šæœåŠ¡100%
        - name: critical_services
          type: string_attribute
          string_attribute:
            key: service.name
            values:
              - payment-service
              - auth-service
        
        # ç­–ç•¥4: å…¶ä»–æµé‡ä½é‡‡æ ·
        - name: random_sample
          type: probabilistic
          probabilistic:
            sampling_percentage: 1
```

**é‡‡æ ·ç‡å†³ç­–æ ‘**:

```text
å¦‚ä½•é€‰æ‹©é‡‡æ ·ç‡?

æµé‡ < 1K req/s:
â†’ 10-50% (å¯è´Ÿæ‹…å…¨é‡‡æ ·)

æµé‡ 1K-10K req/s:
â†’ 1-10%

æµé‡ 10K-100K req/s:
â†’ 0.1-1%

æµé‡ > 100K req/s:
â†’ < 0.1% + Tail sampling

å…³é”®è€ƒè™‘:
1. å­˜å‚¨æˆæœ¬
2. æŸ¥è¯¢æ€§èƒ½
3. ä¸šåŠ¡ä»·å€¼ (é”™è¯¯ > æˆåŠŸ)
4. SLAè¦æ±‚
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

**SDKä¼˜åŒ–**:

```go
// 1. ä½¿ç”¨BatchSpanProcessor
provider := trace.NewTracerProvider(
    trace.WithBatcher(
        exporter,
        trace.WithMaxExportBatchSize(512),      // æ‰¹é‡å¤§å°
        trace.WithBatchTimeout(5 * time.Second), // è¶…æ—¶
        trace.WithMaxQueueSize(2048),           // é˜Ÿåˆ—
    ),
)

// 2. é™åˆ¶Spanå±æ€§æ•°é‡
span.SetAttributes(
    // åªè®°å½•å¿…è¦å±æ€§ (< 20ä¸ª)
    attribute.String("http.method", method),
    attribute.Int("http.status_code", status),
)

// 3. é¿å…é«˜åŸºæ•°å±æ€§
// âŒ é”™è¯¯
span.SetAttributes(
    attribute.String("http.url", fullURL),  // é«˜åŸºæ•°!
)

// âœ… æ­£ç¡®
span.SetAttributes(
    attribute.String("http.route", "/users/:id"),  // ä½åŸºæ•°
)

// 4. é‡‡æ ·å†³ç­–å‰ç½®
sampler := trace.TraceIDRatioBased(0.01)
provider := trace.NewTracerProvider(
    trace.WithSampler(sampler),
)
```

**Collectorä¼˜åŒ–**:

```yaml
receivers:
  otlp:
    protocols:
      grpc:
        max_concurrent_streams: 16
        read_buffer_size: 524288  # 512KB
        write_buffer_size: 524288

processors:
  batch:
    send_batch_size: 8192
    send_batch_max_size: 10000
    timeout: 200ms
  
  memory_limiter:
    check_interval: 1s
    limit_mib: 2000
    spike_limit_mib: 500

exporters:
  otlp:
    compression: gzip
    sending_queue:
      enabled: true
      num_consumers: 20
      queue_size: 5000
```

---

## 6. ç›‘æ§ä¸å‘Šè­¦

**å…³é”®æŒ‡æ ‡**:

```yaml
# Collectorç›‘æ§
alerts:
  # 1. æ•°æ®ä¸¢å¤±
  - alert: CollectorDataLoss
    expr: rate(otelcol_processor_refused_spans[5m]) > 0
    for: 5m
    severity: critical
    
  # 2. é«˜å»¶è¿Ÿ
  - alert: CollectorHighLatency
    expr: histogram_quantile(0.99, rate(otelcol_exporter_send_duration_bucket[5m])) > 5
    for: 10m
    severity: warning
  
  # 3. å†…å­˜å‹åŠ›
  - alert: CollectorMemoryPressure
    expr: otelcol_process_memory_rss / 1024 / 1024 > 2000
    for: 5m
    severity: warning
  
  # 4. é˜Ÿåˆ—é¥±å’Œ
  - alert: CollectorQueueFull
    expr: otelcol_exporter_queue_size / otelcol_exporter_queue_capacity > 0.9
    for: 5m
    severity: critical

# åº”ç”¨ç›‘æ§
alerts:
  # 5. SDK overhead
  - alert: HighTracingOverhead
    expr: (otel_sdk_cpu_usage / app_cpu_usage) > 0.05
    for: 10m
    severity: warning
  
  # 6. å¯¼å‡ºå¤±è´¥
  - alert: SpanExportFailure
    expr: rate(otelcol_exporter_send_failed_spans[5m]) > 100
    for: 5m
    severity: critical
```

**Dashboard**:

```text
æ ¸å¿ƒDashboard (Grafana):

é¢æ¿1: ååé‡
- Spans received/s
- Spans exported/s
- Spans dropped/s

é¢æ¿2: å»¶è¿Ÿ
- Export latency (p50, p99)
- End-to-end latency

é¢æ¿3: èµ„æº
- CPU usage
- Memory usage
- Network I/O

é¢æ¿4: é”™è¯¯ç‡
- Export errors/s
- Receiver errors/s

é¢æ¿5: é˜Ÿåˆ—çŠ¶æ€
- Queue size
- Queue capacity
```

---

## 7. å®‰å…¨å®è·µ

**TLSé…ç½®**:

```yaml
# Collector Gateway
receivers:
  otlp:
    protocols:
      grpc:
        tls:
          cert_file: /certs/server.crt
          key_file: /certs/server.key
          client_ca_file: /certs/ca.crt
          client_ca_file_reload: true

exporters:
  otlp:
    endpoint: backend:4317
    tls:
      insecure: false
      cert_file: /certs/client.crt
      key_file: /certs/client.key
      ca_file: /certs/ca.crt
```

**PIIè¿‡æ»¤**:

```yaml
processors:
  attributes:
    actions:
      # åˆ é™¤æ•æ„Ÿå±æ€§
      - key: user.email
        action: delete
      - key: user.phone
        action: delete
      - key: credit.card
        action: delete
      
      # å“ˆå¸Œuser.id
      - key: user.id
        action: hash
      
      # æ©ç IPåœ°å€
      - key: http.client.ip
        action: extract
        pattern: ^(\d+\.\d+\.\d+)\.
```

**è®¤è¯**:

```yaml
# Bearer Token
extensions:
  bearertokenauth:
    filename: /secrets/token

receivers:
  otlp:
    protocols:
      grpc:
        auth:
          authenticator: bearertokenauth

# OAuth2
extensions:
  oauth2client:
    client_id: "otel-collector"
    client_secret: "${OAUTH_SECRET}"
    token_url: "https://auth.example.com/oauth/token"
    scopes: ["traces.write", "metrics.write"]

exporters:
  otlp:
    auth:
      authenticator: oauth2client
```

---

## 8. æ•…éšœæ¢å¤

**å¤‡ä»½ç­–ç•¥**:

```yaml
# Elasticsearchå¿«ç…§
PUT _snapshot/backup_repo
{
  "type": "s3",
  "settings": {
    "bucket": "jaeger-backups",
    "region": "us-west-2",
    "base_path": "snapshots"
  }
}

# æ¯æ—¥å¿«ç…§
PUT _snapshot/backup_repo/daily-snapshot
{
  "indices": "jaeger-span-*",
  "ignore_unavailable": true,
  "include_global_state": false
}

# è‡ªåŠ¨å¿«ç…§ (Elasticsearch SLM)
PUT _slm/policy/daily-snapshots
{
  "schedule": "0 2 * * *",  # æ¯å¤©å‡Œæ™¨2ç‚¹
  "name": "<daily-snap-{now/d}>",
  "repository": "backup_repo",
  "config": {
    "indices": ["jaeger-span-*"],
    "ignore_unavailable": true
  },
  "retention": {
    "expire_after": "30d",
    "min_count": 7
  }
}
```

**ç¾éš¾æ¢å¤è®¡åˆ’**:

```text
åœºæ™¯1: Collectoré›†ç¾¤å¤±è´¥
1. æ£€æµ‹: å‘Šè­¦è§¦å‘ (æ‰€æœ‰collector down)
2. å½±å“: æ–°æ•°æ®æ— æ³•æ”¶é›†ï¼Œåº”ç”¨æ­£å¸¸ (SDK drop)
3. æ¢å¤:
   a. æ£€æŸ¥Kubernetes podsçŠ¶æ€
   b. æŸ¥çœ‹Collectoræ—¥å¿—
   c. å¦‚é…ç½®é—®é¢˜ â†’ å›æ»šé…ç½®
   d. å¦‚èµ„æºä¸è¶³ â†’ æ‰©å®¹
   e. ETA: 5-10åˆ†é’Ÿ

åœºæ™¯2: Backendå­˜å‚¨å¤±è´¥
1. æ£€æµ‹: Elasticsearch unreachable
2. å½±å“: æŸ¥è¯¢å¤±è´¥ï¼Œæ•°æ®å †ç§¯åœ¨Collector
3. æ¢å¤:
   a. æ£€æŸ¥Elasticsearché›†ç¾¤å¥åº·
   b. å¦‚ç´¢å¼•æŸå â†’ ä»å¿«ç…§æ¢å¤
   c. å¦‚ç£ç›˜æ»¡ â†’ åˆ é™¤æ—§æ•°æ®æˆ–æ‰©å®¹
   d. Collectorä¼šè‡ªåŠ¨é‡è¯•
   e. ETA: 15-30åˆ†é’Ÿ

åœºæ™¯3: æ•°æ®ä¸¢å¤±
1. æ£€æµ‹: æŸ¥è¯¢åˆ°æ•°æ®ç¼ºå£
2. æ ¹å› :
   - Collector OOM
   - é˜Ÿåˆ—æº¢å‡º
   - Backendæ‹’ç»
3. æ¢å¤:
   - æ•°æ®æ— æ³•æ¢å¤ (å®æ—¶æ•°æ®)
   - é˜²æ­¢: é…ç½®æŒä¹…åŒ–é˜Ÿåˆ—
4. è¡¥æ•‘:
   - åˆ†ææ—¥å¿—é‡å»ºå…³é”®ä¿¡æ¯
   - ä»åº”ç”¨æ—¥å¿—è¡¥å……
```

---

## 9. æˆæœ¬ä¼˜åŒ–

**ç­–ç•¥**:

```text
1. é‡‡æ ·ä¼˜åŒ–
   - åŠ¨æ€é‡‡æ ·ç‡ (ä¸šåŠ¡æ—¶é—´é«˜é‡‡æ ·)
   - Tail sampling (åªé‡‡æ ·æœ‰ä»·å€¼æ•°æ®)
   - é¢„æœŸèŠ‚çœ: 50-90%

2. æ•°æ®ä¿ç•™
   - Hot data: 7å¤© (SSD)
   - Warm data: 30å¤© (HDD)
   - Cold data: 90å¤© (S3)
   - é¢„æœŸèŠ‚çœ: 60%

3. å‹ç¼©
   - gzipå‹ç¼© (2-5x)
   - Collectoræ‰¹å¤„ç†
   - é¢„æœŸèŠ‚çœ: 50-70% (ç½‘ç»œ/å­˜å‚¨)

4. å±æ€§ä¼˜åŒ–
   - åˆ é™¤ä¸å¿…è¦å±æ€§
   - ä½¿ç”¨Resourceå…±äº«å±æ€§
   - é¢„æœŸèŠ‚çœ: 20-30%

5. ç´¢å¼•ä¼˜åŒ–
   - åªç´¢å¼•å¿…è¦å­—æ®µ
   - ä½¿ç”¨keywordè€Œétext
   - é¢„æœŸèŠ‚çœ: 30-40% (å­˜å‚¨)

ç¤ºä¾‹æˆæœ¬è®¡ç®—:
åŸå§‹æˆæœ¬:
- 1B spans/day * 2KB = 2TB/day
- å­˜å‚¨ (30å¤©): 60TB * $0.1/GB = $6000/month
- ä¼ è¾“: 2TB/day * $0.09/GB * 30 = $5400/month
- æ€»è®¡: $11,400/month

ä¼˜åŒ–å:
- é‡‡æ · (1%): 600GB/day
- å‹ç¼© (3x): 200GB/day
- å­˜å‚¨ (7å¤©): 1.4TB * $0.1/GB = $140/month
- ä¼ è¾“: 200GB/day * $0.09/GB * 30 = $540/month
- æ€»è®¡: $680/month

èŠ‚çœ: 94% ğŸ‰
```

---

## 10. åˆè§„æ€§

```text
GDPR:
- [ ] åˆ é™¤PII (processor: attributes)
- [ ] æ•°æ®ä¿ç•™é™åˆ¶ (< 90å¤©)
- [ ] DSARæ”¯æŒ (æŸ¥è¯¢/åˆ é™¤API)
- [ ] æ•°æ®å¤„ç†è®°å½• (ROPA)

PCI-DSS:
- [ ] ä¸è®°å½•å®Œæ•´ä¿¡ç”¨å¡å·
- [ ] TLSåŠ å¯†ä¼ è¾“
- [ ] è®¿é—®æ—¥å¿—å®¡è®¡
- [ ] å®šæœŸå®‰å…¨æ‰«æ

HIPAA:
- [ ] ä¸è®°å½•PHI
- [ ] åŠ å¯†å­˜å‚¨ (at-rest)
- [ ] BAAåè®®
- [ ] å®¡è®¡è¿½è¸ª
```

---

## 11. å›¢é˜Ÿåä½œ

**è§’è‰²èŒè´£**:

```text
è§’è‰²1: Platform Team (å¹³å°å›¢é˜Ÿ)
èŒè´£:
- Collectorç»´æŠ¤
- Backendè¿ç»´
- æ€§èƒ½ä¼˜åŒ–
- æˆæœ¬ç®¡ç†

è§’è‰²2: Application Team (åº”ç”¨å›¢é˜Ÿ)
èŒè´£:
- SDKé›†æˆ
- è‡ªå®šä¹‰instrumentation
- Spanå±æ€§å®šä¹‰
- Dashboardåˆ›å»º

è§’è‰²3: SRE Team
èŒè´£:
- å‘Šè­¦å“åº”
- äº‹ä»¶è°ƒæŸ¥
- å®¹é‡è§„åˆ’
- æ•…éšœæ¢å¤

åä½œæµç¨‹:
1. Platformæä¾›ç¨³å®šCollector
2. Applicationé›†æˆSDK
3. SREåŸºäºé¥æµ‹æ•°æ®å“åº”æ•…éšœ
```

**çŸ¥è¯†åˆ†äº«**:

```text
æ–‡æ¡£:
- README: å¿«é€Ÿå¼€å§‹
- Runbook: æ•…éšœå¤„ç†
- Best Practices: æœ€ä½³å®è·µ
- Troubleshooting: å¸¸è§é—®é¢˜

åŸ¹è®­:
- æ–°äººåŸ¹è®­ (1å°æ—¶)
- æœˆåº¦åˆ†äº«ä¼š
- Hands-on workshop
```

---

## 12. æ¸è¿›å¼éƒ¨ç½²

**é˜¶æ®µæ€§æ¨å¹¿**:

```text
é˜¶æ®µ1: POC (2å‘¨)
- å•ä¸ªæœåŠ¡æ¥å…¥
- éªŒè¯å¯è¡Œæ€§
- æ€§èƒ½åŸºçº¿

é˜¶æ®µ2: Pilot (1æœˆ)
- 5-10ä¸ªæœåŠ¡
- ç”Ÿäº§æµé‡1%
- æ”¶é›†åé¦ˆ

é˜¶æ®µ3: æ¨å¹¿ (3æœˆ)
- æ‰€æœ‰æ ¸å¿ƒæœåŠ¡
- ç”Ÿäº§æµé‡100%
- ä¼˜åŒ–é…ç½®

é˜¶æ®µ4: ä¼˜åŒ– (æŒç»­)
- æˆæœ¬ä¼˜åŒ–
- æ€§èƒ½è°ƒä¼˜
- æ–°åŠŸèƒ½
```

---

## 13. å…¸å‹ç”Ÿäº§é…ç½®

**å®Œæ•´é…ç½®ç¤ºä¾‹** (æ ‡å‡†ç”Ÿäº§ç¯å¢ƒ):

```yaml
# Gateway Collectoré…ç½®
extensions:
  health_check:
    endpoint: :13133
  
  pprof:
    endpoint: :1777
  
  zpages:
    endpoint: :55679

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_concurrent_streams: 16
      http:
        endpoint: 0.0.0.0:4318

processors:
  memory_limiter:
    check_interval: 1s
    limit_percentage: 75
    spike_limit_percentage: 15
  
  batch:
    send_batch_size: 8192
    timeout: 200ms
    send_batch_max_size: 10000
  
  attributes:
    actions:
      - key: user.email
        action: delete
      - key: http.client.ip
        action: hash
  
  tail_sampling:
    decision_wait: 10s
    num_traces: 100000
    expected_new_traces_per_sec: 1000
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow
        type: latency
        latency: {threshold_ms: 1000}
      - name: random
        type: probabilistic
        probabilistic: {sampling_percentage: 1}

exporters:
  otlp/jaeger:
    endpoint: jaeger-collector:4317
    compression: gzip
    retry_on_failure:
      enabled: true
      max_elapsed_time: 5m
    sending_queue:
      enabled: true
      num_consumers: 20
      queue_size: 5000
  
  prometheus:
    endpoint: :8889

service:
  extensions: [health_check, pprof, zpages]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, attributes, batch, tail_sampling]
      exporters: [otlp/jaeger]
    
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [prometheus]
```

---

## 14. æ•…éšœåœºæ™¯ä¸åº”å¯¹

**åœºæ™¯æ‰‹å†Œ**:

```text
åœºæ™¯1: åº”ç”¨å»¶è¿Ÿå¢åŠ 
ç—‡çŠ¶: API p99å»¶è¿Ÿ 50ms â†’ 500ms
è¯Šæ–­:
  1. æ£€æŸ¥Jaeger: æ˜¯å¦Tracing overhead?
  2. æ£€æŸ¥SDKé…ç½®: BatchProcessor vs SimpleProcessor?
  3. æ£€æŸ¥Collector: æ˜¯å¦å“åº”æ…¢?

è§£å†³:
  - ä½¿ç”¨BatchSpanProcessor
  - é™ä½é‡‡æ ·ç‡
  - å¼‚æ­¥å¯¼å‡º

åœºæ™¯2: Collector OOM
ç—‡çŠ¶: Collectoré¢‘ç¹é‡å¯ï¼Œå†…å­˜å‘Šè­¦
è¯Šæ–­:
  1. æ£€æŸ¥å†…å­˜ä½¿ç”¨: otelcol_process_memory_rss
  2. æ£€æŸ¥é˜Ÿåˆ—å¤§å°: otelcol_exporter_queue_size
  3. æ£€æŸ¥æ‹’ç»ç‡: otelcol_processor_refused_spans

è§£å†³:
  - é…ç½®memory_limiter
  - å¢åŠ å†…å­˜é™åˆ¶
  - å‡å°queue_size
  - å¢åŠ consumers

åœºæ™¯3: æ•°æ®æŸ¥è¯¢æ…¢
ç—‡çŠ¶: Jaeger UIæŸ¥è¯¢è¶…æ—¶
è¯Šæ–­:
  1. æ£€æŸ¥Elasticsearch: é›†ç¾¤å¥åº·ï¼Œç´¢å¼•å¤§å°
  2. æ£€æŸ¥æŸ¥è¯¢: æ˜¯å¦æ‰«æå¤§é‡æ•°æ®?
  3. æ£€æŸ¥ç´¢å¼•: æ˜¯å¦ä¼˜åŒ–?

è§£å†³:
  - ä¼˜åŒ–ç´¢å¼•ç­–ç•¥
  - å¢åŠ ElasticsearchèŠ‚ç‚¹
  - é™åˆ¶æŸ¥è¯¢æ—¶é—´èŒƒå›´
  - ä½¿ç”¨ç¼“å­˜
```

---

## 15. å‚è€ƒèµ„æº

- **ç”Ÿäº§æœ€ä½³å®è·µ**: <https://opentelemetry.io/docs/collector/deployment/>
- **æ€§èƒ½è°ƒä¼˜**: <https://opentelemetry.io/docs/collector/performance/>
- **å®‰å…¨æŒ‡å—**: <https://opentelemetry.io/docs/collector/security/>

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸  
**å®é™…æ¡ˆä¾‹**: åŸºäºçœŸå®ç”Ÿäº§ç¯å¢ƒç»éªŒæ€»ç»“
