# CQRS æ¶æ„ (Command Query Responsibility Segregation) - Rust OTLP è¯»å†™åˆ†ç¦»è¿½è¸ª

> **æ¶æ„æ¨¡å¼**: CQRS (Command Query Responsibility Segregation)  
> **æå‡ºè€…**: Greg Young (2010)  
> **å›½é™…æ ‡å‡†**: å¾®è½¯ Azure æ¨èæ¨¡å¼, CNCF äº‹ä»¶é©±åŠ¨æ¶æ„  
> **Rust ç‰ˆæœ¬**: 1.90+  
> **OpenTelemetry**: 0.31.0  
> **æ›´æ–°æ—¥æœŸ**: 2025å¹´10æœˆ11æ—¥

---

## ğŸ“‹ ç›®å½•

- [CQRS æ¶æ„ (Command Query Responsibility Segregation) - Rust OTLP è¯»å†™åˆ†ç¦»è¿½è¸ª](#cqrs-æ¶æ„-command-query-responsibility-segregation---rust-otlp-è¯»å†™åˆ†ç¦»è¿½è¸ª)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ›ï¸ æ¶æ„æ¦‚è¿°](#ï¸-æ¶æ„æ¦‚è¿°)
    - [ä»€ä¹ˆæ˜¯ CQRS?](#ä»€ä¹ˆæ˜¯-cqrs)
      - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
    - [å›½é™…æ ‡å‡†å¯¹æ ‡](#å›½é™…æ ‡å‡†å¯¹æ ‡)
  - [ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ](#-æ ¸å¿ƒæ¦‚å¿µ)
    - [1. Command (å‘½ä»¤) - å†™æ“ä½œ](#1-command-å‘½ä»¤---å†™æ“ä½œ)
    - [2. Query (æŸ¥è¯¢) - è¯»æ“ä½œ](#2-query-æŸ¥è¯¢---è¯»æ“ä½œ)
    - [3. Write Model vs Read Model](#3-write-model-vs-read-model)
    - [4. Event Bus (äº‹ä»¶æ€»çº¿)](#4-event-bus-äº‹ä»¶æ€»çº¿)
  - [ğŸ†š CQRS vs ä¼ ç»Ÿ CRUD](#-cqrs-vs-ä¼ ç»Ÿ-crud)
    - [ä¼ ç»Ÿ CRUD çš„é—®é¢˜](#ä¼ ç»Ÿ-crud-çš„é—®é¢˜)
    - [CQRS çš„ä¼˜åŠ¿](#cqrs-çš„ä¼˜åŠ¿)
  - [ğŸ”„ Event Sourcing é›†æˆ](#-event-sourcing-é›†æˆ)
    - [ä»€ä¹ˆæ˜¯ Event Sourcing?](#ä»€ä¹ˆæ˜¯-event-sourcing)
  - [ğŸ¦€ Rust å®ç°è®¾è®¡](#-rust-å®ç°è®¾è®¡)
    - [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
  - [ğŸ”­ OTLP è¯»å†™åˆ†ç¦»è¿½è¸ª](#-otlp-è¯»å†™åˆ†ç¦»è¿½è¸ª)
    - [ç­–ç•¥: Command ç«¯ vs Query ç«¯è¿½è¸ª](#ç­–ç•¥-command-ç«¯-vs-query-ç«¯è¿½è¸ª)
  - [ğŸ“¦ å®Œæ•´è®¢å•ç³»ç»Ÿç¤ºä¾‹](#-å®Œæ•´è®¢å•ç³»ç»Ÿç¤ºä¾‹)
    - [1. é¢†åŸŸå±‚ (Domain Layer)](#1-é¢†åŸŸå±‚-domain-layer)
      - [1.1 èšåˆæ ¹ (Aggregate Root)](#11-èšåˆæ ¹-aggregate-root)
      - [1.2 é¢†åŸŸäº‹ä»¶ (Domain Events)](#12-é¢†åŸŸäº‹ä»¶-domain-events)
    - [2. Write Side (Command ç«¯)](#2-write-side-command-ç«¯)
      - [2.1 Command Handler](#21-command-handler)
      - [2.2 Event Store (PostgreSQL)](#22-event-store-postgresql)
    - [3. Read Side (Query ç«¯)](#3-read-side-query-ç«¯)
      - [3.1 Read Model](#31-read-model)
      - [3.2 Projection (æŠ•å½±)](#32-projection-æŠ•å½±)
      - [3.3 Elasticsearch Repository](#33-elasticsearch-repository)
      - [3.4 Query Handler](#34-query-handler)
  - [â±ï¸ æœ€ç»ˆä¸€è‡´æ€§å¤„ç†](#ï¸-æœ€ç»ˆä¸€è‡´æ€§å¤„ç†)
    - [é—®é¢˜: è¯»æ¨¡å‹å¯èƒ½æ»å](#é—®é¢˜-è¯»æ¨¡å‹å¯èƒ½æ»å)
    - [è§£å†³æ–¹æ¡ˆ](#è§£å†³æ–¹æ¡ˆ)
      - [æ–¹æ¡ˆ 1: ç‰ˆæœ¬å· + é‡è¯•](#æ–¹æ¡ˆ-1-ç‰ˆæœ¬å·--é‡è¯•)
      - [æ–¹æ¡ˆ 2: Command è¿”å›å®Œæ•´ç»“æœ](#æ–¹æ¡ˆ-2-command-è¿”å›å®Œæ•´ç»“æœ)
  - [ğŸš€ æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
    - [1. è¯»æ¨¡å‹ç¼“å­˜](#1-è¯»æ¨¡å‹ç¼“å­˜)
  - [ğŸ“¦ ç”Ÿäº§éƒ¨ç½²](#-ç”Ÿäº§éƒ¨ç½²)
    - [Cargo.toml](#cargotoml)
    - [Docker Compose](#docker-compose)
  - [âœ… æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [CQRS è®¾è®¡](#cqrs-è®¾è®¡)
    - [OTLP é›†æˆ](#otlp-é›†æˆ)

---

## ğŸ›ï¸ æ¶æ„æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ CQRS?

**CQRS** (Command Query Responsibility Segregation) æ˜¯ä¸€ç§æ¶æ„æ¨¡å¼ï¼Œå°†**å†™æ“ä½œ (Command)** å’Œ**è¯»æ“ä½œ (Query)** åˆ†ç¦»åˆ°ä¸åŒçš„æ¨¡å‹ä¸­ã€‚

#### æ ¸å¿ƒæ€æƒ³

```text
ä¼ ç»Ÿ CRUD (ç»Ÿä¸€æ¨¡å‹):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service    â”‚ (è¯»å†™ä½¿ç”¨åŒä¸€æ¨¡å‹)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database   â”‚ (å•ä¸€æ•°æ®åº“)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


CQRS (è¯»å†™åˆ†ç¦»):
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Client    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚
    å†™æ“ä½œ (Command)                 è¯»æ“ä½œ (Query)
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Command Handlerâ”‚              â”‚  Query Handler â”‚
â”‚  (ä¸šåŠ¡é€»è¾‘)     â”‚              â”‚  (æ•°æ®æŸ¥è¯¢)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Event Bus  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Write Model  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚   Read Model   â”‚
â”‚  (PostgreSQL)  â”‚   åŒæ­¥/å¼‚æ­¥   â”‚ (Elasticsearch)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### å›½é™…æ ‡å‡†å¯¹æ ‡

| æ ‡å‡†/æ¡†æ¶ | æå‡ºè€…/ç»„ç»‡ | å¹´ä»½ | CQRS å¯¹æ ‡ |
|----------|-----------|------|-----------|
| **CQRS Pattern** | Greg Young | 2010 | âœ… æœ¬æ¶æ„ |
| **Event Sourcing** | Martin Fowler | 2005 | âœ… å®Œç¾æ­æ¡£ |
| **Microsoft Azure Architecture** | Microsoft | 2017 | âœ… æ¨èæ¨¡å¼ |
| **DDD (Domain-Driven Design)** | Eric Evans | 2003 | âœ… èšåˆæ ¹åˆ†ç¦» |
| **Event-Driven Architecture** | CNCF | - | âœ… äº‹ä»¶é©±åŠ¨ |
| **Microservices Patterns** | Chris Richardson | 2018 | âœ… æœåŠ¡æ‹†åˆ† |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### 1. Command (å‘½ä»¤) - å†™æ“ä½œ

**ç‰¹ç‚¹**:

- æ”¹å˜ç³»ç»ŸçŠ¶æ€
- æœ‰å‰¯ä½œç”¨
- è¿”å›æ“ä½œç»“æœ (æˆåŠŸ/å¤±è´¥)
- éœ€è¦éªŒè¯ä¸šåŠ¡è§„åˆ™

**ç¤ºä¾‹**:

- `CreateOrder` - åˆ›å»ºè®¢å•
- `CancelOrder` - å–æ¶ˆè®¢å•
- `UpdateInventory` - æ›´æ–°åº“å­˜

```rust
// Command å®šä¹‰
pub struct CreateOrderCommand {
    pub customer_id: CustomerId,
    pub items: Vec<OrderItem>,
    pub shipping_address: Address,
}

// Command Handler
#[async_trait]
pub trait CommandHandler<C>: Send + Sync {
    type Result;
    async fn handle(&self, command: C) -> Result<Self::Result>;
}
```

---

### 2. Query (æŸ¥è¯¢) - è¯»æ“ä½œ

**ç‰¹ç‚¹**:

- ä¸æ”¹å˜ç³»ç»ŸçŠ¶æ€
- æ— å‰¯ä½œç”¨ (å¹‚ç­‰)
- è¿”å›æ•°æ®
- å¯ä»¥ç¼“å­˜
- å¯ä»¥ä¼˜åŒ–ç´¢å¼•

**ç¤ºä¾‹**:

- `GetOrderById` - æŸ¥è¯¢è®¢å•è¯¦æƒ…
- `ListOrdersByCustomer` - æŸ¥è¯¢å®¢æˆ·è®¢å•åˆ—è¡¨
- `SearchOrders` - æœç´¢è®¢å•

```rust
// Query å®šä¹‰
pub struct GetOrderByIdQuery {
    pub order_id: OrderId,
}

// Query Handler
#[async_trait]
pub trait QueryHandler<Q>: Send + Sync {
    type Result;
    async fn handle(&self, query: Q) -> Result<Self::Result>;
}
```

---

### 3. Write Model vs Read Model

| ç»´åº¦ | Write Model (å†™æ¨¡å‹) | Read Model (è¯»æ¨¡å‹) |
|------|---------------------|-------------------|
| **ç›®çš„** | ä¿è¯ä¸šåŠ¡è§„åˆ™ä¸€è‡´æ€§ | å¿«é€ŸæŸ¥è¯¢ |
| **æ•°æ®åº“** | PostgreSQL (ACID) | Elasticsearch (æœç´¢) |
| **æ•°æ®ç»“æ„** | è§„èŒƒåŒ– (3NF) | åè§„èŒƒåŒ– (æ‰å¹³) |
| **ä¸€è‡´æ€§** | å¼ºä¸€è‡´æ€§ | æœ€ç»ˆä¸€è‡´æ€§ |
| **æ€§èƒ½** | å†™ä¼˜åŒ– | è¯»ä¼˜åŒ– |
| **ç´¢å¼•** | ä¸»é”®ã€å¤–é”® | å…¨æ–‡ç´¢å¼•ã€èšåˆ |

---

### 4. Event Bus (äº‹ä»¶æ€»çº¿)

è¿æ¥ Write Model å’Œ Read Model çš„æ¡¥æ¢ï¼š

```text
Write Model                Event Bus              Read Model
    â”‚                          â”‚                      â”‚
    â”‚  1. å†™å…¥æ•°æ®              â”‚                      â”‚
    â–¼                          â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                      â”‚
â”‚ Postgresâ”‚                   â”‚                      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                   â”‚                      â”‚
     â”‚                         â”‚                      â”‚
     â”‚  2. å‘å¸ƒäº‹ä»¶             â–¼                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚    Kafka     â”‚              â”‚
                       â”‚  (Event Bus) â”‚              â”‚
                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                              â”‚  3. æ¶ˆè´¹äº‹ä»¶          â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚Elasticsearch â”‚
                                              â”‚ (æ›´æ–°ç´¢å¼•)   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ†š CQRS vs ä¼ ç»Ÿ CRUD

### ä¼ ç»Ÿ CRUD çš„é—®é¢˜

```rust
// ä¼ ç»Ÿ CRUD: è¯»å†™ä½¿ç”¨åŒä¸€æ¨¡å‹
pub struct Order {
    pub id: OrderId,
    pub customer: Customer,         // âŒ æŸ¥è¯¢æ—¶éœ€è¦ JOIN
    pub items: Vec<OrderItem>,      // âŒ æŸ¥è¯¢æ—¶éœ€è¦ JOIN
    pub shipping_address: Address,  // âŒ æŸ¥è¯¢æ—¶éœ€è¦ JOIN
    pub status: OrderStatus,
    // ... è¿˜æœ‰å¾ˆå¤šå­—æ®µ
}

// æŸ¥è¯¢è®¢å•åˆ—è¡¨: éœ€è¦å¤šè¡¨ JOIN, æ€§èƒ½å·®
SELECT o.*, c.*, oi.*, a.*
FROM orders o
JOIN customers c ON o.customer_id = c.id
JOIN order_items oi ON o.id = oi.order_id
JOIN addresses a ON o.address_id = a.id
WHERE c.id = ?;  -- æ…¢!
```

### CQRS çš„ä¼˜åŠ¿

```rust
// Write Model: è§„èŒƒåŒ–,ä¿è¯ä¸€è‡´æ€§
pub struct Order {
    pub id: OrderId,
    pub customer_id: CustomerId,    // âœ… åªå­˜ ID
    pub items: Vec<OrderItem>,
    pub address_id: AddressId,      // âœ… åªå­˜ ID
    pub status: OrderStatus,
}

// Read Model: åè§„èŒƒåŒ–,æŸ¥è¯¢ä¼˜åŒ–
pub struct OrderReadModel {
    pub id: OrderId,
    pub customer_name: String,      // âœ… ç›´æ¥å­˜åå­—
    pub customer_email: String,     // âœ… ç›´æ¥å­˜é‚®ç®±
    pub item_names: Vec<String>,    // âœ… ç›´æ¥å­˜å•†å“å
    pub total_amount: f64,          // âœ… é¢„è®¡ç®—æ€»é‡‘é¢
    pub address_full: String,       // âœ… å®Œæ•´åœ°å€å­—ç¬¦ä¸²
    pub status: String,
    pub created_at: DateTime<Utc>,
}

// æŸ¥è¯¢è®¢å•åˆ—è¡¨: æ— éœ€ JOIN, ç›´æ¥æŸ¥è¯¢
SELECT * FROM order_read_models WHERE customer_name LIKE ?;  -- å¿«!
```

---

## ğŸ”„ Event Sourcing é›†æˆ

### ä»€ä¹ˆæ˜¯ Event Sourcing?

å°†æ‰€æœ‰çŠ¶æ€å˜åŒ–å­˜å‚¨ä¸º**äº‹ä»¶åºåˆ—**ï¼Œè€Œéå­˜å‚¨å½“å‰çŠ¶æ€ã€‚

```text
ä¼ ç»Ÿæ–¹å¼ (State-Oriented):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è®¢å•è¡¨ (å½“å‰çŠ¶æ€)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ID: 001              â”‚
â”‚ Status: SHIPPED      â”‚  â† åªå­˜æœ€ç»ˆçŠ¶æ€,ä¸¢å¤±å†å²
â”‚ Amount: $100         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Event Sourcing (Event-Oriented):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ äº‹ä»¶æµ (å®Œæ•´å†å²)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. OrderCreated               â”‚
â”‚ 2. ItemAdded (Item1)          â”‚
â”‚ 3. ItemAdded (Item2)          â”‚
â”‚ 4. PaymentProcessed ($100)    â”‚
â”‚ 5. OrderShipped               â”‚  â† ä¿å­˜æ‰€æœ‰å†å²
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ é‡æ”¾äº‹ä»¶ (Replay)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å½“å‰çŠ¶æ€ (é‡å»º)       â”‚
â”‚ Status: SHIPPED      â”‚
â”‚ Amount: $100         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¦€ Rust å®ç°è®¾è®¡

### é¡¹ç›®ç»“æ„

```text
cqrs-order-service/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/                        # é¢†åŸŸå±‚
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ aggregates/
â”‚   â”‚   â”‚   â””â”€â”€ order.rs               # è®¢å•èšåˆæ ¹
â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ create_order.rs        # åˆ›å»ºè®¢å•å‘½ä»¤
â”‚   â”‚   â”‚   â””â”€â”€ cancel_order.rs        # å–æ¶ˆè®¢å•å‘½ä»¤
â”‚   â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ order_created.rs       # è®¢å•åˆ›å»ºäº‹ä»¶
â”‚   â”‚   â”‚   â””â”€â”€ order_cancelled.rs     # è®¢å•å–æ¶ˆäº‹ä»¶
â”‚   â”‚   â””â”€â”€ value_objects/
â”‚   â”‚       â”œâ”€â”€ order_id.rs
â”‚   â”‚       â””â”€â”€ money.rs
â”‚   â”‚
â”‚   â”œâ”€â”€ write/                         # å†™ç«¯ (Command Side)
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ create_order_handler.rs
â”‚   â”‚   â”‚   â””â”€â”€ cancel_order_handler.rs
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ order_repository.rs    # PostgreSQL å†™åº“
â”‚   â”‚   â””â”€â”€ event_store/
â”‚   â”‚       â””â”€â”€ postgres_event_store.rs # äº‹ä»¶å­˜å‚¨
â”‚   â”‚
â”‚   â”œâ”€â”€ read/                          # è¯»ç«¯ (Query Side)
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ order_read_model.rs    # è¯»æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ get_order_handler.rs
â”‚   â”‚   â”‚   â””â”€â”€ list_orders_handler.rs
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ order_read_repo.rs     # Elasticsearch è¯»åº“
â”‚   â”‚   â””â”€â”€ projections/
â”‚   â”‚       â””â”€â”€ order_projection.rs    # æŠ•å½± (äº‹ä»¶â†’è¯»æ¨¡å‹)
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/                # åŸºç¡€è®¾æ–½å±‚
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”‚   â”œâ”€â”€ command_controller.rs  # å‘½ä»¤ HTTP ç«¯ç‚¹
â”‚   â”‚   â”‚   â””â”€â”€ query_controller.rs    # æŸ¥è¯¢ HTTP ç«¯ç‚¹
â”‚   â”‚   â”œâ”€â”€ event_bus/
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_producer.rs      # Kafka ç”Ÿäº§è€…
â”‚   â”‚   â”‚   â””â”€â”€ kafka_consumer.rs      # Kafka æ¶ˆè´¹è€…
â”‚   â”‚   â””â”€â”€ telemetry/
â”‚   â”‚       â””â”€â”€ init.rs                # OTLP åˆå§‹åŒ–
â”‚   â”‚
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ app_config.rs
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## ğŸ”­ OTLP è¯»å†™åˆ†ç¦»è¿½è¸ª

### ç­–ç•¥: Command ç«¯ vs Query ç«¯è¿½è¸ª

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Command Side (å†™ç«¯)                   â”‚
â”‚  âœ… å®Œæ•´ä¸šåŠ¡é€»è¾‘è¿½è¸ª                                      â”‚
â”‚  - Command Handler (#[instrument])                      â”‚
â”‚  - ä¸šåŠ¡è§„åˆ™éªŒè¯                                          â”‚
â”‚  - äº‹ä»¶å‘å¸ƒ                                              â”‚
â”‚  - æ•°æ®åº“å†™å…¥ (PostgreSQL)                               â”‚
â”‚  - Kafka äº‹ä»¶å‘é€                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ äº‹ä»¶æµ (Kafka)
                       â”‚ Trace Context ä¼ æ’­
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Query Side (è¯»ç«¯)                     â”‚
â”‚  âœ… æŠ•å½±å¤„ç†è¿½è¸ª                                         â”‚
â”‚  - Event Consumer (#[instrument])                       â”‚
â”‚  - Projection æ›´æ–°                                      â”‚
â”‚  - Elasticsearch ç´¢å¼•æ›´æ–°                                â”‚
â”‚  âœ… æŸ¥è¯¢è¿½è¸ª                                            â”‚
â”‚  - Query Handler (#[instrument])                        â”‚
â”‚  - Elasticsearch æŸ¥è¯¢                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å…³é”®ç‚¹:
1. Command â†’ Event: é€šè¿‡ Kafka ä¼ é€’ Trace Context
2. Event â†’ Projection: ç»§ç»­è¿½è¸ªé“¾è·¯
3. Query: ç‹¬ç«‹è¿½è¸ª (å¯é€‰å…³è”åˆ° Command)
```

---

## ğŸ“¦ å®Œæ•´è®¢å•ç³»ç»Ÿç¤ºä¾‹

### 1. é¢†åŸŸå±‚ (Domain Layer)

#### 1.1 èšåˆæ ¹ (Aggregate Root)

```rust
// domain/aggregates/order.rs
use crate::domain::events::OrderEvent;
use crate::domain::value_objects::{OrderId, CustomerId, Money};
use chrono::{DateTime, Utc};

/// è®¢å•èšåˆæ ¹
/// 
/// è´Ÿè´£:
/// 1. ä¸šåŠ¡è§„åˆ™éªŒè¯
/// 2. ç”Ÿæˆé¢†åŸŸäº‹ä»¶
/// 3. é‡æ”¾äº‹ä»¶ (Event Sourcing)
#[derive(Debug, Clone)]
pub struct OrderAggregate {
    // çŠ¶æ€
    id: OrderId,
    customer_id: CustomerId,
    items: Vec<OrderItem>,
    total_amount: Money,
    status: OrderStatus,
    created_at: DateTime<Utc>,
    
    // äº‹ä»¶æº¯æº
    version: u64,                    // ç‰ˆæœ¬å· (ç”¨äºä¹è§‚é”)
    uncommitted_events: Vec<OrderEvent>,  // æœªæäº¤çš„äº‹ä»¶
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum OrderStatus {
    Pending,
    Confirmed,
    Shipped,
    Delivered,
    Cancelled,
}

impl OrderAggregate {
    /// åˆ›å»ºè®¢å• (Command)
    pub fn create(
        customer_id: CustomerId,
        items: Vec<OrderItem>,
    ) -> Result<Self, DomainError> {
        // ä¸šåŠ¡è§„åˆ™éªŒè¯
        if items.is_empty() {
            return Err(DomainError::EmptyOrder);
        }
        
        let total_amount = Self::calculate_total(&items);
        
        if total_amount.amount() < 10.0 {
            return Err(DomainError::BelowMinimumAmount);
        }
        
        // åˆ›å»ºäº‹ä»¶
        let event = OrderEvent::OrderCreated {
            order_id: OrderId::new(),
            customer_id,
            items: items.clone(),
            total_amount,
            created_at: Utc::now(),
        };
        
        // åº”ç”¨äº‹ä»¶
        let mut aggregate = Self::default();
        aggregate.apply(event.clone());
        aggregate.uncommitted_events.push(event);
        
        Ok(aggregate)
    }
    
    /// å–æ¶ˆè®¢å• (Command)
    pub fn cancel(&mut self, reason: String) -> Result<(), DomainError> {
        // ä¸šåŠ¡è§„åˆ™
        match self.status {
            OrderStatus::Delivered => {
                return Err(DomainError::CannotCancelDeliveredOrder);
            }
            OrderStatus::Cancelled => {
                return Err(DomainError::AlreadyCancelled);
            }
            _ => {}
        }
        
        // åˆ›å»ºäº‹ä»¶
        let event = OrderEvent::OrderCancelled {
            order_id: self.id,
            reason,
            cancelled_at: Utc::now(),
        };
        
        // åº”ç”¨äº‹ä»¶
        self.apply(event.clone());
        self.uncommitted_events.push(event);
        
        Ok(())
    }
    
    /// åº”ç”¨äº‹ä»¶ (ä¿®æ”¹èšåˆæ ¹çŠ¶æ€)
    fn apply(&mut self, event: OrderEvent) {
        match event {
            OrderEvent::OrderCreated {
                order_id,
                customer_id,
                items,
                total_amount,
                created_at,
            } => {
                self.id = order_id;
                self.customer_id = customer_id;
                self.items = items;
                self.total_amount = total_amount;
                self.status = OrderStatus::Pending;
                self.created_at = created_at;
                self.version += 1;
            }
            OrderEvent::OrderCancelled { .. } => {
                self.status = OrderStatus::Cancelled;
                self.version += 1;
            }
            // ... å…¶ä»–äº‹ä»¶
        }
    }
    
    /// ä»äº‹ä»¶æµé‡å»ºèšåˆæ ¹ (Event Sourcing)
    pub fn from_events(events: Vec<OrderEvent>) -> Result<Self, DomainError> {
        let mut aggregate = Self::default();
        
        for event in events {
            aggregate.apply(event);
        }
        
        Ok(aggregate)
    }
    
    /// è·å–æœªæäº¤çš„äº‹ä»¶
    pub fn uncommitted_events(&self) -> &[OrderEvent] {
        &self.uncommitted_events
    }
    
    /// æ¸…ç©ºæœªæäº¤çš„äº‹ä»¶ (ä¿å­˜åè°ƒç”¨)
    pub fn clear_uncommitted_events(&mut self) {
        self.uncommitted_events.clear();
    }
    
    fn calculate_total(items: &[OrderItem]) -> Money {
        items.iter()
            .map(|item| item.unit_price.multiply(item.quantity))
            .fold(Money::zero(), |acc, price| acc.add(&price))
    }
}

impl Default for OrderAggregate {
    fn default() -> Self {
        Self {
            id: OrderId::default(),
            customer_id: CustomerId::default(),
            items: Vec::new(),
            total_amount: Money::zero(),
            status: OrderStatus::Pending,
            created_at: Utc::now(),
            version: 0,
            uncommitted_events: Vec::new(),
        }
    }
}
```

#### 1.2 é¢†åŸŸäº‹ä»¶ (Domain Events)

```rust
// domain/events/order_event.rs
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};

/// è®¢å•é¢†åŸŸäº‹ä»¶
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum OrderEvent {
    OrderCreated {
        order_id: OrderId,
        customer_id: CustomerId,
        items: Vec<OrderItem>,
        total_amount: Money,
        created_at: DateTime<Utc>,
    },
    OrderConfirmed {
        order_id: OrderId,
        confirmed_at: DateTime<Utc>,
    },
    OrderShipped {
        order_id: OrderId,
        tracking_number: String,
        shipped_at: DateTime<Utc>,
    },
    OrderDelivered {
        order_id: OrderId,
        delivered_at: DateTime<Utc>,
    },
    OrderCancelled {
        order_id: OrderId,
        reason: String,
        cancelled_at: DateTime<Utc>,
    },
}

impl OrderEvent {
    pub fn order_id(&self) -> OrderId {
        match self {
            Self::OrderCreated { order_id, .. } => *order_id,
            Self::OrderConfirmed { order_id, .. } => *order_id,
            Self::OrderShipped { order_id, .. } => *order_id,
            Self::OrderDelivered { order_id, .. } => *order_id,
            Self::OrderCancelled { order_id, .. } => *order_id,
        }
    }
    
    pub fn event_type(&self) -> &str {
        match self {
            Self::OrderCreated { .. } => "OrderCreated",
            Self::OrderConfirmed { .. } => "OrderConfirmed",
            Self::OrderShipped { .. } => "OrderShipped",
            Self::OrderDelivered { .. } => "OrderDelivered",
            Self::OrderCancelled { .. } => "OrderCancelled",
        }
    }
}
```

---

### 2. Write Side (Command ç«¯)

#### 2.1 Command Handler

```rust
// write/handlers/create_order_handler.rs
use crate::domain::aggregates::OrderAggregate;
use crate::domain::commands::CreateOrderCommand;
use crate::write::repositories::OrderRepository;
use crate::infrastructure::event_bus::EventBus;
use std::sync::Arc;
use tracing::{instrument, info, error};

/// åˆ›å»ºè®¢å•å‘½ä»¤å¤„ç†å™¨
/// 
/// Command Side: å®Œæ•´ä¸šåŠ¡é€»è¾‘è¿½è¸ª
pub struct CreateOrderHandler<R: OrderRepository, E: EventBus> {
    order_repo: Arc<R>,
    event_bus: Arc<E>,
}

impl<R: OrderRepository, E: EventBus> CreateOrderHandler<R, E> {
    pub fn new(order_repo: Arc<R>, event_bus: Arc<E>) -> Self {
        Self {
            order_repo,
            event_bus,
        }
    }
    
    #[instrument(
        name = "create_order_command_handler",
        skip(self, command),
        fields(
            command_type = "CreateOrder",
            customer_id = %command.customer_id,
            item_count = command.items.len(),
            otel.kind = "internal",
        )
    )]
    pub async fn handle(
        &self,
        command: CreateOrderCommand,
    ) -> Result<OrderId, CommandError> {
        info!("ğŸ›ï¸ Handling CreateOrder command");
        
        // Step 1: åˆ›å»ºèšåˆæ ¹ (ä¸šåŠ¡è§„åˆ™éªŒè¯)
        let mut aggregate = OrderAggregate::create(
            command.customer_id,
            command.items,
        )
        .map_err(|e| {
            error!(error = ?e, "âŒ Business rule validation failed");
            CommandError::DomainError(e)
        })?;
        
        let order_id = aggregate.id();
        info!(order_id = %order_id, "âœ… Order aggregate created");
        
        // Step 2: æŒä¹…åŒ–åˆ°äº‹ä»¶å­˜å‚¨ (Event Store)
        let events = aggregate.uncommitted_events().to_vec();
        
        self.order_repo
            .save_events(order_id, events.clone(), aggregate.version())
            .await
            .map_err(|e| {
                error!(error = ?e, "âŒ Failed to save events");
                CommandError::RepositoryError(e)
            })?;
        
        info!(
            order_id = %order_id,
            event_count = events.len(),
            "ğŸ’¾ Events saved to event store"
        );
        
        aggregate.clear_uncommitted_events();
        
        // Step 3: å‘å¸ƒäº‹ä»¶åˆ° Event Bus (Kafka)
        for event in events {
            self.event_bus
                .publish(event.clone())
                .await
                .map_err(|e| {
                    error!(error = ?e, "âŒ Failed to publish event");
                    CommandError::EventBusError(e)
                })?;
            
            info!(
                event_type = event.event_type(),
                "ğŸ“¤ Event published to Kafka"
            );
        }
        
        info!(order_id = %order_id, "ğŸ‰ CreateOrder command completed");
        
        Ok(order_id)
    }
}
```

#### 2.2 Event Store (PostgreSQL)

```rust
// write/event_store/postgres_event_store.rs
use crate::domain::events::OrderEvent;
use crate::domain::value_objects::OrderId;
use sqlx::PgPool;
use tracing::{instrument, info, error};

/// PostgreSQL äº‹ä»¶å­˜å‚¨
/// 
/// è¡¨ç»“æ„:
/// CREATE TABLE event_store (
///     id BIGSERIAL PRIMARY KEY,
///     aggregate_id UUID NOT NULL,
///     aggregate_type VARCHAR(255) NOT NULL,
///     event_type VARCHAR(255) NOT NULL,
///     event_data JSONB NOT NULL,
///     version BIGINT NOT NULL,
///     created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
///     UNIQUE(aggregate_id, version)
/// );
pub struct PostgresEventStore {
    pool: PgPool,
}

impl PostgresEventStore {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }
    
    #[instrument(
        name = "save_events_to_event_store",
        skip(self, events),
        fields(
            db.system = "postgresql",
            db.table = "event_store",
            aggregate_id = %aggregate_id,
            event_count = events.len(),
            version = version,
            otel.kind = "client",
        )
    )]
    pub async fn save_events(
        &self,
        aggregate_id: OrderId,
        events: Vec<OrderEvent>,
        version: u64,
    ) -> Result<(), EventStoreError> {
        info!("ğŸ’¾ Saving events to event store");
        
        // å¼€å¯äº‹åŠ¡
        let mut tx = self.pool.begin().await.map_err(|e| {
            error!(error = ?e, "âŒ Failed to begin transaction");
            EventStoreError::DatabaseError(e.to_string())
        })?;
        
        for (i, event) in events.iter().enumerate() {
            let event_version = version - events.len() as u64 + i as u64 + 1;
            
            let event_data = serde_json::to_value(event).map_err(|e| {
                error!(error = ?e, "âŒ Failed to serialize event");
                EventStoreError::SerializationError(e.to_string())
            })?;
            
            sqlx::query!(
                r#"
                INSERT INTO event_store (aggregate_id, aggregate_type, event_type, event_data, version)
                VALUES ($1, $2, $3, $4, $5)
                "#,
                aggregate_id.as_uuid(),
                "Order",
                event.event_type(),
                event_data,
                event_version as i64,
            )
            .execute(&mut *tx)
            .await
            .map_err(|e| {
                error!(error = ?e, "âŒ Failed to insert event");
                EventStoreError::DatabaseError(e.to_string())
            })?;
            
            info!(
                event_type = event.event_type(),
                version = event_version,
                "âœ… Event saved"
            );
        }
        
        // æäº¤äº‹åŠ¡
        tx.commit().await.map_err(|e| {
            error!(error = ?e, "âŒ Failed to commit transaction");
            EventStoreError::DatabaseError(e.to_string())
        })?;
        
        info!(
            aggregate_id = %aggregate_id,
            event_count = events.len(),
            "ğŸ‰ All events saved successfully"
        );
        
        Ok(())
    }
    
    #[instrument(
        name = "load_events_from_event_store",
        skip(self),
        fields(
            db.system = "postgresql",
            db.table = "event_store",
            aggregate_id = %aggregate_id,
            otel.kind = "client",
        )
    )]
    pub async fn load_events(
        &self,
        aggregate_id: OrderId,
    ) -> Result<Vec<OrderEvent>, EventStoreError> {
        info!(aggregate_id = %aggregate_id, "ğŸ” Loading events from event store");
        
        let rows = sqlx::query!(
            r#"
            SELECT event_data
            FROM event_store
            WHERE aggregate_id = $1
            ORDER BY version ASC
            "#,
            aggregate_id.as_uuid(),
        )
        .fetch_all(&self.pool)
        .await
        .map_err(|e| {
            error!(error = ?e, "âŒ Failed to load events");
            EventStoreError::DatabaseError(e.to_string())
        })?;
        
        let mut events = Vec::new();
        
        for row in rows {
            let event: OrderEvent = serde_json::from_value(row.event_data).map_err(|e| {
                error!(error = ?e, "âŒ Failed to deserialize event");
                EventStoreError::SerializationError(e.to_string())
            })?;
            
            events.push(event);
        }
        
        info!(
            aggregate_id = %aggregate_id,
            event_count = events.len(),
            "âœ… Events loaded successfully"
        );
        
        Ok(events)
    }
}
```

---

### 3. Read Side (Query ç«¯)

#### 3.1 Read Model

```rust
// read/models/order_read_model.rs
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};

/// è®¢å•è¯»æ¨¡å‹
/// 
/// ç‰¹ç‚¹:
/// 1. åè§„èŒƒåŒ– (æ‰€æœ‰æ•°æ®æ‰å¹³åŒ–)
/// 2. ä¼˜åŒ–æŸ¥è¯¢ (æ— éœ€ JOIN)
/// 3. å¯ä»¥æœ‰å¤šä¸ªè¯»æ¨¡å‹ (ä¸åŒè§†å›¾)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OrderReadModel {
    // åŸºæœ¬ä¿¡æ¯
    pub id: String,                      // Order ID
    pub customer_id: String,
    pub customer_name: String,           // âœ… åè§„èŒƒåŒ–
    pub customer_email: String,          // âœ… åè§„èŒƒåŒ–
    
    // è®¢å•é¡¹ä¿¡æ¯
    pub item_names: Vec<String>,         // âœ… åè§„èŒƒåŒ–
    pub item_quantities: Vec<u32>,       // âœ… åè§„èŒƒåŒ–
    pub total_amount: f64,               // âœ… é¢„è®¡ç®—
    pub currency: String,
    
    // çŠ¶æ€ä¿¡æ¯
    pub status: String,
    pub tracking_number: Option<String>,
    
    // æ—¶é—´ä¿¡æ¯
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub shipped_at: Option<DateTime<Utc>>,
    pub delivered_at: Option<DateTime<Utc>>,
    
    // æœç´¢ä¼˜åŒ–å­—æ®µ
    pub search_text: String,             // âœ… å…¨æ–‡æœç´¢å­—æ®µ
}

impl OrderReadModel {
    /// ä»é¢†åŸŸäº‹ä»¶æ„å»ºè¯»æ¨¡å‹
    pub fn from_created_event(
        event: &OrderCreatedEvent,
        customer_name: String,
        customer_email: String,
    ) -> Self {
        let item_names: Vec<String> = event.items.iter()
            .map(|item| item.product_name.clone())
            .collect();
        
        let item_quantities: Vec<u32> = event.items.iter()
            .map(|item| item.quantity)
            .collect();
        
        // æ„å»ºæœç´¢æ–‡æœ¬ (ç”¨äºå…¨æ–‡æœç´¢)
        let search_text = format!(
            "{} {} {} {}",
            event.order_id,
            customer_name,
            customer_email,
            item_names.join(" ")
        );
        
        Self {
            id: event.order_id.to_string(),
            customer_id: event.customer_id.to_string(),
            customer_name,
            customer_email,
            item_names,
            item_quantities,
            total_amount: event.total_amount.amount(),
            currency: event.total_amount.currency().to_string(),
            status: "Pending".to_string(),
            tracking_number: None,
            created_at: event.created_at,
            updated_at: event.created_at,
            shipped_at: None,
            delivered_at: None,
            search_text,
        }
    }
    
    /// æ›´æ–°çŠ¶æ€ (åŸºäºäº‹ä»¶)
    pub fn apply_event(&mut self, event: &OrderEvent) {
        match event {
            OrderEvent::OrderShipped { tracking_number, shipped_at, .. } => {
                self.status = "Shipped".to_string();
                self.tracking_number = Some(tracking_number.clone());
                self.shipped_at = Some(*shipped_at);
                self.updated_at = *shipped_at;
            }
            OrderEvent::OrderDelivered { delivered_at, .. } => {
                self.status = "Delivered".to_string();
                self.delivered_at = Some(*delivered_at);
                self.updated_at = *delivered_at;
            }
            OrderEvent::OrderCancelled { cancelled_at, .. } => {
                self.status = "Cancelled".to_string();
                self.updated_at = *cancelled_at;
            }
            _ => {}
        }
    }
}
```

#### 3.2 Projection (æŠ•å½±)

```rust
// read/projections/order_projection.rs
use crate::domain::events::OrderEvent;
use crate::read::models::OrderReadModel;
use crate::read::repositories::OrderReadRepository;
use std::sync::Arc;
use tracing::{instrument, info, error, warn};

/// è®¢å•æŠ•å½±
/// 
/// è´Ÿè´£:
/// 1. ç›‘å¬äº‹ä»¶ (ä» Kafka æ¶ˆè´¹)
/// 2. æ›´æ–°è¯»æ¨¡å‹ (å†™å…¥ Elasticsearch)
pub struct OrderProjection<R: OrderReadRepository> {
    read_repo: Arc<R>,
    customer_service: Arc<dyn CustomerService>,  // è·å–å®¢æˆ·ä¿¡æ¯
}

impl<R: OrderReadRepository> OrderProjection<R> {
    pub fn new(
        read_repo: Arc<R>,
        customer_service: Arc<dyn CustomerService>,
    ) -> Self {
        Self {
            read_repo,
            customer_service,
        }
    }
    
    /// å¤„ç†è®¢å•äº‹ä»¶ (æ›´æ–°è¯»æ¨¡å‹)
    #[instrument(
        name = "order_projection_handle_event",
        skip(self, event),
        fields(
            projection = "OrderProjection",
            event_type = event.event_type(),
            order_id = %event.order_id(),
            otel.kind = "internal",
        )
    )]
    pub async fn handle(&self, event: OrderEvent) -> Result<(), ProjectionError> {
        info!(
            event_type = event.event_type(),
            order_id = %event.order_id(),
            "ğŸ“¥ Handling event in projection"
        );
        
        match event {
            OrderEvent::OrderCreated {
                ref order_id,
                ref customer_id,
                ref items,
                ref total_amount,
                created_at,
            } => {
                // è·å–å®¢æˆ·ä¿¡æ¯ (å¯èƒ½éœ€è¦è°ƒç”¨å…¶ä»–æœåŠ¡)
                let customer = self.customer_service
                    .get_customer(*customer_id)
                    .await
                    .map_err(|e| {
                        error!(error = ?e, "âŒ Failed to get customer info");
                        ProjectionError::CustomerServiceError(e)
                    })?;
                
                // æ„å»ºè¯»æ¨¡å‹
                let read_model = OrderReadModel::from_created_event(
                    &event,
                    customer.name,
                    customer.email,
                );
                
                // ä¿å­˜åˆ° Elasticsearch
                self.read_repo
                    .save(&read_model)
                    .await
                    .map_err(|e| {
                        error!(error = ?e, "âŒ Failed to save read model");
                        ProjectionError::RepositoryError(e)
                    })?;
                
                info!(order_id = %order_id, "âœ… Read model created");
            }
            
            _ => {
                // å…¶ä»–äº‹ä»¶: æ›´æ–°å·²æœ‰è¯»æ¨¡å‹
                let order_id = event.order_id();
                
                let mut read_model = self.read_repo
                    .find_by_id(order_id)
                    .await
                    .map_err(|e| {
                        error!(error = ?e, "âŒ Failed to find read model");
                        ProjectionError::RepositoryError(e)
                    })?
                    .ok_or_else(|| {
                        warn!(order_id = %order_id, "âš ï¸ Read model not found");
                        ProjectionError::ReadModelNotFound(order_id)
                    })?;
                
                // åº”ç”¨äº‹ä»¶
                read_model.apply_event(&event);
                
                // æ›´æ–° Elasticsearch
                self.read_repo
                    .update(&read_model)
                    .await
                    .map_err(|e| {
                        error!(error = ?e, "âŒ Failed to update read model");
                        ProjectionError::RepositoryError(e)
                    })?;
                
                info!(order_id = %order_id, "âœ… Read model updated");
            }
        }
        
        info!(
            event_type = event.event_type(),
            "ğŸ‰ Event handled successfully"
        );
        
        Ok(())
    }
}
```

#### 3.3 Elasticsearch Repository

```rust
// read/repositories/elasticsearch_order_read_repo.rs
use crate::read::models::OrderReadModel;
use elasticsearch::{Elasticsearch, IndexParts, SearchParts};
use serde_json::json;
use tracing::{instrument, info, error};

pub struct ElasticsearchOrderReadRepository {
    client: Elasticsearch,
    index: String,
}

impl ElasticsearchOrderReadRepository {
    pub fn new(client: Elasticsearch, index: String) -> Self {
        Self { client, index }
    }
    
    #[instrument(
        name = "elasticsearch_save_order",
        skip(self, order),
        fields(
            db.system = "elasticsearch",
            db.operation = "INDEX",
            db.index = %self.index,
            order_id = %order.id,
            otel.kind = "client",
        )
    )]
    pub async fn save(&self, order: &OrderReadModel) -> Result<(), ReadRepoError> {
        info!(order_id = %order.id, "ğŸ“ Indexing order to Elasticsearch");
        
        let response = self.client
            .index(IndexParts::IndexId(&self.index, &order.id))
            .body(order)
            .send()
            .await
            .map_err(|e| {
                error!(error = ?e, "âŒ Failed to index document");
                ReadRepoError::ElasticsearchError(e.to_string())
            })?;
        
        if !response.status_code().is_success() {
            error!(status = response.status_code().as_u16(), "âŒ Indexing failed");
            return Err(ReadRepoError::ElasticsearchError(
                format!("Status code: {}", response.status_code())
            ));
        }
        
        info!(order_id = %order.id, "âœ… Order indexed successfully");
        Ok(())
    }
    
    #[instrument(
        name = "elasticsearch_search_orders",
        skip(self),
        fields(
            db.system = "elasticsearch",
            db.operation = "SEARCH",
            db.index = %self.index,
            customer_id = %customer_id,
            otel.kind = "client",
        )
    )]
    pub async fn find_by_customer_id(
        &self,
        customer_id: CustomerId,
    ) -> Result<Vec<OrderReadModel>, ReadRepoError> {
        info!(customer_id = %customer_id, "ğŸ” Searching orders in Elasticsearch");
        
        let response = self.client
            .search(SearchParts::Index(&[&self.index]))
            .body(json!({
                "query": {
                    "term": {
                        "customer_id": customer_id.to_string()
                    }
                },
                "sort": [
                    { "created_at": "desc" }
                ],
                "size": 100
            }))
            .send()
            .await
            .map_err(|e| {
                error!(error = ?e, "âŒ Search failed");
                ReadRepoError::ElasticsearchError(e.to_string())
            })?;
        
        let json = response.json::<serde_json::Value>().await.map_err(|e| {
            error!(error = ?e, "âŒ Failed to parse response");
            ReadRepoError::ElasticsearchError(e.to_string())
        })?;
        
        let hits = json["hits"]["hits"].as_array()
            .ok_or_else(|| ReadRepoError::ElasticsearchError("Invalid response".to_string()))?;
        
        let orders: Vec<OrderReadModel> = hits.iter()
            .filter_map(|hit| {
                serde_json::from_value(hit["_source"].clone()).ok()
            })
            .collect();
        
        info!(
            customer_id = %customer_id,
            order_count = orders.len(),
            "âœ… Found {} orders",
            orders.len()
        );
        
        Ok(orders)
    }
}
```

#### 3.4 Query Handler

```rust
// read/handlers/list_orders_handler.rs
use crate::read::models::OrderReadModel;
use crate::read::repositories::OrderReadRepository;
use std::sync::Arc;
use tracing::{instrument, info};

pub struct ListOrdersHandler<R: OrderReadRepository> {
    read_repo: Arc<R>,
}

impl<R: OrderReadRepository> ListOrdersHandler<R> {
    pub fn new(read_repo: Arc<R>) -> Self {
        Self { read_repo }
    }
    
    #[instrument(
        name = "list_orders_query_handler",
        skip(self),
        fields(
            query_type = "ListOrdersByCustomer",
            customer_id = %customer_id,
            otel.kind = "internal",
        )
    )]
    pub async fn handle(
        &self,
        customer_id: CustomerId,
    ) -> Result<Vec<OrderReadModel>, QueryError> {
        info!(customer_id = %customer_id, "ğŸ” Handling ListOrders query");
        
        let orders = self.read_repo
            .find_by_customer_id(customer_id)
            .await
            .map_err(|e| {
                error!(error = ?e, "âŒ Query failed");
                QueryError::RepositoryError(e)
            })?;
        
        info!(
            customer_id = %customer_id,
            order_count = orders.len(),
            "âœ… Query completed"
        );
        
        Ok(orders)
    }
}
```

---

## â±ï¸ æœ€ç»ˆä¸€è‡´æ€§å¤„ç†

### é—®é¢˜: è¯»æ¨¡å‹å¯èƒ½æ»å

```text
æ—¶é—´çº¿:
T1: Command â†’ å†™å…¥ PostgreSQL âœ…
T2: Event â†’ å‘é€åˆ° Kafka âœ…
T3: (ç½‘ç»œå»¶è¿Ÿ...)
T4: Projection â†’ æ›´æ–° Elasticsearch âœ…
T5: Query â†’ è¯»å– Elasticsearch (å¯èƒ½è¯»åˆ°æ—§æ•°æ®)
```

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ 1: ç‰ˆæœ¬å· + é‡è¯•

```rust
pub async fn get_order_with_retry(
    &self,
    order_id: OrderId,
    expected_version: u64,
    max_retries: u32,
) -> Result<OrderReadModel> {
    for attempt in 0..max_retries {
        if let Some(order) = self.read_repo.find_by_id(order_id).await? {
            if order.version >= expected_version {
                return Ok(order);
            }
        }
        
        // ç­‰å¾…æŠ•å½±æ›´æ–°
        tokio::time::sleep(Duration::from_millis(100)).await;
    }
    
    Err(QueryError::EventualConsistencyTimeout)
}
```

#### æ–¹æ¡ˆ 2: Command è¿”å›å®Œæ•´ç»“æœ

```rust
// Command è¿”å›è¶³å¤Ÿä¿¡æ¯,é¿å…ç«‹å³æŸ¥è¯¢
pub struct CreateOrderResponse {
    pub order_id: OrderId,
    pub status: String,
    pub total_amount: Money,
    pub estimated_delivery: DateTime<Utc>,  // âœ… åŒ…å«å…³é”®ä¿¡æ¯
}
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### 1. è¯»æ¨¡å‹ç¼“å­˜

```rust
use redis::AsyncCommands;

pub struct CachedOrderReadRepository<R: OrderReadRepository> {
    inner: Arc<R>,
    redis: redis::Client,
    ttl: usize,  // ç¼“å­˜æ—¶é—´ (ç§’)
}

impl<R: OrderReadRepository> CachedOrderReadRepository<R> {
    pub async fn find_by_id(&self, id: OrderId) -> Result<Option<OrderReadModel>> {
        let cache_key = format!("order:read:{}", id);
        
        // 1. å°è¯•ä»ç¼“å­˜è¯»å–
        let mut conn = self.redis.get_async_connection().await?;
        
        if let Some(cached): Option<String> = conn.get(&cache_key).await.ok() {
            info!(order_id = %id, "âœ… Cache HIT");
            return Ok(Some(serde_json::from_str(&cached)?));
        }
        
        info!(order_id = %id, "âš ï¸ Cache MISS");
        
        // 2. ä» Elasticsearch è¯»å–
        let order = self.inner.find_by_id(id).await?;
        
        // 3. å†™å…¥ç¼“å­˜
        if let Some(ref o) = order {
            let json = serde_json::to_string(o)?;
            let _: () = conn.set_ex(&cache_key, json, self.ttl).await?;
            info!(order_id = %id, ttl = self.ttl, "ğŸ’¾ Cached");
        }
        
        Ok(order)
    }
}
```

---

## ğŸ“¦ ç”Ÿäº§éƒ¨ç½²

### Cargo.toml

```toml
[package]
name = "cqrs-order-service"
version = "1.0.0"
edition = "2024"
rust-version = "1.90"

[dependencies]
# Async runtime
tokio = { version = "1.41", features = ["full"] }
async-trait = "0.1.82"

# Web framework
axum = { version = "0.7", features = ["macros"] }

# Database (Write Side)
sqlx = { version = "0.8", features = ["postgres", "runtime-tokio", "macros"] }

# Elasticsearch (Read Side)
elasticsearch = "8.15"

# Kafka (Event Bus)
rdkafka = { version = "0.36", features = ["tokio"] }

# Redis (Cache)
redis = { version = "0.27", features = ["tokio-comp", "connection-manager"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
anyhow = "1.0"
thiserror = "2.0"

# UUID & Time
uuid = { version = "1.11", features = ["serde", "v4"] }
chrono = { version = "0.4", features = ["serde"] }

# Tracing & OTLP
tracing = "0.1"
tracing-subscriber = { version = "0.3.18", features = ["env-filter"] }
tracing-opentelemetry = "0.31"
opentelemetry = "0.31"
opentelemetry_sdk = "0.31"
opentelemetry-otlp = "0.16"
```

---

### Docker Compose

```yaml
version: '3.9'

services:
  # Command Side - PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: orders_write
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Query Side - Elasticsearch
  elasticsearch:
    image: elasticsearch:8.15.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  # Event Bus - Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.7.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Cache - Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # CQRS Order Service
  order-service:
    build: .
    ports:
      - "8080:8080"
    environment:
      - WRITE_DB_URL=postgres://postgres:password@postgres:5432/orders_write
      - READ_ES_URL=http://elasticsearch:9200
      - KAFKA_BROKERS=kafka:9092
      - REDIS_URL=redis://redis:6379
      - OTLP_ENDPOINT=http://otel-collector:4317
    depends_on:
      - postgres
      - elasticsearch
      - kafka
      - redis
      - otel-collector

  # OTLP Collector
  otel-collector:
    image: otel/opentelemetry-collector:0.111.0
    command: ["--config=/etc/otel-config.yaml"]
    volumes:
      - ./otel-config.yaml:/etc/otel-config.yaml
    ports:
      - "4317:4317"

  # Jaeger
  jaeger:
    image: jaegertracing/all-in-one:1.62
    ports:
      - "16686:16686"
    environment:
      - COLLECTOR_OTLP_ENABLED=true

volumes:
  postgres_data:
  es_data:
```

---

## âœ… æœ€ä½³å®è·µ

### CQRS è®¾è®¡

- [x] **ä¸¥æ ¼åˆ†ç¦»**: Command å’Œ Query å®Œå…¨ç‹¬ç«‹
- [x] **ä¸åŒæ•°æ®åº“**: å†™ç”¨ PostgreSQL, è¯»ç”¨ Elasticsearch
- [x] **äº‹ä»¶é©±åŠ¨**: é€šè¿‡äº‹ä»¶åŒæ­¥è¯»å†™æ¨¡å‹
- [x] **æœ€ç»ˆä¸€è‡´æ€§**: æ¥å—è¯»æ¨¡å‹å¯èƒ½æ»å
- [x] **Event Sourcing**: ç»“åˆäº‹ä»¶æº¯æºå­˜å‚¨å®Œæ•´å†å²

### OTLP é›†æˆ

- [x] **Command Side**: å®Œæ•´ä¸šåŠ¡é€»è¾‘è¿½è¸ª
- [x] **Event Bus**: è¿½è¸ªä¸Šä¸‹æ–‡é€šè¿‡ Kafka ä¼ æ’­
- [x] **Projection**: æŠ•å½±å¤„ç†è¿½è¸ª
- [x] **Query Side**: æŸ¥è¯¢æ€§èƒ½è¿½è¸ª
- [x] **å…³è”åˆ†æ**: Command â†’ Event â†’ Projection â†’ Query å®Œæ•´é“¾è·¯

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ11æ—¥  
**Rust ç‰ˆæœ¬**: 1.90+  
**OpenTelemetry**: 0.31.0

---

**ğŸ“Š CQRS æ¶æ„ - æ„å»ºé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„è¯»å†™åˆ†ç¦»ç³»ç»Ÿï¼**
