# LogRecordExporter - Rust å®Œæ•´å®ç°æŒ‡å—

## ğŸ“‹ ç›®å½•

- [LogRecordExporter - Rust å®Œæ•´å®ç°æŒ‡å—](#logrecordexporter---rust-å®Œæ•´å®ç°æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
  - [Exporter ç±»å‹](#exporter-ç±»å‹)
  - [Rust å®ç°](#rust-å®ç°)
    - [OTLP Exporter](#otlp-exporter)
      - [**gRPC ä¼ è¾“**](#grpc-ä¼ è¾“)
      - [**HTTP/JSON ä¼ è¾“**](#httpjson-ä¼ è¾“)
      - [**TLS è®¤è¯**](#tls-è®¤è¯)
      - [**Header è®¤è¯**](#header-è®¤è¯)
    - [Stdout Exporter](#stdout-exporter)
    - [File Exporter](#file-exporter)
    - [è‡ªå®šä¹‰ Exporter](#è‡ªå®šä¹‰-exporter)
      - [**Elasticsearch Exporter**](#elasticsearch-exporter)
  - [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
    - [**é‡è¯•æœºåˆ¶**](#é‡è¯•æœºåˆ¶)
    - [**é™çº§ç­–ç•¥**](#é™çº§ç­–ç•¥)
  - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
    - [**æ‰¹é‡å‹ç¼©**](#æ‰¹é‡å‹ç¼©)
    - [**è¿æ¥æ± å¤ç”¨**](#è¿æ¥æ± å¤ç”¨)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [âœ… **æ¨è**](#-æ¨è)
    - [âŒ **é¿å…**](#-é¿å…)
  - [ä¾èµ–åº“](#ä¾èµ–åº“)
    - [**æ ¸å¿ƒä¾èµ–**](#æ ¸å¿ƒä¾èµ–)
    - [**è‡ªå®šä¹‰ Exporter ä¾èµ–**](#è‡ªå®šä¹‰-exporter-ä¾èµ–)
  - [æ€»ç»“](#æ€»ç»“)

---

## æ ¸å¿ƒæ¦‚å¿µ

**LogRecordExporter** è´Ÿè´£å°†æ—¥å¿—æ•°æ®å‘é€åˆ°å­˜å‚¨åç«¯ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LogRecordProcessor                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ‰¹é‡èšåˆæ—¥å¿—è®°å½•                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â†“                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LogRecordExporter                     â”‚  â”‚
â”‚  â”‚  - åºåˆ—åŒ–æ—¥å¿—æ•°æ®                      â”‚  â”‚
â”‚  â”‚  - å‘é€åˆ°åç«¯                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â†“                          â”‚
â”‚   Backend (OTLP/Elasticsearch/File/...)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Exporter ç±»å‹

| Exporter | åè®® | é€‚ç”¨åœºæ™¯ |
|----------|------|---------|
| **OTLP** | gRPC/HTTP | æ ‡å‡†åç«¯ã€Collector |
| **Stdout** | æ ‡å‡†è¾“å‡º | æœ¬åœ°è°ƒè¯• |
| **File** | æ–‡ä»¶ç³»ç»Ÿ | æœ¬åœ°æŒä¹…åŒ–ã€å¤‡ä»½ |
| **è‡ªå®šä¹‰** | ä»»æ„ | Elasticsearchã€Lokiã€Splunk |

---

## Rust å®ç°

### OTLP Exporter

#### **gRPC ä¼ è¾“**

```rust
use opentelemetry::{global, KeyValue};
use opentelemetry_sdk::{
    logs::{BatchLogProcessor, LoggerProvider},
    Resource,
};
use opentelemetry_otlp::WithExportConfig;
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»º OTLP gRPC Exporter
    let exporter = opentelemetry_otlp::new_exporter()
        .tonic()
        .with_endpoint("http://localhost:4317")
        .with_timeout(Duration::from_secs(10))
        .build_log_exporter()?;

    let processor = BatchLogProcessor::builder(exporter).build();

    let provider = LoggerProvider::builder()
        .with_resource(Resource::new(vec![
            KeyValue::new("service.name", "otlp-logs-demo"),
        ]))
        .with_log_processor(processor)
        .build();

    global::set_logger_provider(provider.clone());

    // ä½¿ç”¨æ—¥å¿—
    tracing::info!("Application started with OTLP logging");
    tracing::error!(error_code = 500, "Server error occurred");

    provider.shutdown()?;
    Ok(())
}
```

---

#### **HTTP/JSON ä¼ è¾“**

```rust
let exporter = opentelemetry_otlp::new_exporter()
    .http()
    .with_endpoint("http://localhost:4318/v1/logs")
    .with_timeout(Duration::from_secs(10))
    .build_log_exporter()?;
```

---

#### **TLS è®¤è¯**

```rust
let exporter = opentelemetry_otlp::new_exporter()
    .tonic()
    .with_endpoint("https://collector.example.com:4317")
    .with_tls_config(
        tonic::transport::ClientTlsConfig::new()
            .ca_certificate(tonic::transport::Certificate::from_pem(
                std::fs::read_to_string("ca.pem")?
            ))
            .domain_name("collector.example.com"),
    )
    .build_log_exporter()?;
```

---

#### **Header è®¤è¯**

```rust
let mut headers = std::collections::HashMap::new();
headers.insert("Authorization".to_string(), "Bearer YOUR_TOKEN".to_string());

let exporter = opentelemetry_otlp::new_exporter()
    .http()
    .with_endpoint("http://localhost:4318/v1/logs")
    .with_headers(headers)
    .build_log_exporter()?;
```

---

### Stdout Exporter

```rust
use opentelemetry_stdout::LogExporter;

let exporter = LogExporter::default();

let processor = BatchLogProcessor::builder(exporter).build();

let provider = LoggerProvider::builder()
    .with_log_processor(processor)
    .build();

global::set_logger_provider(provider.clone());

// æ—¥å¿—ä¼šè¾“å‡ºåˆ°æ§åˆ¶å°
tracing::info!("This will be printed to stdout");
```

**ä¾èµ–**ï¼š

```toml
[dependencies]
opentelemetry-stdout = { version = "0.24", features = ["logs"] }
```

---

### File Exporter

**è‡ªå®šä¹‰æ–‡ä»¶å¯¼å‡ºå™¨**-

```rust
use opentelemetry::logs::LogRecord;
use opentelemetry_sdk::logs::{LogExporter, LogResult};
use std::fs::OpenOptions;
use std::io::Write;
use std::sync::Mutex;

struct FileLogExporter {
    file: Mutex<std::fs::File>,
}

impl FileLogExporter {
    fn new(path: &str) -> std::io::Result<Self> {
        let file = OpenOptions::new()
            .create(true)
            .append(true)
            .open(path)?;
        
        Ok(Self {
            file: Mutex::new(file),
        })
    }
}

impl LogExporter for FileLogExporter {
    fn export(&self, batch: Vec<&LogRecord>) -> LogResult<()> {
        let mut file = self.file.lock().unwrap();
        
        for record in batch {
            let line = format!(
                "[{}] {}: {}\n",
                record.timestamp
                    .map(|t| format!("{:?}", t))
                    .unwrap_or_else(|| "unknown".to_string()),
                record.severity_text.as_ref().unwrap_or(&"INFO".to_string()),
                record.body.as_ref()
                    .map(|b| b.to_string())
                    .unwrap_or_else(|| "".to_string())
            );
            
            file.write_all(line.as_bytes())
                .map_err(|e| opentelemetry::logs::LogError::Other(e.to_string()))?;
        }
        
        file.flush()
            .map_err(|e| opentelemetry::logs::LogError::Other(e.to_string()))?;
        
        Ok(())
    }

    fn shutdown(&self) -> LogResult<()> {
        self.file.lock().unwrap().flush()
            .map_err(|e| opentelemetry::logs::LogError::Other(e.to_string()))?;
        Ok(())
    }
}

// ä½¿ç”¨
let file_exporter = FileLogExporter::new("logs/app.log")?;
let processor = SimpleLogProcessor::new(Box::new(file_exporter));
```

---

### è‡ªå®šä¹‰ Exporter

#### **Elasticsearch Exporter**

```rust
use elasticsearch::{Elasticsearch, IndexParts};
use serde_json::json;

struct ElasticsearchExporter {
    client: Elasticsearch,
    index: String,
}

impl ElasticsearchExporter {
    async fn new(url: &str, index: String) -> Result<Self, elasticsearch::Error> {
        let transport = elasticsearch::http::transport::Transport::single_node(url)?;
        let client = Elasticsearch::new(transport);
        
        Ok(Self { client, index })
    }
}

#[async_trait::async_trait]
impl LogExporter for ElasticsearchExporter {
    fn export(&self, batch: Vec<&LogRecord>) -> LogResult<()> {
        tokio::runtime::Handle::current().block_on(async {
            for record in batch {
                let doc = json!({
                    "timestamp": record.timestamp,
                    "severity": record.severity_text,
                    "body": record.body,
                    "attributes": record.attributes,
                    "trace_id": record.trace_context.as_ref().map(|ctx| ctx.trace_id),
                    "span_id": record.trace_context.as_ref().map(|ctx| ctx.span_id),
                });

                self.client
                    .index(IndexParts::Index(&self.index))
                    .body(doc)
                    .send()
                    .await
                    .map_err(|e| opentelemetry::logs::LogError::Other(e.to_string()))?;
            }
            Ok(())
        })
    }

    fn shutdown(&self) -> LogResult<()> {
        Ok(())
    }
}

// ä½¿ç”¨
let es_exporter = ElasticsearchExporter::new(
    "http://localhost:9200",
    "logs-production".to_string()
).await?;

let processor = BatchLogProcessor::builder(es_exporter).build();
```

**ä¾èµ–**ï¼š

```toml
[dependencies]
elasticsearch = "8.5"
serde_json = "1.0"
async-trait = "0.1"
```

---

## é”™è¯¯å¤„ç†

### **é‡è¯•æœºåˆ¶**

```rust
use std::time::Duration;

struct RetryableExporter {
    inner: Box<dyn LogExporter>,
    max_retries: usize,
}

impl LogExporter for RetryableExporter {
    fn export(&self, batch: Vec<&LogRecord>) -> LogResult<()> {
        let mut attempts = 0;
        
        loop {
            match self.inner.export(batch.clone()) {
                Ok(_) => return Ok(()),
                Err(e) if attempts < self.max_retries => {
                    attempts += 1;
                    eprintln!("Export failed, retry {}/{}: {:?}", attempts, self.max_retries, e);
                    std::thread::sleep(Duration::from_secs(2u64.pow(attempts as u32)));
                }
                Err(e) => return Err(e),
            }
        }
    }

    fn shutdown(&self) -> LogResult<()> {
        self.inner.shutdown()
    }
}
```

---

### **é™çº§ç­–ç•¥**

```rust
struct FallbackExporter {
    primary: Box<dyn LogExporter>,
    fallback: Box<dyn LogExporter>,
}

impl LogExporter for FallbackExporter {
    fn export(&self, batch: Vec<&LogRecord>) -> LogResult<()> {
        match self.primary.export(batch.clone()) {
            Ok(_) => Ok(()),
            Err(e) => {
                eprintln!("Primary exporter failed, using fallback: {:?}", e);
                self.fallback.export(batch)
            }
        }
    }

    fn shutdown(&self) -> LogResult<()> {
        self.primary.shutdown()?;
        self.fallback.shutdown()?;
        Ok(())
    }
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šOTLP å¤±è´¥æ—¶å†™å…¥æœ¬åœ°æ–‡ä»¶
let fallback_exporter = FallbackExporter {
    primary: Box::new(otlp_exporter),
    fallback: Box::new(FileLogExporter::new("logs/fallback.log")?),
};
```

---

## æ€§èƒ½ä¼˜åŒ–

### **æ‰¹é‡å‹ç¼©**

```rust
use flate2::write::GzEncoder;
use flate2::Compression;

fn compress_logs(data: &[u8]) -> Vec<u8> {
    let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
    encoder.write_all(data).unwrap();
    encoder.finish().unwrap()
}

// åœ¨è‡ªå®šä¹‰ Exporter ä¸­ä½¿ç”¨
impl LogExporter for CustomExporter {
    fn export(&self, batch: Vec<&LogRecord>) -> LogResult<()> {
        let json = serde_json::to_vec(&batch).unwrap();
        let compressed = compress_logs(&json);
        
        self.client
            .post(&self.url)
            .header("Content-Encoding", "gzip")
            .body(compressed)
            .send()
            .map_err(|e| LogError::Other(e.to_string()))?;
        
        Ok(())
    }
}
```

---

### **è¿æ¥æ± å¤ç”¨**

```rust
use reqwest::Client;
use std::sync::Arc;

struct PooledExporter {
    client: Arc<Client>,
    url: String,
}

impl PooledExporter {
    fn new(url: String) -> Self {
        let client = Client::builder()
            .pool_max_idle_per_host(10)
            .timeout(Duration::from_secs(10))
            .build()
            .unwrap();
        
        Self {
            client: Arc::new(client),
            url,
        }
    }
}
```

---

## æœ€ä½³å®è·µ

### âœ… **æ¨è**

1. **é€‰æ‹©åˆé€‚çš„ä¼ è¾“åè®®**ï¼š
   - gRPCï¼šä½å»¶è¿Ÿã€é«˜æ€§èƒ½
   - HTTP/JSONï¼šé˜²ç«å¢™å‹å¥½ã€æ˜“è°ƒè¯•
2. **é…ç½®è¶…æ—¶**ï¼šé¿å…é˜»å¡ Processor
3. **å®ç°é‡è¯•**ï¼šç½‘ç»œæŠ–åŠ¨æ—¶è‡ªåŠ¨é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
4. **å‹ç¼©æ•°æ®**ï¼šå¤§æ‰¹é‡æ—¥å¿—å¯¼å‡ºåº”å¯ç”¨ gzip
5. **é™çº§ç­–ç•¥**ï¼šä¸» Exporter å¤±è´¥æ—¶å†™å…¥æœ¬åœ°æ–‡ä»¶
6. **è¿æ¥æ± **ï¼šå¤ç”¨ HTTP è¿æ¥å‡å°‘æ¡æ‰‹å¼€é”€
7. **ç›‘æ§å¯¼å‡ºçŠ¶æ€**ï¼šè®°å½•æˆåŠŸç‡å’Œå»¶è¿Ÿ

### âŒ **é¿å…**

1. **é˜»å¡å¯¼å‡º**ï¼šExporter ä¸åº”æ‰§è¡ŒåŒæ­¥é˜»å¡æ“ä½œ
2. **å¿½ç•¥é”™è¯¯**ï¼šå¯¼å‡ºå¤±è´¥åº”è®°å½•åˆ°å¤‡ä»½ä½ç½®
3. **æ— é™é‡è¯•**ï¼šåº”è®¾ç½®æœ€å¤§é‡è¯•æ¬¡æ•°
4. **æœªå…³é—­èµ„æº**ï¼š`shutdown()` åº”æ¸…ç†è¿æ¥å’Œç¼“å†²åŒº

---

## ä¾èµ–åº“

### **æ ¸å¿ƒä¾èµ–**

```toml
[dependencies]
opentelemetry = "0.24"
opentelemetry-sdk = "0.24"
opentelemetry-otlp = "0.24"          # OTLP
opentelemetry-stdout = "0.24"        # Stdout
tokio = { version = "1", features = ["full"] }
```

### **è‡ªå®šä¹‰ Exporter ä¾èµ–**

```toml
reqwest = { version = "0.12", features = ["json", "gzip"] }
elasticsearch = "8.5"
async-trait = "0.1"
serde_json = "1.0"
flate2 = "1.0"             # gzip å‹ç¼©
```

---

## æ€»ç»“

| Exporter | åè®® | é€‚ç”¨åœºæ™¯ | é…ç½®è¦ç‚¹ |
|----------|------|---------|---------|
| **OTLP gRPC** | gRPC | æ ‡å‡†åç«¯ | `with_endpoint()` + `with_timeout()` |
| **OTLP HTTP** | HTTP/JSON | é˜²ç«å¢™ç¯å¢ƒ | `http()` + `with_headers()` |
| **Stdout** | æ ‡å‡†è¾“å‡º | æœ¬åœ°è°ƒè¯• | ç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å° |
| **File** | æ–‡ä»¶ç³»ç»Ÿ | æœ¬åœ°å¤‡ä»½ | å®ç°è‡ªå®šä¹‰ `FileLogExporter` |
| **è‡ªå®šä¹‰** | ä»»æ„ | Elasticsearch/Loki | å®ç° `LogExporter` trait |

**å®Œæˆ**ï¼šLogs SDK æ¨¡å—å…¨éƒ¨æ–‡æ¡£å·²åˆ›å»ºï¼
