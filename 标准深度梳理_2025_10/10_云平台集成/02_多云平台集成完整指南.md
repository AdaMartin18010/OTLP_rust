# 多云平台集成完整指南 - Rust OTLP

> **版本信息**
>
> - Rust: 1.90 (2024 Edition)
> - opentelemetry: 0.31.0
> - 更新日期: 2025-10-08
> - 适用场景: AWS/Azure/GCP 多云环境

## 目录

- [多云平台集成完整指南 - Rust OTLP](#多云平台集成完整指南---rust-otlp)
  - [目录](#目录)
  - [概述](#概述)
  - [1. Azure 集成](#1-azure-集成)
    - [1.1 Application Insights](#11-application-insights)
    - [1.2 Azure Monitor](#12-azure-monitor)
    - [1.3 AKS 部署](#13-aks-部署)
  - [2. GCP 集成](#2-gcp-集成)
    - [2.1 Cloud Trace](#21-cloud-trace)
    - [2.2 Cloud Logging](#22-cloud-logging)
    - [2.3 GKE 部署](#23-gke-部署)
  - [3. 多云策略](#3-多云策略)
    - [3.1 统一配置](#31-统一配置)
    - [3.2 云平台抽象](#32-云平台抽象)
    - [3.3 环境检测](#33-环境检测)
  - [4. 完整示例](#4-完整示例)
  - [总结](#总结)

---

## 概述

本指南提供 Rust OTLP 应用的多云平台集成方案：

- ✅ Azure Application Insights 集成
- ✅ Azure Monitor 集成
- ✅ GCP Cloud Trace 集成
- ✅ GCP Cloud Logging 集成
- ✅ 多云统一配置
- ✅ 云平台抽象层

---

## 1. Azure 集成

### 1.1 Application Insights

**Cargo.toml**:

```toml
[dependencies]
opentelemetry = "0.31.0"
opentelemetry_sdk = { version = "0.31.0", features = ["rt-tokio"] }
opentelemetry-application-insights = "0.33"
azure_core = "0.20"
tracing = "0.1.41"
tracing-opentelemetry = "0.27.0"
```

**配置 Application Insights**:

```rust
use opentelemetry::global;
use opentelemetry_application_insights::{
    ApplicationInsightsExporter,
    new_pipeline,
};
use opentelemetry_sdk::{Resource, trace::TracerProvider};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_application_insights(
    instrumentation_key: impl Into<String>,
) -> Result<TracerProvider, Box<dyn std::error::Error>> {
    // 1. 创建资源
    let resource = Resource::new(vec![
        opentelemetry::KeyValue::new("service.name", "rust-azure-app"),
        opentelemetry::KeyValue::new("service.version", env!("CARGO_PKG_VERSION")),
        opentelemetry::KeyValue::new("cloud.provider", "azure"),
    ]);
    
    // 2. 创建 Application Insights Exporter
    let exporter = ApplicationInsightsExporter::new(instrumentation_key.into());
    
    // 3. 构建 TracerProvider
    let tracer_provider = new_pipeline()
        .with_exporter(exporter)
        .with_resource(resource)
        .install_batch(opentelemetry_sdk::runtime::Tokio)?;
    
    // 4. 设置全局 provider
    global::set_tracer_provider(tracer_provider.clone());
    
    // 5. 配置 tracing
    tracing_subscriber::registry()
        .with(tracing_opentelemetry::layer())
        .with(tracing_subscriber::fmt::layer())
        .init();
    
    Ok(tracer_provider)
}

// 使用示例
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let instrumentation_key = std::env::var("APPLICATIONINSIGHTS_CONNECTION_STRING")?;
    let _provider = init_application_insights(instrumentation_key)?;
    
    // 运行应用
    run_application().await?;
    
    // 优雅关闭
    global::shutdown_tracer_provider();
    
    Ok(())
}

#[tracing::instrument]
async fn run_application() -> Result<(), Box<dyn std::error::Error>> {
    tracing::info!("Application started on Azure");
    // 业务逻辑
    Ok(())
}
```

---

### 1.2 Azure Monitor

```rust
use azure_core::auth::TokenCredential;
use azure_identity::DefaultAzureCredential;

pub struct AzureMonitorClient {
    credential: DefaultAzureCredential,
    workspace_id: String,
}

impl AzureMonitorClient {
    pub fn new(workspace_id: impl Into<String>) -> Self {
        Self {
            credential: DefaultAzureCredential::default(),
            workspace_id: workspace_id.into(),
        }
    }
    
    pub async fn send_custom_metric(
        &self,
        metric_name: &str,
        value: f64,
        dimensions: Vec<(String, String)>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // 发送自定义指标到 Azure Monitor
        tracing::info!(
            metric = metric_name,
            value = value,
            "Sending metric to Azure Monitor"
        );
        
        // 实际发送逻辑
        // ...
        
        Ok(())
    }
}

// 使用示例
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = AzureMonitorClient::new("your-workspace-id");
    
    client
        .send_custom_metric(
            "request_duration",
            123.45,
            vec![
                ("endpoint".to_string(), "/api/users".to_string()),
                ("method".to_string(), "GET".to_string()),
            ],
        )
        .await?;
    
    Ok(())
}
```

---

### 1.3 AKS 部署

`azure-pipelines.yml`:

```yaml
trigger:
  branches:
    include:
      - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  imageName: 'rust-otlp-app'
  registryName: 'myregistry.azurecr.io'

stages:
  - stage: Build
    jobs:
      - job: BuildAndPush
        steps:
          - task: Docker@2
            inputs:
              command: buildAndPush
              repository: $(imageName)
              dockerfile: Dockerfile
              containerRegistry: $(registryName)
              tags: |
                $(Build.BuildId)
                latest

  - stage: Deploy
    dependsOn: Build
    jobs:
      - deployment: DeployToAKS
        environment: 'production'
        strategy:
          runOnce:
            deploy:
              steps:
                - task: KubernetesManifest@0
                  inputs:
                    action: deploy
                    manifests: |
                      k8s/deployment.yaml
                      k8s/service.yaml
```

`k8s/deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rust-app
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rust-app
  template:
    metadata:
      labels:
        app: rust-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      containers:
        - name: app
          image: myregistry.azurecr.io/rust-otlp-app:latest
          ports:
            - containerPort: 8080
          env:
            - name: APPLICATIONINSIGHTS_CONNECTION_STRING
              valueFrom:
                secretKeyRef:
                  name: app-insights
                  key: connection-string
            - name: OTEL_SERVICE_NAME
              value: "rust-app"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: "service.namespace=production"
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
```

---

## 2. GCP 集成

### 2.1 Cloud Trace

**Cargo.toml**:

```toml
[dependencies]
opentelemetry = "0.31.0"
opentelemetry_sdk = { version = "0.31.0", features = ["rt-tokio"] }
opentelemetry-stackdriver = "0.21"
gcp_auth = "0.12"
```

**配置 Cloud Trace**:

```rust
use opentelemetry::global;
use opentelemetry_stackdriver::StackdriverPropagator;
use opentelemetry_sdk::{Resource, trace::TracerProvider};

pub async fn init_cloud_trace(
    project_id: impl Into<String>,
) -> Result<TracerProvider, Box<dyn std::error::Error>> {
    // 1. 创建资源
    let resource = Resource::new(vec![
        opentelemetry::KeyValue::new("service.name", "rust-gcp-app"),
        opentelemetry::KeyValue::new("service.version", env!("CARGO_PKG_VERSION")),
        opentelemetry::KeyValue::new("cloud.provider", "gcp"),
        opentelemetry::KeyValue::new("cloud.platform", "gcp_kubernetes_engine"),
    ]);
    
    // 2. 创建 Stackdriver Exporter
    let exporter = opentelemetry_stackdriver::StackdriverExporter::builder()
        .project_id(project_id.into())
        .build()
        .await?;
    
    // 3. 构建 TracerProvider
    let tracer_provider = TracerProvider::builder()
        .with_simple_exporter(exporter)
        .with_config(
            opentelemetry_sdk::trace::config()
                .with_resource(resource)
        )
        .build();
    
    // 4. 设置 Stackdriver 传播器
    global::set_text_map_propagator(StackdriverPropagator::default());
    global::set_tracer_provider(tracer_provider.clone());
    
    Ok(tracer_provider)
}

// 使用示例
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let project_id = std::env::var("GCP_PROJECT_ID")?;
    let _provider = init_cloud_trace(project_id).await?;
    
    // 运行应用
    run_application().await?;
    
    // 优雅关闭
    global::shutdown_tracer_provider();
    
    Ok(())
}

#[tracing::instrument]
async fn run_application() -> Result<(), Box<dyn std::error::Error>> {
    tracing::info!("Application started on GCP");
    // 业务逻辑
    Ok(())
}
```

---

### 2.2 Cloud Logging

```rust
use google_cloud_logging_v2::LoggingServiceClient;
use tonic::transport::Channel;

pub struct CloudLoggingClient {
    client: LoggingServiceClient<Channel>,
    project_id: String,
}

impl CloudLoggingClient {
    pub async fn new(project_id: impl Into<String>) -> Result<Self, Box<dyn std::error::Error>> {
        let channel = Channel::from_static("https://logging.googleapis.com")
            .connect()
            .await?;
        
        let client = LoggingServiceClient::new(channel);
        
        Ok(Self {
            client,
            project_id: project_id.into(),
        })
    }
    
    pub async fn write_log(
        &mut self,
        log_name: &str,
        severity: &str,
        message: &str,
    ) -> Result<(), Box<dyn std::error::Error>> {
        use google_cloud_logging_v2::{LogEntry, WriteLogEntriesRequest};
        
        let log_entry = LogEntry {
            log_name: format!(
                "projects/{}/logs/{}",
                self.project_id,
                log_name
            ),
            severity: severity.to_string(),
            text_payload: Some(message.to_string()),
            ..Default::default()
        };
        
        let request = WriteLogEntriesRequest {
            log_name: log_entry.log_name.clone(),
            entries: vec![log_entry],
            ..Default::default()
        };
        
        self.client.write_log_entries(request).await?;
        
        Ok(())
    }
}
```

---

### 2.3 GKE 部署

`cloudbuild.yaml`:

```yaml
steps:
  # Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/rust-otlp-app:$SHORT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/rust-otlp-app:latest'
      - '.'

  # Push to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - 'gcr.io/$PROJECT_ID/rust-otlp-app'

  # Deploy to GKE
  - name: 'gcr.io/cloud-builders/kubectl'
    args:
      - 'set'
      - 'image'
      - 'deployment/rust-app'
      - 'rust-app=gcr.io/$PROJECT_ID/rust-otlp-app:$SHORT_SHA'
    env:
      - 'CLOUDSDK_COMPUTE_ZONE=us-central1-a'
      - 'CLOUDSDK_CONTAINER_CLUSTER=production-cluster'

images:
  - 'gcr.io/$PROJECT_ID/rust-otlp-app:$SHORT_SHA'
  - 'gcr.io/$PROJECT_ID/rust-otlp-app:latest'
```

`k8s/deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rust-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rust-app
  template:
    metadata:
      labels:
        app: rust-app
    spec:
      serviceAccountName: rust-app-sa
      containers:
        - name: rust-app
          image: gcr.io/PROJECT_ID/rust-otlp-app:latest
          ports:
            - containerPort: 8080
          env:
            - name: GCP_PROJECT_ID
              value: "your-project-id"
            - name: OTEL_SERVICE_NAME
              value: "rust-app"
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
```

---

## 3. 多云策略

### 3.1 统一配置

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CloudProvider {
    AWS,
    Azure,
    GCP,
    OnPremise,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TelemetryConfig {
    pub cloud_provider: CloudProvider,
    pub service_name: String,
    pub service_version: String,
    pub exporter_endpoint: String,
    pub sampling_rate: f64,
}

impl TelemetryConfig {
    pub fn from_env() -> Result<Self, Box<dyn std::error::Error>> {
        let provider = std::env::var("CLOUD_PROVIDER")
            .unwrap_or_else(|_| "on-premise".to_string());
        
        let cloud_provider = match provider.to_lowercase().as_str() {
            "aws" => CloudProvider::AWS,
            "azure" => CloudProvider::Azure,
            "gcp" => CloudProvider::GCP,
            _ => CloudProvider::OnPremise,
        };
        
        Ok(Self {
            cloud_provider,
            service_name: std::env::var("SERVICE_NAME")?,
            service_version: std::env::var("SERVICE_VERSION")?,
            exporter_endpoint: std::env::var("OTEL_EXPORTER_OTLP_ENDPOINT")?,
            sampling_rate: std::env::var("OTEL_SAMPLING_RATE")
                .unwrap_or_else(|_| "1.0".to_string())
                .parse()?,
        })
    }
}
```

---

### 3.2 云平台抽象

```rust
use async_trait::async_trait;

#[async_trait]
pub trait CloudTelemetryProvider: Send + Sync {
    async fn init(&self) -> Result<(), Box<dyn std::error::Error>>;
    async fn shutdown(&self) -> Result<(), Box<dyn std::error::Error>>;
    fn provider_name(&self) -> &str;
}

pub struct AWSTelemetryProvider {
    config: TelemetryConfig,
}

#[async_trait]
impl CloudTelemetryProvider for AWSTelemetryProvider {
    async fn init(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Initializing AWS telemetry");
        // AWS-specific initialization
        Ok(())
    }
    
    async fn shutdown(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Shutting down AWS telemetry");
        Ok(())
    }
    
    fn provider_name(&self) -> &str {
        "AWS"
    }
}

pub struct AzureTelemetryProvider {
    config: TelemetryConfig,
}

#[async_trait]
impl CloudTelemetryProvider for AzureTelemetryProvider {
    async fn init(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Initializing Azure telemetry");
        // Azure-specific initialization
        Ok(())
    }
    
    async fn shutdown(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Shutting down Azure telemetry");
        Ok(())
    }
    
    fn provider_name(&self) -> &str {
        "Azure"
    }
}

pub struct GCPTelemetryProvider {
    config: TelemetryConfig,
}

#[async_trait]
impl CloudTelemetryProvider for GCPTelemetryProvider {
    async fn init(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Initializing GCP telemetry");
        // GCP-specific initialization
        Ok(())
    }
    
    async fn shutdown(&self) -> Result<(), Box<dyn std::error::Error>> {
        tracing::info!("Shutting down GCP telemetry");
        Ok(())
    }
    
    fn provider_name(&self) -> &str {
        "GCP"
    }
}

pub fn create_provider(config: TelemetryConfig) -> Box<dyn CloudTelemetryProvider> {
    match config.cloud_provider {
        CloudProvider::AWS => Box::new(AWSTelemetryProvider { config }),
        CloudProvider::Azure => Box::new(AzureTelemetryProvider { config }),
        CloudProvider::GCP => Box::new(GCPTelemetryProvider { config }),
        CloudProvider::OnPremise => Box::new(AWSTelemetryProvider { config }),
    }
}
```

---

### 3.3 环境检测

```rust
pub fn detect_cloud_environment() -> CloudProvider {
    // 1. 检查环境变量
    if let Ok(provider) = std::env::var("CLOUD_PROVIDER") {
        return match provider.to_lowercase().as_str() {
            "aws" => CloudProvider::AWS,
            "azure" => CloudProvider::Azure,
            "gcp" => CloudProvider::GCP,
            _ => CloudProvider::OnPremise,
        };
    }
    
    // 2. 检查 AWS 元数据服务
    if is_aws_environment() {
        return CloudProvider::AWS;
    }
    
    // 3. 检查 Azure 元数据服务
    if is_azure_environment() {
        return CloudProvider::Azure;
    }
    
    // 4. 检查 GCP 元数据服务
    if is_gcp_environment() {
        return CloudProvider::GCP;
    }
    
    CloudProvider::OnPremise
}

fn is_aws_environment() -> bool {
    std::env::var("AWS_EXECUTION_ENV").is_ok()
        || std::env::var("AWS_LAMBDA_FUNCTION_NAME").is_ok()
        || std::path::Path::new("/proc/sys/kernel/random/boot_id").exists()
}

fn is_azure_environment() -> bool {
    std::env::var("AZURE_FUNCTIONS_ENVIRONMENT").is_ok()
        || std::env::var("WEBSITE_INSTANCE_ID").is_ok()
}

fn is_gcp_environment() -> bool {
    std::env::var("K_SERVICE").is_ok()
        || std::env::var("FUNCTION_NAME").is_ok()
        || std::env::var("GCP_PROJECT").is_ok()
}
```

---

## 4. 完整示例

多云统一初始化：

```rust
use opentelemetry::global;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. 检测云环境
    let cloud_provider = detect_cloud_environment();
    tracing::info!("Detected cloud provider: {:?}", cloud_provider);
    
    // 2. 加载配置
    let config = TelemetryConfig::from_env()?;
    
    // 3. 创建并初始化 provider
    let provider = create_provider(config);
    provider.init().await?;
    
    // 4. 运行应用
    run_application().await?;
    
    // 5. 优雅关闭
    provider.shutdown().await?;
    global::shutdown_tracer_provider();
    
    Ok(())
}

#[tracing::instrument]
async fn run_application() -> Result<(), Box<dyn std::error::Error>> {
    tracing::info!("Application is running");
    // 业务逻辑
    Ok(())
}
```

---

## 总结

本指南提供了完整的多云平台集成方案：

1. ✅ **Azure 集成**
   - Application Insights
   - Azure Monitor
   - AKS 部署

2. ✅ **GCP 集成**
   - Cloud Trace
   - Cloud Logging
   - GKE 部署

3. ✅ **多云策略**
   - 统一配置
   - 云平台抽象
   - 自动环境检测

4. ✅ **最佳实践**
   - 配置管理
   - 错误处理
   - 优雅关闭

通过这些配置，您可以在多云环境中运行统一的 Rust OTLP 应用。

---

**文档版本**: 1.0.0  
**最后更新**: 2025-10-08  
**维护者**: OTLP Rust Team  
**许可证**: MIT OR Apache-2.0
