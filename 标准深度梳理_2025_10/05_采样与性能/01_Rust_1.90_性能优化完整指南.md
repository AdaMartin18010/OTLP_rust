# Rust 1.90 OTLP æ€§èƒ½ä¼˜åŒ–å®Œæ•´æŒ‡å—

> **Rustç‰ˆæœ¬**: 1.90+  
> **OpenTelemetry**: 0.31.0  
> **Tokio**: 1.47.1  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥

---

## ç›®å½•

- [Rust 1.90 OTLP æ€§èƒ½ä¼˜åŒ–å®Œæ•´æŒ‡å—](#rust-190-otlp-æ€§èƒ½ä¼˜åŒ–å®Œæ•´æŒ‡å—)
  - [ç›®å½•](#ç›®å½•)
  - [1. æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°](#1-æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°)
  - [2. é›¶æ‹·è´æŠ€æœ¯](#2-é›¶æ‹·è´æŠ€æœ¯)
  - [3. æ‰¹å¤„ç†ä¼˜åŒ–](#3-æ‰¹å¤„ç†ä¼˜åŒ–)
  - [4. é‡‡æ ·ç­–ç•¥](#4-é‡‡æ ·ç­–ç•¥)
  - [5. å†…å­˜ä¼˜åŒ–](#5-å†…å­˜ä¼˜åŒ–)
  - [6. CPU ä¼˜åŒ–](#6-cpu-ä¼˜åŒ–)
  - [7. ç½‘ç»œä¼˜åŒ–](#7-ç½‘ç»œä¼˜åŒ–)
  - [8. å¹¶å‘ä¼˜åŒ–](#8-å¹¶å‘ä¼˜åŒ–)
  - [9. ç¼–è¯‘ä¼˜åŒ–](#9-ç¼–è¯‘ä¼˜åŒ–)
  - [10. æ€§èƒ½åŸºå‡†æµ‹è¯•](#10-æ€§èƒ½åŸºå‡†æµ‹è¯•)
  - [11. æ€§èƒ½ç›‘æ§](#11-æ€§èƒ½ç›‘æ§)
  - [12. å®æˆ˜ä¼˜åŒ–æ¡ˆä¾‹](#12-å®æˆ˜ä¼˜åŒ–æ¡ˆä¾‹)
  - [13. æœ€ä½³å®è·µ](#13-æœ€ä½³å®è·µ)
  - [14. å‚è€ƒèµ„æº](#14-å‚è€ƒèµ„æº)

---

## 1. æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°

**æ€§èƒ½ç›®æ ‡**:

```text
OTLP æ€§èƒ½æŒ‡æ ‡:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æŒ‡æ ‡           â”‚ ç›®æ ‡       â”‚ ä¼˜åŒ–å       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Span åˆ›å»ºå»¶è¿Ÿ  â”‚ < 1Î¼s      â”‚ < 0.5Î¼s      â”‚
â”‚ æ‰¹å¤„ç†ååé‡   â”‚ 10K/s      â”‚ 100K/s       â”‚
â”‚ å†…å­˜å ç”¨       â”‚ < 100MB    â”‚ < 50MB       â”‚
â”‚ CPU ä½¿ç”¨ç‡     â”‚ < 5%       â”‚ < 2%         â”‚
â”‚ ç½‘ç»œå¸¦å®½       â”‚ < 10MB/s   â”‚ < 5MB/s      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¼˜åŒ–åŸåˆ™:
1. æµ‹é‡ä¼˜å…ˆ - å…ˆæµ‹é‡å†ä¼˜åŒ–
2. ç“¶é¢ˆè¯†åˆ« - æ‰¾åˆ°çœŸæ­£çš„ç“¶é¢ˆ
3. é€æ­¥ä¼˜åŒ– - ä¸€æ¬¡ä¼˜åŒ–ä¸€ä¸ªç‚¹
4. éªŒè¯æ•ˆæœ - ç¡®è®¤ä¼˜åŒ–æœ‰æ•ˆ
5. æƒè¡¡å–èˆ - å¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦
```

**æ€§èƒ½åˆ†æå·¥å…·**:

```bash
# CPU æ€§èƒ½åˆ†æ
cargo flamegraph --bin my-app

# å†…å­˜åˆ†æ
cargo valgrind --bin my-app

# åŸºå‡†æµ‹è¯•
cargo bench

# æ€§èƒ½ç›‘æ§
tokio-console
```

---

## 2. é›¶æ‹·è´æŠ€æœ¯

**ä½¿ç”¨ Bytes å®ç°é›¶æ‹·è´**:

```rust
use bytes::{Bytes, BytesMut};
use std::sync::Arc;

/// é›¶æ‹·è´ Span æ•°æ®
#[derive(Clone)]
pub struct ZeroCopySpan {
    trace_id: Bytes,
    span_id: Bytes,
    name: Bytes,
    attributes: Arc<Vec<(Bytes, Bytes)>>,
}

impl ZeroCopySpan {
    /// åˆ›å»ºé›¶æ‹·è´ Span
    pub fn new(
        trace_id: &[u8],
        span_id: &[u8],
        name: &str,
    ) -> Self {
        Self {
            trace_id: Bytes::copy_from_slice(trace_id),
            span_id: Bytes::copy_from_slice(span_id),
            name: Bytes::copy_from_slice(name.as_bytes()),
            attributes: Arc::new(Vec::new()),
        }
    }
    
    /// é›¶æˆæœ¬å…‹éš† (åªå¢åŠ å¼•ç”¨è®¡æ•°)
    pub fn cheap_clone(&self) -> Self {
        Self {
            trace_id: self.trace_id.clone(),  // åªå¢åŠ å¼•ç”¨è®¡æ•°
            span_id: self.span_id.clone(),
            name: self.name.clone(),
            attributes: Arc::clone(&self.attributes),
        }
    }
    
    /// é«˜æ•ˆåºåˆ—åŒ–
    pub fn serialize_to_bytes(&self) -> Bytes {
        let mut buf = BytesMut::with_capacity(
            self.trace_id.len() + self.span_id.len() + self.name.len() + 100
        );
        
        // ç›´æ¥å†™å…¥å·²åˆ†é…çš„ç¼“å†²åŒº
        buf.extend_from_slice(&self.trace_id);
        buf.extend_from_slice(&self.span_id);
        buf.extend_from_slice(&self.name);
        
        buf.freeze()  // è½¬æ¢ä¸ºä¸å¯å˜ Bytes (é›¶æ‹·è´)
    }
}

/// æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹
mod performance_comparison {
    use super::*;
    
    // ä¼ ç»Ÿæ–¹å¼ (ä¼šå¤åˆ¶æ•°æ®)
    pub fn traditional_clone(span: &str, times: usize) {
        let data = span.to_string();
        for _ in 0..times {
            let _cloned = data.clone();  // æ¯æ¬¡éƒ½å¤åˆ¶æ•´ä¸ªå­—ç¬¦ä¸²
        }
    }
    
    // é›¶æ‹·è´æ–¹å¼
    pub fn zero_copy_clone(span: Bytes, times: usize) {
        for _ in 0..times {
            let _cloned = span.clone();  // åªå¢åŠ å¼•ç”¨è®¡æ•°
        }
    }
}

/// åŸºå‡†æµ‹è¯•
#[cfg(test)]
mod benches {
    use super::*;
    use criterion::{black_box, Criterion};
    
    pub fn benchmark_clone(c: &mut Criterion) {
        let data = "a".repeat(1000);
        let bytes_data = Bytes::from(data.clone());
        
        c.bench_function("traditional_clone", |b| {
            b.iter(|| {
                performance_comparison::traditional_clone(black_box(&data), 1000)
            })
        });
        
        c.bench_function("zero_copy_clone", |b| {
            b.iter(|| {
                performance_comparison::zero_copy_clone(black_box(bytes_data.clone()), 1000)
            })
        });
    }
}
```

---

## 3. æ‰¹å¤„ç†ä¼˜åŒ–

**é«˜æ•ˆæ‰¹å¤„ç†å®ç°**:

```rust
use tokio::time::{Duration, Instant};

/// ä¼˜åŒ–çš„æ‰¹å¤„ç†å™¨
pub struct OptimizedBatchProcessor<T> {
    max_size: usize,
    max_wait: Duration,
    buffer: Vec<T>,
    last_flush: Instant,
}

impl<T> OptimizedBatchProcessor<T> {
    pub fn new(max_size: usize, max_wait: Duration) -> Self {
        Self {
            max_size,
            max_wait,
            buffer: Vec::with_capacity(max_size),
            last_flush: Instant::now(),
        }
    }
    
    /// æ·»åŠ é¡¹ç›® (ä½¿ç”¨é¢„åˆ†é…é¿å…é¢‘ç¹åˆ†é…)
    pub fn add(&mut self, item: T) -> Option<Vec<T>> {
        self.buffer.push(item);
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if self.buffer.len() >= self.max_size 
            || self.last_flush.elapsed() >= self.max_wait {
            self.flush()
        } else {
            None
        }
    }
    
    /// åˆ·æ–°ç¼“å†²åŒº
    pub fn flush(&mut self) -> Option<Vec<T>> {
        if self.buffer.is_empty() {
            return None;
        }
        
        // ä½¿ç”¨ mem::take é¿å…é¢å¤–åˆ†é…
        let batch = std::mem::take(&mut self.buffer);
        self.buffer = Vec::with_capacity(self.max_size);
        self.last_flush = Instant::now();
        
        Some(batch)
    }
}

/// è‡ªé€‚åº”æ‰¹å¤„ç†
pub struct AdaptiveBatchProcessor<T> {
    current_size: usize,
    min_size: usize,
    max_size: usize,
    buffer: Vec<T>,
    metrics: BatchMetrics,
}

#[derive(Default)]
struct BatchMetrics {
    avg_latency: f64,
    throughput: f64,
}

impl<T> AdaptiveBatchProcessor<T> {
    /// æ ¹æ®æ€§èƒ½æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´æ‰¹å¤„ç†å¤§å°
    pub fn adjust_batch_size(&mut self) {
        // å¦‚æœå»¶è¿Ÿå¤ªé«˜ï¼Œå‡å°æ‰¹å¤„ç†
        if self.metrics.avg_latency > 100.0 {
            self.current_size = (self.current_size * 90 / 100).max(self.min_size);
        }
        // å¦‚æœååé‡è¿˜æœ‰ä½™é‡ï¼Œå¢å¤§æ‰¹å¤„ç†
        else if self.metrics.throughput < 0.8 {
            self.current_size = (self.current_size * 110 / 100).min(self.max_size);
        }
        
        tracing::debug!(
            current_size = self.current_size,
            avg_latency = self.metrics.avg_latency,
            throughput = self.metrics.throughput,
            "Adjusted batch size"
        );
    }
}
```

---

## 4. é‡‡æ ·ç­–ç•¥

**æ™ºèƒ½é‡‡æ ·å®ç°**:

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use std::collections::HashMap;

/// é‡‡æ ·å™¨ Trait
pub trait Sampler: Send + Sync {
    fn should_sample(&self, trace_id: &[u8], span_name: &str) -> bool;
}

/// æ¦‚ç‡é‡‡æ ·å™¨
pub struct ProbabilitySampler {
    rate: f64,
    counter: AtomicU64,
}

impl ProbabilitySampler {
    pub fn new(rate: f64) -> Self {
        assert!(rate >= 0.0 && rate <= 1.0);
        Self {
            rate,
            counter: AtomicU64::new(0),
        }
    }
}

impl Sampler for ProbabilitySampler {
    fn should_sample(&self, _trace_id: &[u8], _span_name: &str) -> bool {
        let count = self.counter.fetch_add(1, Ordering::Relaxed);
        (count as f64 * self.rate) % 1.0 < self.rate
    }
}

/// é€Ÿç‡é™åˆ¶é‡‡æ ·å™¨
pub struct RateLimitingSampler {
    max_per_second: u64,
    window_start: AtomicU64,
    current_count: AtomicU64,
}

impl RateLimitingSampler {
    pub fn new(max_per_second: u64) -> Self {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        Self {
            max_per_second,
            window_start: AtomicU64::new(now),
            current_count: AtomicU64::new(0),
        }
    }
}

impl Sampler for RateLimitingSampler {
    fn should_sample(&self, _trace_id: &[u8], _span_name: &str) -> bool {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        let window_start = self.window_start.load(Ordering::Relaxed);
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®çª—å£
        if now > window_start {
            self.window_start.store(now, Ordering::Relaxed);
            self.current_count.store(0, Ordering::Relaxed);
        }
        
        // æ£€æŸ¥æ˜¯å¦åœ¨é€Ÿç‡é™åˆ¶å†…
        let count = self.current_count.fetch_add(1, Ordering::Relaxed);
        count < self.max_per_second
    }
}

/// ä¼˜å…ˆçº§é‡‡æ ·å™¨ (é”™è¯¯å’Œæ…¢è¯·æ±‚ä¼˜å…ˆ)
pub struct PrioritySampler {
    base_rate: f64,
    error_rate: f64,
    slow_threshold_ms: u64,
}

impl PrioritySampler {
    pub fn new(base_rate: f64, error_rate: f64, slow_threshold_ms: u64) -> Self {
        Self {
            base_rate,
            error_rate,
            slow_threshold_ms,
        }
    }
    
    pub fn should_sample_with_context(
        &self,
        is_error: bool,
        duration_ms: u64,
    ) -> bool {
        // é”™è¯¯æ€»æ˜¯é«˜é‡‡æ ·ç‡
        if is_error {
            return rand::random::<f64>() < self.error_rate;
        }
        
        // æ…¢è¯·æ±‚ä¹Ÿé«˜é‡‡æ ·ç‡
        if duration_ms > self.slow_threshold_ms {
            return rand::random::<f64>() < self.error_rate;
        }
        
        // æ­£å¸¸è¯·æ±‚ä½¿ç”¨åŸºç¡€é‡‡æ ·ç‡
        rand::random::<f64>() < self.base_rate
    }
}
```

---

## 5. å†…å­˜ä¼˜åŒ–

**å†…å­˜æ± å’Œå¯¹è±¡å¤ç”¨**:

```rust
use std::sync::Arc;
use tokio::sync::Mutex;

/// å¯¹è±¡æ± 
pub struct ObjectPool<T> {
    pool: Arc<Mutex<Vec<T>>>,
    factory: Arc<dyn Fn() -> T + Send + Sync>,
    max_size: usize,
}

impl<T: Send> ObjectPool<T> {
    pub fn new<F>(factory: F, max_size: usize) -> Self
    where
        F: Fn() -> T + Send + Sync + 'static,
    {
        Self {
            pool: Arc::new(Mutex::new(Vec::with_capacity(max_size))),
            factory: Arc::new(factory),
            max_size,
        }
    }
    
    /// è·å–å¯¹è±¡
    pub async fn acquire(&self) -> PooledObject<T> {
        let mut pool = self.pool.lock().await;
        
        let obj = pool.pop().unwrap_or_else(|| (self.factory)());
        
        PooledObject {
            obj: Some(obj),
            pool: Arc::clone(&self.pool),
        }
    }
}

/// æ± åŒ–å¯¹è±¡ (Drop æ—¶è‡ªåŠ¨å½’è¿˜)
pub struct PooledObject<T> {
    obj: Option<T>,
    pool: Arc<Mutex<Vec<T>>>,
}

impl<T> PooledObject<T> {
    pub fn get_mut(&mut self) -> &mut T {
        self.obj.as_mut().unwrap()
    }
}

impl<T> Drop for PooledObject<T> {
    fn drop(&mut self) {
        if let Some(obj) = self.obj.take() {
            let pool = Arc::clone(&self.pool);
            tokio::spawn(async move {
                let mut pool = pool.lock().await;
                pool.push(obj);
            });
        }
    }
}

/// Span æ•°æ®å¯¹è±¡æ± 
pub type SpanPool = ObjectPool<Vec<u8>>;

pub fn create_span_pool() -> SpanPool {
    ObjectPool::new(
        || Vec::with_capacity(1024),  // é¢„åˆ†é… 1KB
        1000,  // æ± å¤§å°
    )
}
```

---

## 6. CPU ä¼˜åŒ–

**CPU å¯†é›†å‹ä¼˜åŒ–**:

```rust
/// SIMD ä¼˜åŒ– (å¦‚æœé€‚ç”¨)
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

/// å†…è”ä¼˜åŒ–
#[inline(always)]
pub fn fast_hash(data: &[u8]) -> u64 {
    // ä½¿ç”¨å¿«é€Ÿå“ˆå¸Œç®—æ³•
    let mut hash = 0u64;
    for &byte in data {
        hash = hash.wrapping_mul(31).wrapping_add(byte as u64);
    }
    hash
}

/// é¿å…åˆ†æ”¯é¢„æµ‹å¤±è´¥
#[inline]
pub fn branchless_min(a: u64, b: u64) -> u64 {
    a ^ ((a ^ b) & -(((a < b) as i64) as u64))
}

/// å¾ªç¯å±•å¼€
#[inline]
pub fn sum_optimized(data: &[u64]) -> u64 {
    let mut sum = 0u64;
    let mut i = 0;
    
    // 4-way å±•å¼€
    while i + 4 <= data.len() {
        sum += data[i];
        sum += data[i + 1];
        sum += data[i + 2];
        sum += data[i + 3];
        i += 4;
    }
    
    // å¤„ç†å‰©ä½™å…ƒç´ 
    while i < data.len() {
        sum += data[i];
        i += 1;
    }
    
    sum
}
```

---

## 7. ç½‘ç»œä¼˜åŒ–

**ç½‘ç»œä¼ è¾“ä¼˜åŒ–**:

```rust
/// å‹ç¼©é…ç½®
pub enum CompressionLevel {
    None,
    Fast,      // Gzip level 1
    Balanced,  // Gzip level 6
    Best,      // Gzip level 9
}

/// ä¼˜åŒ–çš„ç½‘ç»œå¯¼å‡ºå™¨
pub struct OptimizedNetworkExporter {
    compression: CompressionLevel,
    max_retries: u32,
    timeout: Duration,
}

impl OptimizedNetworkExporter {
    /// å‹ç¼©æ•°æ®
    pub fn compress(&self, data: &[u8]) -> Result<Vec<u8>, std::io::Error> {
        use flate2::write::GzEncoder;
        use flate2::Compression;
        use std::io::Write;
        
        let level = match self.compression {
            CompressionLevel::None => return Ok(data.to_vec()),
            CompressionLevel::Fast => Compression::fast(),
            CompressionLevel::Balanced => Compression::default(),
            CompressionLevel::Best => Compression::best(),
        };
        
        let mut encoder = GzEncoder::new(Vec::new(), level);
        encoder.write_all(data)?;
        encoder.finish()
    }
    
    /// æ‰¹é‡å¯¼å‡º (HTTP/2 å¤šè·¯å¤ç”¨)
    pub async fn batch_export_http2(
        &self,
        batches: Vec<Vec<u8>>,
    ) -> Result<(), anyhow::Error> {
        // ä½¿ç”¨ HTTP/2 å¹¶å‘å‘é€å¤šä¸ªæ‰¹æ¬¡
        let futures: Vec<_> = batches
            .into_iter()
            .map(|batch| self.send_batch(batch))
            .collect();
        
        futures::future::try_join_all(futures).await?;
        
        Ok(())
    }
    
    async fn send_batch(&self, batch: Vec<u8>) -> Result<(), anyhow::Error> {
        // å®ç°æ‰¹é‡å‘é€
        Ok(())
    }
}
```

---

## 8. å¹¶å‘ä¼˜åŒ–

**é«˜æ•ˆå¹¶å‘å¤„ç†**:

```rust
/// å¹¶å‘é™åˆ¶å™¨
pub struct ConcurrencyLimiter {
    semaphore: Arc<tokio::sync::Semaphore>,
}

impl ConcurrencyLimiter {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(tokio::sync::Semaphore::new(max_concurrent)),
        }
    }
    
    /// é™æµæ‰§è¡Œ
    pub async fn execute<F, T>(&self, f: F) -> Result<T, anyhow::Error>
    where
        F: std::future::Future<Output = Result<T, anyhow::Error>>,
    {
        let _permit = self.semaphore.acquire().await?;
        f.await
    }
}

/// å·¥ä½œçªƒå–è°ƒåº¦
pub struct WorkStealingScheduler<T> {
    queues: Vec<Arc<tokio::sync::Mutex<Vec<T>>>>,
    workers: usize,
}

impl<T: Send + 'static> WorkStealingScheduler<T> {
    pub fn new(workers: usize) -> Self {
        let queues = (0..workers)
            .map(|_| Arc::new(tokio::sync::Mutex::new(Vec::new())))
            .collect();
        
        Self { queues, workers }
    }
    
    /// æäº¤ä»»åŠ¡
    pub async fn submit(&self, task: T) {
        // è½®è¯¢åˆ†é…åˆ°é˜Ÿåˆ—
        let idx = rand::random::<usize>() % self.workers;
        let mut queue = self.queues[idx].lock().await;
        queue.push(task);
    }
}
```

---

## 9. ç¼–è¯‘ä¼˜åŒ–

**Cargo.toml ä¼˜åŒ–é…ç½®**:

```toml
[profile.release]
# LTO (Link Time Optimization)
lto = "fat"              # å®Œæ•´ LTO (æœ€ä½³æ€§èƒ½)
# lto = "thin"           # è½»é‡ LTO (å¹³è¡¡ç¼–è¯‘æ—¶é—´å’Œæ€§èƒ½)

# ä»£ç ç”Ÿæˆå•å…ƒ
codegen-units = 1        # æœ€ä½³æ€§èƒ½ (ç¼–è¯‘æ…¢)
# codegen-units = 16     # é»˜è®¤ (ç¼–è¯‘å¿«)

# ä¼˜åŒ–çº§åˆ«
opt-level = 3            # æœ€é«˜ä¼˜åŒ–
# opt-level = "z"        # ä¼˜åŒ–äºŒè¿›åˆ¶å¤§å°

# ç¬¦å·å‰¥ç¦»
strip = "symbols"        # å‰¥ç¦»ç¬¦å· (å‡å°äºŒè¿›åˆ¶å¤§å°)

# Panic ç­–ç•¥
panic = "abort"          # ä½¿ç”¨ abort (æ›´å°çš„äºŒè¿›åˆ¶)

# ç›®æ ‡ CPU
[build]
rustflags = [
    "-C", "target-cpu=native",  # ä½¿ç”¨æœ¬æœº CPU ç‰¹æ€§
]

# PGO (Profile-Guided Optimization)
[profile.release-pgo]
inherits = "release"
```

**PGO ä¼˜åŒ–æ­¥éª¤**:

```bash
# 1. æ„å»º instrumented ç‰ˆæœ¬
RUSTFLAGS="-Cprofile-generate=/tmp/pgo-data" cargo build --release

# 2. è¿è¡Œåº”ç”¨ç”Ÿæˆ profile æ•°æ®
./target/release/my-app

# 3. ä½¿ç”¨ profile æ•°æ®ä¼˜åŒ–ç¼–è¯‘
RUSTFLAGS="-Cprofile-use=/tmp/pgo-data/merged.profdata" cargo build --release
```

---

## 10. æ€§èƒ½åŸºå‡†æµ‹è¯•

**ä½¿ç”¨ Criterion è¿›è¡ŒåŸºå‡†æµ‹è¯•**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn bench_span_creation(c: &mut Criterion) {
    let mut group = c.benchmark_group("span_creation");
    
    for size in [10, 100, 1000].iter() {
        group.bench_with_input(
            BenchmarkId::from_parameter(size),
            size,
            |b, &size| {
                b.iter(|| {
                    let spans: Vec<_> = (0..size)
                        .map(|i| create_span(black_box(i)))
                        .collect();
                    black_box(spans)
                });
            },
        );
    }
    
    group.finish();
}

fn create_span(id: usize) -> ZeroCopySpan {
    ZeroCopySpan::new(
        &[0u8; 16],
        &[0u8; 8],
        &format!("span-{}", id),
    )
}

criterion_group!(benches, bench_span_creation);
criterion_main!(benches);
```

---

## 11. æ€§èƒ½ç›‘æ§

**å®æ—¶æ€§èƒ½ç›‘æ§**:

```rust
use std::sync::atomic::{AtomicU64, Ordering};

pub struct PerformanceMonitor {
    spans_created: AtomicU64,
    spans_exported: AtomicU64,
    bytes_sent: AtomicU64,
    errors: AtomicU64,
}

impl PerformanceMonitor {
    pub fn record_span_created(&self) {
        self.spans_created.fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn report(&self) -> PerformanceReport {
        PerformanceReport {
            spans_created: self.spans_created.load(Ordering::Relaxed),
            spans_exported: self.spans_exported.load(Ordering::Relaxed),
            bytes_sent: self.bytes_sent.load(Ordering::Relaxed),
            errors: self.errors.load(Ordering::Relaxed),
        }
    }
}

#[derive(Debug)]
pub struct PerformanceReport {
    pub spans_created: u64,
    pub spans_exported: u64,
    pub bytes_sent: u64,
    pub errors: u64,
}
```

---

## 12. å®æˆ˜ä¼˜åŒ–æ¡ˆä¾‹

**å®Œæ•´ä¼˜åŒ–æµç¨‹**:

```rust
/// ä¼˜åŒ–å‰åå¯¹æ¯”
pub mod optimization_case_study {
    // ä¼˜åŒ–å‰: æ¯æ¬¡éƒ½åˆ†é…å’Œå¤åˆ¶
    pub fn before_optimization() {
        let data = vec![1, 2, 3, 4, 5];
        for _ in 0..1000 {
            let _copy = data.clone();  // æ¯æ¬¡éƒ½å¤åˆ¶
        }
    }
    
    // ä¼˜åŒ–å: ä½¿ç”¨ Arc å…±äº«æ•°æ®
    pub fn after_optimization() {
        let data = std::sync::Arc::new(vec![1, 2, 3, 4, 5]);
        for _ in 0..1000 {
            let _ref = data.clone();  // åªå¢åŠ å¼•ç”¨è®¡æ•°
        }
    }
}
```

---

## 13. æœ€ä½³å®è·µ

```text
âœ… æµ‹é‡å’Œåˆ†æ
  â–¡ ä½¿ç”¨ criterion è¿›è¡ŒåŸºå‡†æµ‹è¯•
  â–¡ ä½¿ç”¨ flamegraph åˆ†æ CPU
  â–¡ ä½¿ç”¨ valgrind åˆ†æå†…å­˜
  â–¡ ä½¿ç”¨ tokio-console ç›‘æ§å¼‚æ­¥

âœ… å†…å­˜ä¼˜åŒ–
  â–¡ ä½¿ç”¨å¯¹è±¡æ± å¤ç”¨å¯¹è±¡
  â–¡ é¿å…ä¸å¿…è¦çš„å…‹éš†
  â–¡ ä½¿ç”¨ Bytes å®ç°é›¶æ‹·è´
  â–¡ åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡

âœ… CPU ä¼˜åŒ–
  â–¡ ä½¿ç”¨å†…è”ä¼˜åŒ–çƒ­ç‚¹å‡½æ•°
  â–¡ å‡å°‘åˆ†æ”¯é¢„æµ‹å¤±è´¥
  â–¡ ä½¿ç”¨ SIMD (å¦‚é€‚ç”¨)
  â–¡ å¾ªç¯å±•å¼€

âœ… ç½‘ç»œä¼˜åŒ–
  â–¡ å¯ç”¨å‹ç¼©
  â–¡ ä½¿ç”¨æ‰¹å¤„ç†
  â–¡ HTTP/2 å¤šè·¯å¤ç”¨
  â–¡ è¿æ¥å¤ç”¨

âœ… å¹¶å‘ä¼˜åŒ–
  â–¡ åˆç†è®¾ç½®å¹¶å‘æ•°
  â–¡ ä½¿ç”¨èƒŒå‹æ§åˆ¶
  â–¡ é¿å…é”ç«äº‰
  â–¡ ä½¿ç”¨æ— é”æ•°æ®ç»“æ„
```

---

## 14. å‚è€ƒèµ„æº

**å®˜æ–¹æ–‡æ¡£**:

- [Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [Tokio Performance](https://tokio.rs/tokio/topics/performance)
- [Criterion.rs](https://github.com/bheisler/criterion.rs)

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ (Rust 1.90)  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥  
**å®¡æ ¸çŠ¶æ€**: ç”Ÿäº§å°±ç»ª  
**è®¸å¯è¯**: MIT OR Apache-2.0

---

[ğŸ  è¿”å›ä¸»ç›®å½•](../README.md) | [ğŸ“– æŸ¥çœ‹å…¶ä»–ä¸»é¢˜](../README.md)
