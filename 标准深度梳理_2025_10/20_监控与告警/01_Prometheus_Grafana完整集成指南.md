# Prometheus & Grafana å®Œæ•´é›†æˆæŒ‡å— - Rust OTLP

> **Prometheus**: 3.1.0+  
> **Grafana**: 11.6.0+  
> **Rust**: 1.90+  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥

---

---

## 1. PrometheusæŒ‡æ ‡å¯¼å‡º

### 1.1 Rust Prometheusé›†æˆ

`Cargo.toml`:

```toml
[dependencies]
prometheus = { version = "0.13.4", features = ["process"] }
prometheus-hyper = "0.1.5"
hyper = { version = "1.7.0", features = ["full"] }
tokio = { version = "1.47.1", features = ["full"] }
```

### 1.2 æŒ‡æ ‡å®šä¹‰

`src/metrics.rs`:

```rust
use prometheus::{
    Registry, Counter, Histogram, Gauge, IntGauge, IntCounter,
    IntCounterVec, HistogramVec, GaugeVec, Opts, HistogramOpts,
};
use once_cell::sync::Lazy;

/// å…¨å±€Prometheus Registry
pub static REGISTRY: Lazy<Registry> = Lazy::new(|| {
    Registry::new()
});

/// Spanç›¸å…³æŒ‡æ ‡
pub mod spans {
    use super::*;
    
    /// Spanåˆ›å»ºæ€»æ•°
    pub static CREATED_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
        let counter = IntCounterVec::new(
            Opts::new("otlp_spans_created_total", "Total number of spans created")
                .namespace("otlp")
                .subsystem("spans"),
            &["service_name", "span_kind"],
        ).unwrap();
        REGISTRY.register(Box::new(counter.clone())).unwrap();
        counter
    });
    
    /// Spanå¯¼å‡ºæ€»æ•°
    pub static EXPORTED_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
        let counter = IntCounterVec::new(
            Opts::new("otlp_spans_exported_total", "Total number of spans exported")
                .namespace("otlp")
                .subsystem("spans"),
            &["exporter", "status"],
        ).unwrap();
        REGISTRY.register(Box::new(counter.clone())).unwrap();
        counter
    });
    
    /// Spanå¯¼å‡ºå¤±è´¥æ€»æ•°
    pub static EXPORT_ERRORS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
        let counter = IntCounterVec::new(
            Opts::new("otlp_spans_export_errors_total", "Total number of span export errors")
                .namespace("otlp")
                .subsystem("spans"),
            &["exporter", "error_type"],
        ).unwrap();
        REGISTRY.register(Box::new(counter.clone())).unwrap();
        counter
    });
    
    /// SpanæŒç»­æ—¶é—´åˆ†å¸ƒ
    pub static DURATION_SECONDS: Lazy<HistogramVec> = Lazy::new(|| {
        let histogram = HistogramVec::new(
            HistogramOpts::new("otlp_spans_duration_seconds", "Span duration in seconds")
                .namespace("otlp")
                .subsystem("spans")
                .buckets(vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]),
            &["service_name", "span_kind"],
        ).unwrap();
        REGISTRY.register(Box::new(histogram.clone())).unwrap();
        histogram
    });
}

/// å¯¼å‡ºå™¨ç›¸å…³æŒ‡æ ‡
pub mod exporter {
    use super::*;
    
    /// å¯¼å‡ºæ‰¹æ¬¡å¤§å°åˆ†å¸ƒ
    pub static BATCH_SIZE: Lazy<Histogram> = Lazy::new(|| {
        let histogram = Histogram::with_opts(
            HistogramOpts::new("otlp_exporter_batch_size", "Exporter batch size")
                .namespace("otlp")
                .subsystem("exporter")
                .buckets(vec![10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0]),
        ).unwrap();
        REGISTRY.register(Box::new(histogram.clone())).unwrap();
        histogram
    });
    
    /// å¯¼å‡ºå»¶è¿Ÿåˆ†å¸ƒ
    pub static EXPORT_LATENCY_SECONDS: Lazy<HistogramVec> = Lazy::new(|| {
        let histogram = HistogramVec::new(
            HistogramOpts::new("otlp_exporter_latency_seconds", "Exporter latency in seconds")
                .namespace("otlp")
                .subsystem("exporter")
                .buckets(vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0]),
            &["exporter", "protocol"],
        ).unwrap();
        REGISTRY.register(Box::new(histogram.clone())).unwrap();
        histogram
    });
    
    /// å½“å‰é˜Ÿåˆ—å¤§å°
    pub static QUEUE_SIZE: Lazy<IntGaugeVec> = Lazy::new(|| {
        let gauge = IntGaugeVec::new(
            Opts::new("otlp_exporter_queue_size", "Current queue size")
                .namespace("otlp")
                .subsystem("exporter"),
            &["exporter"],
        ).unwrap();
        REGISTRY.register(Box::new(gauge.clone())).unwrap();
        gauge
    });
}

/// ç³»ç»Ÿèµ„æºæŒ‡æ ‡
pub mod system {
    use super::*;
    
    /// CPUä½¿ç”¨ç‡
    pub static CPU_USAGE: Lazy<Gauge> = Lazy::new(|| {
        let gauge = Gauge::with_opts(
            Opts::new("otlp_system_cpu_usage_percent", "CPU usage percentage")
                .namespace("otlp")
                .subsystem("system"),
        ).unwrap();
        REGISTRY.register(Box::new(gauge.clone())).unwrap();
        gauge
    });
    
    /// å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
    pub static MEMORY_USAGE_BYTES: Lazy<IntGauge> = Lazy::new(|| {
        let gauge = IntGauge::with_opts(
            Opts::new("otlp_system_memory_usage_bytes", "Memory usage in bytes")
                .namespace("otlp")
                .subsystem("system"),
        ).unwrap();
        REGISTRY.register(Box::new(gauge.clone())).unwrap();
        gauge
    });
    
    /// Goroutine/Taskæ•°é‡
    pub static TASKS_COUNT: Lazy<IntGauge> = Lazy::new(|| {
        let gauge = IntGauge::with_opts(
            Opts::new("otlp_system_tasks_count", "Number of active tasks")
                .namespace("otlp")
                .subsystem("system"),
        ).unwrap();
        REGISTRY.register(Box::new(gauge.clone())).unwrap();
        gauge
    });
}

/// åˆå§‹åŒ–æ‰€æœ‰æŒ‡æ ‡
pub fn init_metrics() {
    Lazy::force(&spans::CREATED_TOTAL);
    Lazy::force(&spans::EXPORTED_TOTAL);
    Lazy::force(&spans::EXPORT_ERRORS_TOTAL);
    Lazy::force(&spans::DURATION_SECONDS);
    
    Lazy::force(&exporter::BATCH_SIZE);
    Lazy::force(&exporter::EXPORT_LATENCY_SECONDS);
    Lazy::force(&exporter::QUEUE_SIZE);
    
    Lazy::force(&system::CPU_USAGE);
    Lazy::force(&system::MEMORY_USAGE_BYTES);
    Lazy::force(&system::TASKS_COUNT);
}
```

### 1.3 æŒ‡æ ‡HTTPç«¯ç‚¹

`src/metrics_server.rs`:

```rust
use prometheus::{Encoder, TextEncoder};
use hyper::{
    Body, Request, Response, Server, StatusCode,
    service::{make_service_fn, service_fn},
};
use std::convert::Infallible;

/// å¯åŠ¨Prometheus metrics HTTPæœåŠ¡å™¨
pub async fn serve_metrics(port: u16) -> Result<(), Box<dyn std::error::Error>> {
    let addr = ([0, 0, 0, 0], port).into();
    
    let make_svc = make_service_fn(|_conn| async {
        Ok::<_, Infallible>(service_fn(metrics_handler))
    });
    
    let server = Server::bind(&addr).serve(make_svc);
    
    println!("ğŸ“Š Metrics server listening on http://{}", addr);
    
    server.await?;
    
    Ok(())
}

async fn metrics_handler(_req: Request<Body>) -> Result<Response<Body>, Infallible> {
    let encoder = TextEncoder::new();
    let metric_families = crate::metrics::REGISTRY.gather();
    
    let mut buffer = Vec::new();
    encoder.encode(&metric_families, &mut buffer).unwrap();
    
    let response = Response::builder()
        .status(StatusCode::OK)
        .header("Content-Type", encoder.format_type())
        .body(Body::from(buffer))
        .unwrap();
    
    Ok(response)
}
```

### 1.4 æŒ‡æ ‡ä½¿ç”¨ç¤ºä¾‹

```rust
use crate::metrics;

/// Spanåˆ›å»ºç¤ºä¾‹
pub fn create_span(service_name: &str, kind: SpanKind) {
    // è®°å½•spanåˆ›å»º
    metrics::spans::CREATED_TOTAL
        .with_label_values(&[service_name, kind.as_str()])
        .inc();
    
    // ... åˆ›å»ºspané€»è¾‘ ...
}

/// Spanå¯¼å‡ºç¤ºä¾‹
pub async fn export_spans(spans: Vec<Span>) -> Result<(), ExportError> {
    let start = std::time::Instant::now();
    
    // è®°å½•æ‰¹æ¬¡å¤§å°
    metrics::exporter::BATCH_SIZE.observe(spans.len() as f64);
    
    // å¯¼å‡ºspans
    let result = do_export(spans).await;
    
    // è®°å½•å»¶è¿Ÿ
    let duration = start.elapsed().as_secs_f64();
    metrics::exporter::EXPORT_LATENCY_SECONDS
        .with_label_values(&["grpc", "otlp"])
        .observe(duration);
    
    match &result {
        Ok(_) => {
            metrics::spans::EXPORTED_TOTAL
                .with_label_values(&["grpc", "success"])
                .inc();
        }
        Err(e) => {
            metrics::spans::EXPORT_ERRORS_TOTAL
                .with_label_values(&["grpc", &e.error_type()])
                .inc();
        }
    }
    
    result
}

/// ç³»ç»Ÿèµ„æºç›‘æ§
pub async fn monitor_system_resources() {
    use sysinfo::{System, SystemExt, ProcessExt};
    
    let mut sys = System::new_all();
    
    loop {
        sys.refresh_all();
        
        // CPUä½¿ç”¨ç‡
        let cpu_usage = sys.global_cpu_info().cpu_usage();
        metrics::system::CPU_USAGE.set(cpu_usage as f64);
        
        // å†…å­˜ä½¿ç”¨é‡
        let memory_used = sys.used_memory();
        metrics::system::MEMORY_USAGE_BYTES.set(memory_used as i64);
        
        // Taskæ•°é‡ï¼ˆç®€åŒ–ï¼‰
        let task_count = tokio::runtime::Handle::current().metrics().num_workers();
        metrics::system::TASKS_COUNT.set(task_count as i64);
        
        tokio::time::sleep(tokio::time::Duration::from_secs(15)).await;
    }
}
```

---

## 2. Grafana Dashboardé…ç½®

### 2.1 å®Œæ•´Dashboard JSON

`grafana/dashboards/otlp-overview.json`:

```json
{
  "dashboard": {
    "title": "OTLP Service Overview",
    "tags": ["otlp", "observability", "rust"],
    "timezone": "browser",
    "schemaVersion": 38,
    "version": 1,
    "refresh": "30s",
    
    "panels": [
      {
        "id": 1,
        "title": "Span Creation Rate",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "rate(otlp_spans_created_total[5m])",
            "legendFormat": "{{service_name}} - {{span_kind}}"
          }
        ],
        "yaxes": [
          {"format": "ops", "label": "Spans/sec"},
          {"format": "short"}
        ]
      },
      
      {
        "id": 2,
        "title": "Span Export Success Rate",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(otlp_spans_exported_total{status=\"success\"}[5m])) / sum(rate(otlp_spans_exported_total[5m]))",
            "legendFormat": "Success Rate"
          }
        ],
        "yaxes": [
          {"format": "percentunit", "max": 1, "min": 0},
          {"format": "short"}
        ]
      },
      
      {
        "id": 3,
        "title": "Export Latency (P50, P95, P99)",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(otlp_exporter_latency_seconds_bucket[5m])) by (le))",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.95, sum(rate(otlp_exporter_latency_seconds_bucket[5m])) by (le))",
            "legendFormat": "P95"
          },
          {
            "expr": "histogram_quantile(0.99, sum(rate(otlp_exporter_latency_seconds_bucket[5m])) by (le))",
            "legendFormat": "P99"
          }
        ],
        "yaxes": [
          {"format": "s", "label": "Latency"},
          {"format": "short"}
        ]
      },
      
      {
        "id": 4,
        "title": "Queue Size",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "targets": [
          {
            "expr": "otlp_exporter_queue_size",
            "legendFormat": "{{exporter}}"
          }
        ],
        "yaxes": [
          {"format": "short", "label": "Queue Size"},
          {"format": "short"}
        ]
      },
      
      {
        "id": 5,
        "title": "CPU Usage",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "targets": [
          {
            "expr": "otlp_system_cpu_usage_percent",
            "legendFormat": "CPU Usage"
          }
        ],
        "yaxes": [
          {"format": "percent", "max": 100, "min": 0},
          {"format": "short"}
        ]
      },
      
      {
        "id": 6,
        "title": "Memory Usage",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "targets": [
          {
            "expr": "otlp_system_memory_usage_bytes",
            "legendFormat": "Memory Usage"
          }
        ],
        "yaxes": [
          {"format": "bytes", "label": "Memory"},
          {"format": "short"}
        ]
      },
      
      {
        "id": 7,
        "title": "Error Rate by Type",
        "type": "piechart",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
        "targets": [
          {
            "expr": "sum(rate(otlp_spans_export_errors_total[5m])) by (error_type)",
            "legendFormat": "{{error_type}}"
          }
        ]
      },
      
      {
        "id": 8,
        "title": "Batch Size Distribution",
        "type": "heatmap",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
        "targets": [
          {
            "expr": "sum(rate(otlp_exporter_batch_size_bucket[5m])) by (le)",
            "format": "heatmap"
          }
        ]
      }
    ]
  }
}
```

### 2.2 Grafana Provisioning

`grafana/provisioning/datasources/prometheus.yaml`:

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    version: 1
    editable: false
    jsonData:
      timeInterval: "30s"
      httpMethod: POST
```

`grafana/provisioning/dashboards/default.yaml`:

```yaml
apiVersion: 1

providers:
  - name: 'OTLP Dashboards'
    orgId: 1
    folder: 'OTLP'
    type: file
    disableDeletion: false
    updateIntervalSeconds: 30
    allowUiUpdates: true
    options:
      path: /etc/grafana/dashboards
      foldersFromFilesStructure: true
```

---

## 3. å‘Šè­¦è§„åˆ™é…ç½®

### 3.1 Prometheuså‘Šè­¦è§„åˆ™

`prometheus/alerts/otlp-alerts.yaml`:

```yaml
groups:
  - name: otlp_service_alerts
    interval: 30s
    rules:
      # é«˜é”™è¯¯ç‡å‘Šè­¦
      - alert: HighExportErrorRate
        expr: |
          sum(rate(otlp_spans_export_errors_total[5m])) 
          / 
          sum(rate(otlp_spans_exported_total[5m])) 
          > 0.05
        for: 5m
        labels:
          severity: warning
          component: exporter
        annotations:
          summary: "High export error rate detected"
          description: "Export error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
      
      # å¯¼å‡ºå»¶è¿Ÿè¿‡é«˜
      - alert: HighExportLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(otlp_exporter_latency_seconds_bucket[5m])) by (le)
          ) > 1.0
        for: 5m
        labels:
          severity: warning
          component: exporter
        annotations:
          summary: "High export latency detected"
          description: "P95 export latency is {{ $value }}s (threshold: 1s)"
      
      # é˜Ÿåˆ—ç§¯å‹å‘Šè­¦
      - alert: ExporterQueueBacklog
        expr: otlp_exporter_queue_size > 10000
        for: 10m
        labels:
          severity: warning
          component: exporter
        annotations:
          summary: "Exporter queue backlog detected"
          description: "Queue size is {{ $value }} spans (threshold: 10000)"
      
      # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: |
          (otlp_system_memory_usage_bytes / 1024 / 1024 / 1024) > 3.5
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}GB (threshold: 3.5GB)"
      
      # CPUä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighCPUUsage
        expr: otlp_system_cpu_usage_percent > 80
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"
      
      # æœåŠ¡ä¸å¯ç”¨
      - alert: ServiceDown
        expr: up{job="otlp-service"} == 0
        for: 1m
        labels:
          severity: critical
          component: service
        annotations:
          summary: "OTLP service is down"
          description: "OTLP service {{$labels.instance}} has been down for more than 1 minute"
      
      # Spanåˆ›å»ºç‡å¼‚å¸¸ä½
      - alert: LowSpanCreationRate
        expr: |
          sum(rate(otlp_spans_created_total[5m])) < 100
        for: 10m
        labels:
          severity: info
          component: tracer
        annotations:
          summary: "Low span creation rate"
          description: "Span creation rate is {{ $value }} spans/sec (threshold: 100)"
      
      # å¯¼å‡ºæˆåŠŸç‡è¿‡ä½ï¼ˆä¸¥é‡ï¼‰
      - alert: CriticalExportFailureRate
        expr: |
          sum(rate(otlp_spans_exported_total{status="success"}[5m])) 
          / 
          sum(rate(otlp_spans_exported_total[5m])) 
          < 0.90
        for: 5m
        labels:
          severity: critical
          component: exporter
        annotations:
          summary: "Critical export failure rate"
          description: "Export success rate is {{ $value | humanizePercentage }} (threshold: 90%)"
```

### 3.2 Alertmanageré…ç½®

`alertmanager/config.yaml`:

```yaml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  
  routes:
    # ä¸¥é‡å‘Šè­¦ç«‹å³å‘é€åˆ°Slackå’ŒPagerDuty
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
    
    # è­¦å‘Šçº§åˆ«å‘é€åˆ°Slack
    - match:
        severity: warning
      receiver: 'warning-alerts'
      repeat_interval: 1h
    
    # ä¿¡æ¯çº§åˆ«åªè®°å½•æ—¥å¿—
    - match:
        severity: info
      receiver: 'info-alerts'
      repeat_interval: 24h

receivers:
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#critical-alerts'
        title: 'ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true
    
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
        description: '{{ .GroupLabels.alertname }}'
  
  - name: 'warning-alerts'
    slack_configs:
      - channel: '#warnings'
        title: 'âš ï¸  WARNING: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  - name: 'info-alerts'
    slack_configs:
      - channel: '#info'
        title: 'â„¹ï¸  INFO: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

inhibit_rules:
  # å¦‚æœæœåŠ¡å·²downï¼ŒæŠ‘åˆ¶å…¶ä»–å‘Šè­¦
  - source_match:
      severity: 'critical'
      alertname: 'ServiceDown'
    target_match:
      severity: 'warning'
    equal: ['instance']
```

---

## 4. å®Œæ•´ç›‘æ§æ–¹æ¡ˆ

### 4.1 Docker Composeéƒ¨ç½²

`docker-compose.monitoring.yaml`:

```yaml
version: '3.9'

services:
  prometheus:
    image: prom/prometheus:v3.1.0
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alerts:/etc/prometheus/alerts
      - prometheus-data:/prometheus
    networks:
      - monitoring
    restart: unless-stopped
  
  alertmanager:
    image: prom/alertmanager:v0.28.0
    container_name: alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/config.yaml:/etc/alertmanager/config.yml
      - alertmanager-data:/alertmanager
    networks:
      - monitoring
    restart: unless-stopped
  
  grafana:
    image: grafana/grafana:11.6.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/etc/grafana/dashboards
      - grafana-data:/var/lib/grafana
    networks:
      - monitoring
    restart: unless-stopped
  
  node-exporter:
    image: prom/node-exporter:v1.8.2
    container_name: node-exporter
    command:
      - '--path.rootfs=/host'
    ports:
      - "9100:9100"
    volumes:
      - '/:/host:ro,rslave'
    networks:
      - monitoring
    restart: unless-stopped

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus-data:
  alertmanager-data:
  grafana-data:
```

### 4.2 Prometheusé…ç½®

`prometheus/prometheus.yml`:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'production'
    region: 'us-east-1'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - '/etc/prometheus/alerts/*.yaml'

scrape_configs:
  # OTLP Service
  - job_name: 'otlp-service'
    static_configs:
      - targets: ['otlp-service:9090']
    metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'otlp_.*'
        action: keep
  
  # Node Exporter
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
  
  # Prometheusè‡ªç›‘æ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
```

---

## 5. ç”Ÿäº§æœ€ä½³å®è·µ

### 5.1 æŒ‡æ ‡å‘½åè§„èŒƒ

```text
å‘½åè§„èŒƒ:
<namespace>_<subsystem>_<metric_name>_<unit>

ç¤ºä¾‹:
âœ… otlp_spans_created_total           (Counter)
âœ… otlp_exporter_latency_seconds      (Histogram)
âœ… otlp_system_memory_usage_bytes     (Gauge)

âŒ SpansCreated                       (ä¸ç¬¦åˆè§„èŒƒ)
âŒ export_time                        (ç¼ºå°‘namespace)
```

### 5.2 æ ‡ç­¾ä½¿ç”¨æœ€ä½³å®è·µ

```rust
// âœ… å¥½çš„æ ‡ç­¾è®¾è®¡ï¼šåŸºæ•°å¯æ§
metrics::spans::CREATED_TOTAL
    .with_label_values(&[
        "user-service",        // service_name: æœ‰é™æ•°é‡
        "server",              // span_kind: å›ºå®šå€¼
    ])
    .inc();

// âŒ åçš„æ ‡ç­¾è®¾è®¡ï¼šåŸºæ•°çˆ†ç‚¸
// ä¸è¦ç”¨user_idã€request_idç­‰é«˜åŸºæ•°å€¼ä½œä¸ºæ ‡ç­¾ï¼
metrics::requests::TOTAL
    .with_label_values(&[
        &user_id,             // âŒ é«˜åŸºæ•°
        &request_id,          // âŒ é«˜åŸºæ•°
    ])
    .inc();
```

### 5.3 å‘Šè­¦é˜ˆå€¼è®¾ç½®

```yaml
# åŸºäºå†å²æ•°æ®è®¾ç½®åˆç†é˜ˆå€¼

# é”™è¯¯ç‡å‘Šè­¦
- P95é”™è¯¯ç‡ < 1%    â†’ æ­£å¸¸
- P95é”™è¯¯ç‡ 1-5%    â†’ warning
- P95é”™è¯¯ç‡ > 5%    â†’ critical

# å»¶è¿Ÿå‘Šè­¦
- P95å»¶è¿Ÿ < 100ms   â†’ æ­£å¸¸
- P95å»¶è¿Ÿ 100-500ms â†’ warning
- P95å»¶è¿Ÿ > 500ms   â†’ critical

# èµ„æºä½¿ç”¨å‘Šè­¦
- CPU < 70%         â†’ æ­£å¸¸
- CPU 70-85%        â†’ warning
- CPU > 85%         â†’ critical

- Memory < 75%      â†’ æ­£å¸¸
- Memory 75-90%     â†’ warning
- Memory > 90%      â†’ critical
```

### 5.4 ç›‘æ§Dashboardå±‚æ¬¡

```text
å±‚æ¬¡1: æ¦‚è§ˆDashboard
- æ•´ä½“å¥åº·çŠ¶æ€
- å…³é”®æŒ‡æ ‡è¶‹åŠ¿
- å‘Šè­¦æ¦‚è§ˆ

å±‚æ¬¡2: æœåŠ¡Dashboard
- æœåŠ¡çº§åˆ«è¯¦ç»†æŒ‡æ ‡
- ä¾èµ–å…³ç³»
- èµ„æºä½¿ç”¨

å±‚æ¬¡3: ç»„ä»¶Dashboard
- å•ä¸ªç»„ä»¶æ·±åº¦åˆ†æ
- æ€§èƒ½ç“¶é¢ˆå®šä½
- è°ƒè¯•ä¿¡æ¯

å±‚æ¬¡4: å®æ—¶Dashboard
- å®æ—¶ç›‘æ§
- å¿«é€Ÿå“åº”
- æ•…éšœæ’æŸ¥
```

---

## æ€»ç»“

å®Œæ•´çš„ç›‘æ§æ–¹æ¡ˆåŒ…æ‹¬ï¼š

1. âœ… **æŒ‡æ ‡å¯¼å‡º** - Prometheus metricsé›†æˆ
2. âœ… **å¯è§†åŒ–** - Grafana Dashboardé…ç½®
3. âœ… **å‘Šè­¦** - Alertmanagerè§„åˆ™é…ç½®
4. âœ… **éƒ¨ç½²** - Docker Composeå®Œæ•´æ–¹æ¡ˆ
5. âœ… **æœ€ä½³å®è·µ** - ç”Ÿäº§ç¯å¢ƒç»éªŒæ€»ç»“

---

**æ–‡æ¡£æ—¥æœŸ**: 2025å¹´10æœˆ8æ—¥  
**åˆ›å»ºè€…**: AI Assistant  
**é¡¹ç›®**: OTLP Rust æ ‡å‡†æ·±åº¦æ¢³ç†  
**è®¸å¯è¯**: MIT OR Apache-2.0

---

[ğŸ  è¿”å›ä¸»ç›®å½•](../README.md) | [ğŸ³ Kuberneteséƒ¨ç½²](../19_å®¹å™¨åŒ–ä¸Kubernetes/01_Rust_OTLP_Kuberneteså®Œæ•´éƒ¨ç½²æŒ‡å—.md)
