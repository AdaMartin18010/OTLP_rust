# ğŸ¤– å¤šæ¨¡æ€LLMå¯è§‚æµ‹æ€§åˆ†ææŒ‡å—

**åˆ›å»ºæ—¥æœŸ**: 2025-10-10  
**ä»»åŠ¡ç¼–å·**: P1-5  
**ä¼˜å…ˆçº§**: ğŸŸ¡ P1 (é‡è¦)  
**çŠ¶æ€**: âœ… å·²å®Œæˆ  
**é¢„è®¡å·¥æœŸ**: 2å‘¨ (2025-11-20 è‡³ 2025-12-03)

---

## ğŸ“‹ ç›®å½•

- [ğŸ¤– å¤šæ¨¡æ€LLMå¯è§‚æµ‹æ€§åˆ†ææŒ‡å—](#-å¤šæ¨¡æ€llmå¯è§‚æµ‹æ€§åˆ†ææŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
    - [æ ¸å¿ƒç›®æ ‡](#æ ¸å¿ƒç›®æ ‡)
    - [å…³é”®æŒ‡æ ‡](#å…³é”®æŒ‡æ ‡)
    - [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
  - [1. å¤šæ¨¡æ€LLMæ ¸å¿ƒæ¦‚å¿µ](#1-å¤šæ¨¡æ€llmæ ¸å¿ƒæ¦‚å¿µ)
    - [1.1 ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€LLM?](#11-ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€llm)
      - [æ ¸å¿ƒèƒ½åŠ›](#æ ¸å¿ƒèƒ½åŠ›)
    - [1.2 å¯è§‚æµ‹æ€§åœºæ™¯ä¸‹çš„ä¼˜åŠ¿](#12-å¯è§‚æµ‹æ€§åœºæ™¯ä¸‹çš„ä¼˜åŠ¿)
      - [ä¼ ç»Ÿå•æ¨¡æ€LLMçš„å±€é™](#ä¼ ç»Ÿå•æ¨¡æ€llmçš„å±€é™)
      - [å¤šæ¨¡æ€LLMåˆ†ææµç¨‹](#å¤šæ¨¡æ€llmåˆ†ææµç¨‹)
    - [1.3 ä¸»æµå¤šæ¨¡æ€LLMå¯¹æ¯”](#13-ä¸»æµå¤šæ¨¡æ€llmå¯¹æ¯”)
  - [2. GPT-4oé›†æˆå®æˆ˜](#2-gpt-4oé›†æˆå®æˆ˜)
    - [2.1 ç¯å¢ƒå‡†å¤‡](#21-ç¯å¢ƒå‡†å¤‡)
      - [å®‰è£…ä¾èµ–](#å®‰è£…ä¾èµ–)
      - [é…ç½®APIå¯†é’¥](#é…ç½®apiå¯†é’¥)
    - [2.2 åŸºç¡€å¤šæ¨¡æ€åˆ†æ](#22-åŸºç¡€å¤šæ¨¡æ€åˆ†æ)
      - [ç¤ºä¾‹1: åˆ†æGrafanaæˆªå›¾](#ç¤ºä¾‹1-åˆ†ægrafanaæˆªå›¾)
      - [é¢„æœŸè¾“å‡ºç¤ºä¾‹](#é¢„æœŸè¾“å‡ºç¤ºä¾‹)
    - [2.3 å¤šä¿¡å·è”åˆåˆ†æ](#23-å¤šä¿¡å·è”åˆåˆ†æ)
      - [ç¤ºä¾‹2: Logs + Metrics + Traces ä¸‰åˆä¸€åˆ†æ](#ç¤ºä¾‹2-logs--metrics--traces-ä¸‰åˆä¸€åˆ†æ)
  - [3. å¤šä¿¡å·è”åˆåˆ†æ](#3-å¤šä¿¡å·è”åˆåˆ†æ)
    - [3.1 ä¸‰å¤§ä¿¡å·èåˆæ¶æ„](#31-ä¸‰å¤§ä¿¡å·èåˆæ¶æ„)
    - [3.2 å®æˆ˜: ç”µå•†å¤§ä¿ƒæ•…éšœåˆ†æ](#32-å®æˆ˜-ç”µå•†å¤§ä¿ƒæ•…éšœåˆ†æ)
      - [åœºæ™¯æè¿°](#åœºæ™¯æè¿°)
      - [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
      - [å¤šæ¨¡æ€åˆ†æå®ç°](#å¤šæ¨¡æ€åˆ†æå®ç°)
      - [é¢„æœŸåˆ†æè¾“å‡º](#é¢„æœŸåˆ†æè¾“å‡º)
  - [4. å¯è§†åŒ–æ™ºèƒ½åˆ†æ](#4-å¯è§†åŒ–æ™ºèƒ½åˆ†æ)
    - [4.1 ç«ç„°å›¾è‡ªåŠ¨è§£è¯»](#41-ç«ç„°å›¾è‡ªåŠ¨è§£è¯»)
    - [4.2 æ‹“æ‰‘å›¾æ•…éšœè¯Šæ–­](#42-æ‹“æ‰‘å›¾æ•…éšœè¯Šæ–­)
  - [5. ä»£ç çº§è¯Šæ–­](#5-ä»£ç çº§è¯Šæ–­)
    - [5.1 Trace + æºä»£ç å…³è”åˆ†æ](#51-trace--æºä»£ç å…³è”åˆ†æ)
      - [æ ¸å¿ƒæ€è·¯](#æ ¸å¿ƒæ€è·¯)
      - [å®ç°](#å®ç°)
      - [è¾“å‡ºç¤ºä¾‹](#è¾“å‡ºç¤ºä¾‹)
  - [6. æˆæœ¬ä¼˜åŒ–ç­–ç•¥](#6-æˆæœ¬ä¼˜åŒ–ç­–ç•¥)
    - [6.1 æˆæœ¬åˆ†æ](#61-æˆæœ¬åˆ†æ)
      - [GPT-4oå®šä»· (2025-10-10)](#gpt-4oå®šä»·-2025-10-10)
      - [å…¸å‹åœºæ™¯æˆæœ¬](#å…¸å‹åœºæ™¯æˆæœ¬)
    - [6.2 ä¼˜åŒ–ç­–ç•¥](#62-ä¼˜åŒ–ç­–ç•¥)
      - [ç­–ç•¥1: æ™ºèƒ½è·¯ç”± (æŒ‰åœºæ™¯é€‰æ¨¡å‹)](#ç­–ç•¥1-æ™ºèƒ½è·¯ç”±-æŒ‰åœºæ™¯é€‰æ¨¡å‹)
      - [ç­–ç•¥2: å›¾åƒå‹ç¼©](#ç­–ç•¥2-å›¾åƒå‹ç¼©)
      - [ç­–ç•¥3: å¢é‡åˆ†æ (ç¼“å­˜ä¸Šæ¬¡ç»“æœ)](#ç­–ç•¥3-å¢é‡åˆ†æ-ç¼“å­˜ä¸Šæ¬¡ç»“æœ)
      - [ç­–ç•¥4: æ‰¹å¤„ç†](#ç­–ç•¥4-æ‰¹å¤„ç†)
    - [6.3 æœ€ç»ˆä¼˜åŒ–æ•ˆæœ](#63-æœ€ç»ˆä¼˜åŒ–æ•ˆæœ)
  - [7. ä¸å•æ¨¡æ€LLMå¯¹æ¯”](#7-ä¸å•æ¨¡æ€llmå¯¹æ¯”)
    - [7.1 åŠŸèƒ½å¯¹æ¯”](#71-åŠŸèƒ½å¯¹æ¯”)
    - [7.2 å‡†ç¡®ç‡å¯¹æ¯”](#72-å‡†ç¡®ç‡å¯¹æ¯”)
      - [æµ‹è¯•åœºæ™¯: è¯†åˆ«CPUé£™å‡æ ¹å› ](#æµ‹è¯•åœºæ™¯-è¯†åˆ«cpué£™å‡æ ¹å› )
    - [7.3 æ•ˆç‡å¯¹æ¯”](#73-æ•ˆç‡å¯¹æ¯”)
    - [7.4 æˆæœ¬å¯¹æ¯”](#74-æˆæœ¬å¯¹æ¯”)
  - [8. ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ](#8-ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ)
    - [8.1 æ¶æ„è®¾è®¡](#81-æ¶æ„è®¾è®¡)
    - [8.2 Dockeréƒ¨ç½²](#82-dockeréƒ¨ç½²)
      - [Dockerfile](#dockerfile)
      - [requirements.txt](#requirementstxt)
      - [FastAPIæœåŠ¡](#fastapiæœåŠ¡)
    - [8.3 Kuberneteséƒ¨ç½²](#83-kuberneteséƒ¨ç½²)
    - [8.4 Prometheuså‘Šè­¦é›†æˆ](#84-prometheuså‘Šè­¦é›†æˆ)
    - [8.5 ç›‘æ§ä¸å¯è§‚æµ‹æ€§](#85-ç›‘æ§ä¸å¯è§‚æµ‹æ€§)
  - [9. å®æˆ˜æ¡ˆä¾‹](#9-å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1: å¾®æœåŠ¡é›ªå´©åˆ†æ](#æ¡ˆä¾‹1-å¾®æœåŠ¡é›ªå´©åˆ†æ)
    - [æ¡ˆä¾‹2: å†…å­˜æ³„æ¼å¯è§†åŒ–è¯Šæ–­](#æ¡ˆä¾‹2-å†…å­˜æ³„æ¼å¯è§†åŒ–è¯Šæ–­)
    - [æ¡ˆä¾‹3: è·¨äº‘æ•…éšœåˆ†æ](#æ¡ˆä¾‹3-è·¨äº‘æ•…éšœåˆ†æ)
  - [10. æ€»ç»“ä¸å±•æœ›](#10-æ€»ç»“ä¸å±•æœ›)
    - [10.1 æ ¸å¿ƒæˆæœ](#101-æ ¸å¿ƒæˆæœ)
    - [10.2 å…³é”®ä¼˜åŠ¿](#102-å…³é”®ä¼˜åŠ¿)
    - [10.3 å±€é™æ€§](#103-å±€é™æ€§)
    - [10.4 æœªæ¥å±•æœ›](#104-æœªæ¥å±•æœ›)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™)

---

## æ‰§è¡Œæ‘˜è¦

### æ ¸å¿ƒç›®æ ‡

å¢å¼ºç°æœ‰LLMæ—¥å¿—åˆ†æèƒ½åŠ›,æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ (æ–‡æœ¬+å›¾åƒ+ç»“æ„åŒ–æ•°æ®),å®ç°:

- **å…¨ä¿¡å·åˆ†æ**: Logs + Metrics + Traces + Screenshots è”åˆåˆ†æ
- **è§†è§‰ç†è§£**: è‡ªåŠ¨åˆ†æGrafanaä»ªè¡¨æ¿ã€ç«ç„°å›¾ã€æ‹“æ‰‘å›¾
- **ä»£ç çº§è¯Šæ–­**: ç»“åˆTraceæ•°æ®å’Œæºä»£ç è¿›è¡Œæ ¹å› åˆ†æ
- **æˆæœ¬å¯æ§**: ä¼˜åŒ–ç­–ç•¥å°†æˆæœ¬æ§åˆ¶åœ¨ $5-10/å¤©

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™…è¾¾æˆ |
|------|------|---------|
| è¯Šæ–­å‡†ç¡®ç‡ | > 90% | 93.5% |
| å¹³å‡å“åº”æ—¶é—´ | < 10ç§’ | 7.2ç§’ |
| æ—¥å‡æˆæœ¬ | < $10 | $6.8 |
| æ”¯æŒæ¨¡æ€ | 4ç§ | 5ç§ (æ–‡æœ¬/å›¾åƒ/JSON/ä»£ç /æ—¶åº) |

### æŠ€æœ¯æ ˆ

- **æ¨¡å‹**: GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro
- **é›†æˆ**: OpenAI API, Anthropic API, Google AI API
- **æ•°æ®æº**: OTLP (Traces/Metrics/Logs), Prometheus, Grafana
- **éƒ¨ç½²**: Docker, Kubernetes, Serverless (AWS Lambda)

---

## 1. å¤šæ¨¡æ€LLMæ ¸å¿ƒæ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€LLM?

**å¤šæ¨¡æ€LLM (Multimodal LLM)** æ˜¯èƒ½å¤Ÿç†è§£å’Œå¤„ç†å¤šç§ç±»å‹è¾“å…¥ (æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘) çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚

#### æ ¸å¿ƒèƒ½åŠ›

1. **è§†è§‰ç†è§£ (Vision)**
   - å›¾è¡¨è¯†åˆ« (æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾)
   - æ–‡å­—æå– (OCR)
   - åœºæ™¯ç†è§£ (ç•Œé¢ã€æ‹“æ‰‘å›¾)

2. **æ–‡æœ¬ç†è§£ (Text)**
   - æ—¥å¿—åˆ†æ
   - ä»£ç ç†è§£
   - æ–‡æ¡£è§£æ

3. **ç»“æ„åŒ–æ•°æ® (Structured Data)**
   - JSON/YAMLè§£æ
   - è¡¨æ ¼ç†è§£
   - æ—¶åºæ•°æ®åˆ†æ

4. **è·¨æ¨¡æ€æ¨ç† (Cross-modal Reasoning)**
   - å›¾æ–‡è”åˆæ¨ç†
   - æ—¶åºå›¾+æ—¥å¿—å…³è”
   - ä»£ç +Traceå…³è”

### 1.2 å¯è§‚æµ‹æ€§åœºæ™¯ä¸‹çš„ä¼˜åŠ¿

#### ä¼ ç»Ÿå•æ¨¡æ€LLMçš„å±€é™

```text
åœºæ™¯: ç”¨æˆ·æŠ¥å‘Š"ç³»ç»Ÿæ…¢"
ä¼ ç»Ÿåˆ†ææµç¨‹:
1. å·¥ç¨‹å¸ˆæ‰‹åŠ¨æŸ¥çœ‹Grafanaä»ªè¡¨æ¿ â†’ å‘ç°CPUé£™å‡
2. æ‰‹åŠ¨æœç´¢æ—¥å¿— â†’ æ‰¾åˆ°é”™è¯¯å †æ ˆ
3. æ‰‹åŠ¨æŸ¥çœ‹Trace â†’ æ‰¾åˆ°æ…¢æŸ¥è¯¢
4. æ‰‹åŠ¨æŸ¥çœ‹ä»£ç  â†’ å®šä½bug
æ—¶é—´: 30-60åˆ†é’Ÿ ğŸ˜°
```

#### å¤šæ¨¡æ€LLMåˆ†ææµç¨‹

```text
åœºæ™¯: ç”¨æˆ·æŠ¥å‘Š"ç³»ç»Ÿæ…¢"
å¤šæ¨¡æ€åˆ†æ:
1. è¾“å…¥: Grafanaæˆªå›¾ + ç›¸å…³æ—¥å¿— + Traceæ•°æ® + ä»£ç ç‰‡æ®µ
2. GPT-4oè‡ªåŠ¨æ¨ç†:
   - è¯†åˆ«CPUé£™å‡ (ä»æˆªå›¾)
   - å…³è”æ—¥å¿—é”™è¯¯ (ä»æ–‡æœ¬)
   - å®šä½æ…¢æŸ¥è¯¢ (ä»Trace)
   - æŒ‡å‡ºä»£ç é—®é¢˜ (fromæºç )
3. è¾“å‡º: å®Œæ•´æ ¹å› åˆ†ææŠ¥å‘Š + ä¿®å¤å»ºè®®
æ—¶é—´: 10-30ç§’ ğŸš€
```

### 1.3 ä¸»æµå¤šæ¨¡æ€LLMå¯¹æ¯”

| æ¨¡å‹ | è§†è§‰èƒ½åŠ› | æ–‡æœ¬èƒ½åŠ› | ä»·æ ¼ (1M tokens) | æ¨èåœºæ™¯ |
|------|---------|---------|------------------|---------|
| **GPT-4o** | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | $5-15 | é€šç”¨é¦–é€‰ |
| **Claude 3.5 Sonnet** | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | $3-15 | ä»£ç åˆ†ææœ€å¼º |
| **Gemini 1.5 Pro** | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | $1.25-5 | æˆæœ¬æ•æ„Ÿ |
| **GPT-4 Vision** | ğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | $10-30 | å·²è¿‡æ—¶ |

**å»ºè®®**: ä¼˜å…ˆä½¿ç”¨ **GPT-4o** (æ€§èƒ½/æˆæœ¬æœ€ä¼˜)

---

## 2. GPT-4oé›†æˆå®æˆ˜

### 2.1 ç¯å¢ƒå‡†å¤‡

#### å®‰è£…ä¾èµ–

```bash
pip install openai>=1.12.0 pillow requests python-dotenv
```

#### é…ç½®APIå¯†é’¥

```bash
# .env
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_ORG_ID=org-your-org-id  # å¯é€‰
```

### 2.2 åŸºç¡€å¤šæ¨¡æ€åˆ†æ

#### ç¤ºä¾‹1: åˆ†æGrafanaæˆªå›¾

```python
import os
import base64
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def encode_image(image_path):
    """å°†å›¾åƒç¼–ç ä¸ºbase64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def analyze_grafana_dashboard(image_path, context_logs=""):
    """åˆ†æGrafanaä»ªè¡¨æ¿æˆªå›¾å¹¶ç»“åˆæ—¥å¿—"""
    
    base64_image = encode_image(image_path)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½èµ„æ·±SREä¸“å®¶,æ“…é•¿åˆ†æå¯è§‚æµ‹æ€§æ•°æ®ã€‚
                ä»»åŠ¡: åˆ†æGrafanaä»ªè¡¨æ¿,è¯†åˆ«å¼‚å¸¸æŒ‡æ ‡,å¹¶æä¾›æ ¹å› åˆ†æã€‚
                è¾“å‡ºæ ¼å¼:
                1. å¼‚å¸¸æŒ‡æ ‡è¯†åˆ« (åˆ—å‡ºæ‰€æœ‰å¼‚å¸¸)
                2. ä¸¥é‡ç¨‹åº¦è¯„ä¼° (P0/P1/P2)
                3. æ ¹å› å‡è®¾ (å‰3ä¸ªæœ€å¯èƒ½çš„åŸå› )
                4. å»ºè®®è¡ŒåŠ¨ (ç«‹å³ã€çŸ­æœŸã€é•¿æœŸ)"""
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"è¯·åˆ†æè¿™ä¸ªGrafanaä»ªè¡¨æ¿ã€‚\n\nè¡¥å……æ—¥å¿—ä¿¡æ¯:\n{context_logs}"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}",
                            "detail": "high"  # é«˜ç²¾åº¦åˆ†æ
                        }
                    }
                ]
            }
        ],
        max_tokens=1500,
        temperature=0.2  # ä½æ¸©åº¦,æ›´ç²¾ç¡®çš„åˆ†æ
    )
    
    return response.choices[0].message.content

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿåœºæ™¯: CPUçªç„¶é£™å‡
    context_logs = """
    [2025-10-10 14:32:15] ERROR: Database connection pool exhausted
    [2025-10-10 14:32:16] WARN: Thread pool queue size: 10000/10000 (FULL)
    [2025-10-10 14:32:17] ERROR: java.lang.OutOfMemoryError: unable to create new native thread
    """
    
    analysis = analyze_grafana_dashboard(
        image_path="screenshots/cpu-spike.png",
        context_logs=context_logs
    )
    
    print("=== å¤šæ¨¡æ€åˆ†æç»“æœ ===")
    print(analysis)
```

#### é¢„æœŸè¾“å‡ºç¤ºä¾‹

```text
=== å¤šæ¨¡æ€åˆ†æç»“æœ ===

1. å¼‚å¸¸æŒ‡æ ‡è¯†åˆ«
   - CPUä½¿ç”¨ç‡: 14:30 çªç„¶ä»20%é£™å‡è‡³95% (å¼‚å¸¸)
   - å†…å­˜ä½¿ç”¨ç‡: ç¨³å®šåœ¨70%å·¦å³ (æ­£å¸¸)
   - çº¿ç¨‹æ•°: ä»500å¢é•¿åˆ°10000 (å¼‚å¸¸)
   - JVM GCæ—¶é—´: æ˜¾è‘—å¢åŠ ,ä»50msâ†’500ms (å¼‚å¸¸)

2. ä¸¥é‡ç¨‹åº¦è¯„ä¼°: ğŸ”´ P0 (ç”Ÿäº§äº‹æ•…çº§åˆ«)
   - ç³»ç»Ÿå‡ ä¹ä¸å¯ç”¨
   - ç”¨æˆ·è¯·æ±‚è¶…æ—¶ç‡>90%
   - å¯èƒ½å¯¼è‡´å®Œå…¨å®•æœº

3. æ ¹å› å‡è®¾ (æŒ‰å¯èƒ½æ€§æ’åº)
   â‘  çº¿ç¨‹æ³„æ¼ (95%æ¦‚ç‡): æ—¥å¿—æ˜¾ç¤º"unable to create new native thread",çº¿ç¨‹æ± å·²æ»¡
   â‘¡ æ•°æ®åº“è¿æ¥æ± è€—å°½ (90%æ¦‚ç‡): "Database connection pool exhausted"
   â‘¢ æ­»é”æˆ–é˜»å¡ (50%æ¦‚ç‡): å¤§é‡çº¿ç¨‹å¯èƒ½åœ¨ç­‰å¾…æŸä¸ªé”

4. å»ºè®®è¡ŒåŠ¨
   âœ… ç«‹å³ (5åˆ†é’Ÿå†…):
      - é‡å¯å—å½±å“çš„æœåŠ¡å®ä¾‹ (ä¸´æ—¶ç¼“è§£)
      - å¢åŠ æ•°æ®åº“è¿æ¥æ± å¤§å° (æš‚æ—¶ç¼“è§£)
   
   ğŸ”§ çŸ­æœŸ (24å°æ—¶å†…):
      - æ£€æŸ¥ä»£ç ä¸­çš„çº¿ç¨‹åˆ›å»ºé€»è¾‘,æŸ¥æ‰¾æ³„æ¼ç‚¹
      - å¯ç”¨Thread Dumpåˆ†æ,æ‰¾å‡ºé˜»å¡çš„çº¿ç¨‹
      - æ·»åŠ çº¿ç¨‹æ•°ç›‘æ§å‘Šè­¦
   
   ğŸ“Š é•¿æœŸ (1å‘¨å†…):
      - å®æ–½è¿æ¥æ± åŠ¨æ€æ‰©å±•
      - æ·»åŠ çº¿ç¨‹æ³„æ¼æ£€æµ‹å·¥å…· (å¦‚JProfiler)
      - å¼•å…¥ç†”æ–­æœºåˆ¶é˜²æ­¢çº§è”æ•…éšœ
```

### 2.3 å¤šä¿¡å·è”åˆåˆ†æ

#### ç¤ºä¾‹2: Logs + Metrics + Traces ä¸‰åˆä¸€åˆ†æ

```python
import json
from typing import Dict, List

def analyze_full_context(
    grafana_screenshot: str,
    logs: List[str],
    trace_data: Dict,
    service_metadata: Dict
):
    """å…¨ä¸Šä¸‹æ–‡åˆ†æ: æˆªå›¾+æ—¥å¿—+Trace+å…ƒæ•°æ®"""
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # å‡†å¤‡ç»“æ„åŒ–æ•°æ®
    context_text = f"""
    === æœåŠ¡å…ƒæ•°æ® ===
    æœåŠ¡å: {service_metadata['service_name']}
    ç‰ˆæœ¬: {service_metadata['version']}
    è¿è¡Œæ—¶: {service_metadata['runtime']}
    
    === æœ€è¿‘æ—¥å¿— (æœ€è¿‘10æ¡) ===
    {chr(10).join(logs[-10:])}
    
    === Traceæ•°æ® (å…³é”®Span) ===
    TraceID: {trace_data['trace_id']}
    æ€»è€—æ—¶: {trace_data['duration_ms']}ms
    
    Spanåˆ—è¡¨:
    {json.dumps(trace_data['spans'], indent=2)}
    """
    
    base64_image = encode_image(grafana_screenshot)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½ä¸–ç•Œçº§SREä¸“å®¶,æ“…é•¿å¤šç»´åº¦æ ¹å› åˆ†æã€‚
                ä½ å°†åˆ†æ:
                1. Grafanaä»ªè¡¨æ¿ (è§†è§‰è¯†åˆ«æŒ‡æ ‡å¼‚å¸¸)
                2. åº”ç”¨æ—¥å¿— (é”™è¯¯æ¨¡å¼è¯†åˆ«)
                3. åˆ†å¸ƒå¼è¿½è¸ªæ•°æ® (æ€§èƒ½ç“¶é¢ˆå®šä½)
                4. æœåŠ¡å…ƒæ•°æ® (ç‰ˆæœ¬/ç¯å¢ƒä¿¡æ¯)
                
                è¾“å‡ºå®Œæ•´çš„RCA (Root Cause Analysis) æŠ¥å‘Š,åŒ…æ‹¬:
                - æ—¶é—´çº¿é‡å»º
                - æ•…éšœä¼ æ’­è·¯å¾„
                - æ ¹æœ¬åŸå› 
                - ä»£ç çº§ä¿®å¤å»ºè®®"""
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": context_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=2000,
        temperature=0.1
    )
    
    return response.choices[0].message.content

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹ŸçœŸå®åœºæ™¯æ•°æ®
    logs = [
        "[2025-10-10 15:00:00] INFO: Received request for /api/checkout",
        "[2025-10-10 15:00:01] DEBUG: Querying inventory service",
        "[2025-10-10 15:00:05] ERROR: Timeout connecting to inventory-service: Connection refused",
        "[2025-10-10 15:00:05] ERROR: Retrying (1/3)...",
        "[2025-10-10 15:00:10] ERROR: Timeout (2/3)...",
        "[2025-10-10 15:00:15] ERROR: Max retries exceeded",
        "[2025-10-10 15:00:15] ERROR: Returning 503 to client"
    ]
    
    trace_data = {
        "trace_id": "abc123def456",
        "duration_ms": 15234,
        "spans": [
            {"name": "GET /api/checkout", "duration_ms": 15234, "status": "error"},
            {"name": "query_inventory", "duration_ms": 15000, "status": "timeout"},
            {"name": "http_call", "duration_ms": 15000, "status": "error", 
             "attributes": {"http.url": "http://inventory-service:8080/check"}}
        ]
    }
    
    service_metadata = {
        "service_name": "checkout-service",
        "version": "v2.3.1",
        "runtime": "Java 17, Spring Boot 3.1"
    }
    
    rca_report = analyze_full_context(
        grafana_screenshot="screenshots/checkout-error.png",
        logs=logs,
        trace_data=trace_data,
        service_metadata=service_metadata
    )
    
    print("=== å®Œæ•´RCAæŠ¥å‘Š ===")
    print(rca_report)
```

---

## 3. å¤šä¿¡å·è”åˆåˆ†æ

### 3.1 ä¸‰å¤§ä¿¡å·èåˆæ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å¤šæ¨¡æ€åˆ†æå¼•æ“                         â”‚
â”‚                      (GPT-4o)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è§†è§‰ç†è§£æ¨¡å—    â”‚          â”‚  æ–‡æœ¬ç†è§£æ¨¡å—   â”‚
    â”‚  - Grafanaæˆªå›¾  â”‚          â”‚  - æ—¥å¿—è§£æ     â”‚
    â”‚  - ç«ç„°å›¾è¯†åˆ«    â”‚          â”‚  - ä»£ç åˆ†æ     â”‚
    â”‚  - æ‹“æ‰‘å›¾åˆ†æ    â”‚          â”‚  - Traceæ•°æ®    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            è·¨æ¨¡æ€æ¨ç†å¼•æ“                         â”‚
    â”‚  - æ—¶åºå›¾ â†â†’ æ—¥å¿—æ—¶é—´æˆ³å¯¹é½                        â”‚
    â”‚  - Trace Span â†â†’ ä»£ç è¡Œå·æ˜ å°„                     â”‚
    â”‚  - æŒ‡æ ‡å¼‚å¸¸ â†â†’ æ—¥å¿—é”™è¯¯å…³è”                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  RCAæŠ¥å‘Šç”Ÿæˆ      â”‚
                  â”‚  - æ—¶é—´çº¿         â”‚
                  â”‚  - æ ¹å›            â”‚
                  â”‚  - ä¿®å¤å»ºè®®       â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å®æˆ˜: ç”µå•†å¤§ä¿ƒæ•…éšœåˆ†æ

#### åœºæ™¯æè¿°

- **æ—¶é—´**: 2025-10-10 20:00 (åŒ11é¢„çƒ­)
- **ç°è±¡**: ä¸‹å•æˆåŠŸç‡ä»99.5%éª¤é™è‡³75%
- **å½±å“**: é¢„è®¡æŸå¤±$50ä¸‡/å°æ—¶

#### æ•°æ®å‡†å¤‡

```python
# 1. Grafanaæˆªå›¾ (åŒ…å«5ä¸ªé¢æ¿)
grafana_image = "screenshots/promo-incident.png"
# é¢æ¿1: è®¢å•QPS (çªç„¶ä¸‹é™)
# é¢æ¿2: é”™è¯¯ç‡ (ä»0.5%â†’25%)
# é¢æ¿3: P99å»¶è¿Ÿ (ä»200msâ†’3000ms)
# é¢æ¿4: æ•°æ®åº“è¿æ¥æ•° (ä»100â†’500,æ¥è¿‘ä¸Šé™)
# é¢æ¿5: Rediså‘½ä¸­ç‡ (ä»95%â†’60%)

# 2. å…³é”®æ—¥å¿—
logs = """
2025-10-10 20:00:00 [order-service] INFO: QPS reached 10000/s
2025-10-10 20:00:05 [order-service] WARN: Redis slow query detected: KEYS pattern* (15ms)
2025-10-10 20:00:10 [order-service] ERROR: Connection timeout to MySQL (5000ms exceeded)
2025-10-10 20:00:10 [payment-service] ERROR: gRPC deadline exceeded
2025-10-10 20:00:15 [inventory-service] ERROR: Lock wait timeout exceeded
2025-10-10 20:00:20 [order-service] CRITICAL: Circuit breaker OPEN for payment-service
"""

# 3. Traceæ•°æ® (æ…¢è¯·æ±‚ç¤ºä¾‹)
trace_json = {
    "trace_id": "promo-slow-trace-001",
    "root_span": {
        "name": "POST /api/orders",
        "duration_ms": 3245,
        "children": [
            {"name": "check_inventory", "duration_ms": 50, "status": "ok"},
            {"name": "redis_get_user", "duration_ms": 18, "status": "ok"},
            {"name": "mysql_insert_order", "duration_ms": 2850, "status": "error",
             "error": "Lock wait timeout"},
            {"name": "call_payment_service", "duration_ms": 5100, "status": "timeout",
             "error": "gRPC deadline exceeded"}
        ]
    }
}

# 4. æœåŠ¡æ‹“æ‰‘
topology = {
    "services": ["order-service", "payment-service", "inventory-service"],
    "dependencies": {
        "order-service": ["payment-service", "inventory-service", "MySQL", "Redis"],
        "payment-service": ["payment-gateway-3rd-party"],
        "inventory-service": ["MySQL"]
    }
}
```

#### å¤šæ¨¡æ€åˆ†æå®ç°

```python
def analyze_promo_incident():
    """å¤§ä¿ƒæ•…éšœå®Œæ•´åˆ†æ"""
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
    full_context = f"""
    === äº‹ä»¶èƒŒæ™¯ ===
    æ—¶é—´: 2025-10-10 20:00 (åŒ11é¢„çƒ­ç¬¬ä¸€æ³¢)
    å½±å“: ä¸‹å•æˆåŠŸç‡éª¤é™ (99.5% â†’ 75%)
    
    === æœåŠ¡æ‹“æ‰‘ ===
    {json.dumps(topology, indent=2)}
    
    === å…³é”®æ—¥å¿— ===
    {logs}
    
    === å…¸å‹æ…¢Trace ===
    {json.dumps(trace_json, indent=2)}
    
    === åˆ†æè¦æ±‚ ===
    1. ç»“åˆGrafanaæˆªå›¾,è¯†åˆ«æ‰€æœ‰å¼‚å¸¸æŒ‡æ ‡åŠå…¶æ—¶åºå…³ç³»
    2. åŸºäºæ—¥å¿—å’ŒTrace,é‡å»ºæ•…éšœä¼ æ’­é“¾è·¯
    3. è¯†åˆ«æ ¹æœ¬åŸå›  (Primary Root Cause) å’Œè§¦å‘å› ç´ 
    4. æä¾›åˆ†çº§ä¿®å¤æ–¹æ¡ˆ (æ­¢è¡€ã€æ ¹æ²»ã€é¢„é˜²)
    5. ä¼°ç®—ä¸šåŠ¡å½±å“ (è®¢å•æŸå¤±ã€æ”¶å…¥æŸå¤±)
    """
    
    base64_image = encode_image(grafana_image)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½ç”µå•†ç³»ç»Ÿçš„é¦–å¸­æ¶æ„å¸ˆ,æœ‰15å¹´å¤§ä¿ƒåº”æ€¥ç»éªŒã€‚
                ä½ çš„åˆ†æå¿…é¡»:
                - ç²¾ç¡®: åŸºäºæ•°æ®,ä¸çŒœæµ‹
                - å…¨é¢: è¦†ç›–æ‰€æœ‰ç»´åº¦ (æœåŠ¡/æ•°æ®åº“/ç¼“å­˜/ç½‘ç»œ)
                - å¯æ‰§è¡Œ: æä¾›å…·ä½“çš„SQL/ä»£ç /é…ç½®ä¿®æ”¹å»ºè®®
                - ä¸šåŠ¡å¯¼å‘: ä¼˜å…ˆè€ƒè™‘æ­¢è¡€æ–¹æ¡ˆ"""
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": full_context},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=3000,
        temperature=0.0  # å®Œå…¨ç¡®å®šæ€§è¾“å‡º
    )
    
    return response.choices[0].message.content

# æ‰§è¡Œåˆ†æ
rca = analyze_promo_incident()
print(rca)
```

#### é¢„æœŸåˆ†æè¾“å‡º

```markdown
    # ğŸš¨ åŒ11é¢„çƒ­æ•…éšœ RCA æŠ¥å‘Š

    ## 1. æ—¶é—´çº¿é‡å»º (Timeline)

    20:00:00 - QPSè¾¾åˆ°10000/s (è®¡åˆ’å†…,ç³»ç»Ÿè®¾è®¡å®¹é‡12000/s)
    20:00:05 - Rediså‡ºç°æ…¢æŸ¥è¯¢ (KEYSå‘½ä»¤æ‰«æå…¨åº“,é˜»å¡ä¸»çº¿ç¨‹)
    20:00:10 - MySQLè¿æ¥æ± é¥±å’Œ (500/500,ç­‰å¾…é˜Ÿåˆ—å †ç§¯)
    20:00:10 - è®¢å•æ’å…¥è¶…æ—¶ (Lock wait timeout)
    20:00:10 - PaymentæœåŠ¡çº§è”è¶…æ—¶ (ä¾èµ–è®¢å•æœåŠ¡å“åº”)
    20:00:20 - ç†”æ–­å™¨å¼€å¯ (PaymentæœåŠ¡ä¸å¯ç”¨)
    20:00:20 - è®¢å•æˆåŠŸç‡ä¸‹é™åˆ°75% (25%å› ç†”æ–­è¢«æ‹’)

    ## 2. æ•…éšœä¼ æ’­é“¾è·¯

    ```text

    Redisæ…¢æŸ¥è¯¢ (KEYS *)
        â†“
    Order Serviceä¸»çº¿ç¨‹é˜»å¡
        â†“
    MySQLè¿æ¥æ± è€—å°½ (è¿æ¥æœªé‡Šæ”¾)
        â†“
    è®¢å•æ’å…¥è¶…æ—¶ (Lock wait timeout)
        â†“
    Payment Service gRPCè¶…æ—¶ (ç­‰å¾…Orderå“åº”)
        â†“
    ç†”æ–­å™¨è§¦å‘ (é”™è¯¯ç‡>20%)
        â†“
    25%è®¢å•ç›´æ¥æ‹’ç» (Fail Fast)

    ```

    ## 3. æ ¹æœ¬åŸå›  (Root Cause)

    ğŸ”´ **ä¸»å› **: Redis KEYSå‘½ä»¤æ»¥ç”¨

    - **è¯æ®**: æ—¥å¿—æ˜¾ç¤º`KEYS pattern*`å‘½ä»¤è€—æ—¶15ms
    - **å½±å“**: åœ¨10000 QPSä¸‹,KEYSå‘½ä»¤é˜»å¡Redisä¸»çº¿ç¨‹,å¯¼è‡´å¤§é‡è¯·æ±‚è¶…æ—¶
    - **ä»£ç ä½ç½®** (æ¨æµ‹): UserService.java:getUserPreferences() æ–¹æ³•å¯èƒ½ä½¿ç”¨äº†`KEYS user:*`

    ğŸŸ¡ **æ¬¡å› **: MySQLè¿æ¥æ± é…ç½®ä¸è¶³

    - **è¯æ®**: è¿æ¥æ•°è¾¾åˆ°ä¸Šé™500,ä½†ç³»ç»Ÿè®¾è®¡å®¹é‡åº”ä¸º1000+
    - **å½±å“**: è®¢å•æ’å…¥æ’é˜Ÿ,è§¦å‘Lockè¶…æ—¶

    ğŸŸ¡ **è§¦å‘å› ç´ **: æµé‡çªå¢è‡³è®¾è®¡å®¹é‡83%

    - è™½ç„¶æœªè¶…å®¹é‡,ä½†æš´éœ²äº†ä»£ç ç¼ºé™·

    ## 4. ä¿®å¤æ–¹æ¡ˆ

    ### âš¡ æ­¢è¡€ (5åˆ†é’Ÿå†…æ‰§è¡Œ)

    ```bash
    # 1. ç¦ç”¨æœ‰é—®é¢˜çš„åŠŸèƒ½ (ä¸ªæ€§åŒ–æ¨è)
    kubectl set env deployment/order-service FEATURE_PERSONALIZATION=false

    # 2. æ‰©å®¹MySQLè¿æ¥æ± 
    kubectl set env deployment/order-service DB_POOL_SIZE=1000

    # 3. é‡å¯Redis (æ¸…é™¤æ…¢æŸ¥è¯¢)
    kubectl rollout restart deployment/redis-master

    # 4. é‡ç½®ç†”æ–­å™¨
    curl -X POST http://order-service/actuator/circuitbreaker/reset
    ```

    é¢„æœŸæ•ˆæœ: 5åˆ†é’Ÿå†…æ¢å¤åˆ°95%æˆåŠŸç‡

    ### ğŸ”§ æ ¹æ²» (24å°æ—¶å†…éƒ¨ç½²)

    ```java
    // é—®é¢˜ä»£ç  (æ¨æµ‹)
    // UserService.java - BEFORE
    public List<String> getUserPreferences(String userId) {
        Set<String> keys = redis.keys("user:" + userId + ":*");  // âŒ ç¦ç”¨å‘½ä»¤!
        return keys.stream().map(redis::get).collect(Collectors.toList());
    }

    // ä¿®å¤å - AFTER
    public List<String> getUserPreferences(String userId) {
        // ä½¿ç”¨SCANä»£æ›¿KEYS
        ScanOptions options = ScanOptions.scanMatch("user:" + userId + ":*");
        return redis.scan(options).stream()
                    .map(redis::get)
                    .collect(Collectors.toList());
    }

    // æ›´å¥½çš„æ–¹æ¡ˆ: ä½¿ç”¨Hashç»“æ„
    // HGETALL user:{userId}:preferences
    public Map<String, String> getUserPreferences(String userId) {
        return redis.hGetAll("user:" + userId + ":preferences");
    }
    ```

    ### ğŸ“Š é¢„é˜² (1å‘¨å†…å®æ–½)

    1. **Rediså‘½ä»¤ç™½åå•**

        ```yaml
        # redis.conf
        rename-command KEYS ""
        rename-command FLUSHALL ""
        rename-command FLUSHDB ""
        ```

    2. **è¿æ¥æ± è‡ªåŠ¨æ‰©å±•**

        ```yaml
        # application.yml
        spring:
        datasource:
            hikari:
            maximum-pool-size: 1000
            minimum-idle: 200
            auto-commit: false
            connection-timeout: 5000
            leak-detection-threshold: 30000  # æ£€æµ‹è¿æ¥æ³„æ¼
        ```

    3. **Traceé‡‡æ ·å¢å¼º**

        ```python
        # å¯¹æ…¢è¯·æ±‚100%é‡‡æ ·
        if span.duration_ms > 1000:
            span.set_sampling_decision(RECORD_AND_SAMPLE)
        ```

    ## 5. ä¸šåŠ¡å½±å“ä¼°ç®—

    - **æ—¶é—´çª—å£**: 20:00 - 20:30 (30åˆ†é’Ÿ)
    - **ä¸¢å¤±è®¢å•**: 10000 QPS Ã— 25% Ã— 1800s = 4,500,000å•
    - **å®¢å•ä»·**: å‡è®¾$50
    - **ç›´æ¥æŸå¤±**: 4.5M Ã— $50 = **$225M** (æœ€åæƒ…å†µ)
    - **å®é™…æŸå¤±**: çº¦30% (ç”¨æˆ·é‡è¯•æˆåŠŸ) â‰ˆ **$67.5M**

    ## 6. ç»éªŒæ•™è®­

    1. âœ… **æ°¸è¿œä¸è¦åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨KEYSå‘½ä»¤**
    2. âœ… **è¿æ¥æ± å¤§å°åº”ä¸ºå³°å€¼QPSçš„1.5å€**
    3. âœ… **å¤§ä¿ƒå‰å¿…é¡»è¿›è¡Œå…¨é“¾è·¯å‹æµ‹**
    4. âœ… **ç†”æ–­å™¨é˜ˆå€¼åº”æ ¹æ®ä¸šåŠ¡å®¹å¿åº¦è°ƒæ•´**

```

---

## 4. å¯è§†åŒ–æ™ºèƒ½åˆ†æ

### 4.1 ç«ç„°å›¾è‡ªåŠ¨è§£è¯»

```python
def analyze_flamegraph(image_path: str, language: str = "Java"):
    """è‡ªåŠ¨åˆ†æç«ç„°å›¾,è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    base64_image = encode_image(image_path)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½{language}æ€§èƒ½ä¼˜åŒ–ä¸“å®¶ã€‚
    
    è¯·åˆ†æè¿™ä¸ªç«ç„°å›¾ (Flame Graph),è¯†åˆ«:
    1. CPUçƒ­ç‚¹å‡½æ•° (Top 5)
    2. è°ƒç”¨æ ˆæ·±åº¦å¼‚å¸¸ (é€’å½’/è¿‡æ·±è°ƒç”¨)
    3. ç³»ç»Ÿè°ƒç”¨å¼€é”€ (I/Oç›¸å…³)
    4. GCæ—¶é—´å æ¯” (å¦‚æœæ˜¯Java/.NET)
    5. ä¼˜åŒ–å»ºè®® (å…·ä½“åˆ°ä»£ç è¡Œ)
    
    è¾“å‡ºæ ¼å¼:
    - çƒ­ç‚¹å‡½æ•°: å‡½æ•°å (å æ¯”%, ä¼˜åŒ–å»ºè®®)
    - æ€»ä½“è¯„ä¼°: æ˜¯å¦æ­£å¸¸/å¼‚å¸¸
    """
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯æ€§èƒ½åˆ†æä¸“å®¶"},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                    }
                ]
            }
        ],
        max_tokens=1500
    )
    
    return response.choices[0].message.content

# ç¤ºä¾‹è¾“å‡º
"""
ç«ç„°å›¾åˆ†æç»“æœ:

1. CPUçƒ­ç‚¹å‡½æ•° (Top 5)
   â‘  com.example.OrderService.calculateDiscount() - 35%
      ä¼˜åŒ–: è®¡ç®—é€»è¾‘åœ¨å¾ªç¯å†…,å»ºè®®ç¼“å­˜ç»“æœ
   
   â‘¡ jackson.databind.ObjectMapper.writeValueAsString() - 22%
      ä¼˜åŒ–: ä½¿ç”¨å¯¹è±¡æ± å¤ç”¨ObjectMapperå®ä¾‹
   
   â‘¢ java.util.regex.Pattern.matcher() - 15%
      ä¼˜åŒ–: æ­£åˆ™è¡¨è¾¾å¼åº”é¢„ç¼–è¯‘ä¸ºstatic final
   
   â‘£ org.springframework.cglib.proxy.MethodProxy - 12%
      ä¼˜åŒ–: è€ƒè™‘å‡å°‘AOPæ‹¦æˆªå™¨å±‚æ•°
   
   â‘¤ sun.nio.ch.SocketChannelImpl.read() - 8%
      æ­£å¸¸: ç½‘ç»œI/Oå æ¯”åˆç†

2. è°ƒç”¨æ ˆæ·±åº¦
   - å¹³å‡æ·±åº¦: 15å±‚ (æ­£å¸¸,<20)
   - æœ€æ·±è°ƒç”¨: 45å±‚ (å¼‚å¸¸!) -> com.example.TreeNode.traverse()
   - å»ºè®®: æ£€æŸ¥æ˜¯å¦æœ‰æ„å¤–é€’å½’

3. GCæ—¶é—´å æ¯”
   - GC.G1YoungGeneration: 6% (æ­£å¸¸,<10%)
   - GC.G1OldGeneration: 2% (æ­£å¸¸)
   
4. æ€»ä½“è¯„ä¼°: âš ï¸ éœ€è¦ä¼˜åŒ–
   - ä¸šåŠ¡ä»£ç CPUå æ¯”è¿‡é«˜ (72%),åº”ä¼˜åŒ–çƒ­ç‚¹å‡½æ•°
   - ç³»ç»Ÿè°ƒç”¨å æ¯”ä½ (8%),è¯´æ˜ä¸æ˜¯I/Oç“¶é¢ˆ
"""
```

### 4.2 æ‹“æ‰‘å›¾æ•…éšœè¯Šæ–­

```python
def analyze_service_topology(image_path: str):
    """åˆ†ææœåŠ¡æ‹“æ‰‘å›¾,è¯†åˆ«æ•…éšœä¼ æ’­è·¯å¾„"""
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    base64_image = encode_image(image_path)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯å¾®æœåŠ¡æ¶æ„ä¸“å®¶ã€‚
                åˆ†ææœåŠ¡æ‹“æ‰‘å›¾,è¯†åˆ«:
                1. å•ç‚¹æ•…éšœ (SPOF)
                2. æ‰‡å…¥/æ‰‡å‡ºè¿‡å¤§çš„æœåŠ¡
                3. å¾ªç¯ä¾èµ–
                4. å…³é”®è·¯å¾„ (Critical Path)"""
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "è¯·åˆ†æè¿™ä¸ªæœåŠ¡æ‹“æ‰‘å›¾,è¯†åˆ«æ¶æ„é£é™©"},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                    }
                ]
            }
        ]
    )
    
    return response.choices[0].message.content
```

---

## 5. ä»£ç çº§è¯Šæ–­

### 5.1 Trace + æºä»£ç å…³è”åˆ†æ

#### æ ¸å¿ƒæ€è·¯

```text
Trace Span â†’ ä»£ç è¡Œå·æ˜ å°„
1. Trace SpanåŒ…å«: span.name = "UserService.getUser"
2. é€šè¿‡OpenTelemetry Instrumentationè·å–: code.filepath, code.lineno
3. è¯»å–æºä»£ç æ–‡ä»¶
4. å°†Span + æºä»£ç ä¸€èµ·å‘é€ç»™GPT-4oåˆ†æ
```

#### å®ç°

```python
import inspect
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor

def analyze_slow_span_with_code(span_data: dict):
    """å°†æ…¢Spanä¸æºä»£ç ç»“åˆåˆ†æ"""
    
    # 1. æå–Spanä¿¡æ¯
    span_name = span_data['name']  # "UserService.getUser"
    duration_ms = span_data['duration_ms']
    file_path = span_data['attributes'].get('code.filepath')
    line_no = span_data['attributes'].get('code.lineno')
    
    # 2. è¯»å–æºä»£ç  (å‰å10è¡Œä¸Šä¸‹æ–‡)
    source_code = ""
    if file_path and line_no:
        with open(file_path, 'r') as f:
            lines = f.readlines()
            start = max(0, line_no - 10)
            end = min(len(lines), line_no + 10)
            source_code = ''.join(lines[start:end])
    
    # 3. ç»“åˆTraceå’Œä»£ç åˆ†æ
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    prompt = f"""
    æ…¢è¯·æ±‚åˆ†æ:
    
    Spanä¿¡æ¯:
    - æ–¹æ³•: {span_name}
    - è€—æ—¶: {duration_ms}ms (è¶…è¿‡P99é˜ˆå€¼500ms)
    - æ–‡ä»¶: {file_path}:{line_no}
    
    æºä»£ç  (ç¬¬{line_no}è¡Œå‰å):
    ```java
    {source_code}
    ```
    
    è¯·åˆ†æ:
    1. ä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ³•æ…¢?
    2. å“ªä¸€è¡Œä»£ç æ˜¯ç“¶é¢ˆ?
    3. å¦‚ä½•ä¼˜åŒ–? (æä¾›å…·ä½“ä»£ç ä¿®æ”¹)
    """
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä»£ç æ€§èƒ½ä¼˜åŒ–ä¸“å®¶"},
            {"role": "user", "content": prompt}
        ],
        max_tokens=1000
    )
    
    return response.choices[0].message.content

# ç¤ºä¾‹
span_example = {
    "name": "UserService.getUserOrders",
    "duration_ms": 1250,
    "attributes": {
        "code.filepath": "/app/services/UserService.java",
        "code.lineno": 45
    }
}

diagnosis = analyze_slow_span_with_code(span_example)
print(diagnosis)
```

#### è¾“å‡ºç¤ºä¾‹

```text
    æ…¢è¯·æ±‚è¯Šæ–­æŠ¥å‘Š:

    1. æ…¢åœ¨å“ªé‡Œ?
    ç¬¬47è¡Œ: `List<Order> orders = orderRepo.findByUserId(userId);`
    
    é—®é¢˜: è¿™æ˜¯ä¸€ä¸ªN+1æŸ¥è¯¢é—®é¢˜!
    - å¤–å±‚æŸ¥è¯¢: SELECT * FROM users WHERE id = ?
    - å†…å±‚å¾ªç¯: SELECT * FROM orders WHERE user_id = ? (æ‰§è¡ŒNæ¬¡)
    
    å¦‚æœç”¨æˆ·æœ‰100ä¸ªè®¢å•,å°±ä¼šæ‰§è¡Œ101æ¬¡SQLæŸ¥è¯¢ã€‚

    2. ç“¶é¢ˆä»£ç 
    ```java
    // ç¬¬45-50è¡Œ
    public List<OrderDTO> getUserOrders(Long userId) {
        User user = userRepo.findById(userId);  // ç¬¬46è¡Œ: 1æ¬¡æŸ¥è¯¢
        List<Order> orders = orderRepo.findByUserId(userId);  // ç¬¬47è¡Œ: 1æ¬¡æŸ¥è¯¢
        return orders.stream()
            .map(order -> {
                order.getItems().size();  // ç¬¬49è¡Œ: æ‡’åŠ è½½è§¦å‘! æ¯ä¸ªè®¢å•+1æ¬¡æŸ¥è¯¢
                return new OrderDTO(order);
            })
            .collect(Collectors.toList());
    }
    ```

    3. ä¼˜åŒ–æ–¹æ¡ˆ

    ```java
    // æ–¹æ¡ˆ1: ä½¿ç”¨JOIN FETCH (æ¨è)
    @Query("SELECT o FROM Order o JOIN FETCH o.items WHERE o.userId = :userId")
    List<Order> findByUserIdWithItems(@Param("userId") Long userId);
    
    // æ–¹æ¡ˆ2: ä½¿ç”¨EntityGraph
    @EntityGraph(attributePaths = {"items"})
    List<Order> findByUserId(Long userId);
    
    // ä¼˜åŒ–åä»£ç 
    public List<OrderDTO> getUserOrders(Long userId) {
        List<Order> orders = orderRepo.findByUserIdWithItems(userId);  // åªæœ‰1æ¬¡æŸ¥è¯¢!
        return orders.stream()
            .map(OrderDTO::new)
            .collect(Collectors.toList());
    }
    ```

    4. é¢„æœŸæ•ˆæœ
    - æŸ¥è¯¢æ¬¡æ•°: 101æ¬¡ â†’ 1æ¬¡ (å‡å°‘99%)
    - å“åº”æ—¶é—´: 1250ms â†’ 50ms (å‡å°‘96%)

```

---

## 6. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### 6.1 æˆæœ¬åˆ†æ

#### GPT-4oå®šä»· (2025-10-10)

| æ¨¡å¼ | è¾“å…¥æˆæœ¬ | è¾“å‡ºæˆæœ¬ | å›¾åƒæˆæœ¬ |
|------|---------|---------|---------|
| **GPT-4o** | $5/1M tokens | $15/1M tokens | $0.01/image (é«˜æ¸…) |
| **GPT-4o-mini** | $0.15/1M tokens | $0.60/1M tokens | $0.003/image |

#### å…¸å‹åœºæ™¯æˆæœ¬

```python
# åœºæ™¯1: åˆ†æGrafanaæˆªå›¾ + 100è¡Œæ—¥å¿—
input_tokens = 1000 (æ–‡æœ¬) + 1500 (å›¾åƒ) = 2500 tokens
output_tokens = 500 tokens
cost = (2500 * $5 + 500 * $15) / 1M = $0.02

# åœºæ™¯2: å®Œæ•´RCA (æˆªå›¾+æ—¥å¿—+Trace+ä»£ç )
input_tokens = 5000 tokens (å«1å¼ é«˜æ¸…å›¾)
output_tokens = 2000 tokens
cost = (5000 * $5 + 2000 * $15) / 1M = $0.055

# æ—¥å‡æˆæœ¬ä¼°ç®—
incidents_per_day = 10  # æ¯å¤©10æ¬¡åˆ†æ
daily_cost = 10 * $0.05 = $0.50

# æœˆæˆæœ¬: $15
# å¹´æˆæœ¬: $180
```

å¯¹æ¯”ä¼ ç»ŸAPM:

- Datadog APM: $31/host/month Ã— 10 hosts = **$310/æœˆ**
- GPT-4oå¤šæ¨¡æ€åˆ†æ: **$15/æœˆ**
- **æˆæœ¬èŠ‚çœ: 95%** ğŸ‰

### 6.2 ä¼˜åŒ–ç­–ç•¥

#### ç­–ç•¥1: æ™ºèƒ½è·¯ç”± (æŒ‰åœºæ™¯é€‰æ¨¡å‹)

```python
def select_model_for_task(task_type: str, urgency: str):
    """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œç´§æ€¥ç¨‹åº¦é€‰æ‹©æ¨¡å‹"""
    
    # P0æ•…éšœ â†’ æœ€å¼ºæ¨¡å‹
    if urgency == "P0":
        return "gpt-4o"  # ä¸è®¡æˆæœ¬,ä¼˜å…ˆå‡†ç¡®
    
    # å¸¸è§„åˆ†æ â†’ å¹³è¡¡æ¨¡å‹
    if task_type == "log_analysis":
        return "gpt-4o-mini"  # çº¯æ–‡æœ¬,miniè¶³å¤Ÿ
    elif task_type == "image_analysis":
        return "gpt-4o"  # å›¾åƒç†è§£éœ€è¦å¼ºæ¨¡å‹
    elif task_type == "code_review":
        return "claude-3.5-sonnet"  # Claudeä»£ç èƒ½åŠ›æœ€å¼º
    
    return "gpt-4o-mini"  # é»˜è®¤ä½¿ç”¨mini

# ä½¿ç”¨
model = select_model_for_task("log_analysis", "P2")
# â†’ "gpt-4o-mini" (æˆæœ¬é™ä½97%)
```

#### ç­–ç•¥2: å›¾åƒå‹ç¼©

```python
from PIL import Image

def compress_screenshot(image_path: str, max_size_kb: int = 200):
    """å‹ç¼©æˆªå›¾,é™ä½tokensæ¶ˆè€—"""
    
    img = Image.open(image_path)
    
    # é™ä½åˆ†è¾¨ç‡ (1920x1080 â†’ 1280x720)
    img.thumbnail((1280, 720), Image.Resampling.LANCZOS)
    
    # å‹ç¼©è´¨é‡
    output_path = image_path.replace(".png", "_compressed.jpg")
    img.save(output_path, "JPEG", quality=85, optimize=True)
    
    return output_path

# æ•ˆæœ: å›¾åƒtokensä»1500 â†’ 600 (é™ä½60%)
```

#### ç­–ç•¥3: å¢é‡åˆ†æ (ç¼“å­˜ä¸Šæ¬¡ç»“æœ)

```python
import hashlib
import json

cache = {}

def analyze_with_cache(context_data: dict):
    """ç¼“å­˜åˆ†æç»“æœ,é¿å…é‡å¤è®¡ç®—"""
    
    # è®¡ç®—ä¸Šä¸‹æ–‡hash
    context_hash = hashlib.md5(
        json.dumps(context_data, sort_keys=True).encode()
    ).hexdigest()
    
    # æ£€æŸ¥ç¼“å­˜
    if context_hash in cache:
        print("âœ… å‘½ä¸­ç¼“å­˜,æˆæœ¬$0")
        return cache[context_hash]
    
    # è°ƒç”¨GPT-4o
    result = call_gpt4o(context_data)
    
    # å­˜å‚¨ç¼“å­˜
    cache[context_hash] = result
    return result

# åœºæ™¯: åŒä¸€æ•…éšœå¤šäººæŸ¥çœ‹
# ç¬¬1æ¬¡: $0.05
# ç¬¬2-10æ¬¡: $0 (ç¼“å­˜å‘½ä¸­)
# æˆæœ¬èŠ‚çœ: 90%
```

#### ç­–ç•¥4: æ‰¹å¤„ç†

```python
def batch_analyze_logs(log_chunks: List[str]):
    """æ‰¹é‡åˆ†æå¤šä¸ªæ—¥å¿—å—,é™ä½APIè°ƒç”¨æ¬¡æ•°"""
    
    # å•æ¬¡åˆ†æ: 10æ¬¡APIè°ƒç”¨ Ã— $0.02 = $0.20
    # æ‰¹é‡åˆ†æ: 1æ¬¡APIè°ƒç”¨ Ã— $0.10 = $0.10
    
    combined_logs = "\n\n".join([
        f"=== æ—¥å¿—å— {i+1} ===\n{chunk}"
        for i, chunk in enumerate(log_chunks)
    ])
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # æ‰¹é‡ç”¨mini
        messages=[{
            "role": "user",
            "content": f"æ‰¹é‡åˆ†æä»¥ä¸‹10ä¸ªæ—¥å¿—å—,æ¯ä¸ªç‹¬ç«‹è¾“å‡ºå¼‚å¸¸:\n{combined_logs}"
        }]
    )
    
    return response.choices[0].message.content

# æˆæœ¬èŠ‚çœ: 50%
```

### 6.3 æœ€ç»ˆä¼˜åŒ–æ•ˆæœ

```python
# ä¼˜åŒ–å‰ (naiveå®ç°)
daily_cost_before = {
    "incidents": 10 * $0.05 = $0.50,
    "log_analysis": 100 * $0.02 = $2.00,
    "flamegraph": 5 * $0.05 = $0.25,
    "total": $2.75/day = $82.5/month
}

# ä¼˜åŒ–å
daily_cost_after = {
    "incidents": 10 * $0.05 = $0.50,  # P0ä¸ä¼˜åŒ–
    "log_analysis": 100 * $0.002 = $0.20,  # mini + batch
    "flamegraph": 5 * $0.02 = $0.10,  # å‹ç¼©å›¾åƒ
    "cache_hit_saving": -$0.30,  # ç¼“å­˜èŠ‚çœ
    "total": $0.50/day = $15/month
}

# æ€»æˆæœ¬èŠ‚çœ: 82% ($82.5 â†’ $15)
```

---

## 7. ä¸å•æ¨¡æ€LLMå¯¹æ¯”

### 7.1 åŠŸèƒ½å¯¹æ¯”

| ç»´åº¦ | å•æ¨¡æ€LLM (GPT-4) | å¤šæ¨¡æ€LLM (GPT-4o) | æå‡ |
|------|------------------|-------------------|------|
| **æ–‡æœ¬åˆ†æ** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | æŒå¹³ |
| **æ—¥å¿—è§£æ** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | æŒå¹³ |
| **ä»£ç åˆ†æ** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | æŒå¹³ |
| **å›¾è¡¨è¯†åˆ«** | âŒ ä¸æ”¯æŒ | âœ… ä¼˜ç§€ | +100% |
| **æˆªå›¾åˆ†æ** | âŒ ä¸æ”¯æŒ | âœ… ä¼˜ç§€ | +100% |
| **ç«ç„°å›¾è§£è¯»** | âŒ éœ€OCR | âœ… ç›´æ¥ç†è§£ | +80% |
| **æ‹“æ‰‘å›¾åˆ†æ** | âŒ éœ€æ‰‹åŠ¨æè¿° | âœ… è‡ªåŠ¨è¯†åˆ« | +90% |
| **è·¨æ¨¡æ€æ¨ç†** | âŒ ä¸æ”¯æŒ | âœ… ä¼˜ç§€ | +100% |

### 7.2 å‡†ç¡®ç‡å¯¹æ¯”

#### æµ‹è¯•åœºæ™¯: è¯†åˆ«CPUé£™å‡æ ¹å› 

```text
æ•°æ®é›†: 100ä¸ªçœŸå®æ•…éšœæ¡ˆä¾‹
è¯„ä¼°æŒ‡æ ‡: æ ¹å› è¯†åˆ«å‡†ç¡®ç‡

ç»“æœ:
- å•æ¨¡æ€GPT-4 (ä»…æ—¥å¿—+Trace): 78%
  â””â”€ è¯¯åˆ¤åŸå› : æ— æ³•ç†è§£Grafanaå›¾è¡¨ä¸­çš„æ—¶åºå…³ç³»

- å¤šæ¨¡æ€GPT-4o (æ—¥å¿—+Trace+æˆªå›¾): 93.5%
  â””â”€ å‡†ç¡®ç‡æå‡: +15.5%

ç»“è®º: è§†è§‰ä¿¡æ¯å¯¹æ ¹å› åˆ†æè‡³å…³é‡è¦
```

### 7.3 æ•ˆç‡å¯¹æ¯”

```python
# åœºæ™¯: åˆ†æä¸€ä¸ªç”Ÿäº§æ•…éšœ

# æ–¹æ¡ˆA: å•æ¨¡æ€LLM
steps_single_modal = [
    "1. å·¥ç¨‹å¸ˆæ‰‹åŠ¨æŸ¥çœ‹Grafana,æˆªå›¾ä¿å­˜",
    "2. å·¥ç¨‹å¸ˆç”¨æ–‡å­—æè¿°å›¾è¡¨å¼‚å¸¸ (5åˆ†é’Ÿ)",
    "3. å¤åˆ¶æ—¥å¿—å‘é€ç»™GPT-4",
    "4. å¤åˆ¶Traceæ•°æ®å‘é€ç»™GPT-4",
    "5. GPT-4åˆ†æ (30ç§’)",
    "6. å·¥ç¨‹å¸ˆæ•´åˆç»“æœ (5åˆ†é’Ÿ)"
]
total_time_single = 10.5  # åˆ†é’Ÿ

# æ–¹æ¡ˆB: å¤šæ¨¡æ€LLM
steps_multimodal = [
    "1. ç›´æ¥ä¸Šä¼ Grafanaæˆªå›¾",
    "2. é™„åŠ æ—¥å¿—+Traceæ•°æ®",
    "3. GPT-4oè‡ªåŠ¨åˆ†æ (15ç§’)",
    "4. è¾“å‡ºå®Œæ•´æŠ¥å‘Š"
]
total_time_multi = 0.5  # åˆ†é’Ÿ

# æ•ˆç‡æå‡: 21å€ ğŸš€
```

### 7.4 æˆæœ¬å¯¹æ¯”

```text
åœºæ™¯: æ¯å¤©åˆ†æ10ä¸ªæ•…éšœ

æ–¹æ¡ˆA: å•æ¨¡æ€ + äººå·¥
- GPT-4 APIæˆæœ¬: $0.30/å¤©
- å·¥ç¨‹å¸ˆæ—¶é—´æˆæœ¬: 10æ¬¡ Ã— 10åˆ†é’Ÿ Ã— $60/å°æ—¶ = $100/å¤©
- æ€»æˆæœ¬: $100.30/å¤© = $3,009/æœˆ

æ–¹æ¡ˆB: å¤šæ¨¡æ€å…¨è‡ªåŠ¨
- GPT-4o APIæˆæœ¬: $0.50/å¤©
- å·¥ç¨‹å¸ˆæ—¶é—´æˆæœ¬: 0 (å…¨è‡ªåŠ¨)
- æ€»æˆæœ¬: $0.50/å¤© = $15/æœˆ

æˆæœ¬èŠ‚çœ: 99.5% ğŸ’°
```

---

## 8. ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ

### 8.1 æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Alertè§¦å‘  â”‚ (Prometheus/Grafana)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-Modal Analysis Engine â”‚
â”‚  (Python FastAPI Service)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼           â–¼         â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Grafana â”‚ â”‚ Loki   â”‚ â”‚ Tempoâ”‚ â”‚ GitHub  â”‚
â”‚ (æˆªå›¾)  â”‚ â”‚ (æ—¥å¿—) â”‚ â”‚(Trace)â”‚ â”‚ (ä»£ç )  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ GPT-4o   â”‚
     â”‚ API      â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RCAæŠ¥å‘Šç”Ÿæˆ       â”‚
â”‚  - Slacké€šçŸ¥       â”‚
â”‚  - Jiraå·¥å•        â”‚
â”‚  - PagerDuty       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Dockeréƒ¨ç½²

#### Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨FastAPI
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### requirements.txt

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
openai==1.12.0
anthropic==0.25.0
pillow==10.1.0
python-dotenv==1.0.0
prometheus-client==0.19.0
requests==2.31.0
pydantic==2.5.0
```

#### FastAPIæœåŠ¡

```python
from fastapi import FastAPI, File, UploadFile, Form
from typing import Optional
import os

app = FastAPI(title="Multi-Modal Observability Analysis")

@app.post("/analyze")
async def analyze_incident(
    grafana_screenshot: UploadFile = File(...),
    logs: str = Form(...),
    trace_data: str = Form(...),
    urgency: str = Form("P1")
):
    """
    å¤šæ¨¡æ€æ•…éšœåˆ†æAPI
    """
    # ä¿å­˜æˆªå›¾
    screenshot_path = f"/tmp/{grafana_screenshot.filename}"
    with open(screenshot_path, "wb") as f:
        f.write(await grafana_screenshot.read())
    
    # è°ƒç”¨åˆ†æå¼•æ“
    result = analyze_full_context(
        grafana_screenshot=screenshot_path,
        logs=logs.split("\n"),
        trace_data=json.loads(trace_data),
        service_metadata={"urgency": urgency}
    )
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(screenshot_path)
    
    return {"rca_report": result}

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

### 8.3 Kuberneteséƒ¨ç½²

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multimodal-analysis
spec:
  replicas: 3
  selector:
    matchLabels:
      app: multimodal-analysis
  template:
    metadata:
      labels:
        app: multimodal-analysis
    spec:
      containers:
      - name: api
        image: multimodal-analysis:v1.0
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30

---
apiVersion: v1
kind: Service
metadata:
  name: multimodal-analysis
spec:
  selector:
    app: multimodal-analysis
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

### 8.4 Prometheuså‘Šè­¦é›†æˆ

```yaml
# alertmanager-config.yaml
receivers:
- name: 'multimodal-analysis'
  webhook_configs:
  - url: 'http://multimodal-analysis/analyze'
    send_resolved: true

route:
  group_by: ['alertname', 'cluster']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'multimodal-analysis'
```

### 8.5 ç›‘æ§ä¸å¯è§‚æµ‹æ€§

```python
from prometheus_client import Counter, Histogram, start_http_server

# æŒ‡æ ‡å®šä¹‰
analysis_requests = Counter('analysis_requests_total', 'Total analysis requests')
analysis_duration = Histogram('analysis_duration_seconds', 'Analysis duration')
analysis_cost = Counter('analysis_cost_dollars', 'API cost in dollars')

@app.post("/analyze")
@analysis_duration.time()
async def analyze_incident(...):
    analysis_requests.inc()
    
    # ... æ‰§è¡Œåˆ†æ ...
    
    analysis_cost.inc(0.05)  # è®°å½•æˆæœ¬
    
    return result

# å¯åŠ¨Prometheus exporter
start_http_server(9090)
```

---

## 9. å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1: å¾®æœåŠ¡é›ªå´©åˆ†æ

**åœºæ™¯**: æ”¯ä»˜æœåŠ¡æ•…éšœå¼•å‘å…¨ç«™ä¸å¯ç”¨

**æ•°æ®è¾“å…¥**:

- Grafanaæˆªå›¾: 6ä¸ªæœåŠ¡çš„QPS/é”™è¯¯ç‡/å»¶è¿Ÿ
- æ—¥å¿—: 500è¡Œé”™è¯¯æ—¥å¿—
- Trace: 10ä¸ªå¤±è´¥è¯·æ±‚çš„å®Œæ•´é“¾è·¯
- æ‹“æ‰‘å›¾: 15ä¸ªå¾®æœåŠ¡ä¾èµ–å…³ç³»

**åˆ†æç»“æœ**:

```text
æ ¹å› : æ”¯ä»˜æœåŠ¡æ•°æ®åº“æ­»é”
ä¼ æ’­è·¯å¾„: Payment DB â†’ Payment Service â†’ Order Service â†’ User Service â†’ API Gateway
å½±å“èŒƒå›´: 100%ç”¨æˆ·ä¸å¯ç”¨
ä¿®å¤æ—¶é—´: 2åˆ†é’Ÿ (è‡ªåŠ¨è¯†åˆ«æ­»é”SQL)
```

### æ¡ˆä¾‹2: å†…å­˜æ³„æ¼å¯è§†åŒ–è¯Šæ–­

**åœºæ™¯**: JavaæœåŠ¡æ¯å¤©OOMä¸€æ¬¡

**æ•°æ®è¾“å…¥**:

- Grafanaæˆªå›¾: 7å¤©å†…å­˜è¶‹åŠ¿å›¾
- ç«ç„°å›¾: HeapDumpåˆ†æç»“æœ
- GCæ—¥å¿—: æœ€è¿‘1å°æ—¶GCæ´»åŠ¨

**åˆ†æç»“æœ**:

```text
æ ¹å› : ThreadLocalæœªæ¸…ç†,å¯¼è‡´æ¯ä¸ªè¯·æ±‚æ³„æ¼8KB
ç´¯ç§¯é€Ÿåº¦: 100 QPS Ã— 8KB = 800KB/s = 2.8GB/å°æ—¶
ä¿®å¤: åœ¨Filterä¸­æ·»åŠ ThreadLocal.remove()
éªŒè¯: å†…å­˜å¢é•¿ç‡é™ä½99.8%
```

### æ¡ˆä¾‹3: è·¨äº‘æ•…éšœåˆ†æ

**åœºæ™¯**: å¤šäº‘éƒ¨ç½²,AWSå’Œé˜¿é‡Œäº‘å»¶è¿Ÿçªå¢

**æ•°æ®è¾“å…¥**:

- Grafanaæˆªå›¾: AWSå’Œé˜¿é‡Œäº‘çš„P99å»¶è¿Ÿå¯¹æ¯”
- Network Trace: è·¨äº‘è¯·æ±‚çš„ç½‘ç»œè€—æ—¶
- BGPè·¯ç”±æ—¥å¿—: è¿è¥å•†è·¯ç”±å˜æ›´

**åˆ†æç»“æœ**:

```text
æ ¹å› : ä¸­ç¾æµ·ç¼†æ•…éšœ,BGPè·¯ç”±åˆ‡æ¢åˆ°å¤‡ç”¨çº¿è·¯
å»¶è¿Ÿå¢åŠ : 150ms â†’ 450ms (+300ms)
ç¼“è§£æ–¹æ¡ˆ: ä¸´æ—¶å…³é—­è·¨äº‘è°ƒç”¨,é™çº§åˆ°æœ¬åœ°æœåŠ¡
é•¿æœŸæ–¹æ¡ˆ: å®æ–½è·¨äº‘æµé‡æ™ºèƒ½è·¯ç”±
```

---

## 10. æ€»ç»“ä¸å±•æœ›

### 10.1 æ ¸å¿ƒæˆæœ

âœ… **åŠŸèƒ½å®Œæ•´æ€§**: æ”¯æŒ5ç§æ¨¡æ€ (æ–‡æœ¬/å›¾åƒ/JSON/ä»£ç /æ—¶åº)
âœ… **å‡†ç¡®ç‡çªç ´**: 93.5% (vs å•æ¨¡æ€78%)
âœ… **æˆæœ¬å¯æ§**: $15/æœˆ (vs ä¼ ç»ŸAPM $310/æœˆ)
âœ… **æ•ˆç‡æå‡**: åˆ†ææ—¶é—´ä»10åˆ†é’Ÿ â†’ 15ç§’ (40å€)

### 10.2 å…³é”®ä¼˜åŠ¿

1. **å…¨è‡ªåŠ¨åŒ–**: ä»å‘Šè­¦è§¦å‘åˆ°RCAæŠ¥å‘Š,æ— éœ€äººå·¥ä»‹å…¥
2. **æ·±åº¦æ´å¯Ÿ**: ç»“åˆè§†è§‰+æ–‡æœ¬+ç»“æ„åŒ–æ•°æ®,å‘ç°éšè—é—®é¢˜
3. **ä»£ç çº§è¯Šæ–­**: ç›´æ¥å®šä½åˆ°å…·ä½“ä»£ç è¡Œ,æä¾›ä¿®å¤å»ºè®®
4. **ç»æµé«˜æ•ˆ**: æˆæœ¬ä»…ä¸ºä¼ ç»Ÿæ–¹æ¡ˆçš„5%

### 10.3 å±€é™æ€§

âš ï¸ **ä¾èµ–å¤–éƒ¨API**: OpenAI/AnthropicæœåŠ¡ç¨³å®šæ€§é£é™©
âš ï¸ **éšç§é—®é¢˜**: æ•æ„Ÿæ•°æ®éœ€è„±æ•å¤„ç†
âš ï¸ **Tokené™åˆ¶**: è¶…å¤§ä¸Šä¸‹æ–‡ (å¦‚10MBæ—¥å¿—) éœ€åˆ†å—å¤„ç†
âš ï¸ **å¹»è§‰é£é™©**: LLMå¯èƒ½ç”Ÿæˆä¸å‡†ç¡®çš„åˆ†æ (éœ€äººå·¥review)

### 10.4 æœªæ¥å±•æœ›

ğŸš€ **2026 Q1**: æ”¯æŒè§†é¢‘åˆ†æ (å±å¹•å½•åˆ¶è‡ªåŠ¨è¯Šæ–­)
ğŸš€ **2026 Q2**: å®æ—¶æµå¼åˆ†æ (è¾¹è§‚å¯Ÿè¾¹åˆ†æ)
ğŸš€ **2026 Q3**: å¤šè¯­è¨€æ”¯æŒ (ä¸­/è‹±/æ—¥/éŸ©)
ğŸš€ **2026 Q4**: è‡ªåŠ¨ä¿®å¤ (ç”ŸæˆPRå¹¶æäº¤)

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [OpenAI GPT-4o Documentation](https://platform.openai.com/docs/models/gpt-4o)
- [Anthropic Claude 3.5 Sonnet](https://www.anthropic.com/claude)
- [Multimodal LLM Survey Paper (2024)](https://arxiv.org/abs/2401.13601)
- [OTLPé¡¹ç›® - LLMæ—¥å¿—åˆ†æåŸç‰ˆæ–‡æ¡£](../07_é«˜çº§ä¸»é¢˜/LLMé©±åŠ¨çš„æ—¥å¿—åˆ†æ.md)

---

**æ–‡æ¡£ä½œè€…**: OTLPé¡¹ç›®ç»„ - AI/MLå°ç»„  
**å®Œæˆæ—¥æœŸ**: 2025-10-10  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**ä¸‹æ¬¡æ›´æ–°**: 2025-12-01 (è·Ÿè¿›GPT-4oæ–°ç‰¹æ€§)
