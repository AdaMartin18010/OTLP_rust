# PostgreSQL All-in-One å®ç°ç¤ºä¾‹ä¸ä»£ç æ¨¡æ¿ - 2025å¹´

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£æä¾›äº†PostgreSQL All-in-Oneæ¶æ„çš„å…·ä½“å®ç°ç¤ºä¾‹å’Œä»£ç æ¨¡æ¿ï¼ŒåŒ…æ‹¬å®Œæ•´çš„é¡¹ç›®ç»“æ„ã€æ ¸å¿ƒä»£ç å®ç°ã€é…ç½®æ–‡ä»¶å’Œéƒ¨ç½²è„šæœ¬ã€‚é€šè¿‡è¿™äº›æ¨¡æ¿ï¼Œå¼€å‘å›¢é˜Ÿå¯ä»¥å¿«é€Ÿå¯åŠ¨é¡¹ç›®å¹¶æŒ‰ç…§æœ€ä½³å®è·µè¿›è¡Œå¼€å‘ã€‚

## ğŸ—ï¸ é¡¹ç›®ç»“æ„æ¨¡æ¿

### 1. å®Œæ•´é¡¹ç›®ç»“æ„

```text
postgresql-all-in-one/
â”œâ”€â”€ Cargo.toml                    # å·¥ä½œåŒºé…ç½®
â”œâ”€â”€ Cargo.lock                    # ä¾èµ–é”å®š
â”œâ”€â”€ rust-toolchain.toml           # Rustå·¥å…·é“¾é…ç½®
â”œâ”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ LICENSE                       # è®¸å¯è¯
â”œâ”€â”€ .gitignore                    # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ .github/                      # GitHubé…ç½®
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml               # æŒç»­é›†æˆ
â”‚       â”œâ”€â”€ cd.yml               # æŒç»­éƒ¨ç½²
â”‚       â””â”€â”€ security.yml         # å®‰å…¨æ‰«æ
â”œâ”€â”€ docs/                         # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ architecture/            # æ¶æ„æ–‡æ¡£
â”‚   â”œâ”€â”€ api/                     # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ deployment/              # éƒ¨ç½²æ–‡æ¡£
â”‚   â””â”€â”€ examples/                # ç¤ºä¾‹æ–‡æ¡£
â”œâ”€â”€ crates/                       # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ core/                    # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ database/                # æ•°æ®åº“å±‚
â”‚   â”œâ”€â”€ cache/                   # ç¼“å­˜å±‚
â”‚   â”œâ”€â”€ monitoring/              # ç›‘æ§å±‚
â”‚   â””â”€â”€ security/                # å®‰å…¨å±‚
â”œâ”€â”€ services/                     # æœåŠ¡å±‚
â”‚   â”œâ”€â”€ api-gateway/             # APIç½‘å…³
â”‚   â”œâ”€â”€ query-engine/            # æŸ¥è¯¢å¼•æ“
â”‚   â”œâ”€â”€ data-processor/          # æ•°æ®å¤„ç†å™¨
â”‚   â””â”€â”€ monitoring-service/      # ç›‘æ§æœåŠ¡
â”œâ”€â”€ examples/                     # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ basic-usage/             # åŸºç¡€ä½¿ç”¨
â”‚   â”œâ”€â”€ advanced-features/       # é«˜çº§åŠŸèƒ½
â”‚   â””â”€â”€ performance-tests/       # æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ tests/                        # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ e2e/                     # ç«¯åˆ°ç«¯æµ‹è¯•
â”œâ”€â”€ scripts/                      # è„šæœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ build.sh                 # æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ test.sh                  # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ deploy.sh                # éƒ¨ç½²è„šæœ¬
â”œâ”€â”€ k8s/                          # Kubernetesé…ç½®
â”‚   â”œâ”€â”€ postgres/                # PostgreSQLé…ç½®
â”‚   â”œâ”€â”€ redis/                   # Redisé…ç½®
â”‚   â”œâ”€â”€ monitoring/              # ç›‘æ§é…ç½®
â”‚   â””â”€â”€ ingress/                 # å…¥å£é…ç½®
â”œâ”€â”€ docker/                       # Dockeré…ç½®
â”‚   â”œâ”€â”€ Dockerfile.postgres      # PostgreSQLé•œåƒ
â”‚   â”œâ”€â”€ Dockerfile.redis         # Redisé•œåƒ
â”‚   â””â”€â”€ docker-compose.yml       # ç»„åˆé…ç½®
â””â”€â”€ helm/                         # Helmå›¾è¡¨
    â””â”€â”€ postgresql-all-in-one/   # Helmå›¾è¡¨
        â”œâ”€â”€ Chart.yaml           # å›¾è¡¨é…ç½®
        â”œâ”€â”€ values.yaml          # é»˜è®¤å€¼
        â””â”€â”€ templates/           # æ¨¡æ¿æ–‡ä»¶
```

## ğŸ”§ æ ¸å¿ƒä»£ç å®ç°

### 1. å·¥ä½œåŒºé…ç½® (Cargo.toml)

```toml
[workspace]
resolver = "3"

members = [
    "crates/core",
    "crates/database", 
    "crates/cache",
    "crates/monitoring",
    "crates/security",
    "services/api-gateway",
    "services/query-engine",
    "services/data-processor",
    "services/monitoring-service"
]

[workspace.package]
edition = "2024"
rust-version = "1.90"
authors = ["PostgreSQL All-in-One Team"]
license = "MIT OR Apache-2.0"
repository = "https://github.com/your-org/postgresql-all-in-one"
keywords = ["postgresql", "database", "all-in-one", "rust"]
categories = ["database", "development-tools"]

[workspace.dependencies]
# å¼‚æ­¥è¿è¡Œæ—¶
tokio = { version = "1.47.1", features = ["full"] }
tokio-util = "0.7.16"
futures = "0.3.31"

# æ•°æ®åº“ç›¸å…³
sqlx = { version = "0.8.7", features = ["runtime-tokio-rustls", "postgres", "chrono", "uuid"] }
sea-orm = { version = "1.1.16", features = ["sqlx-postgres", "runtime-tokio-rustls"] }

# ç¼“å­˜ç›¸å…³
redis = "0.32.5"

# åºåˆ—åŒ–
serde = { version = "1.0.227", features = ["derive"] }
serde_json = "1.0.145"

# é”™è¯¯å¤„ç†
anyhow = "1.0.100"
thiserror = "2.0.16"

# æ—¥å¿—å’Œè¿½è¸ª
tracing = "0.1.41"
tracing-subscriber = { version = "0.3.20", features = ["env-filter", "json"] }

# ç›‘æ§
prometheus = "0.14.0"
metrics = "0.24.2"

# æ—¶é—´å¤„ç†
chrono = { version = "0.4.42", features = ["serde"] }
time = { version = "0.3.44", features = ["serde", "macros"] }

# ç½‘ç»œ
reqwest = { version = "0.12.23", features = ["json", "rustls-tls"] }
hyper = { version = "1.7.0", features = ["full"] }

# é…ç½®ç®¡ç†
config = "0.15.16"
toml = "0.9.7"

# å¹¶å‘å’ŒåŒæ­¥
parking_lot = "0.12.4"
dashmap = "6.1.0"
crossbeam = "0.8.4"

# æµ‹è¯•
tokio-test = "0.4.4"
criterion = "0.7.0"
mockall = "0.13.1"

[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
strip = "symbols"
panic = "abort"

[profile.dev]
opt-level = 0
debug = true
incremental = true
```

### 2. æ ¸å¿ƒåº“å®ç° (crates/core/src/lib.rs)

```rust
//! # PostgreSQL All-in-One Core Library
//!
//! æ ¸å¿ƒåº“æä¾›åŸºç¡€ç±»å‹ã€é”™è¯¯å¤„ç†å’Œé…ç½®ç®¡ç†åŠŸèƒ½

pub mod config;
pub mod error;
pub mod types;
pub mod traits;

pub use config::*;
pub use error::*;
pub use types::*;
pub use traits::*;

/// åº“ç‰ˆæœ¬ä¿¡æ¯
pub const VERSION: &str = env!("CARGO_PKG_VERSION");

/// åº“åç§°
pub const NAME: &str = env!("CARGO_PKG_NAME");
```

### 3. é…ç½®ç®¡ç† (crates/core/src/config.rs)

```rust
use serde::{Deserialize, Serialize};
use std::time::Duration;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppConfig {
    pub database: DatabaseConfig,
    pub cache: CacheConfig,
    pub monitoring: MonitoringConfig,
    pub security: SecurityConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DatabaseConfig {
    pub url: String,
    pub max_connections: u32,
    pub min_connections: u32,
    pub acquire_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
    pub health_check_interval: Duration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheConfig {
    pub host: String,
    pub port: u16,
    pub password: Option<String>,
    pub database: u8,
    pub default_ttl: Duration,
    pub max_connections: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MonitoringConfig {
    pub prometheus_port: u16,
    pub metrics_path: String,
    pub health_check_path: String,
    pub log_level: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityConfig {
    pub enable_ssl: bool,
    pub ssl_cert_path: Option<String>,
    pub ssl_key_path: Option<String>,
    pub max_connections_per_ip: u32,
    pub rate_limit_per_minute: u32,
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            database: DatabaseConfig::default(),
            cache: CacheConfig::default(),
            monitoring: MonitoringConfig::default(),
            security: SecurityConfig::default(),
        }
    }
}

impl Default for DatabaseConfig {
    fn default() -> Self {
        Self {
            url: "postgresql://postgres:password@localhost:5432/myapp".to_string(),
            max_connections: 100,
            min_connections: 10,
            acquire_timeout: Duration::from_secs(30),
            idle_timeout: Duration::from_secs(600),
            max_lifetime: Duration::from_secs(1800),
            health_check_interval: Duration::from_secs(60),
        }
    }
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            host: "localhost".to_string(),
            port: 6379,
            password: None,
            database: 0,
            default_ttl: Duration::from_secs(3600),
            max_connections: 100,
        }
    }
}

impl Default for MonitoringConfig {
    fn default() -> Self {
        Self {
            prometheus_port: 9090,
            metrics_path: "/metrics".to_string(),
            health_check_path: "/health".to_string(),
            log_level: "info".to_string(),
        }
    }
}

impl Default for SecurityConfig {
    fn default() -> Self {
        Self {
            enable_ssl: false,
            ssl_cert_path: None,
            ssl_key_path: None,
            max_connections_per_ip: 1000,
            rate_limit_per_minute: 1000,
        }
    }
}

impl AppConfig {
    pub fn from_file(path: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let content = std::fs::read_to_string(path)?;
        let config: AppConfig = toml::from_str(&content)?;
        Ok(config)
    }

    pub fn from_env() -> Result<Self, Box<dyn std::error::Error>> {
        let mut config = AppConfig::default();
        
        if let Ok(url) = std::env::var("DATABASE_URL") {
            config.database.url = url;
        }
        
        if let Ok(host) = std::env::var("REDIS_HOST") {
            config.cache.host = host;
        }
        
        if let Ok(port) = std::env::var("REDIS_PORT") {
            config.cache.port = port.parse()?;
        }
        
        Ok(config)
    }
}
```

### 4. é”™è¯¯å¤„ç† (crates/core/src/error.rs)

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum AppError {
    #[error("Database error: {0}")]
    Database(#[from] sqlx::Error),
    
    #[error("Redis error: {0}")]
    Redis(#[from] redis::RedisError),
    
    #[error("Configuration error: {0}")]
    Config(String),
    
    #[error("Validation error: {0}")]
    Validation(String),
    
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
    
    #[error("Timeout error: {0}")]
    Timeout(String),
    
    #[error("Authentication error: {0}")]
    Authentication(String),
    
    #[error("Authorization error: {0}")]
    Authorization(String),
    
    #[error("Rate limit exceeded")]
    RateLimitExceeded,
    
    #[error("Resource not found: {0}")]
    NotFound(String),
    
    #[error("Internal server error: {0}")]
    Internal(String),
}

pub type Result<T> = std::result::Result<T, AppError>;

impl AppError {
    pub fn config(msg: impl Into<String>) -> Self {
        Self::Config(msg.into())
    }
    
    pub fn validation(msg: impl Into<String>) -> Self {
        Self::Validation(msg.into())
    }
    
    pub fn timeout(msg: impl Into<String>) -> Self {
        Self::Timeout(msg.into())
    }
    
    pub fn authentication(msg: impl Into<String>) -> Self {
        Self::Authentication(msg.into())
    }
    
    pub fn authorization(msg: impl Into<String>) -> Self {
        Self::Authorization(msg.into())
    }
    
    pub fn not_found(msg: impl Into<String>) -> Self {
        Self::NotFound(msg.into())
    }
    
    pub fn internal(msg: impl Into<String>) -> Self {
        Self::Internal(msg.into())
    }
}
```

### 5. æ•°æ®åº“è¿æ¥æ±  (crates/database/src/connection/pool.rs)

```rust
use sqlx::{PgPool, PgConnection, Error as SqlxError};
use std::time::{Duration, Instant};
use std::sync::Arc;
use tokio::sync::{RwLock, Semaphore};
use serde::{Deserialize, Serialize};
use tracing::{info, warn, error};

use crate::core::{AppError, Result};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PoolConfig {
    pub max_connections: u32,
    pub min_connections: u32,
    pub acquire_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
    pub health_check_interval: Duration,
}

#[derive(Debug)]
pub struct ConnectionStats {
    pub total_connections: u32,
    pub active_connections: u32,
    pub idle_connections: u32,
    pub waiting_requests: u32,
    pub total_requests: u64,
    pub successful_requests: u64,
    pub failed_requests: u64,
    pub average_response_time: Duration,
}

pub struct DatabasePool {
    pool: PgPool,
    config: PoolConfig,
    stats: Arc<RwLock<ConnectionStats>>,
    semaphore: Arc<Semaphore>,
    health_check_task: Option<tokio::task::JoinHandle<()>>,
}

impl DatabasePool {
    pub async fn new(database_url: &str, config: PoolConfig) -> Result<Self> {
        let pool = PgPool::builder()
            .max_connections(config.max_connections)
            .min_connections(config.min_connections)
            .acquire_timeout(config.acquire_timeout)
            .idle_timeout(config.idle_timeout)
            .max_lifetime(config.max_lifetime)
            .build(database_url)
            .await
            .map_err(AppError::Database)?;

        let stats = Arc::new(RwLock::new(ConnectionStats {
            total_connections: 0,
            active_connections: 0,
            idle_connections: 0,
            waiting_requests: 0,
            total_requests: 0,
            successful_requests: 0,
            failed_requests: 0,
            average_response_time: Duration::from_millis(0),
        }));

        let semaphore = Arc::new(Semaphore::new(config.max_connections as usize));

        let mut pool_instance = Self {
            pool,
            config,
            stats,
            semaphore,
            health_check_task: None,
        };

        pool_instance.start_health_check().await;
        Ok(pool_instance)
    }

    pub async fn with_connection<F, Fut, R>(&self, f: F) -> Result<R>
    where
        F: FnOnce(PgConnection) -> Fut,
        Fut: std::future::Future<Output = Result<R>> + Send + 'static,
        R: Send,
    {
        let start = Instant::now();
        let _permit = self.semaphore.acquire().await
            .map_err(|_| AppError::internal("Failed to acquire semaphore permit"))?;

        self.update_stats(|stats| {
            stats.waiting_requests += 1;
            stats.total_requests += 1;
        }).await;

        let result = async {
            let mut conn = self.pool.acquire().await
                .map_err(AppError::Database)?;
            
            self.update_stats(|stats| {
                stats.active_connections += 1;
                stats.waiting_requests -= 1;
            }).await;

            let result = f(conn).await;

            self.update_stats(|stats| {
                stats.active_connections -= 1;
                if result.is_ok() {
                    stats.successful_requests += 1;
                } else {
                    stats.failed_requests += 1;
                }
            }).await;

            result
        }.await;

        let duration = start.elapsed();
        self.update_stats(|stats| {
            stats.average_response_time = Duration::from_millis(
                (stats.average_response_time.as_millis() + duration.as_millis()) / 2
            );
        }).await;

        result
    }

    pub async fn with_transaction<F, Fut, R>(&self, f: F) -> Result<R>
    where
        F: FnOnce(sqlx::Transaction<'_, sqlx::Postgres>) -> Fut,
        Fut: std::future::Future<Output = Result<R>> + Send + 'static,
        R: Send,
    {
        let start = Instant::now();
        let _permit = self.semaphore.acquire().await
            .map_err(|_| AppError::internal("Failed to acquire semaphore permit"))?;

        self.update_stats(|stats| {
            stats.waiting_requests += 1;
            stats.total_requests += 1;
        }).await;

        let result = async {
            let mut tx = self.pool.begin().await
                .map_err(AppError::Database)?;
            
            self.update_stats(|stats| {
                stats.active_connections += 1;
                stats.waiting_requests -= 1;
            }).await;

            let result = f(tx).await;

            self.update_stats(|stats| {
                stats.active_connections -= 1;
                if result.is_ok() {
                    stats.successful_requests += 1;
                } else {
                    stats.failed_requests += 1;
                }
            }).await;

            if result.is_ok() {
                tx.commit().await.map_err(AppError::Database)?;
            } else {
                tx.rollback().await.map_err(AppError::Database)?;
            }

            result
        }.await;

        let duration = start.elapsed();
        self.update_stats(|stats| {
            stats.average_response_time = Duration::from_millis(
                (stats.average_response_time.as_millis() + duration.as_millis()) / 2
            );
        }).await;

        result
    }

    pub async fn get_stats(&self) -> ConnectionStats {
        self.stats.read().await.clone()
    }

    pub async fn health_check(&self) -> bool {
        match sqlx::query("SELECT 1").fetch_one(&self.pool).await {
            Ok(_) => true,
            Err(e) => {
                error!("Health check failed: {}", e);
                false
            }
        }
    }

    async fn start_health_check(&mut self) {
        let pool = self.pool.clone();
        let stats = self.stats.clone();
        let interval = self.config.health_check_interval;

        let task = tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);
            loop {
                interval_timer.tick().await;
                
                match sqlx::query("SELECT 1").fetch_one(&pool).await {
                    Ok(_) => {
                        info!("Database health check passed");
                    }
                    Err(e) => {
                        error!("Database health check failed: {}", e);
                    }
                }

                // æ›´æ–°è¿æ¥ç»Ÿè®¡
                if let Ok(mut stats_guard) = stats.write().await {
                    stats_guard.total_connections = pool.size();
                    stats_guard.idle_connections = pool.num_idle();
                }
            }
        });

        self.health_check_task = Some(task);
    }

    async fn update_stats<F>(&self, f: F)
    where
        F: FnOnce(&mut ConnectionStats),
    {
        if let Ok(mut stats) = self.stats.write().await {
            f(&mut stats);
        }
    }
}

impl Drop for DatabasePool {
    fn drop(&mut self) {
        if let Some(task) = self.health_check_task.take() {
            task.abort();
        }
    }
}
```

## ğŸš€ éƒ¨ç½²è„šæœ¬

### 1. æ„å»ºè„šæœ¬ (scripts/build.sh)

```bash
#!/bin/bash

# PostgreSQL All-in-One æ„å»ºè„šæœ¬
set -e

echo "ğŸš€ å¼€å§‹æ„å»º PostgreSQL All-in-One..."

# æ£€æŸ¥ Rust ç‰ˆæœ¬
echo "ğŸ“‹ æ£€æŸ¥ Rust ç‰ˆæœ¬..."
rustc --version
cargo --version

# æ¸…ç†ä¹‹å‰çš„æ„å»º
echo "ğŸ§¹ æ¸…ç†ä¹‹å‰çš„æ„å»º..."
cargo clean

# è¿è¡Œæµ‹è¯•
echo "ğŸ§ª è¿è¡Œæµ‹è¯•..."
cargo test --workspace

# è¿è¡Œ clippy æ£€æŸ¥
echo "ğŸ” è¿è¡Œ clippy æ£€æŸ¥..."
cargo clippy --workspace -- -D warnings

# è¿è¡Œæ ¼å¼åŒ–æ£€æŸ¥
echo "ğŸ“ è¿è¡Œæ ¼å¼åŒ–æ£€æŸ¥..."
cargo fmt --all -- --check

# æ„å»ºå‘å¸ƒç‰ˆæœ¬
echo "ğŸ”¨ æ„å»ºå‘å¸ƒç‰ˆæœ¬..."
cargo build --release --workspace

# æ„å»º Docker é•œåƒ
echo "ğŸ³ æ„å»º Docker é•œåƒ..."
docker build -t postgresql-all-in-one:latest -f docker/Dockerfile.postgres .
docker build -t postgresql-all-in-one-redis:latest -f docker/Dockerfile.redis .

echo "âœ… æ„å»ºå®Œæˆï¼"
```

### 2. æµ‹è¯•è„šæœ¬ (scripts/test.sh)

```bash
#!/bin/bash

# PostgreSQL All-in-One æµ‹è¯•è„šæœ¬
set -e

echo "ğŸ§ª å¼€å§‹è¿è¡Œæµ‹è¯•..."

# å¯åŠ¨æµ‹è¯•ç¯å¢ƒ
echo "ğŸš€ å¯åŠ¨æµ‹è¯•ç¯å¢ƒ..."
docker-compose -f docker/docker-compose.test.yml up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# è¿è¡Œå•å…ƒæµ‹è¯•
echo "ğŸ”¬ è¿è¡Œå•å…ƒæµ‹è¯•..."
cargo test --workspace --lib

# è¿è¡Œé›†æˆæµ‹è¯•
echo "ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•..."
cargo test --workspace --test '*'

# è¿è¡Œæ€§èƒ½æµ‹è¯•
echo "âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•..."
cargo bench --workspace

# è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
echo "ğŸ¯ è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•..."
cargo test --workspace --test e2e

# åœæ­¢æµ‹è¯•ç¯å¢ƒ
echo "ğŸ›‘ åœæ­¢æµ‹è¯•ç¯å¢ƒ..."
docker-compose -f docker/docker-compose.test.yml down

echo "âœ… æµ‹è¯•å®Œæˆï¼"
```

### 3. éƒ¨ç½²è„šæœ¬ (scripts/deploy.sh)

```bash
#!/bin/bash

# PostgreSQL All-in-One éƒ¨ç½²è„šæœ¬
set -e

ENVIRONMENT=${1:-development}
NAMESPACE=${2:-postgresql-all-in-one}

echo "ğŸš€ å¼€å§‹éƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒ..."

# æ£€æŸ¥ kubectl
if ! command -v kubectl &> /dev/null; then
    echo "âŒ kubectl æœªå®‰è£…"
    exit 1
fi

# æ£€æŸ¥ helm
if ! command -v helm &> /dev/null; then
    echo "âŒ helm æœªå®‰è£…"
    exit 1
fi

# åˆ›å»ºå‘½åç©ºé—´
echo "ğŸ“¦ åˆ›å»ºå‘½åç©ºé—´..."
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# éƒ¨ç½² PostgreSQL
echo "ğŸ˜ éƒ¨ç½² PostgreSQL..."
helm upgrade --install postgresql-all-in-one ./helm/postgresql-all-in-one \
    --namespace $NAMESPACE \
    --values ./helm/postgresql-all-in-one/values-$ENVIRONMENT.yaml \
    --wait

# éƒ¨ç½² Redis
echo "ğŸ”´ éƒ¨ç½² Redis..."
kubectl apply -f k8s/redis/ -n $NAMESPACE

# éƒ¨ç½²ç›‘æ§
echo "ğŸ“Š éƒ¨ç½²ç›‘æ§..."
kubectl apply -f k8s/monitoring/ -n $NAMESPACE

# éƒ¨ç½²å…¥å£
echo "ğŸŒ éƒ¨ç½²å…¥å£..."
kubectl apply -f k8s/ingress/ -n $NAMESPACE

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
echo "â³ ç­‰å¾…éƒ¨ç½²å®Œæˆ..."
kubectl wait --for=condition=available --timeout=300s deployment/postgresql-all-in-one -n $NAMESPACE

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
echo "ğŸ“‹ æ£€æŸ¥éƒ¨ç½²çŠ¶æ€..."
kubectl get pods -n $NAMESPACE
kubectl get services -n $NAMESPACE

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
```

## ğŸ³ Docker é…ç½®

### 1. PostgreSQL Dockerfile (docker/Dockerfile.postgres)

```dockerfile
FROM timescale/timescaledb:latest-pg15

# å®‰è£…æ‰©å±•
RUN apt-get update && apt-get install -y \
    postgresql-15-zhparser \
    postgresql-15-pg-stat-statements \
    postgresql-15-pgcrypto \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY docker/postgresql.conf /etc/postgresql/postgresql.conf
COPY docker/pg_hba.conf /etc/postgresql/pg_hba.conf

# å¤åˆ¶åˆå§‹åŒ–è„šæœ¬
COPY docker/init.sql /docker-entrypoint-initdb.d/

# è®¾ç½®æƒé™
RUN chown -R postgres:postgres /etc/postgresql/
RUN chmod 600 /etc/postgresql/postgresql.conf
RUN chmod 600 /etc/postgresql/pg_hba.conf

# æš´éœ²ç«¯å£
EXPOSE 5432

# å¯åŠ¨å‘½ä»¤
CMD ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
```

### 2. Docker Compose é…ç½® (docker/docker-compose.yml)

```yaml
version: '3.8'

services:
  postgres:
    build:
      context: .
      dockerfile: docker/Dockerfile.postgres
    container_name: postgresql-all-in-one
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init.sql:/docker-entrypoint-initdb.d/init.sql
    command: >
      postgres
      -c shared_buffers=2GB
      -c effective_cache_size=6GB
      -c work_mem=256MB
      -c maintenance_work_mem=1GB
      -c max_connections=200
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: postgresql-all-in-one-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: postgresql-all-in-one-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: postgresql-all-in-one-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-dashboard.json:/var/lib/grafana/dashboards/postgresql-dashboard.json
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  default:
    name: postgresql-all-in-one-network
```

## ğŸ“Š ç›‘æ§é…ç½®

### 1. Prometheus é…ç½® (monitoring/prometheus.yml)

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 2. Grafana ä»ªè¡¨æ¿ (monitoring/grafana-dashboard.json)

```json
{
  "dashboard": {
    "id": null,
    "title": "PostgreSQL All-in-One Dashboard",
    "tags": ["postgresql", "database", "all-in-one"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "postgresql_stat_database_numbackends",
            "legendFormat": "Active Connections"
          }
        ],
        "yAxes": [
          {
            "label": "Connections",
            "min": 0
          }
        ]
      },
      {
        "id": 2,
        "title": "Query Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(postgresql_stat_database_tup_returned[5m])",
            "legendFormat": "Tuples Returned/sec"
          },
          {
            "expr": "rate(postgresql_stat_database_tup_fetched[5m])",
            "legendFormat": "Tuples Fetched/sec"
          }
        ]
      },
      {
        "id": 3,
        "title": "Cache Hit Ratio",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(postgresql_stat_database_blks_hit[5m]) / (rate(postgresql_stat_database_blks_hit[5m]) + rate(postgresql_stat_database_blks_read[5m])) * 100",
            "legendFormat": "Cache Hit Ratio %"
          }
        ],
        "thresholds": "80,90"
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}
```

## ğŸ§ª æµ‹è¯•æ¡†æ¶

### 1. å•å…ƒæµ‹è¯•ç¤ºä¾‹ (tests/unit/database_tests.rs)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    use crate::core::AppConfig;

    #[tokio::test]
    async fn test_connection_pool_creation() {
        let config = PoolConfig::default();
        let pool = DatabasePool::new("postgresql://test:test@localhost:5432/testdb", config).await;
        assert!(pool.is_ok());
    }

    #[tokio::test]
    async fn test_connection_pool_health_check() {
        let config = PoolConfig::default();
        let pool = DatabasePool::new("postgresql://test:test@localhost:5432/testdb", config).await.unwrap();
        let is_healthy = pool.health_check().await;
        assert!(is_healthy);
    }

    #[tokio::test]
    async fn test_query_execution() {
        let config = PoolConfig::default();
        let pool = DatabasePool::new("postgresql://test:test@localhost:5432/testdb", config).await.unwrap();
        
        let result = pool.with_connection(|conn| async move {
            sqlx::query("SELECT 1 as test")
                .fetch_one(conn)
                .await
                .map_err(AppError::Database)
        }).await;
        
        assert!(result.is_ok());
    }
}
```

### 2. é›†æˆæµ‹è¯•ç¤ºä¾‹ (tests/integration/full_system_tests.rs)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;

    #[tokio::test]
    async fn test_full_system_workflow() {
        // åˆå§‹åŒ–ç³»ç»Ÿ
        let db_config = PoolConfig::default();
        let cache_config = CacheConfig::default();
        
        let db_pool = DatabasePool::new("postgresql://test:test@localhost:5432/testdb", db_config).await.unwrap();
        let cache = RedisCache::new(cache_config).unwrap();
        
        // æµ‹è¯•æ•°æ®å†™å…¥
        let result = db_pool.with_connection(|conn| async move {
            sqlx::query("INSERT INTO test_table (name) VALUES ($1)")
                .bind("test")
                .execute(conn)
                .await
                .map_err(AppError::Database)
        }).await;
        
        assert!(result.is_ok());
        
        // æµ‹è¯•ç¼“å­˜
        let cache_result = cache.set("test_key", &"test_value", Some(Duration::from_secs(60))).await;
        assert!(cache_result.is_ok());
        
        let cached_value: Option<String> = cache.get("test_key").await.unwrap();
        assert_eq!(cached_value, Some("test_value".to_string()));
    }
}
```

## ğŸ“‹ æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†PostgreSQL All-in-Oneæ¶æ„çš„å®Œæ•´å®ç°ç¤ºä¾‹å’Œä»£ç æ¨¡æ¿ï¼ŒåŒ…æ‹¬ï¼š

### 1. é¡¹ç›®ç»“æ„

- æ¸…æ™°çš„åˆ†å±‚æ¶æ„
- æ¨¡å—åŒ–çš„ä»£ç ç»„ç»‡
- å®Œæ•´çš„é…ç½®æ–‡ä»¶

### 2. æ ¸å¿ƒå®ç°

- æ•°æ®åº“è¿æ¥æ± 
- ç¼“å­˜ç³»ç»Ÿ
- ç›‘æ§é›†æˆ
- é”™è¯¯å¤„ç†

### 3. éƒ¨ç½²å·¥å…·

- Dockeré…ç½®
- Kuberneteséƒ¨ç½²
- è‡ªåŠ¨åŒ–è„šæœ¬

### 4. æµ‹è¯•æ¡†æ¶

- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•
- æ€§èƒ½æµ‹è¯•

é€šè¿‡è¿™äº›æ¨¡æ¿ï¼Œå¼€å‘å›¢é˜Ÿå¯ä»¥å¿«é€Ÿå¯åŠ¨é¡¹ç›®å¹¶æŒ‰ç…§æœ€ä½³å®è·µè¿›è¡Œå¼€å‘ï¼Œå®ç°ä¸€ä¸ªé«˜æ€§èƒ½ã€é«˜å¯ç”¨ã€æ˜“ç»´æŠ¤çš„PostgreSQL All-in-Oneç³»ç»Ÿã€‚
