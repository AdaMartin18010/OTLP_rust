# 优化方案库

## 目录

- [优化方案库](#优化方案库)
  - [目录](#目录)
  - [概述](#概述)
  - [代码层优化](#代码层优化)
    - [1. 批处理优化](#1-批处理优化)
    - [2. 对象池复用](#2-对象池复用)
    - [3. 零拷贝优化](#3-零拷贝优化)
  - [架构层优化](#架构层优化)
    - [1. 异步处理](#1-异步处理)
    - [2. 缓存策略](#2-缓存策略)
    - [3. 负载均衡](#3-负载均衡)
  - [系统层优化](#系统层优化)
    - [1. 内核参数调优](#1-内核参数调优)
    - [2. 资源限制配置](#2-资源限制配置)
  - [OTLP 专项优化](#otlp-专项优化)
    - [1. Span 压缩](#1-span-压缩)
    - [2. 采样优化](#2-采样优化)
    - [3. 连接池优化](#3-连接池优化)

## 概述

本文档汇总常见性能优化方案，提供可复用的优化模式和最佳实践。

## 代码层优化

### 1. 批处理优化

```rust
// 优化前：逐个处理
for span in spans {
    export_single_span(span).await?;
}

// 优化后：批量处理
const BATCH_SIZE: usize = 1000;
for batch in spans.chunks(BATCH_SIZE) {
    export_batch(batch).await?;
}
```

### 2. 对象池复用

```rust
use crossbeam::queue::ArrayQueue;
use std::sync::Arc;

pub struct ObjectPool<T> {
    pool: Arc<ArrayQueue<T>>,
    factory: Arc<dyn Fn() -> T + Send + Sync>,
}

impl<T> ObjectPool<T> {
    pub fn new(capacity: usize, factory: impl Fn() -> T + Send + Sync + 'static) -> Self {
        let pool = Arc::new(ArrayQueue::new(capacity));
        Self {
            pool,
            factory: Arc::new(factory),
        }
    }

    pub fn acquire(&self) -> PooledObject<T> {
        let obj = self.pool.pop().unwrap_or_else(|| (self.factory)());
        PooledObject {
            obj: Some(obj),
            pool: self.pool.clone(),
        }
    }
}

pub struct PooledObject<T> {
    obj: Option<T>,
    pool: Arc<ArrayQueue<T>>,
}

impl<T> Drop for PooledObject<T> {
    fn drop(&mut self) {
        if let Some(obj) = self.obj.take() {
            let _ = self.pool.push(obj);
        }
    }
}

impl<T> std::ops::Deref for PooledObject<T> {
    type Target = T;
    fn deref(&self) -> &Self::Target {
        self.obj.as_ref().unwrap()
    }
}
```

### 3. 零拷贝优化

```rust
use bytes::{Bytes, BytesMut};

// 使用 Bytes 避免数据拷贝
pub fn serialize_spans_zero_copy(spans: &[Span]) -> Bytes {
    let mut buf = BytesMut::with_capacity(estimate_size(spans));
    
    for span in spans {
        // 直接写入 buffer，避免中间分配
        span.encode(&mut buf);
    }
    
    buf.freeze()
}
```

## 架构层优化

### 1. 异步处理

```rust
use tokio::sync::mpsc;

pub struct AsyncExporter {
    tx: mpsc::Sender<Vec<Span>>,
}

impl AsyncExporter {
    pub fn new(buffer_size: usize) -> Self {
        let (tx, mut rx) = mpsc::channel(buffer_size);
        
        tokio::spawn(async move {
            while let Some(spans) = rx.recv().await {
                // 异步导出
                export_spans_async(spans).await;
            }
        });
        
        Self { tx }
    }

    pub async fn export(&self, spans: Vec<Span>) -> Result<(), SendError> {
        self.tx.send(spans).await
    }
}
```

### 2. 缓存策略

```rust
use lru::LruCache;
use std::sync::Arc;
use parking_lot::Mutex;

pub struct CachedExporter {
    cache: Arc<Mutex<LruCache<String, CachedResult>>>,
}

impl CachedExporter {
    pub fn new(capacity: usize) -> Self {
        Self {
            cache: Arc::new(Mutex::new(LruCache::new(capacity))),
        }
    }

    pub async fn export_with_cache(&self, key: String, spans: Vec<Span>) -> Result<()> {
        // 检查缓存
        if let Some(cached) = self.cache.lock().get(&key) {
            return Ok(cached.clone());
        }

        // 执行导出
        let result = export_spans(spans).await?;

        // 更新缓存
        self.cache.lock().put(key, result.clone());

        Ok(result)
    }
}
```

### 3. 负载均衡

```rust
use std::sync::atomic::{AtomicUsize, Ordering};

pub struct LoadBalancer {
    endpoints: Vec<String>,
    current: AtomicUsize,
}

impl LoadBalancer {
    pub fn new(endpoints: Vec<String>) -> Self {
        Self {
            endpoints,
            current: AtomicUsize::new(0),
        }
    }

    // 轮询策略
    pub fn next_endpoint(&self) -> &str {
        let index = self.current.fetch_add(1, Ordering::Relaxed) % self.endpoints.len();
        &self.endpoints[index]
    }
}
```

## 系统层优化

### 1. 内核参数调优

```bash
# /etc/sysctl.conf

# 增加 TCP 连接队列
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 8192

# TCP 快速回收
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30

# 增加文件描述符限制
fs.file-max = 1000000

# 网络缓冲区
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
```

### 2. 资源限制配置

```bash
# /etc/security/limits.conf

* soft nofile 1000000
* hard nofile 1000000
* soft nproc 65535
* hard nproc 65535
```

## OTLP 专项优化

### 1. Span 压缩

```rust
use flate2::write::GzEncoder;
use flate2::Compression;
use std::io::Write;

pub fn compress_spans(spans: &[u8]) -> Result<Vec<u8>> {
    let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
    encoder.write_all(spans)?;
    Ok(encoder.finish()?)
}
```

### 2. 采样优化

```rust
pub struct AdaptiveSampler {
    target_rate: f64,
    current_rate: AtomicU64,
}

impl AdaptiveSampler {
    pub fn should_sample(&self, trace_id: &[u8]) -> bool {
        let hash = calculate_hash(trace_id);
        let threshold = (self.target_rate * u64::MAX as f64) as u64;
        hash < threshold
    }

    pub fn adjust_rate(&self, actual_load: f64, target_load: f64) {
        let new_rate = self.target_rate * (target_load / actual_load);
        let new_rate = new_rate.clamp(0.0, 1.0);
        
        self.current_rate.store(
            (new_rate * 1000.0) as u64,
            Ordering::Relaxed
        );
    }
}
```

### 3. 连接池优化

```rust
use deadpool::managed::{Manager, Pool, RecycleResult};

pub struct OtlpConnectionManager {
    endpoint: String,
}

#[async_trait::async_trait]
impl Manager for OtlpConnectionManager {
    type Type = OtlpConnection;
    type Error = Error;

    async fn create(&self) -> Result<OtlpConnection, Error> {
        OtlpConnection::connect(&self.endpoint).await
    }

    async fn recycle(&self, conn: &mut OtlpConnection) -> RecycleResult<Error> {
        if conn.is_healthy().await {
            Ok(())
        } else {
            Err(Error::ConnectionUnhealthy.into())
        }
    }
}

pub type OtlpPool = Pool<OtlpConnectionManager>;
```

---

**相关文档**：

- [性能问题识别](./性能问题识别.md)
- [系统瓶颈分析](./系统瓶颈分析.md)
