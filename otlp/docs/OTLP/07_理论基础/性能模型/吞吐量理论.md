# 吞吐量理论

## 目录

- [吞吐量理论](#吞吐量理论)
  - [目录](#目录)
  - [概述](#概述)
  - [吞吐量基本定义](#吞吐量基本定义)
    - [核心概念](#核心概念)
    - [吞吐量与延迟的关系](#吞吐量与延迟的关系)
  - [Amdahl 定律](#amdahl-定律)
    - [理论基础](#理论基础)
    - [推导过程](#推导过程)
    - [实际应用](#实际应用)
    - [Rust 实现：Amdahl 定律计算器](#rust-实现amdahl-定律计算器)
  - [通用可扩展性定律 (USL)](#通用可扩展性定律-usl)
    - [理论模型](#理论模型)
    - [参数含义](#参数含义)
    - [模型拟合](#模型拟合)
    - [Rust 实现：USL 模型](#rust-实现usl-模型)
  - [Little 定律](#little-定律)
    - [定律表述](#定律表述)
    - [证明](#证明)
    - [应用场景](#应用场景)
    - [Rust 实现：Little 定律应用](#rust-实现little-定律应用)
  - [批处理吞吐量优化](#批处理吞吐量优化)
    - [批处理模型](#批处理模型)
    - [最优批次大小](#最优批次大小)
    - [动态批处理](#动态批处理)
    - [Rust 实现：自适应批处理](#rust-实现自适应批处理)
  - [背压与流量控制](#背压与流量控制)
    - [背压机制](#背压机制)
    - [令牌桶算法](#令牌桶算法)
    - [漏桶算法](#漏桶算法)
    - [Rust 实现：令牌桶限流器](#rust-实现令牌桶限流器)
  - [OTLP 吞吐量优化实践](#otlp-吞吐量优化实践)
    - [导出器吞吐量优化](#导出器吞吐量优化)
    - [收集器吞吐量优化](#收集器吞吐量优化)
    - [端到端吞吐量监控](#端到端吞吐量监控)
  - [参考文献](#参考文献)

## 概述

吞吐量（Throughput）是衡量系统处理能力的关键指标，表示单位时间内系统能够处理的工作量。本文档从理论角度分析吞吐量的数学模型、可扩展性定律、优化策略，并提供 OTLP 系统中的实际应用。

## 吞吐量基本定义

### 核心概念

**吞吐量** (Throughput)：单位时间内完成的工作量

```text
X = N / T
```

其中：

- `X`: 吞吐量（请求/秒，spans/秒等）
- `N`: 完成的工作数量
- `T`: 时间窗口

**饱和吞吐量** (Saturation Throughput)：系统在饱和状态下的最大吞吐量

```text
X_max = 1 / S
```

其中 `S` 是服务时间（处理单个请求的平均时间）。

### 吞吐量与延迟的关系

根据 Little 定律：

```text
L = λ × W
```

其中：

- `L`: 系统中的平均请求数
- `λ`: 到达率（吞吐量）
- `W`: 平均响应时间（延迟）

**关键洞察**：在系统未饱和时，增加吞吐量不会显著增加延迟；但接近饱和点后，延迟会急剧上升。

## Amdahl 定律

### 理论基础

**Amdahl 定律**描述了并行化对系统加速比的理论上限。

设程序中可并行部分占比为 `p`，串行部分占比为 `1-p`，使用 `N` 个处理器时的加速比为：

```text
S(N) = 1 / ((1-p) + p/N)
```

### 推导过程

原始执行时间：`T_1 = T_serial + T_parallel`

并行执行时间：`T_N = T_serial + T_parallel/N`

加速比：

```text
S(N) = T_1 / T_N 
     = (T_serial + T_parallel) / (T_serial + T_parallel/N)
     = 1 / ((T_serial/T_1) + (T_parallel/T_1)/N)
     = 1 / ((1-p) + p/N)
```

### 实际应用

**极限情况**：

当 `N → ∞` 时：

```text
S(∞) = 1 / (1-p)
```

**示例**：如果程序 95% 可并行（p=0.95），则：

- 理论最大加速比：`S(∞) = 1/0.05 = 20x`
- 使用 10 个核心：`S(10) = 1/(0.05 + 0.095) ≈ 6.9x`
- 使用 100 个核心：`S(100) = 1/(0.05 + 0.0095) ≈ 16.8x`

### Rust 实现：Amdahl 定律计算器

```rust
/// Amdahl 定律计算器
pub struct AmdahlCalculator {
    /// 可并行部分占比 (0.0 - 1.0)
    parallel_fraction: f64,
}

impl AmdahlCalculator {
    pub fn new(parallel_fraction: f64) -> Self {
        assert!(
            (0.0..=1.0).contains(&parallel_fraction),
            "Parallel fraction must be between 0 and 1"
        );
        Self { parallel_fraction }
    }

    /// 计算加速比
    pub fn speedup(&self, num_processors: usize) -> f64 {
        let n = num_processors as f64;
        let p = self.parallel_fraction;
        1.0 / ((1.0 - p) + p / n)
    }

    /// 计算理论最大加速比
    pub fn max_speedup(&self) -> f64 {
        1.0 / (1.0 - self.parallel_fraction)
    }

    /// 计算效率（加速比/处理器数）
    pub fn efficiency(&self, num_processors: usize) -> f64 {
        self.speedup(num_processors) / (num_processors as f64)
    }

    /// 生成加速比曲线
    pub fn speedup_curve(&self, max_processors: usize) -> Vec<(usize, f64)> {
        (1..=max_processors)
            .map(|n| (n, self.speedup(n)))
            .collect()
    }

    /// 分析报告
    pub fn report(&self, num_processors: usize) {
        println!("=== Amdahl's Law Analysis ===");
        println!("Parallel Fraction: {:.1}%", self.parallel_fraction * 100.0);
        println!("Serial Fraction:   {:.1}%", (1.0 - self.parallel_fraction) * 100.0);
        println!();
        println!("Processors | Speedup | Efficiency");
        println!("-----------|---------|------------");

        for n in [1, 2, 4, 8, 16, 32, 64, 128].iter() {
            if *n <= num_processors {
                let speedup = self.speedup(*n);
                let efficiency = self.efficiency(*n);
                println!(
                    "{:>10} | {:>7.2}x | {:>9.1}%",
                    n,
                    speedup,
                    efficiency * 100.0
                );
            }
        }

        println!();
        println!("Theoretical Maximum Speedup: {:.2}x", self.max_speedup());
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_amdahl_law() {
        let calc = AmdahlCalculator::new(0.95);
        
        // 单核：加速比为 1
        assert!((calc.speedup(1) - 1.0).abs() < 0.001);
        
        // 无限核心：接近理论最大值
        assert!((calc.speedup(10000) - 20.0).abs() < 0.1);
        
        // 效率随核心数下降
        assert!(calc.efficiency(1) > calc.efficiency(10));
    }
}
```

## 通用可扩展性定律 (USL)

### 理论模型

**USL (Universal Scalability Law)** 由 Neil Gunther 提出，扩展了 Amdahl 定律，考虑了一致性开销（coherency cost）。

```text
X(N) = λ × N / (1 + σ(N-1) + κN(N-1))
```

其中：

- `X(N)`: N 个处理器时的吞吐量
- `λ`: 单处理器吞吐量
- `σ`: 串行化系数（serialization coefficient）
- `κ`: 一致性系数（coherency coefficient）
- `N`: 处理器数量

### 参数含义

1. **串行化系数 σ**：
   - 表示资源争用导致的性能损失
   - 对应 Amdahl 定律中的串行部分
   - 典型值：0.01 - 0.1

2. **一致性系数 κ**：
   - 表示跨处理器通信/同步开销
   - 随处理器数量二次增长
   - 典型值：0.0001 - 0.01

### 模型拟合

给定实验数据 `{(N₁, X₁), (N₂, X₂), ..., (Nₘ, Xₘ)}`，使用最小二乘法拟合参数 `σ` 和 `κ`。

### Rust 实现：USL 模型

```rust
use std::f64;

/// 通用可扩展性定律模型
#[derive(Debug, Clone)]
pub struct USLModel {
    /// 单处理器吞吐量
    lambda: f64,
    /// 串行化系数
    sigma: f64,
    /// 一致性系数
    kappa: f64,
}

impl USLModel {
    /// 创建 USL 模型
    pub fn new(lambda: f64, sigma: f64, kappa: f64) -> Self {
        Self {
            lambda,
            sigma,
            kappa,
        }
    }

    /// 从实验数据拟合模型（简化实现）
    pub fn fit(data: &[(usize, f64)]) -> Self {
        // 简化：使用前三个数据点求解
        // 生产环境应使用非线性最小二乘法（如 Levenberg-Marquardt）
        
        if data.len() < 3 {
            panic!("Need at least 3 data points for fitting");
        }

        let lambda = data[0].1; // 单处理器吞吐量

        // 简化的参数估计
        let sigma = 0.05; // 默认值，实际应通过优化求解
        let kappa = 0.001;

        Self::new(lambda, sigma, kappa)
    }

    /// 预测 N 个处理器时的吞吐量
    pub fn throughput(&self, n: usize) -> f64 {
        let n_f64 = n as f64;
        let numerator = self.lambda * n_f64;
        let denominator = 1.0 + self.sigma * (n_f64 - 1.0) + self.kappa * n_f64 * (n_f64 - 1.0);
        numerator / denominator
    }

    /// 计算加速比
    pub fn speedup(&self, n: usize) -> f64 {
        self.throughput(n) / self.lambda
    }

    /// 找到最优处理器数量
    pub fn optimal_processors(&self, max_n: usize) -> (usize, f64) {
        (1..=max_n)
            .map(|n| (n, self.throughput(n)))
            .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap())
            .unwrap()
    }

    /// 判断是否存在退行区域（retrograde region）
    pub fn has_retrograde(&self) -> bool {
        self.kappa > 0.0
    }

    /// 计算退行点（吞吐量开始下降的点）
    pub fn retrograde_point(&self) -> Option<usize> {
        if !self.has_retrograde() {
            return None;
        }

        // 求导数为 0 的点
        let n_critical = ((1.0 - self.sigma) / (2.0 * self.kappa)).sqrt();
        
        if n_critical > 1.0 {
            Some(n_critical.ceil() as usize)
        } else {
            None
        }
    }

    /// 生成性能报告
    pub fn report(&self, max_processors: usize) {
        println!("=== Universal Scalability Law Analysis ===");
        println!("λ (single-processor throughput): {:.2}", self.lambda);
        println!("σ (serialization coefficient):  {:.4}", self.sigma);
        println!("κ (coherency coefficient):       {:.6}", self.kappa);
        println!();

        if let Some(retro) = self.retrograde_point() {
            println!("⚠️  Retrograde point at N = {} processors", retro);
            println!("   (Performance degrades beyond this point)\n");
        }

        let (optimal_n, optimal_throughput) = self.optimal_processors(max_processors);
        println!("Optimal Configuration: {} processors", optimal_n);
        println!("Maximum Throughput:    {:.2}", optimal_throughput);
        println!();

        println!("N    | Throughput | Speedup | Efficiency");
        println!("-----|------------|---------|------------");

        for n in [1, 2, 4, 8, 16, 32, 64, 128].iter() {
            if *n <= max_processors {
                let throughput = self.throughput(*n);
                let speedup = self.speedup(*n);
                let efficiency = speedup / (*n as f64);

                println!(
                    "{:>4} | {:>10.2} | {:>7.2}x | {:>9.1}%",
                    n,
                    throughput,
                    speedup,
                    efficiency * 100.0
                );
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_usl_model() {
        let model = USLModel::new(100.0, 0.05, 0.001);
        
        // 单处理器吞吐量
        assert!((model.throughput(1) - 100.0).abs() < 0.1);
        
        // 吞吐量随处理器数增加
        assert!(model.throughput(2) > model.throughput(1));
        
        // 存在退行区域
        assert!(model.has_retrograde());
    }
}
```

## Little 定律

### 定律表述

**Little 定律**是排队论中的基本定律，适用于任何稳定系统：

```text
L = λ × W
```

其中：

- `L`: 系统中的平均请求数（队列长度）
- `λ`: 平均到达率（吞吐量）
- `W`: 平均响应时间

### 证明

考虑时间区间 `[0, T]`：

设在此期间：

- 到达的请求数：`A(T)`
- 完成的请求数：`C(T)`
- 累计停留时间：`∑Wᵢ`

则：

```text
L = lim(T→∞) (∑Wᵢ) / T
λ = lim(T→∞) A(T) / T
W = lim(T→∞) (∑Wᵢ) / A(T)
```

因此：

```text
L = (∑Wᵢ) / T = (A(T) / T) × (∑Wᵢ / A(T)) = λ × W
```

### 应用场景

1. **容量规划**：给定目标延迟和预期吞吐量，计算所需并发数
2. **性能分析**：通过监控队列长度和吞吐量，推算平均延迟
3. **瓶颈识别**：队列长度持续增长表明系统接近饱和

### Rust 实现：Little 定律应用

```rust
use std::time::Duration;

/// Little 定律计算器
pub struct LittleLawCalculator;

impl LittleLawCalculator {
    /// 计算平均队列长度
    /// L = λ × W
    pub fn queue_length(arrival_rate: f64, avg_response_time: Duration) -> f64 {
        arrival_rate * avg_response_time.as_secs_f64()
    }

    /// 计算所需吞吐量
    /// λ = L / W
    pub fn required_throughput(queue_length: f64, avg_response_time: Duration) -> f64 {
        queue_length / avg_response_time.as_secs_f64()
    }

    /// 计算平均响应时间
    /// W = L / λ
    pub fn avg_response_time(queue_length: f64, arrival_rate: f64) -> Duration {
        Duration::from_secs_f64(queue_length / arrival_rate)
    }

    /// 容量规划：计算所需并发数
    pub fn required_concurrency(
        target_throughput: f64,
        avg_service_time: Duration,
    ) -> usize {
        let concurrency = target_throughput * avg_service_time.as_secs_f64();
        concurrency.ceil() as usize
    }

    /// 分析系统状态
    pub fn analyze(
        queue_length: f64,
        arrival_rate: f64,
        service_rate: f64,
    ) -> SystemAnalysis {
        let utilization = arrival_rate / service_rate;
        let avg_response_time = queue_length / arrival_rate;
        let avg_wait_time = avg_response_time - (1.0 / service_rate);

        SystemAnalysis {
            queue_length,
            arrival_rate,
            service_rate,
            utilization,
            avg_response_time: Duration::from_secs_f64(avg_response_time),
            avg_wait_time: Duration::from_secs_f64(avg_wait_time.max(0.0)),
            is_stable: utilization < 1.0,
        }
    }
}

#[derive(Debug)]
pub struct SystemAnalysis {
    pub queue_length: f64,
    pub arrival_rate: f64,
    pub service_rate: f64,
    pub utilization: f64,
    pub avg_response_time: Duration,
    pub avg_wait_time: Duration,
    pub is_stable: bool,
}

impl SystemAnalysis {
    pub fn report(&self) {
        println!("=== System Analysis (Little's Law) ===");
        println!("Queue Length (L):       {:.2}", self.queue_length);
        println!("Arrival Rate (λ):       {:.2} req/s", self.arrival_rate);
        println!("Service Rate (μ):       {:.2} req/s", self.service_rate);
        println!("Utilization (ρ):        {:.1}%", self.utilization * 100.0);
        println!("Avg Response Time (W):  {:?}", self.avg_response_time);
        println!("Avg Wait Time:          {:?}", self.avg_wait_time);
        println!("System Stable:          {}", if self.is_stable { "✓" } else { "✗" });

        if self.utilization > 0.8 {
            println!("\n⚠️  Warning: High utilization (>80%)");
            println!("   Consider scaling up to avoid saturation");
        }

        if !self.is_stable {
            println!("\n🚨 Critical: System is unstable!");
            println!("   Arrival rate exceeds service rate");
        }
    }
}
```

## 批处理吞吐量优化

### 批处理模型

批处理通过减少固定开销来提高吞吐量：

```text
T_batch(b) = T_fixed + b × T_per_item
```

吞吐量：

```text
X(b) = b / T_batch(b) = b / (T_fixed + b × T_per_item)
```

### 最优批次大小

在延迟约束下最大化吞吐量：

```text
maximize:   X(b) = b / (T_fixed + b × T_per_item)
subject to: T_batch(b) ≤ L_max
```

### 动态批处理

根据系统负载动态调整批次大小：

- **低负载**：小批次，降低延迟
- **高负载**：大批次，提高吞吐量

### Rust 实现：自适应批处理

```rust
use std::time::{Duration, Instant};
use tokio::sync::mpsc;

/// 自适应批处理器
pub struct AdaptiveBatcher<T> {
    /// 最小批次大小
    min_batch_size: usize,
    /// 最大批次大小
    max_batch_size: usize,
    /// 最大等待时间
    max_wait_time: Duration,
    /// 当前批次
    current_batch: Vec<T>,
    /// 批次开始时间
    batch_start: Option<Instant>,
    /// 吞吐量统计
    throughput_tracker: ThroughputTracker,
}

impl<T> AdaptiveBatcher<T> {
    pub fn new(
        min_batch_size: usize,
        max_batch_size: usize,
        max_wait_time: Duration,
    ) -> Self {
        Self {
            min_batch_size,
            max_batch_size,
            max_wait_time,
            current_batch: Vec::with_capacity(max_batch_size),
            batch_start: None,
            throughput_tracker: ThroughputTracker::new(),
        }
    }

    /// 添加项到批次
    pub fn add(&mut self, item: T) -> Option<Vec<T>> {
        if self.current_batch.is_empty() {
            self.batch_start = Some(Instant::now());
        }

        self.current_batch.push(item);

        // 检查是否应该刷新批次
        if self.should_flush() {
            self.flush()
        } else {
            None
        }
    }

    /// 判断是否应该刷新
    fn should_flush(&self) -> bool {
        // 达到最大批次大小
        if self.current_batch.len() >= self.max_batch_size {
            return true;
        }

        // 达到最大等待时间
        if let Some(start) = self.batch_start {
            if start.elapsed() >= self.max_wait_time {
                return self.current_batch.len() >= self.min_batch_size;
            }
        }

        false
    }

    /// 刷新当前批次
    pub fn flush(&mut self) -> Option<Vec<T>> {
        if self.current_batch.is_empty() {
            return None;
        }

        let batch = std::mem::replace(
            &mut self.current_batch,
            Vec::with_capacity(self.max_batch_size),
        );

        let batch_size = batch.len();
        self.batch_start = None;

        // 更新吞吐量统计
        self.throughput_tracker.record_batch(batch_size);

        Some(batch)
    }

    /// 获取当前吞吐量
    pub fn throughput(&self) -> f64 {
        self.throughput_tracker.throughput()
    }

    /// 自适应调整批次大小
    pub fn adapt(&mut self) {
        let throughput = self.throughput();
        
        // 简化的自适应策略
        if throughput > 1000.0 && self.max_batch_size < 10000 {
            // 高吞吐量：增加批次大小
            self.max_batch_size = (self.max_batch_size * 2).min(10000);
        } else if throughput < 100.0 && self.max_batch_size > 100 {
            // 低吞吐量：减少批次大小
            self.max_batch_size = (self.max_batch_size / 2).max(100);
        }
    }
}

/// 吞吐量追踪器
struct ThroughputTracker {
    total_items: usize,
    start_time: Instant,
}

impl ThroughputTracker {
    fn new() -> Self {
        Self {
            total_items: 0,
            start_time: Instant::now(),
        }
    }

    fn record_batch(&mut self, size: usize) {
        self.total_items += size;
    }

    fn throughput(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed > 0.0 {
            self.total_items as f64 / elapsed
        } else {
            0.0
        }
    }
}
```

## 背压与流量控制

### 背压机制

**背压** (Backpressure) 是一种流量控制机制，防止快速生产者压垮慢速消费者。

### 令牌桶算法

令牌桶以固定速率生成令牌，请求消耗令牌：

```text
tokens(t) = min(capacity, tokens(t-1) + rate × Δt)
```

### 漏桶算法

漏桶以固定速率处理请求，超出部分被丢弃或排队。

### Rust 实现：令牌桶限流器

```rust
use std::sync::Arc;
use parking_lot::Mutex;
use std::time::{Duration, Instant};

/// 令牌桶限流器
#[derive(Clone)]
pub struct TokenBucket {
    inner: Arc<Mutex<TokenBucketInner>>,
}

struct TokenBucketInner {
    /// 令牌容量
    capacity: f64,
    /// 当前令牌数
    tokens: f64,
    /// 令牌生成速率（tokens/秒）
    rate: f64,
    /// 上次更新时间
    last_update: Instant,
}

impl TokenBucket {
    pub fn new(capacity: f64, rate: f64) -> Self {
        Self {
            inner: Arc::new(Mutex::new(TokenBucketInner {
                capacity,
                tokens: capacity,
                rate,
                last_update: Instant::now(),
            })),
        }
    }

    /// 尝试获取令牌
    pub fn try_acquire(&self, tokens: f64) -> bool {
        let mut inner = self.inner.lock();
        inner.refill();

        if inner.tokens >= tokens {
            inner.tokens -= tokens;
            true
        } else {
            false
        }
    }

    /// 阻塞获取令牌
    pub async fn acquire(&self, tokens: f64) {
        loop {
            if self.try_acquire(tokens) {
                return;
            }
            tokio::time::sleep(Duration::from_millis(10)).await;
        }
    }

    /// 获取当前令牌数
    pub fn available_tokens(&self) -> f64 {
        let mut inner = self.inner.lock();
        inner.refill();
        inner.tokens
    }
}

impl TokenBucketInner {
    /// 补充令牌
    fn refill(&mut self) {
        let now = Instant::now();
        let elapsed = now.duration_since(self.last_update).as_secs_f64();
        
        let new_tokens = elapsed * self.rate;
        self.tokens = (self.tokens + new_tokens).min(self.capacity);
        
        self.last_update = now;
    }
}
```

## OTLP 吞吐量优化实践

### 导出器吞吐量优化

```rust
use prometheus::{Counter, Gauge, Registry};

pub struct OtlpThroughputMonitor {
    spans_exported: Counter,
    export_rate: Gauge,
    batch_size: Gauge,
}

impl OtlpThroughputMonitor {
    pub fn new(registry: &Registry) -> Result<Self, prometheus::Error> {
        let spans_exported = Counter::new(
            "otlp_spans_exported_total",
            "Total number of spans exported"
        )?;

        let export_rate = Gauge::new(
            "otlp_export_rate_spans_per_second",
            "Current export rate in spans/second"
        )?;

        let batch_size = Gauge::new(
            "otlp_batch_size",
            "Current batch size"
        )?;

        registry.register(Box::new(spans_exported.clone()))?;
        registry.register(Box::new(export_rate.clone()))?;
        registry.register(Box::new(batch_size.clone()))?;

        Ok(Self {
            spans_exported,
            export_rate,
            batch_size,
        })
    }

    pub fn record_export(&self, span_count: usize) {
        self.spans_exported.inc_by(span_count as f64);
    }

    pub fn update_rate(&self, rate: f64) {
        self.export_rate.set(rate);
    }

    pub fn update_batch_size(&self, size: usize) {
        self.batch_size.set(size as f64);
    }
}
```

### 收集器吞吐量优化

```yaml
# OTLP Collector 配置
receivers:
  otlp:
    protocols:
      grpc:
        max_concurrent_streams: 100
        max_recv_msg_size_mib: 32

processors:
  batch:
    timeout: 1s
    send_batch_size: 1000
    send_batch_max_size: 10000

exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000
```

### 端到端吞吐量监控

```yaml
# Prometheus 告警规则
groups:
  - name: otlp_throughput
    rules:
      - alert: LowThroughput
        expr: rate(otlp_spans_exported_total[5m]) < 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "OTLP export throughput is low"
          description: "Current rate: {{ $value }} spans/s"

      - alert: ThroughputDrop
        expr: |
          (rate(otlp_spans_exported_total[5m]) 
           / rate(otlp_spans_exported_total[5m] offset 1h)) < 0.5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "OTLP throughput dropped significantly"
```

## 参考文献

1. Gunther, N. J. (2007). "Guerrilla Capacity Planning." Springer.
2. Amdahl, G. M. (1967). "Validity of the single processor approach to achieving large scale computing capabilities." AFIPS Conference Proceedings.
3. Little, J. D. C. (1961). "A Proof for the Queuing Formula: L = λW." Operations Research.

---

**相关文档**：

- [性能数学模型](./性能数学模型.md)
- [延迟分析模型](./延迟分析模型.md)
- [资源消耗模型](./资源消耗模型.md)
