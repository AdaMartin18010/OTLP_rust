# å¼‚æ­¥ç¼–ç¨‹ä¼˜åŒ–

## ç›®å½•

- [å¼‚æ­¥ç¼–ç¨‹ä¼˜åŒ–](#å¼‚æ­¥ç¼–ç¨‹ä¼˜åŒ–)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ Async/Await æ¨¡å¼](#-asyncawait-æ¨¡å¼)
  - [âš¡ å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–](#-å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–)
  - [ğŸ”„ Stream å¤„ç†](#-stream-å¤„ç†)
  - [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)

## ğŸ“‹ æ¦‚è¿°

Rust çš„å¼‚æ­¥ç¼–ç¨‹åŸºäº Future trait,Tokio æä¾›äº†é«˜æ€§èƒ½çš„å¼‚æ­¥è¿è¡Œæ—¶ã€‚
æœ¬æ–‡æ¡£ä»‹ç»å¼‚æ­¥ç¼–ç¨‹çš„ä¼˜åŒ–æŠ€å·§ã€‚

## ğŸ¯ Async/Await æ¨¡å¼

```rust
/// å¼‚æ­¥è¯·æ±‚å¤„ç†
pub async fn handle_request(request: Request) -> Result<Response, ServiceError> {
    // å¹¶å‘æ‰§è¡Œå¤šä¸ªå¼‚æ­¥æ“ä½œ
    let (user, orders, products) = tokio::join!(
        fetch_user(request.user_id),
        fetch_orders(request.user_id),
        fetch_products(request.product_ids),
    );
    
    let user = user?;
    let orders = orders?;
    let products = products?;
    
    Ok(build_response(user, orders, products))
}

/// é€‰æ‹©æ€§ç­‰å¾…
pub async fn fetch_with_fallback(primary_url: &str, fallback_url: &str) -> Result<Data, FetchError> {
    tokio::select! {
        result = fetch_from_url(primary_url) => {
            result.or_else(|_| fetch_from_url(fallback_url).await)
        }
        _ = tokio::time::sleep(Duration::from_secs(5)) => {
            fetch_from_url(fallback_url).await
        }
    }
}
```

## âš¡ å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–

```rust
/// æ‰¹å¤„ç†ä¼˜åŒ–
pub struct BatchProcessor {
    batch_size: usize,
    batch_timeout: Duration,
}

impl BatchProcessor {
    pub async fn process_items<T>(&self, items: Vec<T>) -> Result<Vec<ProcessedItem>, ProcessError> {
        // åˆ†æ‰¹å¤„ç†
        let mut results = Vec::new();
        
        for chunk in items.chunks(self.batch_size) {
            let futures: Vec<_> = chunk.iter()
                .map(|item| self.process_single(item))
                .collect();
            
            // å¹¶å‘å¤„ç†æ‰¹æ¬¡
            let batch_results = futures::future::try_join_all(futures).await?;
            results.extend(batch_results);
        }
        
        Ok(results)
    }
    
    async fn process_single<T>(&self, item: &T) -> Result<ProcessedItem, ProcessError> {
        // å¤„ç†å•ä¸ªé¡¹ç›®
        Ok(ProcessedItem::default())
    }
}

/// è¿æ¥æ± ä¼˜åŒ–
pub struct AsyncConnectionPool {
    connections: Arc<Mutex<Vec<Connection>>>,
    max_size: usize,
}

impl AsyncConnectionPool {
    pub async fn acquire(&self) -> Result<PooledConnection, PoolError> {
        let mut connections = self.connections.lock().await;
        
        if let Some(conn) = connections.pop() {
            Ok(PooledConnection { conn: Some(conn), pool: Arc::clone(&self.connections) })
        } else if connections.len() < self.max_size {
            let conn = Connection::new().await?;
            Ok(PooledConnection { conn: Some(conn), pool: Arc::clone(&self.connections) })
        } else {
            Err(PoolError::Exhausted)
        }
    }
}
```

## ğŸ”„ Stream å¤„ç†

```rust
use futures::stream::{Stream, StreamExt};

/// å¼‚æ­¥æµå¤„ç†
pub async fn process_stream<S>(mut stream: S) -> Result<(), StreamError>
where
    S: Stream<Item = Event> + Unpin,
{
    while let Some(event) = stream.next().await {
        process_event(event).await?;
    }
    Ok(())
}

/// æµå¼èšåˆ
pub async fn aggregate_stream<S>(stream: S, window_size: usize) -> impl Stream<Item = Aggregated>
where
    S: Stream<Item = Event>,
{
    stream
        .chunks(window_size)
        .map(|chunk| aggregate_events(chunk))
}
```

## ğŸ¯ æœ€ä½³å®è·µ

1. **é¿å…é˜»å¡**: ä¸åœ¨å¼‚æ­¥ä»£ç ä¸­ä½¿ç”¨é˜»å¡æ“ä½œ
2. **åˆç†å¹¶å‘**: ä½¿ç”¨ `join!` å’Œ `select!` å¹¶å‘æ‰§è¡Œ
3. **æ‰¹å¤„ç†**: æ‰¹é‡å¤„ç†å‡å°‘å¼€é”€
4. **è¿æ¥æ± **: å¤ç”¨è¿æ¥å‡å°‘å»ºç«‹å¼€é”€
5. **è¶…æ—¶æ§åˆ¶**: æ‰€æœ‰å¼‚æ­¥æ“ä½œè®¾ç½®è¶…æ—¶

---

**æ€»ç»“**: åˆç†ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹å¯ä»¥æ˜¾è‘—æå‡å¾®æœåŠ¡çš„å¹¶å‘å¤„ç†èƒ½åŠ›ã€‚
