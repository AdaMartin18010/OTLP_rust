# 并发控制与调度

## 目录

- [并发控制与调度](#并发控制与调度)
  - [目录](#目录)
  - [📋 概述](#-概述)
  - [🎯 并发模型](#-并发模型)
  - [⚡ Tokio 调度器](#-tokio-调度器)
  - [🔒 并发控制](#-并发控制)
  - [🎯 最佳实践](#-最佳实践)

## 📋 概述

Rust 的并发模型基于所有权系统,提供了线程安全的并发原语。
Tokio 提供了高性能的异步运行时。

## 🎯 并发模型

```rust
use tokio::sync::{Semaphore, RwLock, Mutex};

/// 并发限制器
pub struct ConcurrencyLimiter {
    semaphore: Arc<Semaphore>,
}

impl ConcurrencyLimiter {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
        }
    }
    
    pub async fn execute<F, T>(&self, f: F) -> Result<T, LimiterError>
    where
        F: Future<Output = T>,
    {
        let _permit = self.semaphore.acquire().await?;
        Ok(f.await)
    }
}
```

## ⚡ Tokio 调度器

```rust
/// 自定义 Tokio 运行时
pub fn create_runtime() -> tokio::runtime::Runtime {
    tokio::runtime::Builder::new_multi_thread()
        .worker_threads(num_cpus::get())
        .thread_name("otlp-worker")
        .thread_stack_size(3 * 1024 * 1024)
        .enable_all()
        .build()
        .unwrap()
}

/// 任务优先级调度
pub struct PriorityScheduler {
    high_priority: Arc<Mutex<VecDeque<Task>>>,
    normal_priority: Arc<Mutex<VecDeque<Task>>>,
    low_priority: Arc<Mutex<VecDeque<Task>>>,
}

impl PriorityScheduler {
    pub async fn schedule(&self, task: Task, priority: Priority) {
        match priority {
            Priority::High => self.high_priority.lock().await.push_back(task),
            Priority::Normal => self.normal_priority.lock().await.push_back(task),
            Priority::Low => self.low_priority.lock().await.push_back(task),
        }
    }
    
    pub async fn next_task(&self) -> Option<Task> {
        // 优先处理高优先级任务
        if let Some(task) = self.high_priority.lock().await.pop_front() {
            return Some(task);
        }
        
        if let Some(task) = self.normal_priority.lock().await.pop_front() {
            return Some(task);
        }
        
        self.low_priority.lock().await.pop_front()
    }
}
```

## 🔒 并发控制

```rust
/// 读写锁优化
pub struct OptimizedCache {
    data: Arc<RwLock<HashMap<String, Value>>>,
}

impl OptimizedCache {
    pub async fn get(&self, key: &str) -> Option<Value> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    pub async fn set(&self, key: String, value: Value) {
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
}

/// 无锁并发
use std::sync::atomic::{AtomicU64, Ordering};

pub struct AtomicCounter {
    count: AtomicU64,
}

impl AtomicCounter {
    pub fn increment(&self) -> u64 {
        self.count.fetch_add(1, Ordering::Relaxed)
    }
}
```

## 🎯 最佳实践

1. **避免阻塞**: 使用异步 I/O
2. **合理并发度**: 根据 CPU 核心数设置
3. **减少锁竞争**: 使用细粒度锁或无锁结构
4. **任务分片**: 将大任务拆分为小任务
5. **背压控制**: 使用信号量限制并发

---

**总结**: 合理的并发控制和调度策略可以充分利用多核性能。
