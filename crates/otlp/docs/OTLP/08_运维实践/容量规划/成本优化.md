# æˆæœ¬ä¼˜åŒ–

## ç›®å½•

- [æˆæœ¬ä¼˜åŒ–](#æˆæœ¬ä¼˜åŒ–)
  - [ç›®å½•](#ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [ğŸ“Š OTLP æˆæœ¬ä¼˜åŒ–æ¶æ„å›¾](#-otlp-æˆæœ¬ä¼˜åŒ–æ¶æ„å›¾)
    - [ğŸ”„ æˆæœ¬ä¼˜åŒ–å†³ç­–æµç¨‹](#-æˆæœ¬ä¼˜åŒ–å†³ç­–æµç¨‹)
    - [ğŸ’° æˆæœ¬åˆ†è§£é¥¼å›¾](#-æˆæœ¬åˆ†è§£é¥¼å›¾)
  - [æˆæœ¬åˆ†æ](#æˆæœ¬åˆ†æ)
    - [æˆæœ¬æ„æˆ](#æˆæœ¬æ„æˆ)
  - [ä¼˜åŒ–ç­–ç•¥](#ä¼˜åŒ–ç­–ç•¥)
    - [1. é‡‡æ ·ç‡ä¼˜åŒ–](#1-é‡‡æ ·ç‡ä¼˜åŒ–)
    - [2. å­˜å‚¨åˆ†å±‚](#2-å­˜å‚¨åˆ†å±‚)
    - [3. èµ„æºå³é…](#3-èµ„æºå³é…)
  - [æˆæœ¬ç›‘æ§](#æˆæœ¬ç›‘æ§)
    - [Prometheus æˆæœ¬æŒ‡æ ‡](#prometheus-æˆæœ¬æŒ‡æ ‡)
    - [æˆæœ¬å‘Šè­¦](#æˆæœ¬å‘Šè­¦)
  - [è¯¦ç»†æˆæœ¬åˆ†ææ¨¡å‹](#è¯¦ç»†æˆæœ¬åˆ†ææ¨¡å‹)
    - [æˆæœ¬è®¡ç®—å™¨](#æˆæœ¬è®¡ç®—å™¨)
  - [ä¼˜åŒ–ç­–ç•¥è¯¦è§£](#ä¼˜åŒ–ç­–ç•¥è¯¦è§£)
    - [1. æ™ºèƒ½é‡‡æ ·ä¼˜åŒ–](#1-æ™ºèƒ½é‡‡æ ·ä¼˜åŒ–)
    - [2. æ•°æ®å‹ç¼©ä¼˜åŒ–](#2-æ•°æ®å‹ç¼©ä¼˜åŒ–)
    - [3. æ‰¹å¤„ç†ä¼˜åŒ–](#3-æ‰¹å¤„ç†ä¼˜åŒ–)
  - [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šé‡‡æ ·ä¼˜åŒ–èŠ‚çœ 80% æˆæœ¬](#æ¡ˆä¾‹1é‡‡æ ·ä¼˜åŒ–èŠ‚çœ-80-æˆæœ¬)
    - [æ¡ˆä¾‹2ï¼šå­˜å‚¨åˆ†å±‚èŠ‚çœ 60% å­˜å‚¨æˆæœ¬](#æ¡ˆä¾‹2å­˜å‚¨åˆ†å±‚èŠ‚çœ-60-å­˜å‚¨æˆæœ¬)
    - [æ¡ˆä¾‹3ï¼šå‹ç¼©ä¼˜åŒ–](#æ¡ˆä¾‹3å‹ç¼©ä¼˜åŒ–)
  - [æˆæœ¬ä¼˜åŒ–æœ€ä½³å®è·µ](#æˆæœ¬ä¼˜åŒ–æœ€ä½³å®è·µ)
    - [1. å»ºç«‹æˆæœ¬æ„è¯†æ–‡åŒ–](#1-å»ºç«‹æˆæœ¬æ„è¯†æ–‡åŒ–)
    - [2. æˆæœ¬ä¼˜åŒ–æ£€æŸ¥æ¸…å•](#2-æˆæœ¬ä¼˜åŒ–æ£€æŸ¥æ¸…å•)
    - [3. æˆæœ¬ä¼˜åŒ–å·¥å…·](#3-æˆæœ¬ä¼˜åŒ–å·¥å…·)

## æ¦‚è¿°

æˆæœ¬ä¼˜åŒ–åœ¨ä¿è¯æ€§èƒ½å’Œå¯é æ€§çš„å‰æä¸‹ï¼Œæœ€å°åŒ–ç³»ç»Ÿè¿è¥æˆæœ¬ã€‚

### ğŸ“Š OTLP æˆæœ¬ä¼˜åŒ–æ¶æ„å›¾

```mermaid
graph TB
    subgraph "æˆæœ¬æ¥æº"
        A1[è®¡ç®—æˆæœ¬<br/>CPU/å†…å­˜]
        A2[å­˜å‚¨æˆæœ¬<br/>çƒ­/æ¸©/å†·]
        A3[ç½‘ç»œæˆæœ¬<br/>å…¥ç«™/å‡ºç«™]
        A4[è®¸å¯æˆæœ¬<br/>å•†ä¸šè½¯ä»¶]
    end
    
    subgraph "ä¼˜åŒ–ç­–ç•¥"
        B1[æ™ºèƒ½é‡‡æ ·<br/>é™ä½æ•°æ®é‡]
        B2[æ•°æ®å‹ç¼©<br/>å‡å°‘å­˜å‚¨]
        B3[æ‰¹å¤„ç†<br/>æé«˜æ•ˆç‡]
        B4[å­˜å‚¨åˆ†å±‚<br/>é™ä½æˆæœ¬]
    end
    
    subgraph "ä¼˜åŒ–æ•ˆæœ"
        C1[æˆæœ¬èŠ‚çœ<br/>80%+]
        C2[æ€§èƒ½æå‡<br/>30%+]
        C3[èµ„æºä¼˜åŒ–<br/>50%+]
    end
    
    A1 --> B1
    A1 --> B3
    A2 --> B2
    A2 --> B4
    A3 --> B1
    A3 --> B3
    
    B1 --> C1
    B2 --> C1
    B3 --> C2
    B4 --> C3
    
    style C1 fill:#90EE90
    style C2 fill:#87CEEB
    style C3 fill:#FFD700
```

### ğŸ”„ æˆæœ¬ä¼˜åŒ–å†³ç­–æµç¨‹

```mermaid
flowchart TD
    Start([å¼€å§‹æˆæœ¬åˆ†æ]) --> Collect[é‡‡é›†æˆæœ¬æ•°æ®]
    Collect --> Analyze[åˆ†ææˆæœ¬ç»“æ„]
    
    Analyze --> Compute{è®¡ç®—æˆæœ¬å æ¯”}
    Analyze --> Storage{å­˜å‚¨æˆæœ¬å æ¯”}
    Analyze --> Network{ç½‘ç»œæˆæœ¬å æ¯”}
    
    Compute -->|>50%| ComputeOpt[è®¡ç®—ä¼˜åŒ–]
    Storage -->|>30%| StorageOpt[å­˜å‚¨ä¼˜åŒ–]
    Network -->|>20%| NetworkOpt[ç½‘ç»œä¼˜åŒ–]
    
    ComputeOpt --> Sampling[å¯ç”¨æ™ºèƒ½é‡‡æ ·]
    ComputeOpt --> Batch[ä¼˜åŒ–æ‰¹å¤„ç†]
    ComputeOpt --> Rightsize[èµ„æºå³é…]
    
    StorageOpt --> Compress[å¯ç”¨å‹ç¼©]
    StorageOpt --> Tier[å­˜å‚¨åˆ†å±‚]
    StorageOpt --> Retention[ä¼˜åŒ–ä¿ç•™æœŸ]
    
    NetworkOpt --> LocalCache[æœ¬åœ°ç¼“å­˜]
    NetworkOpt --> Compress2[æ•°æ®å‹ç¼©]
    NetworkOpt --> Batch2[æ‰¹é‡ä¼ è¾“]
    
    Sampling --> Evaluate[è¯„ä¼°æ•ˆæœ]
    Batch --> Evaluate
    Rightsize --> Evaluate
    Compress --> Evaluate
    Tier --> Evaluate
    Retention --> Evaluate
    LocalCache --> Evaluate
    Compress2 --> Evaluate
    Batch2 --> Evaluate
    
    Evaluate --> Success{æˆæœ¬é™ä½>20%?}
    Success -->|æ˜¯| Record[è®°å½•ä¼˜åŒ–æ–¹æ¡ˆ]
    Success -->|å¦| Adjust[è°ƒæ•´ç­–ç•¥]
    
    Adjust --> Analyze
    Record --> Monitor[æŒç»­ç›‘æ§]
    Monitor --> End([ç»“æŸ])
    
    style Start fill:#90EE90
    style End fill:#FFB6C1
    style Success fill:#FFD700
    style Record fill:#87CEEB
```

### ğŸ’° æˆæœ¬åˆ†è§£é¥¼å›¾

```mermaid
pie title OTLP æˆæœ¬åˆ†è§£ï¼ˆå…¸å‹åœºæ™¯ï¼‰
    "è®¡ç®—æˆæœ¬ï¼ˆCPU/å†…å­˜ï¼‰" : 45
    "å­˜å‚¨æˆæœ¬ï¼ˆçƒ­å­˜å‚¨ï¼‰" : 30
    "ç½‘ç»œæˆæœ¬ï¼ˆä¼ è¾“ï¼‰" : 15
    "å­˜å‚¨æˆæœ¬ï¼ˆæ¸©/å†·ï¼‰" : 8
    "è®¸å¯æˆæœ¬" : 2
```

## æˆæœ¬åˆ†æ

### æˆæœ¬æ„æˆ

```rust
pub struct CostBreakdown {
    pub compute_cost: f64,      // è®¡ç®—èµ„æºæˆæœ¬
    pub storage_cost: f64,      // å­˜å‚¨æˆæœ¬
    pub network_cost: f64,      // ç½‘ç»œä¼ è¾“æˆæœ¬
    pub license_cost: f64,      // è®¸å¯è¯æˆæœ¬
}

impl CostBreakdown {
    pub fn total(&self) -> f64 {
        self.compute_cost + self.storage_cost + self.network_cost + self.license_cost
    }

    pub fn cost_per_span(&self, total_spans: u64) -> f64 {
        if total_spans == 0 {
            return 0.0;
        }
        self.total() / total_spans as f64
    }
}
```

## ä¼˜åŒ–ç­–ç•¥

### 1. é‡‡æ ·ç‡ä¼˜åŒ–

```rust
pub struct CostAwareSampler {
    target_cost_per_day: f64,
    current_span_rate: f64,
    cost_per_span: f64,
}

impl CostAwareSampler {
    pub fn calculate_optimal_sampling_rate(&self) -> f64 {
        let max_spans_per_day = self.target_cost_per_day / self.cost_per_span;
        let current_spans_per_day = self.current_span_rate * 86400.0;

        if current_spans_per_day <= max_spans_per_day {
            return 1.0; // æ— éœ€é‡‡æ ·
        }

        max_spans_per_day / current_spans_per_day
    }
}
```

### 2. å­˜å‚¨åˆ†å±‚

```rust
pub enum StorageTier {
    Hot,    // SSD, å¿«é€Ÿè®¿é—®
    Warm,   // HDD, ä¸­é€Ÿè®¿é—®
    Cold,   // å¯¹è±¡å­˜å‚¨, å½’æ¡£
}

pub struct TieredStorage {
    hot_retention_days: usize,
    warm_retention_days: usize,
}

impl TieredStorage {
    pub fn calculate_cost_savings(&self, total_spans_per_day: u64) -> f64 {
        let hot_cost_per_gb = 0.10;
        let warm_cost_per_gb = 0.02;
        let cold_cost_per_gb = 0.004;

        let span_size_gb = 0.001; // 1KB per span
        let daily_data_gb = total_spans_per_day as f64 * span_size_gb;

        let hot_cost = daily_data_gb * self.hot_retention_days as f64 * hot_cost_per_gb;
        let warm_cost = daily_data_gb * self.warm_retention_days as f64 * warm_cost_per_gb;
        let cold_cost = daily_data_gb * 365.0 * cold_cost_per_gb;

        // ä¸å…¨éƒ¨ä½¿ç”¨çƒ­å­˜å‚¨ç›¸æ¯”çš„èŠ‚çœ
        let all_hot_cost = daily_data_gb * 365.0 * hot_cost_per_gb;
        all_hot_cost - (hot_cost + warm_cost + cold_cost)
    }
}
```

### 3. èµ„æºå³é…

```rust
pub struct ResourceRightsizing {
    current_utilization: f64,
    current_cost: f64,
}

impl ResourceRightsizing {
    pub fn recommend_downsizing(&self) -> Option<ResizingRecommendation> {
        if self.current_utilization < 0.3 {
            Some(ResizingRecommendation {
                action: "Downsize",
                current_cost: self.current_cost,
                projected_cost: self.current_cost * 0.5,
                savings: self.current_cost * 0.5,
            })
        } else {
            None
        }
    }
}

pub struct ResizingRecommendation {
    pub action: &'static str,
    pub current_cost: f64,
    pub projected_cost: f64,
    pub savings: f64,
}
```

## æˆæœ¬ç›‘æ§

### Prometheus æˆæœ¬æŒ‡æ ‡

```yaml
# æˆæœ¬ç›¸å…³æŒ‡æ ‡
- otlp_cost_total_dollars
- otlp_cost_per_span_dollars
- otlp_storage_cost_dollars
- otlp_compute_cost_dollars
```

### æˆæœ¬å‘Šè­¦

```yaml
groups:
  - name: cost_alerts
    rules:
      - alert: HighDailyCost
        expr: increase(otlp_cost_total_dollars[1d]) > 1000
        labels:
          severity: warning
        annotations:
          summary: "Daily cost exceeds $1000"
          
      - alert: CostPerSpanIncreasing
        expr: |
          rate(otlp_cost_total_dollars[1h]) 
          / rate(otlp_spans_total[1h]) > 0.001
        labels:
          severity: info
        annotations:
          summary: "Cost per span is increasing"
```

## è¯¦ç»†æˆæœ¬åˆ†ææ¨¡å‹

### æˆæœ¬è®¡ç®—å™¨

```rust
/// å®Œæ•´çš„ OTLP æˆæœ¬è®¡ç®—å™¨
pub struct OtlpCostCalculator {
    // è®¡ç®—èµ„æºå®šä»·
    cpu_cost_per_core_hour: f64,
    memory_cost_per_gb_hour: f64,
    
    // å­˜å‚¨å®šä»·
    hot_storage_cost_per_gb_month: f64,
    warm_storage_cost_per_gb_month: f64,
    cold_storage_cost_per_gb_month: f64,
    
    // ç½‘ç»œå®šä»·
    ingress_cost_per_gb: f64,
    egress_cost_per_gb: f64,
    
    // ä½¿ç”¨é‡
    cpu_cores: usize,
    memory_gb: usize,
    spans_per_second: u64,
    avg_span_size_bytes: usize,
    retention_days: usize,
}

impl OtlpCostCalculator {
    /// è®¡ç®—æ¯æœˆæ€»æˆæœ¬
    pub fn calculate_monthly_cost(&self) -> MonthlyCost {
        let hours_per_month = 730.0; // å¹³å‡æ¯æœˆå°æ—¶æ•°
        
        // è®¡ç®—æˆæœ¬
        let compute_cost = self.calculate_compute_cost(hours_per_month);
        let storage_cost = self.calculate_storage_cost();
        let network_cost = self.calculate_network_cost();
        
        MonthlyCost {
            compute: compute_cost,
            storage: storage_cost,
            network: network_cost,
            total: compute_cost + storage_cost + network_cost,
        }
    }
    
    fn calculate_compute_cost(&self, hours: f64) -> f64 {
        let cpu_cost = self.cpu_cores as f64 * self.cpu_cost_per_core_hour * hours;
        let memory_cost = self.memory_gb as f64 * self.memory_cost_per_gb_hour * hours;
        cpu_cost + memory_cost
    }
    
    fn calculate_storage_cost(&self) -> f64 {
        let spans_per_day = self.spans_per_second * 86400;
        let daily_data_gb = (spans_per_day * self.avg_span_size_bytes as u64) as f64 / 1_073_741_824.0;
        
        // åˆ†å±‚å­˜å‚¨ï¼š7å¤©çƒ­å­˜å‚¨ï¼Œ30å¤©æ¸©å­˜å‚¨ï¼Œå…¶ä½™å†·å­˜å‚¨
        let hot_days = 7.min(self.retention_days);
        let warm_days = (self.retention_days.saturating_sub(7)).min(30);
        let cold_days = self.retention_days.saturating_sub(37);
        
        let hot_cost = daily_data_gb * hot_days as f64 * self.hot_storage_cost_per_gb_month / 30.0;
        let warm_cost = daily_data_gb * warm_days as f64 * self.warm_storage_cost_per_gb_month / 30.0;
        let cold_cost = daily_data_gb * cold_days as f64 * self.cold_storage_cost_per_gb_month / 30.0;
        
        hot_cost + warm_cost + cold_cost
    }
    
    fn calculate_network_cost(&self) -> f64 {
        let monthly_data_gb = (self.spans_per_second * 86400 * 30 * self.avg_span_size_bytes as u64) as f64 / 1_073_741_824.0;
        
        // å‡è®¾å…¥ç«™å’Œå‡ºç«™å„å ä¸€åŠ
        let ingress_cost = monthly_data_gb * 0.5 * self.ingress_cost_per_gb;
        let egress_cost = monthly_data_gb * 0.5 * self.egress_cost_per_gb;
        
        ingress_cost + egress_cost
    }
    
    /// è®¡ç®—æ¯ä¸ª Span çš„æˆæœ¬
    pub fn cost_per_span(&self) -> f64 {
        let monthly_cost = self.calculate_monthly_cost();
        let monthly_spans = self.spans_per_second * 86400 * 30;
        
        if monthly_spans == 0 {
            return 0.0;
        }
        
        monthly_cost.total / monthly_spans as f64
    }
    
    /// ç”Ÿæˆæˆæœ¬æŠ¥å‘Š
    pub fn generate_report(&self) -> CostReport {
        let monthly = self.calculate_monthly_cost();
        let yearly = MonthlyCost {
            compute: monthly.compute * 12.0,
            storage: monthly.storage * 12.0,
            network: monthly.network * 12.0,
            total: monthly.total * 12.0,
        };
        
        CostReport {
            monthly,
            yearly,
            cost_per_span: self.cost_per_span(),
            cost_per_million_spans: self.cost_per_span() * 1_000_000.0,
        }
    }
}

#[derive(Debug, Clone)]
pub struct MonthlyCost {
    pub compute: f64,
    pub storage: f64,
    pub network: f64,
    pub total: f64,
}

#[derive(Debug)]
pub struct CostReport {
    pub monthly: MonthlyCost,
    pub yearly: MonthlyCost,
    pub cost_per_span: f64,
    pub cost_per_million_spans: f64,
}
```

## ä¼˜åŒ–ç­–ç•¥è¯¦è§£

### 1. æ™ºèƒ½é‡‡æ ·ä¼˜åŒ–

```rust
/// å¤šçº§é‡‡æ ·ç­–ç•¥
pub struct MultiTierSampler {
    tiers: Vec<SamplingTier>,
}

#[derive(Debug, Clone)]
pub struct SamplingTier {
    name: String,
    condition: SamplingCondition,
    rate: f64,
}

#[derive(Debug, Clone)]
pub enum SamplingCondition {
    /// æ€»æ˜¯é‡‡æ ·ï¼ˆå¦‚é”™è¯¯è¯·æ±‚ï¼‰
    Always,
    /// åŸºäºå»¶è¿Ÿï¼ˆé«˜å»¶è¿Ÿè¯·æ±‚ï¼‰
    HighLatency { threshold_ms: f64 },
    /// åŸºäºç”¨æˆ·ï¼ˆVIPç”¨æˆ·ï¼‰
    VipUser { user_ids: Vec<String> },
    /// åŸºäºæœåŠ¡ï¼ˆå…³é”®æœåŠ¡ï¼‰
    CriticalService { services: Vec<String> },
    /// é»˜è®¤é‡‡æ ·ç‡
    Default,
}

impl MultiTierSampler {
    pub fn new() -> Self {
        Self {
            tiers: vec![
                SamplingTier {
                    name: "é”™è¯¯è¯·æ±‚".to_string(),
                    condition: SamplingCondition::Always,
                    rate: 1.0, // 100% é‡‡æ ·
                },
                SamplingTier {
                    name: "é«˜å»¶è¿Ÿè¯·æ±‚".to_string(),
                    condition: SamplingCondition::HighLatency { threshold_ms: 1000.0 },
                    rate: 1.0, // 100% é‡‡æ ·
                },
                SamplingTier {
                    name: "VIPç”¨æˆ·".to_string(),
                    condition: SamplingCondition::VipUser { user_ids: vec![] },
                    rate: 0.5, // 50% é‡‡æ ·
                },
                SamplingTier {
                    name: "å…³é”®æœåŠ¡".to_string(),
                    condition: SamplingCondition::CriticalService { services: vec![] },
                    rate: 0.2, // 20% é‡‡æ ·
                },
                SamplingTier {
                    name: "é»˜è®¤".to_string(),
                    condition: SamplingCondition::Default,
                    rate: 0.01, // 1% é‡‡æ ·
                },
            ],
        }
    }

    pub fn should_sample(&self, request: &Request) -> bool {
        for tier in &self.tiers {
            if self.matches_condition(&tier.condition, request) {
                return rand::random::<f64>() < tier.rate;
            }
        }
        false
    }

    fn matches_condition(&self, condition: &SamplingCondition, request: &Request) -> bool {
        match condition {
            SamplingCondition::Always => request.is_error,
            SamplingCondition::HighLatency { threshold_ms } => {
                request.latency_ms > *threshold_ms
            }
            SamplingCondition::VipUser { user_ids } => {
                user_ids.contains(&request.user_id)
            }
            SamplingCondition::CriticalService { services } => {
                services.contains(&request.service_name)
            }
            SamplingCondition::Default => true,
        }
    }

    /// è®¡ç®—é‡‡æ ·åçš„æˆæœ¬èŠ‚çœ
    pub fn estimate_cost_savings(
        &self,
        total_requests_per_day: u64,
        cost_per_span: f64,
    ) -> CostSavings {
        // å‡è®¾å„ç±»è¯·æ±‚çš„åˆ†å¸ƒ
        let error_rate = 0.01;
        let high_latency_rate = 0.05;
        let vip_rate = 0.1;
        let critical_service_rate = 0.2;
        
        let error_spans = (total_requests_per_day as f64 * error_rate) * 1.0;
        let high_latency_spans = (total_requests_per_day as f64 * high_latency_rate) * 1.0;
        let vip_spans = (total_requests_per_day as f64 * vip_rate) * 0.5;
        let critical_spans = (total_requests_per_day as f64 * critical_service_rate) * 0.2;
        let default_spans = (total_requests_per_day as f64 * (1.0 - error_rate - high_latency_rate - vip_rate - critical_service_rate)) * 0.01;
        
        let sampled_spans = error_spans + high_latency_spans + vip_spans + critical_spans + default_spans;
        let original_cost = total_requests_per_day as f64 * cost_per_span;
        let sampled_cost = sampled_spans * cost_per_span;
        
        CostSavings {
            original_cost_per_day: original_cost,
            optimized_cost_per_day: sampled_cost,
            savings_per_day: original_cost - sampled_cost,
            savings_percentage: ((original_cost - sampled_cost) / original_cost) * 100.0,
        }
    }
}

#[derive(Debug)]
pub struct Request {
    is_error: bool,
    latency_ms: f64,
    user_id: String,
    service_name: String,
}

#[derive(Debug)]
pub struct CostSavings {
    pub original_cost_per_day: f64,
    pub optimized_cost_per_day: f64,
    pub savings_per_day: f64,
    pub savings_percentage: f64,
}
```

### 2. æ•°æ®å‹ç¼©ä¼˜åŒ–

```rust
/// æ•°æ®å‹ç¼©ç­–ç•¥
pub struct CompressionOptimizer {
    compression_level: CompressionLevel,
}

#[derive(Debug, Clone, Copy)]
pub enum CompressionLevel {
    None,
    Fast,      // å¿«é€Ÿå‹ç¼©ï¼Œä½CPU
    Balanced,  // å¹³è¡¡
    Best,      // æœ€ä½³å‹ç¼©ï¼Œé«˜CPU
}

impl CompressionOptimizer {
    pub fn calculate_compression_savings(
        &self,
        uncompressed_size_gb: f64,
        storage_cost_per_gb: f64,
        cpu_cost_per_hour: f64,
    ) -> CompressionAnalysis {
        let (compression_ratio, cpu_overhead_percent) = match self.compression_level {
            CompressionLevel::None => (1.0, 0.0),
            CompressionLevel::Fast => (0.7, 5.0),      // 30% å‹ç¼©ï¼Œ5% CPU
            CompressionLevel::Balanced => (0.5, 10.0), // 50% å‹ç¼©ï¼Œ10% CPU
            CompressionLevel::Best => (0.3, 20.0),     // 70% å‹ç¼©ï¼Œ20% CPU
        };
        
        let compressed_size_gb = uncompressed_size_gb * compression_ratio;
        let storage_savings = (uncompressed_size_gb - compressed_size_gb) * storage_cost_per_gb;
        let cpu_cost_increase = cpu_cost_per_hour * 730.0 * (cpu_overhead_percent / 100.0);
        
        CompressionAnalysis {
            compression_level: self.compression_level,
            original_size_gb: uncompressed_size_gb,
            compressed_size_gb,
            compression_ratio,
            storage_savings_per_month: storage_savings,
            cpu_cost_increase_per_month: cpu_cost_increase,
            net_savings_per_month: storage_savings - cpu_cost_increase,
        }
    }

    pub fn recommend_compression_level(
        &self,
        data_size_gb: f64,
        storage_cost_per_gb: f64,
        cpu_cost_per_hour: f64,
    ) -> CompressionLevel {
        let levels = [
            CompressionLevel::None,
            CompressionLevel::Fast,
            CompressionLevel::Balanced,
            CompressionLevel::Best,
        ];
        
        let mut best_level = CompressionLevel::None;
        let mut best_savings = 0.0;
        
        for level in levels {
            let optimizer = CompressionOptimizer { compression_level: level };
            let analysis = optimizer.calculate_compression_savings(
                data_size_gb,
                storage_cost_per_gb,
                cpu_cost_per_hour,
            );
            
            if analysis.net_savings_per_month > best_savings {
                best_savings = analysis.net_savings_per_month;
                best_level = level;
            }
        }
        
        best_level
    }
}

#[derive(Debug)]
pub struct CompressionAnalysis {
    pub compression_level: CompressionLevel,
    pub original_size_gb: f64,
    pub compressed_size_gb: f64,
    pub compression_ratio: f64,
    pub storage_savings_per_month: f64,
    pub cpu_cost_increase_per_month: f64,
    pub net_savings_per_month: f64,
}
```

### 3. æ‰¹å¤„ç†ä¼˜åŒ–

```rust
/// æ‰¹å¤„ç†ä¼˜åŒ–å™¨
pub struct BatchOptimizer {
    batch_size: usize,
    batch_interval_seconds: u64,
}

impl BatchOptimizer {
    /// è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°
    pub fn calculate_optimal_batch_size(
        &self,
        request_rate_per_second: f64,
        network_cost_per_request: f64,
        latency_cost_per_second: f64,
    ) -> OptimalBatchConfig {
        let mut best_batch_size = 1;
        let mut best_total_cost = f64::MAX;
        
        // å°è¯•ä¸åŒçš„æ‰¹æ¬¡å¤§å°
        for batch_size in [1, 10, 50, 100, 500, 1000] {
            let batches_per_second = request_rate_per_second / batch_size as f64;
            
            // ç½‘ç»œæˆæœ¬ï¼ˆæ‰¹å¤„ç†å‡å°‘è¯·æ±‚æ•°ï¼‰
            let network_cost = batches_per_second * network_cost_per_request;
            
            // å»¶è¿Ÿæˆæœ¬ï¼ˆæ‰¹å¤„ç†å¢åŠ å»¶è¿Ÿï¼‰
            let avg_wait_time = (batch_size as f64 / 2.0) / request_rate_per_second;
            let latency_cost = avg_wait_time * latency_cost_per_second;
            
            let total_cost = network_cost + latency_cost;
            
            if total_cost < best_total_cost {
                best_total_cost = total_cost;
                best_batch_size = batch_size;
            }
        }
        
        OptimalBatchConfig {
            batch_size: best_batch_size,
            estimated_cost_per_second: best_total_cost,
            estimated_latency_ms: (best_batch_size as f64 / 2.0 / request_rate_per_second) * 1000.0,
        }
    }
}

#[derive(Debug)]
pub struct OptimalBatchConfig {
    pub batch_size: usize,
    pub estimated_cost_per_second: f64,
    pub estimated_latency_ms: f64,
}
```

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šé‡‡æ ·ä¼˜åŒ–èŠ‚çœ 80% æˆæœ¬

**åˆå§‹çŠ¶æ€**ï¼š

- æ¯å¤© 10 äº¿ä¸ª Span
- æ¯ä¸ª Span æˆæœ¬ï¼š$0.0001
- æ¯å¤©æˆæœ¬ï¼š$100,000
- æ¯æœˆæˆæœ¬ï¼š$3,000,000

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

```rust
pub fn sampling_optimization_case_study() {
    let sampler = MultiTierSampler::new();
    
    let total_requests_per_day = 1_000_000_000;
    let cost_per_span = 0.0001;
    
    let savings = sampler.estimate_cost_savings(
        total_requests_per_day,
        cost_per_span,
    );
    
    println!("=== é‡‡æ ·ä¼˜åŒ–æ¡ˆä¾‹åˆ†æ ===");
    println!("åŸå§‹æˆæœ¬: ${:.2}/å¤©", savings.original_cost_per_day);
    println!("ä¼˜åŒ–åæˆæœ¬: ${:.2}/å¤©", savings.optimized_cost_per_day);
    println!("èŠ‚çœ: ${:.2}/å¤©", savings.savings_per_day);
    println!("èŠ‚çœæ¯”ä¾‹: {:.1}%", savings.savings_percentage);
    println!();
    println!("æœˆåº¦èŠ‚çœ: ${:.2}", savings.savings_per_day * 30.0);
    println!("å¹´åº¦èŠ‚çœ: ${:.2}", savings.savings_per_day * 365.0);
}
```

**ç»“æœ**ï¼š

- ä¼˜åŒ–åæ¯å¤©æˆæœ¬ï¼š$20,000
- æ¯å¤©èŠ‚çœï¼š$80,000
- èŠ‚çœæ¯”ä¾‹ï¼š80%
- å¹´åº¦èŠ‚çœï¼š$29,200,000

**å…³é”®ç­–ç•¥**ï¼š

1. é”™è¯¯è¯·æ±‚ 100% é‡‡æ ·ï¼ˆ1%ï¼‰
2. é«˜å»¶è¿Ÿè¯·æ±‚ 100% é‡‡æ ·ï¼ˆ5%ï¼‰
3. VIP ç”¨æˆ· 50% é‡‡æ ·ï¼ˆ10%ï¼‰
4. å…³é”®æœåŠ¡ 20% é‡‡æ ·ï¼ˆ20%ï¼‰
5. å…¶ä»–è¯·æ±‚ 1% é‡‡æ ·ï¼ˆ64%ï¼‰

### æ¡ˆä¾‹2ï¼šå­˜å‚¨åˆ†å±‚èŠ‚çœ 60% å­˜å‚¨æˆæœ¬

**åœºæ™¯**ï¼š

- æ¯å¤©ç”Ÿæˆ 1TB æ•°æ®
- ä¿ç•™ 365 å¤©
- æ€»æ•°æ®é‡ï¼š365TB

**ä¼˜åŒ–å‰**ï¼ˆå…¨éƒ¨çƒ­å­˜å‚¨ï¼‰ï¼š

```text
æˆæœ¬ = 365TB Ã— $0.10/GB/æœˆ = $36,500/æœˆ
```

**ä¼˜åŒ–å**ï¼ˆåˆ†å±‚å­˜å‚¨ï¼‰ï¼š

```rust
pub fn storage_tiering_case_study() {
    let tiered = TieredStorage {
        hot_retention_days: 7,
        warm_retention_days: 30,
    };
    
    let total_spans_per_day = 1_000_000_000;
    let savings = tiered.calculate_cost_savings(total_spans_per_day);
    
    println!("=== å­˜å‚¨åˆ†å±‚æ¡ˆä¾‹åˆ†æ ===");
    println!("å¹´åº¦èŠ‚çœ: ${:.2}", savings * 12.0);
}
```

**æˆæœ¬åˆ†è§£**ï¼š

- çƒ­å­˜å‚¨ï¼ˆ7å¤©ï¼‰ï¼š7TB Ã— $0.10 = $700
- æ¸©å­˜å‚¨ï¼ˆ30å¤©ï¼‰ï¼š30TB Ã— $0.02 = $600
- å†·å­˜å‚¨ï¼ˆ328å¤©ï¼‰ï¼š328TB Ã— $0.004 = $1,312
- **æ€»è®¡ï¼š$2,612/æœˆ**

**ç»“æœ**ï¼š

- ä¼˜åŒ–å‰ï¼š$36,500/æœˆ
- ä¼˜åŒ–åï¼š$2,612/æœˆ
- èŠ‚çœï¼š$33,888/æœˆï¼ˆ93%ï¼‰

### æ¡ˆä¾‹3ï¼šå‹ç¼©ä¼˜åŒ–

**åœºæ™¯**ï¼š

- æ¯æœˆå­˜å‚¨ 30TB æ•°æ®
- å­˜å‚¨æˆæœ¬ï¼š$0.10/GB/æœˆ
- CPU æˆæœ¬ï¼š$50/æ ¸å¿ƒ/æœˆ

**åˆ†æ**ï¼š

```rust
pub fn compression_case_study() {
    let optimizer = CompressionOptimizer {
        compression_level: CompressionLevel::Balanced,
    };
    
    let analysis = optimizer.calculate_compression_savings(
        30_000.0, // 30TB = 30,000GB
        0.10,
        50.0 / 730.0, // æ¯å°æ—¶æˆæœ¬
    );
    
    println!("=== å‹ç¼©ä¼˜åŒ–æ¡ˆä¾‹åˆ†æ ===");
    println!("å‹ç¼©çº§åˆ«: {:?}", analysis.compression_level);
    println!("åŸå§‹å¤§å°: {:.0}GB", analysis.original_size_gb);
    println!("å‹ç¼©åå¤§å°: {:.0}GB", analysis.compressed_size_gb);
    println!("å‹ç¼©æ¯”: {:.1}%", (1.0 - analysis.compression_ratio) * 100.0);
    println!("å­˜å‚¨èŠ‚çœ: ${:.2}/æœˆ", analysis.storage_savings_per_month);
    println!("CPUæˆæœ¬å¢åŠ : ${:.2}/æœˆ", analysis.cpu_cost_increase_per_month);
    println!("å‡€èŠ‚çœ: ${:.2}/æœˆ", analysis.net_savings_per_month);
}
```

**ç»“æœ**ï¼ˆå¹³è¡¡å‹ç¼©ï¼‰ï¼š

- å‹ç¼©æ¯”ï¼š50%
- å­˜å‚¨èŠ‚çœï¼š$1,500/æœˆ
- CPU æˆæœ¬å¢åŠ ï¼š$68/æœˆ
- **å‡€èŠ‚çœï¼š$1,432/æœˆ**

## æˆæœ¬ä¼˜åŒ–æœ€ä½³å®è·µ

### 1. å»ºç«‹æˆæœ¬æ„è¯†æ–‡åŒ–

```yaml
# æˆæœ¬å¯è§æ€§é…ç½®
cost_visibility:
  # å›¢é˜Ÿæˆæœ¬ä»ªè¡¨æ¿
  dashboards:
    - name: "å›¢é˜Ÿæˆæœ¬æ¦‚è§ˆ"
      metrics:
        - total_cost_per_day
        - cost_per_service
        - cost_per_team
        - cost_trend
    
  # æˆæœ¬å‘Šè­¦
  alerts:
    - name: "æˆæœ¬å¼‚å¸¸å¢é•¿"
      threshold: 20%  # æ—¥ç¯æ¯”å¢é•¿è¶…è¿‡20%
      action: "é€šçŸ¥å›¢é˜Ÿè´Ÿè´£äºº"
    
  # æˆæœ¬æŠ¥å‘Š
  reports:
    frequency: weekly
    recipients:
      - engineering_managers
      - finance_team
```

### 2. æˆæœ¬ä¼˜åŒ–æ£€æŸ¥æ¸…å•

```markdown
## æˆæœ¬ä¼˜åŒ–æ£€æŸ¥æ¸…å•

### é‡‡æ ·ä¼˜åŒ–
- [ ] å®æ–½æ™ºèƒ½é‡‡æ ·ç­–ç•¥
- [ ] é”™è¯¯è¯·æ±‚ 100% é‡‡æ ·
- [ ] å…³é”®è·¯å¾„ä¼˜å…ˆé‡‡æ ·
- [ ] å®šæœŸå®¡æŸ¥é‡‡æ ·ç‡

### å­˜å‚¨ä¼˜åŒ–
- [ ] å¯ç”¨å­˜å‚¨åˆ†å±‚
- [ ] é…ç½®æ•°æ®ç”Ÿå‘½å‘¨æœŸç­–ç•¥
- [ ] å¯ç”¨æ•°æ®å‹ç¼©
- [ ] å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®

### è®¡ç®—ä¼˜åŒ–
- [ ] èµ„æºå³é…ï¼ˆRightsizingï¼‰
- [ ] ä½¿ç”¨ Spot å®ä¾‹
- [ ] å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹
- [ ] ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°

### ç½‘ç»œä¼˜åŒ–
- [ ] å¯ç”¨æ•°æ®å‹ç¼©
- [ ] ä½¿ç”¨åŒºåŸŸå†…ä¼ è¾“
- [ ] æ‰¹é‡ä¼ è¾“æ•°æ®
- [ ] ç¼“å­˜å¸¸ç”¨æ•°æ®

### ç›‘æ§ä¸å®¡è®¡
- [ ] è®¾ç½®æˆæœ¬å‘Šè­¦
- [ ] å®šæœŸæˆæœ¬å®¡æŸ¥
- [ ] è·Ÿè¸ªæˆæœ¬è¶‹åŠ¿
- [ ] è¯†åˆ«æˆæœ¬å¼‚å¸¸
```

### 3. æˆæœ¬ä¼˜åŒ–å·¥å…·

```bash
#!/bin/bash
# æˆæœ¬åˆ†æè„šæœ¬

echo "=== OTLP æˆæœ¬åˆ†æ ==="

# 1. å½“å‰æˆæœ¬
CURRENT_COST=$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode "query=sum(increase(otlp_cost_total_dollars[1d]))" \
  | jq -r '.data.result[0].value[1]')

echo "å½“å‰æ—¥æˆæœ¬: \$$CURRENT_COST"

# 2. æˆæœ¬è¶‹åŠ¿
echo ""
echo "è¿‡å»7å¤©æˆæœ¬è¶‹åŠ¿:"
for i in {6..0}; do
  DAY_COST=$(curl -s "http://prometheus:9090/api/v1/query" \
    --data-urlencode "query=sum(increase(otlp_cost_total_dollars[1d] offset ${i}d))" \
    | jq -r '.data.result[0].value[1]')
  echo "  $(date -d "$i days ago" +%Y-%m-%d): \$$DAY_COST"
done

# 3. æˆæœ¬åˆ†è§£
echo ""
echo "æˆæœ¬åˆ†è§£:"
COMPUTE=$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode "query=sum(increase(otlp_compute_cost_dollars[1d]))" \
  | jq -r '.data.result[0].value[1]')
STORAGE=$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode "query=sum(increase(otlp_storage_cost_dollars[1d]))" \
  | jq -r '.data.result[0].value[1]')
NETWORK=$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode "query=sum(increase(otlp_network_cost_dollars[1d]))" \
  | jq -r '.data.result[0].value[1]')

echo "  è®¡ç®—: \$$COMPUTE ($(echo "scale=1; $COMPUTE/$CURRENT_COST*100" | bc)%)"
echo "  å­˜å‚¨: \$$STORAGE ($(echo "scale=1; $STORAGE/$CURRENT_COST*100" | bc)%)"
echo "  ç½‘ç»œ: \$$NETWORK ($(echo "scale=1; $NETWORK/$CURRENT_COST*100" | bc)%)"

# 4. ä¼˜åŒ–å»ºè®®
echo ""
echo "ä¼˜åŒ–å»ºè®®:"
if (( $(echo "$STORAGE > $CURRENT_COST * 0.5" | bc -l) )); then
  echo "  âš ï¸  å­˜å‚¨æˆæœ¬è¿‡é«˜ï¼Œå»ºè®®å¯ç”¨å­˜å‚¨åˆ†å±‚"
fi
if (( $(echo "$COMPUTE > $CURRENT_COST * 0.6" | bc -l) )); then
  echo "  âš ï¸  è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œå»ºè®®èµ„æºå³é…"
fi
```

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [å®¹é‡é¢„æµ‹æ¨¡å‹](./å®¹é‡é¢„æµ‹æ¨¡å‹.md)
- [èµ„æºä½¿ç”¨åˆ†æ](./èµ„æºä½¿ç”¨åˆ†æ.md)
- [æ‰©å®¹å†³ç­–](./æ‰©å®¹å†³ç­–.md)
