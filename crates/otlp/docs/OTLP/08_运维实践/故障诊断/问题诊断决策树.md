# 问题诊断决策树

## 目录

- [问题诊断决策树](#问题诊断决策树)
  - [目录](#目录)
  - [概述](#概述)
  - [诊断流程总览](#诊断流程总览)
  - [1. 高延迟问题](#1-高延迟问题)
    - [1.1 问题识别](#11-问题识别)
    - [1.2 诊断决策树](#12-诊断决策树)
    - [1.3 诊断命令](#13-诊断命令)
    - [1.4 案例：数据库查询慢](#14-案例数据库查询慢)
  - [2. 低吞吐量问题](#2-低吞吐量问题)
    - [2.1 问题识别](#21-问题识别)
    - [2.2 诊断决策树](#22-诊断决策树)
    - [2.3 性能分析工具](#23-性能分析工具)
    - [2.4 案例：批处理优化](#24-案例批处理优化)
  - [3. 服务不可用问题](#3-服务不可用问题)
    - [3.1 问题识别](#31-问题识别)
    - [3.2 诊断决策树](#32-诊断决策树)
    - [3.3 快速恢复脚本](#33-快速恢复脚本)
    - [3.4 案例：数据库连接池耗尽](#34-案例数据库连接池耗尽)
  - [4. 数据准确性问题](#4-数据准确性问题)
    - [4.1 诊断决策树](#41-诊断决策树)
    - [4.2 数据一致性检查](#42-数据一致性检查)
  - [5. 快速诊断命令集](#5-快速诊断命令集)
    - [5.1 一键健康检查](#51-一键健康检查)
    - [5.2 性能分析一键脚本](#52-性能分析一键脚本)
  - [6. 总结](#6-总结)
    - [诊断原则](#诊断原则)
    - [常用工具清单](#常用工具清单)
    - [下一步](#下一步)

## 概述

本文档提供系统化的问题诊断决策树，帮助快速定位和解决OTLP系统的各类问题。

## 诊断流程总览

```text
┌─────────────┐
│  问题报告    │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 确认问题范围 │ ──► 单个用户? 部分用户? 全部用户?
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 识别问题类型 │ ──► 性能? 可用性? 正确性?
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 收集诊断数据 │ ──► 日志、指标、追踪
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 定位根因     │ ──► 代码? 配置? 基础设施?
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 实施修复     │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 验证恢复     │
└─────────────┘
```

## 1. 高延迟问题

### 1.1 问题识别

**症状**：

- P99 延迟显著增加 (> 正常值 2倍)
- 请求超时率上升
- 用户反馈响应慢

**快速检查清单**：

```bash
# 1. 检查当前延迟分布
curl http://localhost:9090/metrics | grep otlp_request_duration

# 2. 查看最近的慢请求
journalctl -u otlp -n 100 | grep "slow request"

# 3. 检查系统负载
top -bn1 | head -n 20
```

### 1.2 诊断决策树

```text
高延迟问题
│
├─► CPU 使用率 > 80%?
│   ├─ Yes ► CPU 密集型任务导致
│   │        ├─ 检查火焰图定位热点函数
│   │        ├─ 优化算法复杂度
│   │        └─ 增加计算资源
│   │
│   └─ No  ► 继续下一步
│
├─► 内存使用率 > 90%?
│   ├─ Yes ► 内存不足导致频繁 GC/Swap
│   │        ├─ 检查内存泄漏
│   │        ├─ 优化内存使用
│   │        └─ 增加内存资源
│   │
│   └─ No  ► 继续下一步
│
├─► 网络 I/O 等待高?
│   ├─ Yes ► 网络通信延迟
│   │        ├─ 检查下游服务延迟
│   │        ├─ 检查网络带宽和丢包率
│   │        ├─ 启用连接池复用
│   │        └─ 考虑使用缓存
│   │
│   └─ No  ► 继续下一步
│
├─► 磁盘 I/O 等待高?
│   ├─ Yes ► 磁盘读写瓶颈
│   │        ├─ 检查磁盘 IOPS 和带宽
│   │        ├─ 优化数据结构减少 I/O
│   │        ├─ 使用 SSD 或增加缓存
│   │        └─ 异步写入
│   │
│   └─ No  ► 继续下一步
│
└─► 锁竞争?
    ├─ Yes ► 并发控制导致
    │        ├─ 使用性能分析工具检测锁等待
    │        ├─ 减小锁粒度
    │        ├─ 使用无锁数据结构
    │        └─ 优化并发策略
    │
    └─ No  ► 深入分析特定业务逻辑
```

### 1.3 诊断命令

```bash
# === CPU 分析 ===
# 查看 CPU 使用率
mpstat -P ALL 1 5

# 生成火焰图
perf record -F 99 -p $(pgrep otlp) -g -- sleep 30
perf script | ./flamegraph.pl > flame.svg

# === 内存分析 ===
# 查看内存使用
free -h
ps aux --sort=-%mem | head -n 10

# 检查内存泄漏 (Rust)
valgrind --leak-check=full --show-leak-kinds=all ./otlp

# === 网络分析 ===
# 检查网络延迟
ping -c 10 downstream-service.local
traceroute downstream-service.local

# 检查连接状态
ss -s
netstat -antp | grep otlp

# 抓包分析
tcpdump -i eth0 -w capture.pcap port 8080

# === 磁盘分析 ===
# 查看磁盘 I/O
iostat -x 1 5
iotop -o

# 检查磁盘空间
df -h
du -sh /var/lib/otlp/*

# === 锁分析 ===
# 查看线程状态 (需要支持)
pstack $(pgrep otlp)

# Rust 异步任务分析
tokio-console
```

### 1.4 案例：数据库查询慢

**症状**：

```text
2025-10-04 15:23:45 WARN Query took 3500ms: SELECT * FROM traces WHERE trace_id = ?
```

**诊断步骤**：

1. **检查数据库性能**：

    ```sql
    -- 查看慢查询
    SHOW PROCESSLIST;

    -- 检查表大小
    SELECT 
        table_name,
        ROUND(((data_length + index_length) / 1024 / 1024), 2) AS "Size (MB)"
    FROM information_schema.TABLES 
    WHERE table_schema = "otlp"
    ORDER BY (data_length + index_length) DESC;

    -- 分析查询计划
    EXPLAIN SELECT * FROM traces WHERE trace_id = ?;
    ```

2. **发现问题**：
   - 缺少 `trace_id` 索引
   - 全表扫描导致慢查询

3. **解决方案**：

    ```sql
    -- 创建索引
    CREATE INDEX idx_trace_id ON traces(trace_id);

    -- 优化查询，只获取需要的字段
    SELECT span_id, parent_span_id, name, timestamp 
    FROM traces 
    WHERE trace_id = ?;
    ```

4. **验证效果**：

    ```bash
    # 查询时间从 3500ms 降到 5ms
    2025-10-04 15:30:12 INFO Query took 5ms: SELECT ... WHERE trace_id = ?
    ```

## 2. 低吞吐量问题

### 2.1 问题识别

**症状**：

- RPS (Requests Per Second) 低于预期
- 任务处理速度慢
- 队列积压

### 2.2 诊断决策树

```text
低吞吐量问题
│
├─► 单线程瓶颈?
│   ├─ Yes ► 并发度不足
│   │        ├─ 增加工作线程数
│   │        ├─ 使用异步 I/O
│   │        └─ 并行处理批量任务
│   │
│   └─ No  ► 继续下一步
│
├─► 批处理大小不足?
│   ├─ Yes ► 未充分利用批处理优势
│   │        ├─ 增加批处理大小
│   │        ├─ 调整批处理超时
│   │        └─ 优化批处理逻辑
│   │
│   └─ No  ► 继续下一步
│
├─► 资源争用?
│   ├─ Yes ► 多个组件竞争资源
│   │        ├─ 资源隔离
│   │        ├─ 优先级调度
│   │        └─ 负载均衡
│   │
│   └─ No  ► 继续下一步
│
└─► 下游服务慢?
    ├─ Yes ► 依赖服务成为瓶颈
    │        ├─ 使用缓存减少调用
    │        ├─ 异步处理非关键路径
    │        ├─ 服务降级
    │        └─ 扩容下游服务
    │
    └─ No  ► 深入分析业务逻辑
```

### 2.3 性能分析工具

```rust
// 吞吐量测试工具
use std::time::{Duration, Instant};
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;

pub struct ThroughputMonitor {
    request_count: Arc<AtomicU64>,
    start_time: Instant,
}

impl ThroughputMonitor {
    pub fn new() -> Self {
        Self {
            request_count: Arc::new(AtomicU64::new(0)),
            start_time: Instant::now(),
        }
    }
    
    pub fn record_request(&self) {
        self.request_count.fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn get_throughput(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        let count = self.request_count.load(Ordering::Relaxed) as f64;
        count / elapsed
    }
    
    pub fn print_stats(&self) {
        let rps = self.get_throughput();
        let count = self.request_count.load(Ordering::Relaxed);
        println!("Total Requests: {}", count);
        println!("Throughput: {:.2} RPS", rps);
    }
}

// 使用示例
#[tokio::main]
async fn main() {
    let monitor = Arc::new(ThroughputMonitor::new());
    
    // 启动监控任务
    let monitor_clone = monitor.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(10));
        loop {
            interval.tick().await;
            monitor_clone.print_stats();
        }
    });
    
    // 处理请求
    loop {
        // 处理业务逻辑
        process_request().await;
        monitor.record_request();
    }
}
```

### 2.4 案例：批处理优化

**原始代码**（低吞吐量）：

```rust
// 逐个处理，吞吐量 ~100 RPS
for item in items {
    process_single(item).await?;
    database.insert(item).await?;
}
```

**优化后**（高吞吐量）：

```rust
// 批量处理，吞吐量 ~2000 RPS
const BATCH_SIZE: usize = 100;

for chunk in items.chunks(BATCH_SIZE) {
    // 并行处理
    let processed: Vec<_> = chunk.iter()
        .map(|item| process_single(item))
        .collect();
    let results = futures::future::join_all(processed).await;
    
    // 批量插入
    database.insert_batch(&results).await?;
}
```

## 3. 服务不可用问题

### 3.1 问题识别

**症状**：

- 健康检查失败
- 服务无响应
- 大量 5xx 错误

### 3.2 诊断决策树

```text
服务不可用
│
├─► 进程存活?
│   ├─ No  ► 进程崩溃
│   │        ├─ 检查 core dump
│   │        ├─ 查看崩溃日志
│   │        ├─ 修复 bug 或增加保护
│   │        └─ 自动重启服务
│   │
│   └─ Yes ► 继续下一步
│
├─► 端口监听?
│   ├─ No  ► 服务未正常启动
│   │        ├─ 检查配置文件
│   │        ├─ 检查端口冲突
│   │        ├─ 查看启动日志
│   │        └─ 修复启动问题
│   │
│   └─ Yes ► 继续下一步
│
├─► 能建立连接?
│   ├─ No  ► 网络或防火墙问题
│   │        ├─ 检查防火墙规则
│   │        ├─ 检查网络连通性
│   │        ├─ 检查负载均衡配置
│   │        └─ 修复网络问题
│   │
│   └─ Yes ► 继续下一步
│
├─► 健康检查通过?
│   ├─ No  ► 依赖服务不可用
│   │        ├─ 检查数据库连接
│   │        ├─ 检查缓存服务
│   │        ├─ 检查下游API
│   │        ├─ 实施降级策略
│   │        └─ 修复依赖问题
│   │
│   └─ Yes ► 继续下一步
│
└─► 请求处理正常?
    ├─ No  ► 业务逻辑错误
    │        ├─ 查看错误日志
    │        ├─ 检查最近部署
    │        ├─ 回滚或热修复
    │        └─ 修复业务逻辑
    │
    └─ Yes ► 问题可能已恢复，持续观察
```

### 3.3 快速恢复脚本

```bash
#!/bin/bash
# otlp_health_check.sh - 健康检查和自动恢复脚本

SERVICE_NAME="otlp"
SERVICE_PORT=8080
MAX_RETRIES=3
RECOVERY_ACTIONS=("restart" "config_reload" "fallback")

# 1. 检查进程
check_process() {
    if pgrep -x "$SERVICE_NAME" > /dev/null; then
        echo "✓ Process is running"
        return 0
    else
        echo "✗ Process not found"
        return 1
    fi
}

# 2. 检查端口
check_port() {
    if netstat -tuln | grep -q ":$SERVICE_PORT "; then
        echo "✓ Port $SERVICE_PORT is listening"
        return 0
    else
        echo "✗ Port $SERVICE_PORT not listening"
        return 1
    fi
}

# 3. 检查 HTTP 健康检查
check_health() {
    local response=$(curl -s -o /dev/null -w "%{http_code}" \
                     http://localhost:$SERVICE_PORT/health)
    if [ "$response" = "200" ]; then
        echo "✓ Health check passed"
        return 0
    else
        echo "✗ Health check failed (HTTP $response)"
        return 1
    fi
}

# 4. 执行恢复操作
recover() {
    local action=$1
    echo "Executing recovery action: $action"
    
    case $action in
        restart)
            systemctl restart $SERVICE_NAME
            sleep 5
            ;;
        config_reload)
            systemctl reload $SERVICE_NAME
            sleep 2
            ;;
        fallback)
            # 启动备用实例或降级模式
            systemctl start ${SERVICE_NAME}-fallback
            ;;
        *)
            echo "Unknown recovery action: $action"
            return 1
            ;;
    esac
}

# 主逻辑
main() {
    echo "=== OTLP Health Check ==="
    echo "Time: $(date)"
    echo
    
    # 运行检查
    local checks_passed=true
    check_process || checks_passed=false
    check_port || checks_passed=false
    check_health || checks_passed=false
    
    if [ "$checks_passed" = true ]; then
        echo
        echo "✓ All checks passed"
        exit 0
    fi
    
    # 尝试恢复
    echo
    echo "=== Attempting Recovery ==="
    for action in "${RECOVERY_ACTIONS[@]}"; do
        recover "$action"
        
        # 重新检查
        if check_health; then
            echo "✓ Service recovered after: $action"
            exit 0
        fi
    done
    
    echo "✗ All recovery attempts failed"
    echo "Manual intervention required!"
    
    # 发送告警
    curl -X POST "https://alert-webhook.example.com/otlp-critical" \
         -d "{\"service\": \"$SERVICE_NAME\", \"status\": \"critical\"}"
    
    exit 1
}

main "$@"
```

### 3.4 案例：数据库连接池耗尽

**症状**：

```text
2025-10-04 16:45:23 ERROR Failed to acquire database connection: timeout
2025-10-04 16:45:23 ERROR Health check failed: cannot connect to database
```

**诊断**：

```bash
# 1. 检查数据库连接数
mysql -e "SHOW PROCESSLIST;" | wc -l
# 输出: 1000 (达到最大连接数限制)

# 2. 检查应用连接池状态
curl http://localhost:9090/metrics | grep db_pool
# db_pool_active_connections 950
# db_pool_idle_connections 0
# db_pool_waiting_requests 50
```

**根因**：

- 连接未正确释放（连接泄漏）
- 连接池大小配置不当
- 慢查询占用连接时间过长

**解决方案**：

```rust
// 1. 确保连接正确释放
async fn query_with_timeout(pool: &DbPool, query: &str) -> Result<()> {
    // 使用 tokio::time::timeout 防止长时间占用
    let result = tokio::time::timeout(
        Duration::from_secs(10),
        async {
            let conn = pool.get().await?;
            conn.execute(query).await
        }
    ).await;
    
    match result {
        Ok(Ok(data)) => Ok(data),
        Ok(Err(e)) => Err(e),
        Err(_) => Err(anyhow::anyhow!("Query timeout")),
    }
    // conn 在这里自动释放
}

// 2. 调整连接池配置
let pool = DbPoolBuilder::new()
    .max_size(100)              // 最大连接数
    .min_idle(10)               // 最小空闲连接
    .max_lifetime(Some(Duration::from_secs(1800)))  // 连接最大生命周期
    .idle_timeout(Some(Duration::from_secs(600)))   // 空闲超时
    .connection_timeout(Duration::from_secs(5))     // 获取连接超时
    .build()?;

// 3. 监控和告警
let pool_monitor = Arc::new(pool.clone());
tokio::spawn(async move {
    let mut interval = tokio::time::interval(Duration::from_secs(60));
    loop {
        interval.tick().await;
        let stats = pool_monitor.state();
        
        if stats.idle_connections == 0 {
            eprintln!("WARNING: No idle database connections!");
        }
        
        if stats.connections >= pool_monitor.max_size() * 90 / 100 {
            eprintln!("WARNING: Database pool nearly exhausted!");
        }
    }
});
```

## 4. 数据准确性问题

### 4.1 诊断决策树

```text
数据准确性问题
│
├─► 数据丢失?
│   ├─ Yes ► 传输或存储问题
│   │        ├─ 检查网络丢包
│   │        ├─ 检查队列溢出
│   │        ├─ 检查磁盘空间
│   │        ├─ 添加重试机制
│   │        └─ 启用持久化
│   │
│   └─ No  ► 继续下一步
│
├─► 数据重复?
│   ├─ Yes ► 幂等性问题
│   │        ├─ 检查去重逻辑
│   │        ├─ 使用唯一ID
│   │        ├─ 数据库唯一约束
│   │        └─ 幂等性保证
│   │
│   └─ No  ► 继续下一步
│
├─► 数据乱序?
│   ├─ Yes ► 时序问题
│   │        ├─ 检查时钟同步
│   │        ├─ 使用逻辑时钟
│   │        ├─ 排序后处理
│   │        └─ 因果关系追踪
│   │
│   └─ No  ► 继续下一步
│
└─► 数据错误?
    ├─ Yes ► 逻辑错误或数据损坏
    │        ├─ 验证数据完整性
    │        ├─ 检查序列化逻辑
    │        ├─ 修复数据处理代码
    │        └─ 数据修复脚本
    │
    └─ No  ► 可能是理解偏差，核对需求
```

### 4.2 数据一致性检查

```rust
use sha2::{Sha256, Digest};

/// 数据完整性验证
pub struct DataIntegrityChecker {
    hasher: Sha256,
}

impl DataIntegrityChecker {
    pub fn new() -> Self {
        Self {
            hasher: Sha256::new(),
        }
    }
    
    /// 计算数据哈希
    pub fn compute_hash(&mut self, data: &[u8]) -> String {
        self.hasher.update(data);
        let result = self.hasher.finalize_reset();
        format!("{:x}", result)
    }
    
    /// 验证数据完整性
    pub fn verify(&mut self, data: &[u8], expected_hash: &str) -> bool {
        let actual_hash = self.compute_hash(data);
        actual_hash == expected_hash
    }
}

/// 数据一致性检查
pub async fn check_data_consistency(
    source: &DataSource,
    replica: &DataSource,
) -> Result<ConsistencyReport> {
    let mut report = ConsistencyReport::new();
    
    // 1. 比较数据量
    let source_count = source.count().await?;
    let replica_count = replica.count().await?;
    
    if source_count != replica_count {
        report.add_issue(format!(
            "Count mismatch: source={}, replica={}",
            source_count, replica_count
        ));
    }
    
    // 2. 抽样验证数据内容
    let sample_size = (source_count / 100).max(100);  // 1% 或最少100条
    let sample_ids: Vec<_> = (0..sample_size)
        .map(|_| rand::random::<u64>() % source_count)
        .collect();
    
    for id in sample_ids {
        let source_data = source.get(id).await?;
        let replica_data = replica.get(id).await?;
        
        if source_data != replica_data {
            report.add_issue(format!(
                "Data mismatch at id={}: source={:?}, replica={:?}",
                id, source_data, replica_data
            ));
        }
    }
    
    // 3. 验证数据完整性
    let mut checker = DataIntegrityChecker::new();
    for id in 0..100 {  // 验证前100条
        if let Ok(data) = source.get(id).await {
            let checksum = data.checksum();
            if !checker.verify(&data.bytes(), &checksum) {
                report.add_issue(format!(
                    "Checksum mismatch at id={}", id
                ));
            }
        }
    }
    
    Ok(report)
}

#[derive(Debug)]
pub struct ConsistencyReport {
    issues: Vec<String>,
    checked_at: std::time::SystemTime,
}

impl ConsistencyReport {
    pub fn new() -> Self {
        Self {
            issues: Vec::new(),
            checked_at: std::time::SystemTime::now(),
        }
    }
    
    pub fn add_issue(&mut self, issue: String) {
        self.issues.push(issue);
    }
    
    pub fn is_consistent(&self) -> bool {
        self.issues.is_empty()
    }
    
    pub fn print(&self) {
        println!("=== Data Consistency Report ===");
        println!("Checked at: {:?}", self.checked_at);
        
        if self.is_consistent() {
            println!("✓ All checks passed");
        } else {
            println!("✗ {} issues found:", self.issues.len());
            for (i, issue) in self.issues.iter().enumerate() {
                println!("  {}. {}", i + 1, issue);
            }
        }
    }
}
```

## 5. 快速诊断命令集

### 5.1 一键健康检查

```bash
#!/bin/bash
# quick_check.sh - 快速健康检查

echo "=== OTLP Quick Health Check ==="

# 系统资源
echo -e "\n[1/7] System Resources:"
echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')% used"
echo "Memory: $(free -h | awk '/^Mem:/ {print $3 "/" $2}')"
echo "Disk: $(df -h / | awk '/\/$/ {print $5 " used"}')"

# 进程状态
echo -e "\n[2/7] Process Status:"
if pgrep -x otlp > /dev/null; then
    echo "✓ OTLP process running (PID: $(pgrep -x otlp))"
else
    echo "✗ OTLP process not found"
fi

# 端口监听
echo -e "\n[3/7] Port Status:"
netstat -tuln | grep ':8080\|:9090' || echo "✗ Ports not listening"

# HTTP 健康检查
echo -e "\n[4/7] HTTP Health:"
curl -s -o /dev/null -w "Health endpoint: HTTP %{http_code}\n" \
     http://localhost:8080/health

# 指标检查
echo -e "\n[5/7] Key Metrics:"
curl -s http://localhost:9090/metrics | grep -E \
    'otlp_requests_total|otlp_request_duration|otlp_errors_total' | \
    head -n 5

# 最近错误
echo -e "\n[6/7] Recent Errors:"
journalctl -u otlp --since "5 minutes ago" | \
    grep -i error | tail -n 5 || echo "No recent errors"

# 依赖服务
echo -e "\n[7/7] Dependencies:"
for service in database:5432 cache:6379; do
    IFS=: read -r host port <<< "$service"
    if nc -zv -w2 $host $port 2>&1 | grep -q succeeded; then
        echo "✓ $host:$port reachable"
    else
        echo "✗ $host:$port unreachable"
    fi
done

echo -e "\n=== Check Complete ==="
```

### 5.2 性能分析一键脚本

```bash
#!/bin/bash
# perf_analysis.sh - 性能分析

DURATION=30
OUTPUT_DIR="./perf_analysis_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$OUTPUT_DIR"

echo "Running performance analysis for ${DURATION}s..."
echo "Output directory: $OUTPUT_DIR"

# 1. CPU 分析
echo "[1/5] CPU profiling..."
perf record -F 99 -p $(pgrep otlp) -g -- sleep $DURATION \
    -o "$OUTPUT_DIR/perf.data" 2>&1 | tee "$OUTPUT_DIR/cpu.log"

perf script -i "$OUTPUT_DIR/perf.data" | \
    ./flamegraph.pl > "$OUTPUT_DIR/flame graph.svg"

# 2. 内存快照
echo "[2/5] Memory snapshot..."
pmap -x $(pgrep otlp) > "$OUTPUT_DIR/memory_map.txt"
ps aux | grep otlp > "$OUTPUT_DIR/process_info.txt"

# 3. 网络统计
echo "[3/5] Network statistics..."
ss -s > "$OUTPUT_DIR/socket_stats.txt"
netstat -antp | grep otlp > "$OUTPUT_DIR/connections.txt"

# 4. 磁盘 I/O
echo "[4/5] Disk I/O..."
iostat -x 1 $DURATION > "$OUTPUT_DIR/disk_io.txt" &

# 5. 系统调用追踪
echo "[5/5] System call tracing..."
strace -c -p $(pgrep otlp) -o "$OUTPUT_DIR/syscalls.txt" \
    sleep $DURATION 2>&1

echo "Analysis complete! Results in: $OUTPUT_DIR"
echo "To view flame graph: firefox $OUTPUT_DIR/flamegraph.svg"
```

## 6. 总结

### 诊断原则

1. **自顶向下**：从用户体验开始，逐步深入底层
2. **二分法**：快速排除一半可能性
3. **数据驱动**：依靠指标和日志，而非猜测
4. **可重现**：确保问题可以稳定重现
5. **最小改动**：一次只改一个变量

### 常用工具清单

| 类别 | 工具 | 用途 |
|-----|------|-----|
| CPU | perf, flamegraph | CPU 性能分析 |
| 内存 | valgrind, heaptrack | 内存泄漏检测 |
| 网络 | tcpdump, wireshark | 网络抓包分析 |
| 磁盘 | iostat, iotop | I/O 性能分析 |
| 追踪 | strace, ltrace | 系统调用追踪 |
| 日志 | journalctl, grep | 日志查询 |
| 监控 | Prometheus, Grafana | 指标可视化 |

### 下一步

- [根因分析方法论](./根因分析方法论.md)
- [常见问题手册](./常见问题手册.md)
- [性能优化方案](../性能调优/优化方案库.md)
