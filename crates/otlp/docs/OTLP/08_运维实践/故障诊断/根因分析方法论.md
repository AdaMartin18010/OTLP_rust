# 根因分析方法论

## 目录

- [根因分析方法论](#根因分析方法论)
  - [目录](#目录)
  - [概述](#概述)
  - [1. RCA 基本原则](#1-rca-基本原则)
    - [1.1 五个为什么 (5 Whys)](#11-五个为什么-5-whys)
    - [1.2 鱼骨图 (Ishikawa Diagram)](#12-鱼骨图-ishikawa-diagram)
    - [1.3 时间线分析](#13-时间线分析)
  - [2. 系统化 RCA 流程](#2-系统化-rca-流程)
    - [2.1 完整流程](#21-完整流程)
    - [2.2 问题定义模板](#22-问题定义模板)
    - [2.3 数据收集清单](#23-数据收集清单)
  - [3. 假设驱动的分析](#3-假设驱动的分析)
    - [3.1 假设生成框架](#31-假设生成框架)
    - [3.2 假设验证方法](#32-假设验证方法)
      - [方法1：实验验证](#方法1实验验证)
      - [方法2：日志分析](#方法2日志分析)
  - [4. 常见反模式](#4-常见反模式)
    - [4.1 过早下结论](#41-过早下结论)
    - [4.2 停在表面症状](#42-停在表面症状)
    - [4.3 忽略时间线](#43-忽略时间线)
  - [5. RCA 报告模板](#5-rca-报告模板)
  - [6. 自动化 RCA 工具](#6-自动化-rca-工具)
  - [7. 总结](#7-总结)
    - [关键要点](#关键要点)
    - [最佳实践](#最佳实践)
    - [工具推荐](#工具推荐)
    - [下一步](#下一步)

## 概述

根因分析（Root Cause Analysis, RCA）是系统化识别问题根本原因的方法论，帮助从症状追溯到根本原因，并制定预防措施。

## 1. RCA 基本原则

### 1.1 五个为什么 (5 Whys)

通过连续追问"为什么"深入挖掘根本原因。

**示例：数据丢失**:

```text
问题：用户报告追踪数据丢失

为什么1：为什么数据丢失？
答：数据未写入数据库

为什么2：为什么数据未写入数据库？
答：写入队列溢出，数据被丢弃

为什么3：为什么队列会溢出？
答：消费速度慢于生产速度

为什么4：为什么消费速度慢？
答：数据库写入有性能瓶颈

为什么5：为什么数据库写入慢？
答：缺少索引，每次插入都需要全表扫描

根因：数据库表缺少必要的索引
解决方案：添加索引，优化查询
预防措施：性能测试流程，索引设计规范
```

### 1.2 鱼骨图 (Ishikawa Diagram)

系统化分析多个可能的原因类别。

```text
                              问题：高延迟
                                    │
              ┌─────────────────────┼─────────────────────┐
              │                     │                     │
          [人为因素]              [流程]               [技术]
              │                     │                     │
    ├─ 配置错误          ├─ 部署流程       ├─ 代码bug
    ├─ 操作失误          ├─ 变更管理       ├─ 架构设计
    └─ 经验不足          └─ 测试不足       └─ 资源不足
              │                     │                     │
              │                     │                     │
          [环境]                [数据]               [依赖]
              │                     │                     │
    ├─ 硬件故障          ├─ 数据量增长     ├─ 下游服务慢
    ├─ 网络问题          ├─ 数据倾斜       ├─ 第三方API
    └─ 资源竞争          └─ 数据损坏       └─ 基础设施
```

### 1.3 时间线分析

构建事件时间线，识别因果关系。

```text
事件时间线
────────────────────────────────────────────────────────►
T₀: 15:00  部署新版本 v2.5.0
            │
T₁: 15:05  CPU 使用率开始上升（30% → 60%）
            │
T₂: 15:10  P99 延迟增加（50ms → 200ms）
            │
T₃: 15:15  开始出现超时错误
            │
T₄: 15:20  触发熔断，部分服务降级
            │
T₅: 15:25  用户投诉增加
            │
T₆: 15:30  回滚到 v2.4.9
            │
T₇: 15:35  指标恢复正常

分析：
- T₀ 是变更点（部署）
- T₁-T₃ 是问题逐步恶化
- T₃ 是用户可感知点
- T₆-T₇ 验证了部署是根因
```

## 2. 系统化 RCA 流程

### 2.1 完整流程

```text
┌─────────────┐
│ 1. 问题定义 │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 2. 数据收集 │ ◄── 日志、指标、追踪
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 3. 假设生成 │ ◄── 使用鱼骨图、5 Whys
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 4. 假设验证 │ ◄── 实验、重现、分析
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 5. 根因确定 │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 6. 解决方案 │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 7. 预防措施 │
└──────┬──────┘
       │
       ▼
┌─────────────┐
│ 8. 文档归档 │
└─────────────┘
```

### 2.2 问题定义模板

```markdown
## 问题摘要
简洁描述问题（一句话）

## 影响范围
- 受影响用户：[百分比/数量]
- 受影响功能：[具体功能列表]
- 持续时间：[开始时间 - 结束时间]
- 业务影响：[订单/收入损失等]

## 问题症状
- 症状1：具体的可观察现象
- 症状2：相关指标变化
- ...

## 初步观察
- 观察到的异常模式
- 相关性分析
- 时间相关性
```

**示例**：

```markdown
## 问题摘要
2025-10-04 15:00-15:35 OTLP 服务 P99 延迟增加 4倍

## 影响范围
- 受影响用户：100% (所有用户)
- 受影响功能：追踪数据上报和查询
- 持续时间：35分钟
- 业务影响：追踪数据延迟，影响实时监控

## 问题症状
- P99 延迟从 50ms 增加到 200ms
- CPU 使用率从 30% 增加到 60%
- 超时错误率从 0% 增加到 5%
- 部分请求触发熔断

## 初步观察
- 问题开始于 v2.5.0 部署之后
- 回滚后立即恢复
- 新版本引入了新的数据处理逻辑
```

### 2.3 数据收集清单

```bash
#!/bin/bash
# collect_rca_data.sh - RCA 数据收集脚本

INCIDENT_ID=$1
OUTPUT_DIR="./rca_${INCIDENT_ID}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$OUTPUT_DIR"

echo "Collecting RCA data for incident: $INCIDENT_ID"
echo "Output directory: $OUTPUT_DIR"

# 1. 系统信息
echo "[1/10] Collecting system info..."
{
    echo "=== System Information ==="
    uname -a
    uptime
    date
} > "$OUTPUT_DIR/system_info.txt"

# 2. 资源使用
echo "[2/10] Collecting resource usage..."
{
    echo "=== CPU ===" 
    top -bn1 | head -n 20
    echo -e "\n=== Memory ==="
    free -h
    echo -e "\n=== Disk ==="
    df -h
    echo -e "\n=== Network ==="
    ss -s
} > "$OUTPUT_DIR/resources.txt"

# 3. 进程状态
echo "[3/10] Collecting process state..."
ps aux | grep otlp > "$OUTPUT_DIR/processes.txt"
pstree -p $(pgrep otlp) > "$OUTPUT_DIR/process_tree.txt"

# 4. 日志（最近1小时）
echo "[4/10] Collecting logs..."
journalctl -u otlp --since "1 hour ago" \
    > "$OUTPUT_DIR/service_logs.txt"

# 5. 指标快照
echo "[5/10] Collecting metrics..."
curl -s http://localhost:9090/metrics \
    > "$OUTPUT_DIR/metrics_snapshot.txt"

# 6. 配置文件
echo "[6/10] Collecting configs..."
cp /etc/otlp/config.toml "$OUTPUT_DIR/"
cp /etc/otlp/*.conf "$OUTPUT_DIR/" 2>/dev/null || true

# 7. 网络连接
echo "[7/10] Collecting network connections..."
{
    netstat -antp | grep otlp
    ss -antp | grep otlp
} > "$OUTPUT_DIR/network_connections.txt"

# 8. 数据库状态
echo "[8/10] Collecting database state..."
{
    mysql -e "SHOW PROCESSLIST;"
    mysql -e "SHOW ENGINE INNODB STATUS\G"
} > "$OUTPUT_DIR/database_state.txt" 2>&1

# 9. 最近部署历史
echo "[9/10] Collecting deployment history..."
{
    echo "=== Recent Deployments ==="
    journalctl -u otlp | grep -i "deploy\|version\|start" | tail -n 20
    echo -e "\n=== Git History ==="
    cd /opt/otlp && git log --oneline -10
} > "$OUTPUT_DIR/deployment_history.txt" 2>&1

# 10. 追踪数据样本
echo "[10/10] Collecting trace samples..."
curl -s "http://localhost:8080/api/traces?limit=10&sort=slow" \
    > "$OUTPUT_DIR/slow_traces.json"

# 打包
echo "Creating archive..."
tar -czf "${OUTPUT_DIR}.tar.gz" "$OUTPUT_DIR"

echo "Data collection complete!"
echo "Archive: ${OUTPUT_DIR}.tar.gz"
```

## 3. 假设驱动的分析

### 3.1 假设生成框架

```text
对于每个症状，生成可能的原因假设：

症状：[具体症状]
│
├─ 假设1：[可能原因1]
│  ├─ 证据支持：[...]
│  ├─ 证据反对：[...]
│  └─ 验证方法：[...]
│
├─ 假设2：[可能原因2]
│  ├─ 证据支持：[...]
│  ├─ 证据反对：[...]
│  └─ 验证方法：[...]
│
└─ ...
```

**示例**：

```text
症状：数据库查询延迟增加

├─ 假设1：数据量增长导致
│  ├─ 证据支持：表大小从 1GB → 10GB
│  ├─ 证据反对：增长是渐进的，但延迟突增
│  └─ 验证方法：检查表大小历史

├─ 假设2：缺少索引
│  ├─ 证据支持：EXPLAIN 显示全表扫描
│  ├─ 证据反对：索引一直没有，为何现在才慢？
│  └─ 验证方法：EXPLAIN 分析，添加索引测试

├─ 假设3：查询模式变化
│  ├─ 证据支持：新版本修改了查询逻辑
│  ├─ 证据反对：（暂无）
│  └─ 验证方法：对比新旧版本的查询，慢查询日志

结论：假设3 最可能，需要重点验证
```

### 3.2 假设验证方法

#### 方法1：实验验证

```rust
/// RCA 实验框架
pub struct RcaExperiment {
    name: String,
    hypothesis: String,
    control_group: Box<dyn Fn() -> Result<Metrics>>,
    experiment_group: Box<dyn Fn() -> Result<Metrics>>,
}

impl RcaExperiment {
    pub fn new(name: &str, hypothesis: &str) -> Self {
        Self {
            name: name.to_string(),
            hypothesis: hypothesis.to_string(),
            control_group: Box::new(|| Ok(Metrics::default())),
            experiment_group: Box::new(|| Ok(Metrics::default())),
        }
    }
    
    pub async fn run(&self, iterations: usize) -> ExperimentResult {
        let mut control_metrics = Vec::new();
        let mut experiment_metrics = Vec::new();
        
        for _ in 0..iterations {
            // 运行对照组
            if let Ok(m) = (self.control_group)() {
                control_metrics.push(m);
            }
            
            // 运行实验组
            if let Ok(m) = (self.experiment_group)() {
                experiment_metrics.push(m);
            }
        }
        
        ExperimentResult {
            hypothesis: self.hypothesis.clone(),
            control_avg: average(&control_metrics),
            experiment_avg: average(&experiment_metrics),
            significant: is_significantly_different(
                &control_metrics,
                &experiment_metrics
            ),
        }
    }
}

#[derive(Debug)]
pub struct ExperimentResult {
    hypothesis: String,
    control_avg: f64,
    experiment_avg: f64,
    significant: bool,
}

impl ExperimentResult {
    pub fn print(&self) {
        println!("=== Experiment Result ===");
        println!("Hypothesis: {}", self.hypothesis);
        println!("Control group avg: {:.2}", self.control_avg);
        println!("Experiment group avg: {:.2}", self.experiment_avg);
        println!("Difference: {:.2}%", 
                (self.experiment_avg - self.control_avg) / self.control_avg * 100.0);
        println!("Statistically significant: {}", self.significant);
        
        if self.significant {
            println!("✓ Hypothesis SUPPORTED");
        } else {
            println!("✗ Hypothesis NOT supported");
        }
    }
}

// 使用示例
#[tokio::main]
async fn main() {
    let exp = RcaExperiment::new(
        "Index Impact",
        "添加索引可以显著降低查询延迟"
    );
    
    // 设置对照组（无索引）
    exp.control_group = Box::new(|| {
        let start = Instant::now();
        database.query_without_index()?;
        Ok(Metrics { latency: start.elapsed().as_millis() as f64 })
    });
    
    // 设置实验组（有索引）
    exp.experiment_group = Box::new(|| {
        let start = Instant::now();
        database.query_with_index()?;
        Ok(Metrics { latency: start.elapsed().as_millis() as f64 })
    });
    
    let result = exp.run(100).await;
    result.print();
}
```

#### 方法2：日志分析

```python
#!/usr/bin/env python3
# log_correlation_analysis.py - 日志相关性分析

import re
from datetime import datetime
from collections import defaultdict
from typing import List, Dict

class LogEvent:
    def __init__(self, timestamp: datetime, level: str, message: str):
        self.timestamp = timestamp
        self.level = level
        self.message = message
    
    def __repr__(self):
        return f"{self.timestamp} [{self.level}] {self.message}"

def parse_log_line(line: str) -> LogEvent:
    """解析日志行"""
    pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) (.+)'
    match = re.match(pattern, line)
    if match:
        timestamp = datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
        level = match.group(2)
        message = match.group(3)
        return LogEvent(timestamp, level, message)
    return None

def analyze_correlation(log_file: str, 
                       event_a_pattern: str,
                       event_b_pattern: str,
                       time_window_seconds: int = 60):
    """
    分析两类事件的相关性
    
    假设：如果事件A发生后，事件B在时间窗口内频繁发生，
    则可能存在因果关系
    """
    events_a = []
    events_b = []
    
    # 读取并解析日志
    with open(log_file) as f:
        for line in f:
            event = parse_log_line(line)
            if not event:
                continue
            
            if re.search(event_a_pattern, event.message):
                events_a.append(event)
            elif re.search(event_b_pattern, event.message):
                events_b.append(event)
    
    # 计算相关性
    correlations = []
    for event_a in events_a:
        # 在时间窗口内查找事件B
        following_events = [
            event_b for event_b in events_b
            if 0 < (event_b.timestamp - event_a.timestamp).total_seconds() <= time_window_seconds
        ]
        
        if following_events:
            correlations.append({
                'trigger': event_a,
                'consequences': following_events,
                'count': len(following_events)
            })
    
    # 输出结果
    print(f"=== Correlation Analysis ===")
    print(f"Event A pattern: {event_a_pattern}")
    print(f"Event B pattern: {event_b_pattern}")
    print(f"Time window: {time_window_seconds}s")
    print()
    
    if correlations:
        print(f"Found {len(correlations)} correlations:")
        for i, corr in enumerate(correlations[:10], 1):  # 显示前10个
            print(f"\n{i}. {corr['trigger']}")
            print(f"   → Followed by {corr['count']} events:")
            for event in corr['consequences'][:3]:  # 显示前3个后续事件
                print(f"      {event}")
        
        # 统计
        total_a = len(events_a)
        correlated_a = len(correlations)
        correlation_rate = correlated_a / total_a * 100 if total_a > 0 else 0
        
        print(f"\nCorrelation rate: {correlation_rate:.1f}% ({correlated_a}/{total_a})")
        
        if correlation_rate > 80:
            print("✓ STRONG correlation - likely causal relationship")
        elif correlation_rate > 50:
            print("⚠ MODERATE correlation - possible relationship")
        else:
            print("✗ WEAK correlation - unlikely causal relationship")
    else:
        print("No correlations found")

# 使用示例
if __name__ == "__main__":
    # 分析：数据库连接错误 与 内存不足 的相关性
    analyze_correlation(
        log_file="/var/log/otlp/service.log",
        event_a_pattern="Failed to acquire database connection",
        event_b_pattern="OutOfMemory|OOM",
        time_window_seconds=60
    )
```

## 4. 常见反模式

### 4.1 过早下结论

**错误示例**：

```text
症状：服务延迟增加
立即结论：一定是数据库慢
行动：立即扩容数据库

结果：问题未解决，实际是应用代码bug
```

**正确做法**：

```text
1. 收集数据验证假设
2. 排查应用层日志
3. 分析数据库慢查询
4. 确认根因后再采取行动
```

### 4.2 停在表面症状

**错误示例**：

```text
问题：磁盘满
解决：清理磁盘

一周后：磁盘又满了（没有找到根因：日志未轮转）
```

**正确做法**：

```text
1. 清理磁盘（立即缓解）
2. 分析磁盘使用趋势
3. 发现日志增长过快
4. 根因：日志未配置轮转
5. 永久修复：配置日志轮转
```

### 4.3 忽略时间线

**错误示例**：

```text
看到CPU高就认为是性能问题，
忽略了10分钟前刚部署了新版本
```

**正确做法**：

```text
构建完整时间线：
15:00 - 部署
15:05 - CPU 开始升高
15:10 - 出现错误

结论：部署是变更点，是主要怀疑对象
```

## 5. RCA 报告模板

```markdown
# 根因分析报告

## 元数据
- **事件ID**: INC-2025-1004-001
- **严重级别**: P1
- **报告人**: [名字]
- **日期**: 2025-10-04

## 执行摘要
用1-2段话概述问题、影响和根本原因。

## 时间线
| 时间 | 事件 | 说明 |
|------|------|------|
| 15:00 | 部署 v2.5.0 | 发布新版本 |
| 15:05 | CPU 升高 | 从30%升至60% |
| 15:10 | 延迟增加 | P99 从50ms升至200ms |
| ... | ... | ... |

## 影响分析
- **用户影响**: 100%用户受影响
- **持续时间**: 35分钟
- **业务影响**: [具体损失]
- **SLA违反**: P99延迟 SLO: <100ms，实际: 200ms

## 根本原因
### 直接原因
新版本的查询优化代码存在bug，导致SQL查询未使用索引。

### 根本原因
1. 代码审查未发现SQL性能问题
2. 性能测试数据量不足，未暴露问题
3. 监控告警阈值设置过高，延迟发现

### 为什么问题会发生？
1. 开发：重构时误删了索引提示
2. 测试：测试环境数据量小（1000条），未暴露问题  
3. 部署：金丝雀发布比例过大（50%），影响面大
4. 监控：P99告警阈值300ms，200ms未触发

## 解决方案
### 短期（已执行）
1. ✓ 15:30 回滚到 v2.4.9
2. ✓ 15:35 验证指标恢复
3. ✓ 16:00 修复代码并测试

### 长期（计划）
1. [ ] 增强代码审查checklist，包含性能专项
2. [ ] 性能测试使用生产级数据量
3. [ ] 调整监控告警阈值，增加敏感度
4. [ ] 金丝雀发布改为 5% → 25% → 50% → 100%

## 预防措施
| 措施 | 责任人 | 截止日期 | 状态 |
|------|--------|----------|------|
| 完善SQL审查规范 | @dev-lead | 2025-10-10 | TODO |
| 增加性能测试数据 | @qa-lead | 2025-10-15 | TODO |
| 优化发布流程 | @sre | 2025-10-20 | TODO |
| 告警规则调整 | @ops | 2025-10-08 | TODO |

## 学到的教训
1. ✅ 性能测试需要使用真实数据量
2. ✅ 金丝雀发布要逐步放量
3. ✅ 监控告警要更敏感
4. ✅ SQL变更需要专项审查

## 附录
- [日志文件](./logs/)
- [指标截图](./metrics/)
- [代码差异](./code-diff.patch)
```

## 6. 自动化 RCA 工具

```rust
/// 自动化根因分析工具
pub struct AutomatedRcaEngine {
    log_analyzer: LogAnalyzer,
    metric_analyzer: MetricAnalyzer,
    trace_analyzer: TraceAnalyzer,
    knowledge_base: KnowledgeBase,
}

impl AutomatedRcaEngine {
    /// 执行自动化 RCA
    pub async fn analyze(&self, incident: &Incident) -> RcaResult {
        let mut findings = Vec::new();
        
        // 1. 时间线分析
        let timeline = self.build_timeline(incident).await?;
        findings.push(Finding::Timeline(timeline));
        
        // 2. 日志异常分析
        let log_anomalies = self.log_analyzer
            .detect_anomalies(incident.start_time, incident.end_time)
            .await?;
        findings.push(Finding::LogAnomalies(log_anomalies));
        
        // 3. 指标相关性分析
        let metric_correlations = self.metric_analyzer
            .correlate_metrics(incident)
            .await?;
        findings.push(Finding::MetricCorrelations(metric_correlations));
        
        // 4. 追踪分析
        let trace_insights = self.trace_analyzer
            .analyze_slow_traces(incident)
            .await?;
        findings.push(Finding::TraceInsights(trace_insights));
        
        // 5. 知识库匹配
        let similar_incidents = self.knowledge_base
            .find_similar(incident)
            .await?;
        findings.push(Finding::SimilarIncidents(similar_incidents));
        
        // 6. 生成假设
        let hypotheses = self.generate_hypotheses(&findings);
        
        // 7. 假设排序（按可能性）
        let ranked_hypotheses = self.rank_hypotheses(hypotheses);
        
        RcaResult {
            incident_id: incident.id.clone(),
            findings,
            hypotheses: ranked_hypotheses,
            confidence: self.calculate_confidence(&ranked_hypotheses),
        }
    }
    
    fn generate_hypotheses(&self, findings: &[Finding]) -> Vec<Hypothesis> {
        let mut hypotheses = Vec::new();
        
        // 基于规则生成假设
        if let Some(Finding::Timeline(timeline)) = 
            findings.iter().find(|f| matches!(f, Finding::Timeline(_))) {
            
            // 检查是否有部署事件
            if timeline.has_deployment() {
                hypotheses.push(Hypothesis {
                    description: "新版本部署引入问题".to_string(),
                    evidence: vec!["部署时间与问题出现时间一致".to_string()],
                    confidence: 0.8,
                });
            }
        }
        
        // 基于知识库生成假设
        if let Some(Finding::SimilarIncidents(similar)) = 
            findings.iter().find(|f| matches!(f, Finding::SimilarIncidents(_))) {
            
            for incident in similar.iter().take(3) {
                hypotheses.push(Hypothesis {
                    description: format!("类似问题: {}", incident.root_cause),
                    evidence: vec![format!("相似度: {:.0}%", incident.similarity * 100.0)],
                    confidence: incident.similarity,
                });
            }
        }
        
        hypotheses
    }
    
    fn rank_hypotheses(&self, mut hypotheses: Vec<Hypothesis>) -> Vec<Hypothesis> {
        hypotheses.sort_by(|a, b| {
            b.confidence.partial_cmp(&a.confidence).unwrap()
        });
        hypotheses
    }
}

#[derive(Debug)]
pub struct RcaResult {
    pub incident_id: String,
    pub findings: Vec<Finding>,
    pub hypotheses: Vec<Hypothesis>,
    pub confidence: f64,
}

impl RcaResult {
    pub fn print(&self) {
        println!("=== Automated RCA Result ===");
        println!("Incident: {}", self.incident_id);
        println!("\nTop Hypotheses:");
        
        for (i, hypo) in self.hypotheses.iter().take(5).enumerate() {
            println!("\n{}. {} (confidence: {:.0}%)", 
                    i + 1, hypo.description, hypo.confidence * 100.0);
            println!("   Evidence:");
            for evidence in &hypo.evidence {
                println!("   - {}", evidence);
            }
        }
        
        println!("\nOverall confidence: {:.0}%", self.confidence * 100.0);
    }
}
```

## 7. 总结

### 关键要点

1. **系统化方法**：使用5 Whys、鱼骨图等工具
2. **数据驱动**：基于日志、指标、追踪数据
3. **假设验证**：生成假设并通过实验验证
4. **时间线分析**：识别变更点和因果关系
5. **预防为主**：从每次事件中学习改进

### 最佳实践

- ✅ 记录完整时间线
- ✅ 保留所有相关数据
- ✅ 多角度分析（日志、指标、追踪）
- ✅ 验证假设，不要猜测
- ✅ 区分直接原因和根本原因
- ✅ 制定预防措施
- ✅ 归档到知识库

### 工具推荐

| 工具类型 | 工具 | 用途 |
|---------|------|------|
| 日志分析 | ELK, Loki | 日志聚合和分析 |
| 指标分析 | Prometheus, Grafana | 时序数据分析 |
| 追踪分析 | Jaeger, Zipkin | 分布式追踪 |
| 相关性分析 | 自研脚本 | 事件相关性 |
| 知识库 | Confluence, Notion | 文档管理 |

### 下一步

- [常见问题手册](./常见问题手册.md)
- [诊断工具集](./诊断工具集.md)
- [事后复盘流程](../应急响应/事后复盘.md)
