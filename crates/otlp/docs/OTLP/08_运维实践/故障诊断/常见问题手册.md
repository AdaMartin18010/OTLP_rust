# OTLP 常见问题手册

## 目录

- [OTLP 常见问题手册](#otlp-常见问题手册)
  - [目录](#目录)
  - [概述](#概述)
  - [服务不可用](#服务不可用)
    - [症状](#症状)
    - [可能原因](#可能原因)
    - [诊断步骤](#诊断步骤)
    - [解决方案](#解决方案)
    - [案例研究](#案例研究)
  - [数据丢失](#数据丢失)
    - [症状1](#症状1)
    - [可能原因1](#可能原因1)
    - [诊断步骤1](#诊断步骤1)
    - [解决方案1](#解决方案1)
    - [预防措施](#预防措施)
  - [请求失败率高](#请求失败率高)
    - [症状2](#症状2)
    - [可能原因2](#可能原因2)
    - [诊断步骤2](#诊断步骤2)
    - [解决方案2](#解决方案2)
  - [高延迟问题](#高延迟问题)
    - [症状3](#症状3)
    - [可能原因3](#可能原因3)
    - [诊断步骤3](#诊断步骤3)
    - [解决方案3](#解决方案3)
  - [内存泄漏](#内存泄漏)
    - [症状4](#症状4)
    - [可能原因4](#可能原因4)
    - [诊断步骤4](#诊断步骤4)
    - [解决方案4](#解决方案4)
    - [解决方案5](#解决方案5)
  - [CPU 使用率高](#cpu-使用率高)
    - [症状5](#症状5)
    - [可能原因5](#可能原因5)
    - [诊断步骤5](#诊断步骤5)
    - [解决方案6](#解决方案6)
  - [磁盘空间不足](#磁盘空间不足)
    - [症状6](#症状6)
    - [可能原因6](#可能原因6)
    - [诊断步骤6](#诊断步骤6)
    - [解决方案7](#解决方案7)
  - [网络问题](#网络问题)
    - [症状7](#症状7)
    - [可能原因7](#可能原因7)
    - [诊断步骤7](#诊断步骤7)
    - [解决方案8](#解决方案8)
  - [配置错误](#配置错误)
    - [常见配置错误](#常见配置错误)
    - [诊断方法](#诊断方法)
    - [最佳实践](#最佳实践)
  - [快速参考](#快速参考)
    - [诊断命令速查](#诊断命令速查)
    - [日志位置](#日志位置)
    - [配置文件位置](#配置文件位置)

## 概述

本手册汇总了 OTLP 系统运维中最常见的问题及其解决方案，帮助运维人员快速定位和解决问题。

**使用方法**：

1. 根据症状找到对应章节
2. 按照诊断步骤逐步排查
3. 应用相应的解决方案
4. 参考案例研究了解实际场景

## 服务不可用

### 症状

- HTTP 503 Service Unavailable
- gRPC UNAVAILABLE 错误
- 健康检查失败
- 无法建立连接

### 可能原因

1. **服务未启动**
2. **端口被占用**
3. **资源耗尽**（内存、文件描述符）
4. **依赖服务不可用**（数据库、消息队列）
5. **网络分区**

### 诊断步骤

**步骤 1：检查服务状态**:

```bash
# 检查进程是否运行
ps aux | grep otlp

# 检查端口监听
netstat -tlnp | grep 4317  # gRPC 端口
netstat -tlnp | grep 4318  # HTTP 端口

# 检查 systemd 服务状态
systemctl status otlp-collector
```

**步骤 2：检查资源使用**:

```bash
# 内存使用
free -h

# 文件描述符
lsof -p $(pgrep otlp) | wc -l
cat /proc/$(pgrep otlp)/limits | grep "open files"

# 磁盘空间
df -h
```

**步骤 3：检查日志**:

```bash
# 查看最近的错误日志
journalctl -u otlp-collector -n 100 --no-pager | grep -i error

# 查看启动日志
journalctl -u otlp-collector --since "10 minutes ago"
```

**步骤 4：检查依赖服务**:

```bash
# 检查数据库连接
pg_isready -h localhost -p 5432

# 检查消息队列
rabbitmqctl status

# 检查网络连通性
ping -c 3 <dependency-host>
telnet <dependency-host> <port>
```

### 解决方案

**解决方案 1：重启服务**:

```bash
systemctl restart otlp-collector
```

**解决方案 2：释放端口**:

```bash
# 查找占用端口的进程
lsof -i :4317

# 杀死进程
kill -9 <PID>
```

**解决方案 3：增加资源限制**:

编辑 `/etc/systemd/system/otlp-collector.service`：

```ini
[Service]
LimitNOFILE=65536
LimitNPROC=4096
```

重新加载配置：

```bash
systemctl daemon-reload
systemctl restart otlp-collector
```

**解决方案 4：修复依赖服务**:

```bash
# 重启数据库
systemctl restart postgresql

# 清理消息队列
rabbitmqctl purge_queue <queue-name>
```

### 案例研究

**案例：文件描述符耗尽导致服务不可用**:

**现象**：

- 服务突然无法接受新连接
- 日志显示 "Too many open files"

**根因**：

- 默认文件描述符限制为 1024
- 高并发场景下连接数超过限制

**解决**：

1. 增加文件描述符限制到 65536
2. 添加监控告警，当使用率超过 80% 时告警
3. 实现连接池管理，复用连接

**预防**：

- 设置合理的资源限制
- 监控资源使用情况
- 定期进行压力测试

## 数据丢失

### 症状1

- Span 数量少于预期
- Trace 不完整
- 指标数据缺失
- 日志显示 "dropped spans"

### 可能原因1

1. **缓冲区溢出**
2. **网络丢包**
3. **采样率过高**
4. **存储失败**
5. **配置错误**

### 诊断步骤1

**步骤 1：检查丢弃指标**:

```bash
# 查询 Prometheus 指标
curl http://localhost:8888/metrics | grep dropped

# 示例输出：
# otlp_receiver_dropped_spans_total{reason="queue_full"} 1234
# otlp_exporter_dropped_spans_total{reason="timeout"} 567
```

**步骤 2：检查队列状态**:

```bash
# 查看队列大小
curl http://localhost:8888/metrics | grep queue_size

# 查看队列容量
curl http://localhost:8888/metrics | grep queue_capacity
```

**步骤 3：检查网络状态**:

```bash
# 检查丢包率
netstat -s | grep -i "packet loss"

# 检查网络延迟
ping -c 100 <collector-host> | tail -1
```

**步骤 4：检查采样配置**:

```yaml
# 查看采样配置
cat /etc/otlp/config.yaml | grep -A 10 sampling
```

### 解决方案1

**解决方案 1：增加缓冲区大小**:

编辑 `config.yaml`：

```yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size_mib: 32  # 增加接收缓冲区

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024
    send_batch_max_size: 2048  # 增加批次大小

exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000  # 增加队列大小
```

**解决方案 2：降低采样率**:

```yaml
processors:
  probabilistic_sampler:
    sampling_percentage: 10  # 从 1% 增加到 10%
```

**解决方案 3：启用持久化队列**:

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      enabled: true
      storage: file_storage  # 启用持久化
      queue_size: 10000

extensions:
  file_storage:
    directory: /var/lib/otlp/queue
    timeout: 10s
```

**解决方案 4：增加并发度**:

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      num_consumers: 20  # 增加并发消费者
```

### 预防措施

1. **监控关键指标**：
   - `otlp_receiver_dropped_spans_total`
   - `otlp_exporter_queue_size`
   - `otlp_exporter_send_failed_spans_total`

2. **设置告警**：

   ```yaml
   groups:
   - name: otlp_alerts
     rules:
     - alert: HighSpanDropRate
       expr: rate(otlp_receiver_dropped_spans_total[5m]) > 10
       annotations:
         summary: "High span drop rate detected"
   ```

3. **定期容量规划**：
   - 评估数据量增长趋势
   - 提前扩容

4. **实施数据备份**：
   - 启用持久化队列
   - 定期备份存储数据

## 请求失败率高

### 症状2

- HTTP 5xx 错误增多
- gRPC 错误码非 OK
- 客户端超时
- 错误率指标上升

### 可能原因2

1. **后端服务过载**
2. **网络不稳定**
3. **配置错误**
4. **资源限制**
5. **Bug 或异常**

### 诊断步骤2

**步骤 1：查看错误分布**:

```bash
# 查询错误码分布
curl http://localhost:8888/metrics | grep -E "otlp.*status_code"

# 分析日志中的错误
journalctl -u otlp-collector --since "1 hour ago" | \
  grep -oP 'error.*' | sort | uniq -c | sort -rn
```

**步骤 2：检查后端健康状态**:

```bash
# 检查后端响应时间
curl -w "@curl-format.txt" -o /dev/null -s http://backend:4318/v1/traces

# curl-format.txt 内容：
# time_namelookup:  %{time_namelookup}\n
# time_connect:     %{time_connect}\n
# time_total:       %{time_total}\n
```

**步骤 3：检查系统资源**:

```bash
# CPU 使用率
top -bn1 | grep "Cpu(s)"

# 内存使用率
free -m

# 网络连接数
ss -s
```

### 解决方案2

**解决方案 1：启用重试机制**:

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
```

**解决方案 2：配置超时**:

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    timeout: 30s  # 增加超时时间
```

**解决方案 3：启用负载均衡**:

```yaml
exporters:
  loadbalancing:
    protocol:
      otlp:
        timeout: 10s
    resolver:
      dns:
        hostname: backend.example.com
        port: 4317
```

**解决方案 4：实施熔断器**:

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

/// 熔断器
pub struct CircuitBreaker {
    /// 失败计数
    failure_count: Arc<AtomicU64>,
    /// 失败阈值
    failure_threshold: u64,
    /// 熔断器状态
    state: Arc<AtomicU64>,  // 0: Closed, 1: Open, 2: HalfOpen
    /// 熔断器打开时间
    open_time: Arc<parking_lot::Mutex<Option<Instant>>>,
    /// 恢复超时
    recovery_timeout: Duration,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum CircuitState {
    Closed = 0,
    Open = 1,
    HalfOpen = 2,
}

impl CircuitBreaker {
    pub fn new(failure_threshold: u64, recovery_timeout: Duration) -> Self {
        Self {
            failure_count: Arc::new(AtomicU64::new(0)),
            failure_threshold,
            state: Arc::new(AtomicU64::new(CircuitState::Closed as u64)),
            open_time: Arc::new(parking_lot::Mutex::new(None)),
            recovery_timeout,
        }
    }

    /// 记录成功
    pub fn record_success(&self) {
        self.failure_count.store(0, Ordering::Relaxed);
        self.state.store(CircuitState::Closed as u64, Ordering::Relaxed);
    }

    /// 记录失败
    pub fn record_failure(&self) {
        let count = self.failure_count.fetch_add(1, Ordering::Relaxed) + 1;
        
        if count >= self.failure_threshold {
            self.state.store(CircuitState::Open as u64, Ordering::Relaxed);
            *self.open_time.lock() = Some(Instant::now());
        }
    }

    /// 检查是否允许请求
    pub fn allow_request(&self) -> bool {
        let state = self.state.load(Ordering::Relaxed);
        
        match state {
            s if s == CircuitState::Closed as u64 => true,
            s if s == CircuitState::Open as u64 => {
                // 检查是否可以进入半开状态
                if let Some(open_time) = *self.open_time.lock() {
                    if open_time.elapsed() >= self.recovery_timeout {
                        self.state.store(CircuitState::HalfOpen as u64, Ordering::Relaxed);
                        return true;
                    }
                }
                false
            }
            s if s == CircuitState::HalfOpen as u64 => true,
            _ => false,
        }
    }
}
```

## 高延迟问题

详见[问题诊断决策树 - 高延迟问题](./问题诊断决策树.md#高延迟问题)。

### 症状3

- P99 延迟超过 SLO
- 请求响应时间长
- 用户体验下降

### 可能原因3

1. **数据库查询慢**
2. **网络延迟高**
3. **CPU 瓶颈**
4. **锁竞争**
5. **GC 停顿**（对于 JVM 应用）

### 诊断步骤3

参见[问题诊断决策树](./问题诊断决策树.md)。

### 解决方案3

1. **优化数据库查询**
2. **添加缓存**
3. **增加并发度**
4. **优化算法**

## 内存泄漏

### 症状4

- 内存使用持续增长
- OOM (Out of Memory) 错误
- 服务定期重启
- 性能逐渐下降

### 可能原因4

1. **未释放的资源**（连接、文件句柄）
2. **循环引用**
3. **缓存无限增长**
4. **第三方库 Bug**

### 诊断步骤4

**步骤 1：监控内存趋势**:

```bash
# 实时监控内存
watch -n 1 'ps aux | grep otlp | grep -v grep'

# 查看内存映射
pmap -x $(pgrep otlp)
```

**步骤 2：生成堆转储**:

```bash
# 对于 Rust 应用，使用 valgrind
valgrind --leak-check=full --show-leak-kinds=all ./otlp-collector

# 或使用 heaptrack
heaptrack ./otlp-collector
heaptrack_gui heaptrack.otlp-collector.*.gz
```

**步骤 3：分析内存分配**:

```rust
// 在代码中添加内存分析
#[global_allocator]
static ALLOC: jemallocator::Jemalloc = jemallocator::Jemalloc;

// 定期打印内存统计
jemalloc_ctl::epoch::mib().unwrap().advance().unwrap();
let allocated = jemalloc_ctl::stats::allocated::mib().unwrap().read().unwrap();
println!("Allocated: {} bytes", allocated);
```

### 解决方案4

**解决方案 1：修复资源泄漏**:

```rust
// 使用 RAII 确保资源释放
pub struct Connection {
    inner: TcpStream,
}

impl Drop for Connection {
    fn drop(&mut self) {
        // 确保连接被关闭
        let _ = self.inner.shutdown(std::net::Shutdown::Both);
    }
}
```

**解决方案 2：限制缓存大小**:

```rust
use lru::LruCache;
use std::num::NonZeroUsize;

// 使用 LRU 缓存
let mut cache = LruCache::new(NonZeroUsize::new(1000).unwrap());
```

**解决方案 3：定期清理**:

```rust
use std::time::Duration;
use tokio::time;

// 定期清理过期数据
let mut interval = time::interval(Duration::from_secs(60));
loop {
    interval.tick().await;
    cache.retain(|_, v| !v.is_expired());
}
```

### 解决方案5

**解决方案 4：启用内存限制**:

```yaml
# 在 Docker 中限制内存
docker run -m 2g otlp-collector

# 在 Kubernetes 中限制内存
resources:
  limits:
    memory: 2Gi
  requests:
    memory: 1Gi
```

## CPU 使用率高

### 症状5

- CPU 使用率持续 > 80%
- 系统响应变慢
- 请求排队

### 可能原因5

1. **计算密集型操作**
2. **无限循环或死循环**
3. **并发度不足**
4. **算法效率低**

### 诊断步骤5

**步骤 1：查看 CPU 使用情况**:

```bash
# 查看进程 CPU 使用
top -p $(pgrep otlp)

# 查看线程 CPU 使用
top -H -p $(pgrep otlp)
```

**步骤 2：生成性能剖析**:

```bash
# 使用 perf 分析
perf record -F 99 -p $(pgrep otlp) -g -- sleep 30
perf report

# 生成火焰图
perf script | stackcollapse-perf.pl | flamegraph.pl > flamegraph.svg
```

**步骤 3：分析热点函数**:

```rust
// 使用 pprof 进行性能分析
#[cfg(feature = "profiling")]
use pprof::ProfilerGuard;

let guard = pprof::ProfilerGuard::new(100).unwrap();
// ... 运行代码 ...
if let Ok(report) = guard.report().build() {
    let file = std::fs::File::create("profile.pb").unwrap();
    report.flamegraph(file).unwrap();
}
```

### 解决方案6

**解决方案 1：优化热点代码**:

```rust
// 使用更高效的数据结构
use ahash::AHashMap;  // 比 HashMap 更快

// 减少不必要的克隆
fn process_span(span: &Span) {  // 使用引用而不是克隆
    // ...
}

// 使用并行处理
use rayon::prelude::*;
spans.par_iter().for_each(|span| {
    process_span(span);
});
```

**解决方案 2：增加并发度**:

```yaml
processors:
  batch:
    timeout: 10s
    send_batch_size: 1024

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp]
  
  # 增加处理线程数
  telemetry:
    metrics:
      level: detailed
```

**解决方案 3：实施限流**:

```rust
use governor::{Quota, RateLimiter};
use std::num::NonZeroU32;

// 创建限流器
let quota = Quota::per_second(NonZeroU32::new(1000).unwrap());
let limiter = RateLimiter::direct(quota);

// 应用限流
if limiter.check().is_ok() {
    process_request(req);
} else {
    return Err("Rate limit exceeded");
}
```

## 磁盘空间不足

### 症状6

- 磁盘使用率 > 90%
- 写入失败
- 服务崩溃

### 可能原因6

1. **日志文件过大**
2. **数据未清理**
3. **临时文件堆积**

### 诊断步骤6

```bash
# 查看磁盘使用
df -h

# 查找大文件
du -sh /* | sort -rh | head -10

# 查找日志文件
find /var/log -type f -size +100M
```

### 解决方案7

**解决方案 1：清理日志**:

```bash
# 清理旧日志
find /var/log/otlp -name "*.log" -mtime +7 -delete

# 配置日志轮转
cat > /etc/logrotate.d/otlp <<EOF
/var/log/otlp/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
}
EOF
```

**解决方案 2：启用数据保留策略**:

```yaml
# 配置数据保留期
storage:
  retention:
    traces: 7d
    metrics: 30d
    logs: 14d
```

**解决方案 3：扩展磁盘**:

```bash
# 扩展 LVM
lvextend -L +50G /dev/vg0/lv_data
resize2fs /dev/vg0/lv_data
```

## 网络问题

### 症状7

- 连接超时
- 丢包率高
- 网络延迟大

### 可能原因7

1. **网络拥塞**
2. **防火墙规则**
3. **DNS 解析失败**
4. **MTU 配置错误**

### 诊断步骤7

```bash
# 检查网络连通性
ping -c 10 <host>

# 检查路由
traceroute <host>

# 检查 DNS
nslookup <host>
dig <host>

# 检查防火墙
iptables -L -n
```

### 解决方案8

**解决方案 1：优化网络配置**:

```bash
# 增加 TCP 缓冲区
sysctl -w net.ipv4.tcp_rmem="4096 87380 16777216"
sysctl -w net.ipv4.tcp_wmem="4096 65536 16777216"

# 启用 TCP 快速打开
sysctl -w net.ipv4.tcp_fastopen=3
```

**解决方案 2：配置防火墙**:

```bash
# 允许 OTLP 端口
firewall-cmd --permanent --add-port=4317/tcp
firewall-cmd --permanent --add-port=4318/tcp
firewall-cmd --reload
```

## 配置错误

### 常见配置错误

1. **端口冲突**
2. **路径错误**
3. **权限不足**
4. **格式错误**

### 诊断方法

```bash
# 验证配置文件
otlp-collector validate --config=/etc/otlp/config.yaml

# 检查配置语法
yamllint /etc/otlp/config.yaml
```

### 最佳实践

1. **使用配置管理工具**（Ansible, Terraform）
2. **版本控制配置文件**
3. **环境变量替换**
4. **配置验证**

## 快速参考

### 诊断命令速查

```bash
# 系统资源
top                    # CPU 和内存
iostat -x 1           # 磁盘 I/O
netstat -s            # 网络统计
ss -s                 # Socket 统计

# 进程信息
ps aux | grep otlp    # 进程列表
lsof -p <PID>         # 打开的文件
strace -p <PID>       # 系统调用追踪

# 网络
tcpdump -i any port 4317  # 抓包
netstat -tlnp         # 监听端口

# 日志
journalctl -u otlp-collector -f  # 实时日志
tail -f /var/log/otlp/collector.log
```

### 日志位置

- **系统日志**：`/var/log/otlp/`
- **应用日志**：`/var/log/otlp/collector.log`
- **审计日志**：`/var/log/otlp/audit.log`

### 配置文件位置

- **主配置**：`/etc/otlp/config.yaml`
- **环境变量**：`/etc/default/otlp`
- **Systemd 配置**：`/etc/systemd/system/otlp-collector.service`

---

*本手册持续更新，欢迎贡献新的问题和解决方案。*
