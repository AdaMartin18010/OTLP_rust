# æ€§èƒ½å›å½’æ£€æµ‹

## ç›®å½•

- [æ€§èƒ½å›å½’æ£€æµ‹](#æ€§èƒ½å›å½’æ£€æµ‹)
  - [ç›®å½•](#ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [ğŸ“Š æ€§èƒ½å›å½’æ£€æµ‹æ¶æ„å›¾](#-æ€§èƒ½å›å½’æ£€æµ‹æ¶æ„å›¾)
    - [ğŸ”„ CI/CD é›†æˆæµç¨‹](#-cicd-é›†æˆæµç¨‹)
    - [ğŸ“ˆ å›å½’æ£€æµ‹å†³ç­–æ ‘](#-å›å½’æ£€æµ‹å†³ç­–æ ‘)
  - [åŸºå‡†æµ‹è¯•æ¡†æ¶](#åŸºå‡†æµ‹è¯•æ¡†æ¶)
    - [Criterion åŸºå‡†æµ‹è¯•](#criterion-åŸºå‡†æµ‹è¯•)
    - [æ€§èƒ½åŸºå‡†é…ç½®](#æ€§èƒ½åŸºå‡†é…ç½®)
  - [æ€§èƒ½å›å½’æ£€æµ‹æ–¹æ³•](#æ€§èƒ½å›å½’æ£€æµ‹æ–¹æ³•)
    - [ç»Ÿè®¡åˆ†ææ–¹æ³•](#ç»Ÿè®¡åˆ†ææ–¹æ³•)
  - [CI/CD é›†æˆ](#cicd-é›†æˆ)
    - [GitHub Actions é…ç½®](#github-actions-é…ç½®)
  - [æ€§èƒ½ç›‘æ§å‘Šè­¦](#æ€§èƒ½ç›‘æ§å‘Šè­¦)
    - [Prometheus å‘Šè­¦è§„åˆ™](#prometheus-å‘Šè­¦è§„åˆ™)
  - [é«˜çº§å›å½’æ£€æµ‹ç®—æ³•](#é«˜çº§å›å½’æ£€æµ‹ç®—æ³•)
    - [1. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€æµ‹ï¼ˆT-testï¼‰](#1-ç»Ÿè®¡æ˜¾è‘—æ€§æ£€æµ‹t-test)
    - [2. å˜åŒ–ç‚¹æ£€æµ‹ï¼ˆChange Point Detectionï¼‰](#2-å˜åŒ–ç‚¹æ£€æµ‹change-point-detection)
    - [3. å¤šç»´åº¦å›å½’æ£€æµ‹](#3-å¤šç»´åº¦å›å½’æ£€æµ‹)
  - [åŸºçº¿ç®¡ç†](#åŸºçº¿ç®¡ç†)
    - [åŸºçº¿å­˜å‚¨å’Œç‰ˆæœ¬æ§åˆ¶](#åŸºçº¿å­˜å‚¨å’Œç‰ˆæœ¬æ§åˆ¶)
  - [è‡ªåŠ¨åŒ–æµ‹è¯•é›†æˆ](#è‡ªåŠ¨åŒ–æµ‹è¯•é›†æˆ)
    - [CI/CD å®Œæ•´æµç¨‹](#cicd-å®Œæ•´æµç¨‹)
    - [å›å½’æ£€æµ‹å·¥å…·](#å›å½’æ£€æµ‹å·¥å…·)
    - [æŠ¥å‘Šç”Ÿæˆå™¨](#æŠ¥å‘Šç”Ÿæˆå™¨)
  - [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šæ£€æµ‹åˆ°å»¶è¿Ÿå›å½’](#æ¡ˆä¾‹1æ£€æµ‹åˆ°å»¶è¿Ÿå›å½’)
    - [æ¡ˆä¾‹2ï¼šå¤šç»´åº¦å›å½’æ£€æµ‹](#æ¡ˆä¾‹2å¤šç»´åº¦å›å½’æ£€æµ‹)

## æ¦‚è¿°

æ€§èƒ½å›å½’æ£€æµ‹ç”¨äºåŠæ—¶å‘ç°ä»£ç å˜æ›´å¯¼è‡´çš„æ€§èƒ½ä¸‹é™ï¼Œç¡®ä¿ç³»ç»Ÿæ€§èƒ½æŒç»­æ”¹è¿›ã€‚

### ğŸ“Š æ€§èƒ½å›å½’æ£€æµ‹æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ä»£ç å˜æ›´"
        A1[å¼€å‘æäº¤PR]
        A2[è§¦å‘CI/CD]
    end
    
    subgraph "åŸºå‡†æµ‹è¯•"
        B1[è¿è¡ŒBenchmark]
        B2[æ”¶é›†æ€§èƒ½æ•°æ®]
        B3[å­˜å‚¨ç»“æœ]
    end
    
    subgraph "å›å½’åˆ†æ"
        C1[ç»Ÿè®¡æ£€éªŒ<br/>Welch's t-test]
        C2[å˜åŒ–ç‚¹æ£€æµ‹<br/>CUSUM]
        C3[å¤šç»´åº¦åˆ†æ]
    end
    
    subgraph "å†³ç­–"
        D1{å›å½’æ£€æµ‹?}
        D2[ç”ŸæˆæŠ¥å‘Š]
        D3[PRè¯„è®º]
        D4[é˜»æ–­åˆå¹¶]
    end
    
    subgraph "åŸºçº¿ç®¡ç†"
        E1[æ›´æ–°åŸºçº¿]
        E2[ç‰ˆæœ¬æ§åˆ¶]
        E3[å†å²è¿½è¸ª]
    end
    
    A1 --> A2
    A2 --> B1
    B1 --> B2
    B2 --> B3
    
    B3 --> C1
    B3 --> C2
    B3 --> C3
    
    C1 --> D1
    C2 --> D1
    C3 --> D1
    
    D1 -->|æ˜¯| D4
    D1 -->|å¦| D2
    D4 --> D3
    D2 --> D3
    
    D3 -->|åˆå¹¶å| E1
    E1 --> E2
    E2 --> E3
    
    style D1 fill:#FFD700
    style D4 fill:#FF6B6B
    style E1 fill:#90EE90
```

### ğŸ”„ CI/CD é›†æˆæµç¨‹

```mermaid
sequenceDiagram
    participant Dev as å¼€å‘è€…
    participant GH as GitHub
    participant CI as CI/CD
    participant Bench as Benchmark
    participant Detector as å›å½’æ£€æµ‹å™¨
    participant Storage as åŸºçº¿å­˜å‚¨
    
    Dev->>GH: æäº¤ PR
    GH->>CI: è§¦å‘å·¥ä½œæµ
    
    CI->>Storage: ä¸‹è½½åŸºçº¿æ•°æ®
    Storage-->>CI: è¿”å›åŸºçº¿
    
    CI->>Bench: è¿è¡Œæ€§èƒ½æµ‹è¯•
    Bench->>Bench: æ‰§è¡Œ Benchmark
    Bench-->>CI: è¿”å›æµ‹è¯•ç»“æœ
    
    CI->>Detector: è°ƒç”¨å›å½’æ£€æµ‹
    Detector->>Detector: Welch's t-test
    Detector->>Detector: CUSUM åˆ†æ
    Detector->>Detector: å¤šç»´åº¦æ£€æµ‹
    
    alt æ£€æµ‹åˆ°å›å½’
        Detector-->>CI: å›å½’æŠ¥å‘Š
        CI->>GH: è¯„è®º PRï¼ˆâŒ å›å½’ï¼‰
        CI->>CI: æ ‡è®°å¤±è´¥
        CI-->>Dev: é€šçŸ¥å›å½’
    else æ— å›å½’
        Detector-->>CI: é€šè¿‡æŠ¥å‘Š
        CI->>GH: è¯„è®º PRï¼ˆâœ… é€šè¿‡ï¼‰
        CI->>CI: æ ‡è®°æˆåŠŸ
    end
    
    alt PR åˆå¹¶
        Dev->>GH: åˆå¹¶åˆ° main
        GH->>CI: è§¦å‘åŸºçº¿æ›´æ–°
        CI->>Storage: ä¸Šä¼ æ–°åŸºçº¿
        Storage-->>CI: ç¡®è®¤ä¿å­˜
    end
```

### ğŸ“ˆ å›å½’æ£€æµ‹å†³ç­–æ ‘

```mermaid
flowchart TD
    Start([å¼€å§‹æ£€æµ‹]) --> Load[åŠ è½½åŸºçº¿æ•°æ®]
    Load --> Run[è¿è¡Œ Benchmark]
    Run --> Collect[æ”¶é›†æ€§èƒ½æŒ‡æ ‡]
    
    Collect --> TTest[Welch's t-test]
    Collect --> CUSUM[CUSUM åˆ†æ]
    Collect --> Multi[å¤šç»´åº¦åˆ†æ]
    
    TTest --> TResult{p-value < 0.05?}
    CUSUM --> CResult{æ£€æµ‹åˆ°å˜åŒ–ç‚¹?}
    Multi --> MResult{å¤šæŒ‡æ ‡å›å½’?}
    
    TResult -->|æ˜¯| Significant[ç»Ÿè®¡æ˜¾è‘—å›å½’]
    CResult -->|æ˜¯| ChangePoint[æ€§èƒ½çªå˜]
    MResult -->|æ˜¯| MultiRegression[å¤šç»´åº¦å›å½’]
    
    TResult -->|å¦| NoRegression1[æ— å›å½’]
    CResult -->|å¦| NoRegression2[æ— å›å½’]
    MResult -->|å¦| NoRegression3[æ— å›å½’]
    
    Significant --> Severity{å›å½’ä¸¥é‡åº¦}
    ChangePoint --> Severity
    MultiRegression --> Severity
    
    Severity -->|>10%| Critical[ä¸¥é‡å›å½’<br/>é˜»æ–­åˆå¹¶]
    Severity -->|5-10%| Warning[è­¦å‘Š<br/>éœ€è¦å®¡æŸ¥]
    Severity -->|<5%| Minor[è½»å¾®å›å½’<br/>å¯æ¥å—]
    
    Critical --> Report[ç”ŸæˆæŠ¥å‘Š]
    Warning --> Report
    Minor --> Report
    NoRegression1 --> Report
    NoRegression2 --> Report
    NoRegression3 --> Report
    
    Report --> Comment[PR è¯„è®º]
    Comment --> End([ç»“æŸ])
    
    style Critical fill:#FF6B6B
    style Warning fill:#FFD700
    style Minor fill:#87CEEB
    style NoRegression1 fill:#90EE90
    style NoRegression2 fill:#90EE90
    style NoRegression3 fill:#90EE90
```

## åŸºå‡†æµ‹è¯•æ¡†æ¶

### Criterion åŸºå‡†æµ‹è¯•

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn export_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("otlp_export");
    
    for size in [100, 1000, 10000].iter() {
        group.bench_with_input(BenchmarkId::from_parameter(size), size, |b, &size| {
            let spans = generate_test_spans(size);
            b.iter(|| {
                export_spans(black_box(&spans))
            });
        });
    }
    
    group.finish();
}

criterion_group!(benches, export_benchmark);
criterion_main!(benches);
```

### æ€§èƒ½åŸºå‡†é…ç½®

```toml
# Cargo.toml
[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "otlp_benchmarks"
harness = false
```

## æ€§èƒ½å›å½’æ£€æµ‹æ–¹æ³•

### ç»Ÿè®¡åˆ†ææ–¹æ³•

```rust
use statrs::statistics::Statistics;

pub struct RegressionDetector {
    baseline_samples: Vec<f64>,
    threshold_percent: f64,
}

impl RegressionDetector {
    pub fn new(baseline: Vec<f64>, threshold: f64) -> Self {
        Self {
            baseline_samples: baseline,
            threshold_percent: threshold,
        }
    }

    pub fn detect_regression(&self, current: &[f64]) -> RegressionResult {
        let baseline_mean = self.baseline_samples.mean();
        let current_mean = current.mean();

        let change_percent = ((current_mean - baseline_mean) / baseline_mean) * 100.0;

        RegressionResult {
            baseline_mean,
            current_mean,
            change_percent,
            is_regression: change_percent > self.threshold_percent,
        }
    }
}

pub struct RegressionResult {
    pub baseline_mean: f64,
    pub current_mean: f64,
    pub change_percent: f64,
    pub is_regression: bool,
}
```

## CI/CD é›†æˆ

### GitHub Actions é…ç½®

```yaml
name: Performance Regression Check

on: [pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      
      - name: Run benchmarks
        run: cargo bench --bench otlp_benchmarks -- --save-baseline current
      
      - name: Compare with baseline
        run: |
          cargo bench --bench otlp_benchmarks -- --baseline main --load-baseline current
      
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: target/criterion/
```

## æ€§èƒ½ç›‘æ§å‘Šè­¦

### Prometheus å‘Šè­¦è§„åˆ™

```yaml
groups:
  - name: performance_regression
    rules:
      - alert: LatencyRegression
        expr: |
          (
            histogram_quantile(0.99, rate(request_duration_seconds_bucket[5m]))
            /
            histogram_quantile(0.99, rate(request_duration_seconds_bucket[5m] offset 1d))
          ) > 1.2
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Performance regression detected"
          description: "P99 latency increased by {{ $value | humanizePercentage }}"
```

## é«˜çº§å›å½’æ£€æµ‹ç®—æ³•

### 1. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€æµ‹ï¼ˆT-testï¼‰

```rust
use statrs::distribution::{StudentsT, ContinuousCDF};
use statrs::statistics::Statistics;

/// ç»Ÿè®¡æ˜¾è‘—æ€§å›å½’æ£€æµ‹å™¨
pub struct StatisticalRegressionDetector {
    significance_level: f64,  // æ˜¾è‘—æ€§æ°´å¹³ï¼ˆå¦‚ 0.05ï¼‰
}

impl StatisticalRegressionDetector {
    pub fn new(significance_level: f64) -> Self {
        Self { significance_level }
    }

    /// ä½¿ç”¨ Welch's t-test æ£€æµ‹å›å½’
    pub fn detect_with_ttest(
        &self,
        baseline: &[f64],
        current: &[f64],
    ) -> StatisticalRegressionResult {
        let baseline_mean = baseline.mean();
        let current_mean = current.mean();
        
        let baseline_var = baseline.variance();
        let current_var = current.variance();
        
        let n1 = baseline.len() as f64;
        let n2 = current.len() as f64;
        
        // Welch's t-statistic
        let t_stat = (current_mean - baseline_mean) 
            / ((baseline_var / n1) + (current_var / n2)).sqrt();
        
        // Welch-Satterthwaite degrees of freedom
        let df = ((baseline_var / n1) + (current_var / n2)).powi(2)
            / ((baseline_var / n1).powi(2) / (n1 - 1.0) 
                + (current_var / n2).powi(2) / (n2 - 1.0));
        
        // è®¡ç®— p-value
        let t_dist = StudentsT::new(0.0, 1.0, df).unwrap();
        let p_value = 1.0 - t_dist.cdf(t_stat);
        
        StatisticalRegressionResult {
            baseline_mean,
            current_mean,
            t_statistic: t_stat,
            p_value,
            is_significant: p_value < self.significance_level,
            degrees_of_freedom: df,
            change_percent: ((current_mean - baseline_mean) / baseline_mean) * 100.0,
        }
    }
}

#[derive(Debug)]
pub struct StatisticalRegressionResult {
    pub baseline_mean: f64,
    pub current_mean: f64,
    pub t_statistic: f64,
    pub p_value: f64,
    pub is_significant: bool,
    pub degrees_of_freedom: f64,
    pub change_percent: f64,
}
```

### 2. å˜åŒ–ç‚¹æ£€æµ‹ï¼ˆChange Point Detectionï¼‰

```rust
/// å˜åŒ–ç‚¹æ£€æµ‹å™¨ - ä½¿ç”¨ CUSUM ç®—æ³•
pub struct ChangePointDetector {
    threshold: f64,
    drift: f64,
}

impl ChangePointDetector {
    pub fn new(threshold: f64, drift: f64) -> Self {
        Self { threshold, drift }
    }

    /// CUSUM (Cumulative Sum) ç®—æ³•
    pub fn detect_change_point(&self, data: &[f64]) -> Option<ChangePoint> {
        let mean = data.mean();
        let std_dev = data.std_dev();
        
        let mut cusum_pos = 0.0;
        let mut cusum_neg = 0.0;
        
        for (i, &value) in data.iter().enumerate() {
            let normalized = (value - mean) / std_dev;
            
            cusum_pos = (cusum_pos + normalized - self.drift).max(0.0);
            cusum_neg = (cusum_neg - normalized - self.drift).max(0.0);
            
            if cusum_pos > self.threshold {
                return Some(ChangePoint {
                    index: i,
                    direction: ChangeDirection::Increase,
                    magnitude: cusum_pos,
                });
            }
            
            if cusum_neg > self.threshold {
                return Some(ChangePoint {
                    index: i,
                    direction: ChangeDirection::Decrease,
                    magnitude: cusum_neg,
                });
            }
        }
        
        None
    }
}

#[derive(Debug)]
pub struct ChangePoint {
    pub index: usize,
    pub direction: ChangeDirection,
    pub magnitude: f64,
}

#[derive(Debug)]
pub enum ChangeDirection {
    Increase,
    Decrease,
}
```

### 3. å¤šç»´åº¦å›å½’æ£€æµ‹

```rust
/// å¤šç»´åº¦æ€§èƒ½å›å½’æ£€æµ‹å™¨
pub struct MultiDimensionalDetector {
    detectors: HashMap<String, Box<dyn RegressionDetectorTrait>>,
}

pub trait RegressionDetectorTrait {
    fn detect(&self, baseline: &[f64], current: &[f64]) -> bool;
}

impl MultiDimensionalDetector {
    pub fn new() -> Self {
        Self {
            detectors: HashMap::new(),
        }
    }

    pub fn add_detector(&mut self, name: String, detector: Box<dyn RegressionDetectorTrait>) {
        self.detectors.insert(name, detector);
    }

    /// æ£€æµ‹å¤šä¸ªæ€§èƒ½æŒ‡æ ‡
    pub fn detect_all(&self, metrics: &PerformanceMetrics) -> MultiDimensionalResult {
        let mut results = HashMap::new();
        let mut has_regression = false;
        
        // å»¶è¿Ÿæ£€æµ‹
        if let Some(detector) = self.detectors.get("latency") {
            let is_regression = detector.detect(
                &metrics.baseline_latency,
                &metrics.current_latency,
            );
            results.insert("latency".to_string(), is_regression);
            has_regression |= is_regression;
        }
        
        // ååé‡æ£€æµ‹
        if let Some(detector) = self.detectors.get("throughput") {
            let is_regression = detector.detect(
                &metrics.baseline_throughput,
                &metrics.current_throughput,
            );
            results.insert("throughput".to_string(), is_regression);
            has_regression |= is_regression;
        }
        
        // CPU ä½¿ç”¨ç‡æ£€æµ‹
        if let Some(detector) = self.detectors.get("cpu") {
            let is_regression = detector.detect(
                &metrics.baseline_cpu,
                &metrics.current_cpu,
            );
            results.insert("cpu".to_string(), is_regression);
            has_regression |= is_regression;
        }
        
        // å†…å­˜ä½¿ç”¨æ£€æµ‹
        if let Some(detector) = self.detectors.get("memory") {
            let is_regression = detector.detect(
                &metrics.baseline_memory,
                &metrics.current_memory,
            );
            results.insert("memory".to_string(), is_regression);
            has_regression |= is_regression;
        }
        
        MultiDimensionalResult {
            dimension_results: results,
            has_any_regression: has_regression,
        }
    }
}

#[derive(Debug)]
pub struct PerformanceMetrics {
    pub baseline_latency: Vec<f64>,
    pub current_latency: Vec<f64>,
    pub baseline_throughput: Vec<f64>,
    pub current_throughput: Vec<f64>,
    pub baseline_cpu: Vec<f64>,
    pub current_cpu: Vec<f64>,
    pub baseline_memory: Vec<f64>,
    pub current_memory: Vec<f64>,
}

#[derive(Debug)]
pub struct MultiDimensionalResult {
    pub dimension_results: HashMap<String, bool>,
    pub has_any_regression: bool,
}
```

## åŸºçº¿ç®¡ç†

### åŸºçº¿å­˜å‚¨å’Œç‰ˆæœ¬æ§åˆ¶

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs;
use std::path::Path;

/// æ€§èƒ½åŸºçº¿ç®¡ç†å™¨
pub struct BaselineManager {
    baseline_dir: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct Baseline {
    pub version: String,
    pub commit_hash: String,
    pub timestamp: u64,
    pub metrics: HashMap<String, MetricBaseline>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct MetricBaseline {
    pub name: String,
    pub samples: Vec<f64>,
    pub mean: f64,
    pub std_dev: f64,
    pub p50: f64,
    pub p95: f64,
    pub p99: f64,
}

impl BaselineManager {
    pub fn new(baseline_dir: String) -> Self {
        fs::create_dir_all(&baseline_dir).ok();
        Self { baseline_dir }
    }

    /// ä¿å­˜åŸºçº¿
    pub fn save_baseline(&self, baseline: &Baseline) -> Result<(), Box<dyn std::error::Error>> {
        let filename = format!("{}/baseline_{}.json", self.baseline_dir, baseline.version);
        let json = serde_json::to_string_pretty(baseline)?;
        fs::write(filename, json)?;
        Ok(())
    }

    /// åŠ è½½åŸºçº¿
    pub fn load_baseline(&self, version: &str) -> Result<Baseline, Box<dyn std::error::Error>> {
        let filename = format!("{}/baseline_{}.json", self.baseline_dir, version);
        let json = fs::read_to_string(filename)?;
        let baseline = serde_json::from_str(&json)?;
        Ok(baseline)
    }

    /// è·å–æœ€æ–°åŸºçº¿
    pub fn get_latest_baseline(&self) -> Result<Baseline, Box<dyn std::error::Error>> {
        let entries = fs::read_dir(&self.baseline_dir)?;
        
        let mut latest_file = None;
        let mut latest_time = 0u64;
        
        for entry in entries {
            let entry = entry?;
            let path = entry.path();
            
            if path.extension().and_then(|s| s.to_str()) == Some("json") {
                let metadata = fs::metadata(&path)?;
                let modified = metadata.modified()?
                    .duration_since(std::time::UNIX_EPOCH)?
                    .as_secs();
                
                if modified > latest_time {
                    latest_time = modified;
                    latest_file = Some(path);
                }
            }
        }
        
        if let Some(path) = latest_file {
            let json = fs::read_to_string(path)?;
            let baseline = serde_json::from_str(&json)?;
            Ok(baseline)
        } else {
            Err("No baseline found".into())
        }
    }

    /// æ¯”è¾ƒä¸¤ä¸ªåŸºçº¿
    pub fn compare_baselines(
        &self,
        baseline1: &Baseline,
        baseline2: &Baseline,
    ) -> BaselineComparison {
        let mut metric_changes = HashMap::new();
        
        for (metric_name, metric1) in &baseline1.metrics {
            if let Some(metric2) = baseline2.metrics.get(metric_name) {
                let change_percent = ((metric2.mean - metric1.mean) / metric1.mean) * 100.0;
                
                metric_changes.insert(
                    metric_name.clone(),
                    MetricChange {
                        old_mean: metric1.mean,
                        new_mean: metric2.mean,
                        change_percent,
                        is_regression: change_percent > 5.0, // 5% é˜ˆå€¼
                    },
                );
            }
        }
        
        BaselineComparison {
            baseline1_version: baseline1.version.clone(),
            baseline2_version: baseline2.version.clone(),
            metric_changes,
        }
    }
}

#[derive(Debug)]
pub struct BaselineComparison {
    pub baseline1_version: String,
    pub baseline2_version: String,
    pub metric_changes: HashMap<String, MetricChange>,
}

#[derive(Debug)]
pub struct MetricChange {
    pub old_mean: f64,
    pub new_mean: f64,
    pub change_percent: f64,
    pub is_regression: bool,
}
```

## è‡ªåŠ¨åŒ–æµ‹è¯•é›†æˆ

### CI/CD å®Œæ•´æµç¨‹

```yaml
# .github/workflows/performance-regression.yml
name: Performance Regression Detection

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

env:
  BASELINE_DIR: performance-baselines
  REGRESSION_THRESHOLD: 5.0  # 5% æ€§èƒ½ä¸‹é™é˜ˆå€¼

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # è·å–å®Œæ•´å†å²
      
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          profile: minimal
          override: true
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Download baseline
        run: |
          mkdir -p $BASELINE_DIR
          # ä» artifact æˆ– S3 ä¸‹è½½åŸºçº¿
          aws s3 cp s3://my-bucket/baselines/latest.json $BASELINE_DIR/ || true
      
      - name: Run benchmarks
        run: |
          cargo bench --bench otlp_benchmarks -- --save-baseline current
      
      - name: Detect regression
        id: regression
        run: |
          cargo run --bin regression-detector -- \
            --baseline $BASELINE_DIR/latest.json \
            --current target/criterion/current.json \
            --threshold $REGRESSION_THRESHOLD \
            --output regression-report.json
      
      - name: Generate report
        run: |
          cargo run --bin report-generator -- \
            --input regression-report.json \
            --output regression-report.md
      
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('regression-report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
      
      - name: Fail on regression
        if: steps.regression.outputs.has_regression == 'true'
        run: |
          echo "Performance regression detected!"
          exit 1
      
      - name: Update baseline (main branch only)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # ä¸Šä¼ æ–°åŸºçº¿
          aws s3 cp target/criterion/current.json s3://my-bucket/baselines/latest.json
          
          # ä¿å­˜ç‰ˆæœ¬åŒ–åŸºçº¿
          VERSION=$(git rev-parse --short HEAD)
          aws s3 cp target/criterion/current.json s3://my-bucket/baselines/$VERSION.json
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: |
            target/criterion/
            regression-report.md
            regression-report.json
```

### å›å½’æ£€æµ‹å·¥å…·

```rust
// regression-detector/src/main.rs
use clap::Parser;
use serde::{Deserialize, Serialize};
use std::fs;

#[derive(Parser)]
struct Args {
    #[arg(long)]
    baseline: String,
    
    #[arg(long)]
    current: String,
    
    #[arg(long, default_value = "5.0")]
    threshold: f64,
    
    #[arg(long)]
    output: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct RegressionReport {
    has_regression: bool,
    regressions: Vec<RegressionDetail>,
    improvements: Vec<RegressionDetail>,
    summary: ReportSummary,
}

#[derive(Debug, Serialize, Deserialize)]
struct RegressionDetail {
    metric_name: String,
    baseline_mean: f64,
    current_mean: f64,
    change_percent: f64,
    p_value: f64,
}

#[derive(Debug, Serialize, Deserialize)]
struct ReportSummary {
    total_metrics: usize,
    regression_count: usize,
    improvement_count: usize,
    unchanged_count: usize,
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let args = Args::parse();
    
    // åŠ è½½åŸºçº¿å’Œå½“å‰ç»“æœ
    let baseline: Baseline = serde_json::from_str(&fs::read_to_string(&args.baseline)?)?;
    let current: Baseline = serde_json::from_str(&fs::read_to_string(&args.current)?)?;
    
    // æ£€æµ‹å›å½’
    let detector = StatisticalRegressionDetector::new(0.05);
    let mut regressions = Vec::new();
    let mut improvements = Vec::new();
    
    for (metric_name, baseline_metric) in &baseline.metrics {
        if let Some(current_metric) = current.metrics.get(metric_name) {
            let result = detector.detect_with_ttest(
                &baseline_metric.samples,
                &current_metric.samples,
            );
            
            if result.is_significant {
                let detail = RegressionDetail {
                    metric_name: metric_name.clone(),
                    baseline_mean: result.baseline_mean,
                    current_mean: result.current_mean,
                    change_percent: result.change_percent,
                    p_value: result.p_value,
                };
                
                if result.change_percent > args.threshold {
                    regressions.push(detail);
                } else if result.change_percent < -args.threshold {
                    improvements.push(detail);
                }
            }
        }
    }
    
    // ç”ŸæˆæŠ¥å‘Š
    let report = RegressionReport {
        has_regression: !regressions.is_empty(),
        regressions: regressions.clone(),
        improvements: improvements.clone(),
        summary: ReportSummary {
            total_metrics: baseline.metrics.len(),
            regression_count: regressions.len(),
            improvement_count: improvements.len(),
            unchanged_count: baseline.metrics.len() - regressions.len() - improvements.len(),
        },
    };
    
    // ä¿å­˜æŠ¥å‘Š
    let json = serde_json::to_string_pretty(&report)?;
    fs::write(&args.output, json)?;
    
    // è¾“å‡ºåˆ° GitHub Actions
    println!("::set-output name=has_regression::{}", report.has_regression);
    
    Ok(())
}
```

### æŠ¥å‘Šç”Ÿæˆå™¨

```rust
// report-generator/src/main.rs
use clap::Parser;
use serde::{Deserialize, Serialize};
use std::fs;

#[derive(Parser)]
struct Args {
    #[arg(long)]
    input: String,
    
    #[arg(long)]
    output: String,
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let args = Args::parse();
    
    let report: RegressionReport = serde_json::from_str(&fs::read_to_string(&args.input)?)?;
    
    let markdown = generate_markdown_report(&report);
    fs::write(&args.output, markdown)?;
    
    Ok(())
}

fn generate_markdown_report(report: &RegressionReport) -> String {
    let mut md = String::new();
    
    md.push_str("# æ€§èƒ½å›å½’æ£€æµ‹æŠ¥å‘Š\n\n");
    
    // æ€»ç»“
    md.push_str("## ğŸ“Š æ€»ç»“\n\n");
    md.push_str(&format!("- æ€»æŒ‡æ ‡æ•°ï¼š{}\n", report.summary.total_metrics));
    md.push_str(&format!("- ğŸ”´ å›å½’ï¼š{}\n", report.summary.regression_count));
    md.push_str(&format!("- ğŸŸ¢ æ”¹è¿›ï¼š{}\n", report.summary.improvement_count));
    md.push_str(&format!("- âšª æœªå˜åŒ–ï¼š{}\n\n", report.summary.unchanged_count));
    
    // å›å½’è¯¦æƒ…
    if !report.regressions.is_empty() {
        md.push_str("## âš ï¸ æ€§èƒ½å›å½’\n\n");
        md.push_str("| æŒ‡æ ‡ | åŸºçº¿ | å½“å‰ | å˜åŒ– | p-value |\n");
        md.push_str("|------|------|------|------|--------|\n");
        
        for reg in &report.regressions {
            md.push_str(&format!(
                "| {} | {:.2}ms | {:.2}ms | **+{:.1}%** | {:.4} |\n",
                reg.metric_name,
                reg.baseline_mean,
                reg.current_mean,
                reg.change_percent,
                reg.p_value
            ));
        }
        md.push_str("\n");
    }
    
    // æ”¹è¿›è¯¦æƒ…
    if !report.improvements.is_empty() {
        md.push_str("## âœ… æ€§èƒ½æ”¹è¿›\n\n");
        md.push_str("| æŒ‡æ ‡ | åŸºçº¿ | å½“å‰ | å˜åŒ– | p-value |\n");
        md.push_str("|------|------|------|------|--------|\n");
        
        for imp in &report.improvements {
            md.push_str(&format!(
                "| {} | {:.2}ms | {:.2}ms | **{:.1}%** | {:.4} |\n",
                imp.metric_name,
                imp.baseline_mean,
                imp.current_mean,
                imp.change_percent,
                imp.p_value
            ));
        }
        md.push_str("\n");
    }
    
    // ç»“è®º
    if report.has_regression {
        md.push_str("## âŒ ç»“è®º\n\n");
        md.push_str("æ£€æµ‹åˆ°æ€§èƒ½å›å½’ï¼Œè¯·æ£€æŸ¥ä»£ç å˜æ›´ã€‚\n");
    } else {
        md.push_str("## âœ… ç»“è®º\n\n");
        md.push_str("æœªæ£€æµ‹åˆ°æ€§èƒ½å›å½’ã€‚\n");
    }
    
    md
}
```

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ£€æµ‹åˆ°å»¶è¿Ÿå›å½’

**åœºæ™¯**ï¼šPR #123 å¼•å…¥äº†æ–°çš„æ—¥å¿—è®°å½•é€»è¾‘

**æ£€æµ‹ç»“æœ**ï¼š

```markdown
# æ€§èƒ½å›å½’æ£€æµ‹æŠ¥å‘Š

## ğŸ“Š æ€»ç»“
- æ€»æŒ‡æ ‡æ•°ï¼š8
- ğŸ”´ å›å½’ï¼š1
- ğŸŸ¢ æ”¹è¿›ï¼š0
- âšª æœªå˜åŒ–ï¼š7

## âš ï¸ æ€§èƒ½å›å½’

| æŒ‡æ ‡ | åŸºçº¿ | å½“å‰ | å˜åŒ– | p-value |
|------|------|------|------|--------|
| span_export_latency_p99 | 45.2ms | 58.7ms | **+29.9%** | 0.0012 |

## âŒ ç»“è®º
æ£€æµ‹åˆ°æ€§èƒ½å›å½’ï¼Œè¯·æ£€æŸ¥ä»£ç å˜æ›´ã€‚
```

**æ ¹å› åˆ†æ**ï¼š

- æ–°å¢çš„æ—¥å¿—è®°å½•åœ¨çƒ­è·¯å¾„ä¸Š
- æ¯ä¸ª Span å¯¼å‡ºéƒ½è§¦å‘åŒæ­¥æ—¥å¿—å†™å…¥
- å»ºè®®ï¼šæ”¹ä¸ºå¼‚æ­¥æ—¥å¿—æˆ–é™ä½æ—¥å¿—çº§åˆ«

**ä¿®å¤å**ï¼š

```markdown
## âœ… æ€§èƒ½æ”¹è¿›

| æŒ‡æ ‡ | åŸºçº¿ | å½“å‰ | å˜åŒ– | p-value |
|------|------|------|------|--------|
| span_export_latency_p99 | 45.2ms | 42.1ms | **-6.9%** | 0.0089 |
```

### æ¡ˆä¾‹2ï¼šå¤šç»´åº¦å›å½’æ£€æµ‹

**åœºæ™¯**ï¼šä¼˜åŒ–æ‰¹å¤„ç†é€»è¾‘

**æ£€æµ‹ç»“æœ**ï¼š

```text
=== å¤šç»´åº¦æ€§èƒ½åˆ†æ ===

âœ… å»¶è¿Ÿï¼šæ”¹è¿› 15%
âœ… ååé‡ï¼šæ”¹è¿› 22%
âš ï¸ CPU ä½¿ç”¨ç‡ï¼šå›å½’ 8%
âœ… å†…å­˜ä½¿ç”¨ï¼šæ”¹è¿› 5%

ç»¼åˆè¯„ä¼°ï¼šæ•´ä½“æ”¹è¿›ï¼ŒCPU ä½¿ç”¨ç‡è½»å¾®å›å½’å¯æ¥å—
```

**å†³ç­–**ï¼šæ¥å—æ­¤å˜æ›´ï¼Œå› ä¸ºå»¶è¿Ÿå’Œååé‡çš„æ˜¾è‘—æ”¹è¿›è¶…è¿‡äº† CPU ä½¿ç”¨ç‡çš„è½»å¾®å¢åŠ ã€‚

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [æ€§èƒ½é—®é¢˜è¯†åˆ«](./æ€§èƒ½é—®é¢˜è¯†åˆ«.md)
- [ç›‘æ§å‘Šè­¦](../ç›‘æ§å‘Šè­¦/README.md)
- [ç³»ç»Ÿç“¶é¢ˆåˆ†æ](./ç³»ç»Ÿç“¶é¢ˆåˆ†æ.md)
