# ğŸš€ OTLP Rust éƒ¨ç½²å’Œè¿ç»´æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº† OTLP Rust é¡¹ç›®çš„å®Œæ•´éƒ¨ç½²å’Œè¿ç»´æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å¼€å‘ç¯å¢ƒæ­å»ºã€ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€ç›‘æ§é…ç½®å’Œæ•…éšœæ’é™¤ç­‰å†…å®¹ã€‚

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒ

### ç³»ç»Ÿè¦æ±‚

- **Rust**: 1.90+
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows
- **å†…å­˜**: æœ€å°‘ 4GB RAM
- **ç£ç›˜**: æœ€å°‘ 2GB å¯ç”¨ç©ºé—´

### ç¯å¢ƒæ­å»º

```bash
# 1. å®‰è£… Rust (å¦‚æœæœªå®‰è£…)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env

# 2. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd OTLP_rust/otlp

# 3. å®‰è£…ä¾èµ–
cargo build

# 4. è¿è¡Œæµ‹è¯•
cargo test

# 5. è¿è¡Œç¤ºä¾‹
cargo run --example resilience_usage
```

### å¼€å‘å·¥å…·é…ç½®

```toml
# .vscode/settings.json
{
    "rust-analyzer.checkOnSave.command": "clippy",
    "rust-analyzer.checkOnSave.extraArgs": ["--", "-W", "clippy::all"],
    "editor.formatOnSave": true,
    "rust-analyzer.cargo.features": "all"
}
```

## ğŸ­ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. äºŒè¿›åˆ¶éƒ¨ç½²

#### æ„å»ºå‘å¸ƒç‰ˆæœ¬

```bash
# æ„å»ºä¼˜åŒ–ç‰ˆæœ¬
cargo build --release

# æ£€æŸ¥äºŒè¿›åˆ¶æ–‡ä»¶
ls -la target/release/otlp
```

#### ç³»ç»ŸæœåŠ¡é…ç½®

```ini
# /etc/systemd/system/otlp.service
[Unit]
Description=OTLP Rust Service
After=network.target

[Service]
Type=simple
User=otlp
Group=otlp
WorkingDirectory=/opt/otlp
ExecStart=/opt/otlp/bin/otlp
Restart=always
RestartSec=5
Environment=RUST_LOG=info

[Install]
WantedBy=multi-user.target
```

#### å¯åŠ¨æœåŠ¡

```bash
# å¯ç”¨å¹¶å¯åŠ¨æœåŠ¡
sudo systemctl enable otlp
sudo systemctl start otlp

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
sudo systemctl status otlp
```

### 2. Docker éƒ¨ç½²

#### Dockerfile

```dockerfile
# å¤šé˜¶æ®µæ„å»º
FROM rust:1.90-slim as builder

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æºä»£ç 
COPY Cargo.toml Cargo.lock ./
COPY src/ ./src/

# æ„å»ºå‘å¸ƒç‰ˆæœ¬
RUN cargo build --release

# è¿è¡Œæ—¶é•œåƒ
FROM debian:bullseye-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºç”¨æˆ·
RUN useradd -r -s /bin/false otlp

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/target/release/otlp /usr/local/bin/

# è®¾ç½®æƒé™
RUN chmod +x /usr/local/bin/otlp

# åˆ‡æ¢åˆ°é root ç”¨æˆ·
USER otlp

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨å‘½ä»¤
CMD ["otlp"]
```

#### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  otlp:
    build: .
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - OTLP_ENDPOINT=http://collector:4317
    depends_on:
      - collector
    restart: unless-stopped

  collector:
    image: otel/opentelemetry-collector-contrib:latest
    ports:
      - "4317:4317"
      - "4318:4318"
    volumes:
      - ./collector-config.yaml:/etc/otelcol-contrib/otel-collector-config.yaml
    command: ["--config=/etc/otelcol-contrib/otel-collector-config.yaml"]

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana-dashboards:/etc/grafana/provisioning/dashboards

volumes:
  grafana-storage:
```

### 3. Kubernetes éƒ¨ç½²

#### Namespace

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: otlp-system
```

#### ConfigMap

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otlp-config
  namespace: otlp-system
data:
  config.yaml: |
    endpoint: "http://otel-collector:4317"
    timeout: "30s"
    retry:
      max_attempts: 3
      base_delay: "100ms"
      max_delay: "5s"
    circuit_breaker:
      failure_threshold: 5
      recovery_timeout: "60s"
    logging:
      level: "info"
      format: "json"
```

#### Deployment

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otlp-deployment
  namespace: otlp-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: otlp
  template:
    metadata:
      labels:
        app: otlp
    spec:
      containers:
      - name: otlp
        image: otlp:latest
        ports:
        - containerPort: 8080
        env:
        - name: RUST_LOG
          value: "info"
        - name: OTLP_CONFIG_PATH
          value: "/etc/otlp/config.yaml"
        volumeMounts:
        - name: config
          mountPath: /etc/otlp
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: otlp-config
```

#### Service

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: otlp-service
  namespace: otlp-system
spec:
  selector:
    app: otlp
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
  type: ClusterIP
```

#### Ingress

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: otlp-ingress
  namespace: otlp-system
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: otlp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: otlp-service
            port:
              number: 8080
```

## ğŸ“Š ç›‘æ§é…ç½®

### 1. Prometheus é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "otlp_rules.yml"

scrape_configs:
  - job_name: 'otlp'
    static_configs:
      - targets: ['otlp:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'otel-collector'
    static_configs:
      - targets: ['otel-collector:8888']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 2. Grafana ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "OTLP Rust Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(otlp_requests_total[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(otlp_errors_total[5m])",
            "legendFormat": "Errors/sec"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(otlp_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Circuit Breaker Status",
        "type": "stat",
        "targets": [
          {
            "expr": "otlp_circuit_breaker_state",
            "legendFormat": "State"
          }
        ]
      }
    ]
  }
}
```

### 3. å‘Šè­¦è§„åˆ™

```yaml
# otlp_rules.yml
groups:
- name: otlp_alerts
  rules:
  - alert: HighErrorRate
    expr: rate(otlp_errors_total[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"

  - alert: HighLatency
    expr: histogram_quantile(0.95, rate(otlp_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High latency detected"
      description: "95th percentile latency is {{ $value }} seconds"

  - alert: CircuitBreakerOpen
    expr: otlp_circuit_breaker_state == 1
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Circuit breaker is open"
      description: "Circuit breaker has been open for more than 1 minute"
```

## ğŸ”§ é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡

```bash
# åŸºæœ¬é…ç½®
export OTLP_ENDPOINT="http://collector:4317"
export RUST_LOG="info"
export OTLP_TIMEOUT="30s"

# é‡è¯•é…ç½®
export OTLP_RETRY_MAX_ATTEMPTS="3"
export OTLP_RETRY_BASE_DELAY="100ms"
export OTLP_RETRY_MAX_DELAY="5s"

# ç†”æ–­å™¨é…ç½®
export OTLP_CIRCUIT_BREAKER_FAILURE_THRESHOLD="5"
export OTLP_CIRCUIT_BREAKER_RECOVERY_TIMEOUT="60s"

# ç›‘æ§é…ç½®
export OTLP_METRICS_ENABLED="true"
export OTLP_METRICS_PORT="9090"
export OTLP_TRACING_ENABLED="true"
```

### é…ç½®æ–‡ä»¶

```yaml
# config.yaml
endpoint: "http://collector:4317"
timeout: "30s"

retry:
  max_attempts: 3
  base_delay: "100ms"
  max_delay: "5s"
  backoff_multiplier: 2.0
  jitter: true
  retryable_errors:
    - "timeout"
    - "connection"
    - "temporary"

circuit_breaker:
  failure_threshold: 5
  recovery_timeout: "60s"
  half_open_max_calls: 3
  sliding_window_size: "60s"
  minimum_calls: 10

timeout:
  connect_timeout: "5s"
  read_timeout: "30s"
  write_timeout: "30s"
  operation_timeout: "60s"

graceful_degradation:
  enabled: true
  strategies:
    - "use_cache"
    - "use_fallback"
    - "reduce_quality"
  trigger_conditions:
    - type: "high_error_rate"
      threshold: 0.5
    - type: "high_latency"
      threshold: "2s"

health_check:
  interval: "30s"
  timeout: "5s"
  path: "/health"
  unhealthy_threshold: 3
  healthy_threshold: 2

logging:
  level: "info"
  format: "json"
  output: "stdout"

monitoring:
  metrics_enabled: true
  metrics_port: 9090
  tracing_enabled: true
  tracing_endpoint: "http://jaeger:14268/api/traces"
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -v http://collector:4317

# æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
sudo iptables -L

# æ£€æŸ¥ DNS è§£æ
nslookup collector
```

#### 2. é«˜å†…å­˜ä½¿ç”¨

```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
top -p $(pgrep otlp)

# æ£€æŸ¥å†…å­˜æ³„æ¼
valgrind --tool=massif ./target/release/otlp

# è°ƒæ•´é…ç½®
export RUST_LOG="warn"
export OTLP_BATCH_SIZE="100"
```

#### 3. é«˜ CPU ä½¿ç”¨

```bash
# æ£€æŸ¥ CPU ä½¿ç”¨
htop -p $(pgrep otlp)

# åˆ†ææ€§èƒ½ç“¶é¢ˆ
perf record -p $(pgrep otlp)
perf report

# è°ƒæ•´å¹¶å‘é…ç½®
export OTLP_WORKER_THREADS="4"
export OTLP_ASYNC_THREADS="2"
```

#### 4. ç†”æ–­å™¨é¢‘ç¹å¼€å¯

```bash
# æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
curl http://collector:4317/health

# è°ƒæ•´ç†”æ–­å™¨é…ç½®
export OTLP_CIRCUIT_BREAKER_FAILURE_THRESHOLD="10"
export OTLP_CIRCUIT_BREAKER_RECOVERY_TIMEOUT="120s"

# æ£€æŸ¥ä¾èµ–æœåŠ¡
kubectl get pods -l app=collector
```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
journalctl -u otlp -f

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
journalctl -u otlp --since "1 hour ago" | grep ERROR

# åˆ†ææ—¥å¿—æ¨¡å¼
grep "circuit_breaker" /var/log/otlp.log | tail -100

# ç»Ÿè®¡é”™è¯¯ç±»å‹
grep "ERROR" /var/log/otlp.log | awk '{print $4}' | sort | uniq -c
```

### æ€§èƒ½è°ƒä¼˜

#### 1. ç³»ç»Ÿçº§ä¼˜åŒ–

```bash
# è°ƒæ•´æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
echo "* soft nofile 65536" >> /etc/security/limits.conf
echo "* hard nofile 65536" >> /etc/security/limits.conf

# è°ƒæ•´ç½‘ç»œå‚æ•°
echo "net.core.somaxconn = 65536" >> /etc/sysctl.conf
echo "net.ipv4.tcp_max_syn_backlog = 65536" >> /etc/sysctl.conf
sysctl -p
```

#### 2. åº”ç”¨çº§ä¼˜åŒ–

```yaml
# ä¼˜åŒ–é…ç½®
batch_size: 1000
flush_interval: "1s"
max_concurrent_requests: 100
connection_pool_size: 50
```

## ğŸ“ˆ æ‰©å±•å’Œå‡çº§

### æ°´å¹³æ‰©å±•

```yaml
# å¢åŠ å‰¯æœ¬æ•°
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otlp-deployment
spec:
  replicas: 5  # ä» 3 å¢åŠ åˆ° 5
```

### å‚ç›´æ‰©å±•

```yaml
# å¢åŠ èµ„æºé™åˆ¶
resources:
  requests:
    memory: "512Mi"  # ä» 256Mi å¢åŠ 
    cpu: "500m"      # ä» 250m å¢åŠ 
  limits:
    memory: "1Gi"    # ä» 512Mi å¢åŠ 
    cpu: "1000m"     # ä» 500m å¢åŠ 
```

### ç‰ˆæœ¬å‡çº§

```bash
# æ»šåŠ¨æ›´æ–°
kubectl set image deployment/otlp-deployment otlp=otlp:v2.0.0

# æ£€æŸ¥æ›´æ–°çŠ¶æ€
kubectl rollout status deployment/otlp-deployment

# å›æ»šï¼ˆå¦‚æœéœ€è¦ï¼‰
kubectl rollout undo deployment/otlp-deployment
```

## ğŸ” å®‰å…¨é…ç½®

### TLS é…ç½®

```yaml
# TLS é…ç½®
tls:
  enabled: true
  cert_file: "/etc/ssl/certs/otlp.crt"
  key_file: "/etc/ssl/private/otlp.key"
  ca_file: "/etc/ssl/certs/ca.crt"
```

### è®¤è¯é…ç½®

```yaml
# è®¤è¯é…ç½®
auth:
  type: "oauth2"
  client_id: "otlp-client"
  client_secret: "your-secret"
  token_url: "https://auth.example.com/oauth/token"
```

### ç½‘ç»œå®‰å…¨

```yaml
# NetworkPolicy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: otlp-netpol
spec:
  podSelector:
    matchLabels:
      app: otlp
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: observability
    ports:
    - protocol: TCP
      port: 4317
```

## ğŸ“š æœ€ä½³å®è·µ

### 1. é…ç½®ç®¡ç†

- ä½¿ç”¨ ConfigMap æˆ– Secret ç®¡ç†é…ç½®
- æ•æ„Ÿä¿¡æ¯ä½¿ç”¨ Secret
- é…ç½®å˜æ›´ä½¿ç”¨æ»šåŠ¨æ›´æ–°

### 2. ç›‘æ§å‘Šè­¦

- è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼
- ä½¿ç”¨å¤šçº§å‘Šè­¦ï¼ˆwarning, criticalï¼‰
- å®šæœŸæ£€æŸ¥å’Œè°ƒæ•´å‘Šè­¦è§„åˆ™

### 3. æ—¥å¿—ç®¡ç†

- ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—ï¼ˆJSON æ ¼å¼ï¼‰
- è®¾ç½®åˆé€‚çš„æ—¥å¿—çº§åˆ«
- å®šæœŸè½®è½¬å’Œæ¸…ç†æ—¥å¿—

### 4. å®‰å…¨å®è·µ

- ä½¿ç”¨é root ç”¨æˆ·è¿è¡Œ
- å¯ç”¨ TLS åŠ å¯†
- å®šæœŸæ›´æ–°ä¾èµ–å’Œé•œåƒ

### 5. å¤‡ä»½æ¢å¤

- å®šæœŸå¤‡ä»½é…ç½®å’ŒçŠ¶æ€
- æµ‹è¯•æ¢å¤æµç¨‹
- æ–‡æ¡£åŒ–æ¢å¤æ­¥éª¤

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**ç»´æŠ¤è€…**: OTLP Rust å›¢é˜Ÿ
