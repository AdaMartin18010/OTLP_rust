# ğŸ“‹ æœ€ä½³å®è·µæŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº† OTLP Rust é¡¹ç›®çš„æœ€ä½³å®è·µæŒ‡å—ï¼ŒåŒ…æ‹¬å¼€å‘å®è·µã€éƒ¨ç½²å®è·µã€è¿ç»´å®è·µå’Œå®‰å…¨å®è·µã€‚

## ğŸ“‹ ç›®å½•

- [ğŸ“‹ æœ€ä½³å®è·µæŒ‡å—](#-æœ€ä½³å®è·µæŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ’» å¼€å‘æœ€ä½³å®è·µ](#-å¼€å‘æœ€ä½³å®è·µ)
    - [ä»£ç è´¨é‡](#ä»£ç è´¨é‡)
      - [ä»£ç é£æ ¼](#ä»£ç é£æ ¼)
      - [ç±»å‹å®‰å…¨](#ç±»å‹å®‰å…¨)
    - [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
      - [é”™è¯¯ç±»å‹è®¾è®¡](#é”™è¯¯ç±»å‹è®¾è®¡)
      - [é”™è¯¯å¤„ç†æ¨¡å¼](#é”™è¯¯å¤„ç†æ¨¡å¼)
    - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
      - [å†…å­˜ç®¡ç†](#å†…å­˜ç®¡ç†)
      - [å¼‚æ­¥ä¼˜åŒ–](#å¼‚æ­¥ä¼˜åŒ–)
    - [æµ‹è¯•ç­–ç•¥](#æµ‹è¯•ç­–ç•¥)
      - [å•å…ƒæµ‹è¯•](#å•å…ƒæµ‹è¯•)
      - [é›†æˆæµ‹è¯•](#é›†æˆæµ‹è¯•)
  - [ğŸš€ éƒ¨ç½²æœ€ä½³å®è·µ](#-éƒ¨ç½²æœ€ä½³å®è·µ)
    - [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
      - [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
      - [ç¯å¢ƒå˜é‡](#ç¯å¢ƒå˜é‡)
    - [å®¹å™¨åŒ–](#å®¹å™¨åŒ–)
      - [Dockerfile æœ€ä½³å®è·µ](#dockerfile-æœ€ä½³å®è·µ)
    - [Kubernetes éƒ¨ç½²](#kubernetes-éƒ¨ç½²)
      - [èµ„æºé™åˆ¶](#èµ„æºé™åˆ¶)
      - [å®‰å…¨é…ç½®](#å®‰å…¨é…ç½®)
    - [ç›‘æ§é…ç½®](#ç›‘æ§é…ç½®)
      - [æŒ‡æ ‡æ”¶é›†](#æŒ‡æ ‡æ”¶é›†)
  - [ğŸ”§ è¿ç»´æœ€ä½³å®è·µ](#-è¿ç»´æœ€ä½³å®è·µ)
    - [æ—¥å¿—ç®¡ç†](#æ—¥å¿—ç®¡ç†)
      - [ç»“æ„åŒ–æ—¥å¿—](#ç»“æ„åŒ–æ—¥å¿—)
    - [æ€§èƒ½ç›‘æ§](#æ€§èƒ½ç›‘æ§)
      - [æ€§èƒ½æŒ‡æ ‡](#æ€§èƒ½æŒ‡æ ‡)
    - [æ•…éšœå¤„ç†](#æ•…éšœå¤„ç†)
      - [æ•…éšœæ£€æµ‹](#æ•…éšœæ£€æµ‹)
    - [å®¹é‡è§„åˆ’](#å®¹é‡è§„åˆ’)
      - [èµ„æºè§„åˆ’](#èµ„æºè§„åˆ’)
  - [ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ](#-å®‰å…¨æœ€ä½³å®è·µ)
    - [è®¤è¯æˆæƒ](#è®¤è¯æˆæƒ)
      - [JWT è®¤è¯](#jwt-è®¤è¯)
    - [æ•°æ®ä¿æŠ¤](#æ•°æ®ä¿æŠ¤)
      - [æ•°æ®åŠ å¯†](#æ•°æ®åŠ å¯†)
    - [ç½‘ç»œå®‰å…¨](#ç½‘ç»œå®‰å…¨)
      - [TLS é…ç½®](#tls-é…ç½®)
    - [å®¡è®¡æ—¥å¿—](#å®¡è®¡æ—¥å¿—)
      - [å®¡è®¡æ—¥å¿—è®°å½•](#å®¡è®¡æ—¥å¿—è®°å½•)
  - [ğŸ“Š æ€§èƒ½æœ€ä½³å®è·µ](#-æ€§èƒ½æœ€ä½³å®è·µ)
    - [å†…å­˜ç®¡ç†1](#å†…å­˜ç®¡ç†1)
      - [å†…å­˜æ± ä½¿ç”¨](#å†…å­˜æ± ä½¿ç”¨)
    - [CPU ä¼˜åŒ–](#cpu-ä¼˜åŒ–)
      - [å¹¶è¡Œå¤„ç†](#å¹¶è¡Œå¤„ç†)
    - [I/O ä¼˜åŒ–](#io-ä¼˜åŒ–)
      - [å¼‚æ­¥ I/O](#å¼‚æ­¥-io)
    - [ç½‘ç»œä¼˜åŒ–](#ç½‘ç»œä¼˜åŒ–)
      - [è¿æ¥å¤ç”¨](#è¿æ¥å¤ç”¨)
  - [ğŸ”— ç›¸å…³æ–‡æ¡£](#-ç›¸å…³æ–‡æ¡£)

## ğŸ’» å¼€å‘æœ€ä½³å®è·µ

### ä»£ç è´¨é‡

#### ä»£ç é£æ ¼

```rust
// âœ… å¥½çš„å®è·µï¼šæ¸…æ™°çš„å‘½åå’Œç»“æ„
pub struct OtlpClient {
    inner: Arc<ClientInner>,
    config: OtlpConfig,
}

impl OtlpClient {
    /// åˆ›å»ºæ–°çš„ OTLP å®¢æˆ·ç«¯
    /// 
    /// # Arguments
    /// 
    /// * `config` - å®¢æˆ·ç«¯é…ç½®
    /// 
    /// # Returns
    /// 
    /// è¿”å›é…ç½®å¥½çš„å®¢æˆ·ç«¯å®ä¾‹
    /// 
    /// # Errors
    /// 
    /// å¦‚æœé…ç½®æ— æ•ˆæˆ–ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¿”å›é”™è¯¯
    pub async fn new(config: OtlpConfig) -> Result<Self, OtlpError> {
        let inner = ClientInner::new(config.clone()).await?;
        Ok(Self {
            inner: Arc::new(inner),
            config,
        })
    }
}

// âŒ é¿å…ï¼šæ¨¡ç³Šçš„å‘½åå’Œç¼ºå°‘æ–‡æ¡£
pub struct Client {
    i: Arc<Inner>,
    c: Config,
}

impl Client {
    pub async fn new(c: Config) -> Result<Self, Error> {
        let i = Inner::new(c.clone()).await?;
        Ok(Self { i: Arc::new(i), c })
    }
}
```

#### ç±»å‹å®‰å…¨

```rust
// âœ… å¥½çš„å®è·µï¼šä½¿ç”¨å¼ºç±»å‹
#[derive(Debug, Clone, PartialEq)]
pub struct Endpoint(String);

impl Endpoint {
    pub fn new(url: &str) -> Result<Self, InvalidEndpoint> {
        if url.starts_with("http://") || url.starts_with("https://") {
            Ok(Self(url.to_string()))
        } else {
            Err(InvalidEndpoint::new(url))
        }
    }
    
    pub fn as_str(&self) -> &str {
        &self.0
    }
}

// âœ… ä½¿ç”¨ Newtype æ¨¡å¼
pub struct BatchSize(usize);

impl BatchSize {
    pub fn new(size: usize) -> Result<Self, InvalidBatchSize> {
        if size > 0 && size <= 10000 {
            Ok(Self(size))
        } else {
            Err(InvalidBatchSize::new(size))
        }
    }
    
    pub fn get(&self) -> usize {
        self.0
    }
}
```

### é”™è¯¯å¤„ç†

#### é”™è¯¯ç±»å‹è®¾è®¡

```rust
use thiserror::Error;

// âœ… å¥½çš„å®è·µï¼šè¯¦ç»†çš„é”™è¯¯ç±»å‹
#[derive(Error, Debug)]
pub enum OtlpError {
    #[error("Network error: {0}")]
    Network(#[from] reqwest::Error),
    
    #[error("gRPC error: {0}")]
    Grpc(#[from] tonic::Status),
    
    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
    
    #[error("Configuration error: {0}")]
    Config(#[from] ConfigError),
    
    #[error("Timeout after {duration:?}")]
    Timeout { duration: Duration },
    
    #[error("Batch processing failed: {reason}")]
    Batch { reason: String },
    
    #[error("Authentication failed: {message}")]
    Auth { message: String },
}

// âœ… é”™è¯¯ä¸Šä¸‹æ–‡
impl OtlpError {
    pub fn with_context<C>(self, context: C) -> ContextualError<C>
    where
        C: std::fmt::Display + Send + Sync + 'static,
    {
        ContextualError {
            error: self,
            context: Some(Box::new(context)),
        }
    }
}
```

#### é”™è¯¯å¤„ç†æ¨¡å¼

```rust
// âœ… å¥½çš„å®è·µï¼šä½¿ç”¨ Result å’Œ ? æ“ä½œç¬¦
pub async fn send_data(&self, data: TelemetryData) -> Result<SendResult, OtlpError> {
    let serialized = serde_json::to_string(&data)?;
    let response = self.transport.send(&serialized).await?;
    
    if response.status().is_success() {
        Ok(SendResult::success())
    } else {
        Err(OtlpError::Network(
            reqwest::Error::from(response.error_for_status().unwrap_err())
        ))
    }
}

// âœ… ä½¿ç”¨ match è¿›è¡Œè¯¦ç»†é”™è¯¯å¤„ç†
pub async fn process_with_retry(&self, data: TelemetryData) -> Result<(), OtlpError> {
    let mut last_error = None;
    
    for attempt in 1..=self.config.max_retries {
        match self.send_data(data.clone()).await {
            Ok(_) => return Ok(()),
            Err(e) => {
                last_error = Some(e);
                if attempt < self.config.max_retries {
                    tokio::time::sleep(self.calculate_backoff(attempt)).await;
                }
            }
        }
    }
    
    Err(last_error.unwrap_or_else(|| OtlpError::Custom("Unknown error".to_string())))
}
```

### æ€§èƒ½ä¼˜åŒ–

#### å†…å­˜ç®¡ç†

```rust
// âœ… å¥½çš„å®è·µï¼šä½¿ç”¨å†…å­˜æ± 
pub struct MemoryPool {
    buffers: Vec<Vec<u8>>,
    max_size: usize,
}

impl MemoryPool {
    pub fn new(pool_size: usize, buffer_size: usize) -> Self {
        let mut buffers = Vec::with_capacity(pool_size);
        for _ in 0..pool_size {
            buffers.push(Vec::with_capacity(buffer_size));
        }
        
        Self {
            buffers,
            max_size: buffer_size,
        }
    }
    
    pub fn get_buffer(&mut self) -> Option<Vec<u8>> {
        self.buffers.pop().map(|mut buffer| {
            buffer.clear();
            buffer
        })
    }
    
    pub fn return_buffer(&mut self, mut buffer: Vec<u8>) {
        if buffer.capacity() <= self.max_size && self.buffers.len() < self.buffers.capacity() {
            buffer.clear();
            self.buffers.push(buffer);
        }
    }
}

// âœ… ä½¿ç”¨é›¶æ‹·è´æŠ€æœ¯
pub struct ZeroCopyBuffer<'a> {
    data: &'a [u8],
}

impl<'a> ZeroCopyBuffer<'a> {
    pub fn new(data: &'a [u8]) -> Self {
        Self { data }
    }
    
    pub fn as_slice(&self) -> &[u8] {
        self.data
    }
}
```

#### å¼‚æ­¥ä¼˜åŒ–

```rust
// âœ… å¥½çš„å®è·µï¼šåˆç†çš„å¹¶å‘æ§åˆ¶
pub struct ConcurrencyLimiter {
    semaphore: Semaphore,
}

impl ConcurrencyLimiter {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Semaphore::new(max_concurrent),
        }
    }
    
    pub async fn execute<F, T>(&self, future: F) -> Result<T, OtlpError>
    where
        F: Future<Output = Result<T, OtlpError>>,
    {
        let _permit = self.semaphore.acquire().await
            .map_err(|_| OtlpError::ConcurrencyLimit)?;
        
        future.await
    }
}

// âœ… ä½¿ç”¨ select! è¿›è¡Œå¹¶å‘æ“ä½œ
pub async fn process_with_timeout(&self, data: TelemetryData) -> Result<(), OtlpError> {
    tokio::select! {
        result = self.send_data(data) => result,
        _ = tokio::time::sleep(self.config.timeout) => {
            Err(OtlpError::Timeout { 
                duration: self.config.timeout 
            })
        }
    }
}
```

### æµ‹è¯•ç­–ç•¥

#### å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    
    // âœ… å¥½çš„å®è·µï¼šæ¸…æ™°çš„æµ‹è¯•ç»“æ„
    #[tokio::test]
    async fn test_client_creation_success() {
        // Arrange
        let config = OtlpConfig::default()
            .with_endpoint("http://localhost:4317");
        
        // Act
        let client = OtlpClient::new(config).await;
        
        // Assert
        assert!(client.is_ok());
    }
    
    #[tokio::test]
    async fn test_client_creation_invalid_endpoint() {
        // Arrange
        let config = OtlpConfig::default()
            .with_endpoint("invalid-url");
        
        // Act
        let client = OtlpClient::new(config).await;
        
        // Assert
        assert!(client.is_err());
        match client.unwrap_err() {
            OtlpError::Config(_) => {}, // æœŸæœ›çš„é”™è¯¯ç±»å‹
            other => panic!("Expected ConfigError, got {:?}", other),
        }
    }
    
    // âœ… ä½¿ç”¨å‚æ•°åŒ–æµ‹è¯•
    #[tokio::test]
    async fn test_batch_processing() {
        let test_cases = vec![
            (1, 1),
            (100, 1),
            (512, 1),
            (1000, 2),
            (2000, 4),
        ];
        
        for (input_size, expected_batches) in test_cases {
            let processor = BatchProcessor::new(512);
            let data = generate_test_data(input_size);
            let batches = processor.process(data).await.unwrap();
            
            assert_eq!(batches.len(), expected_batches);
        }
    }
}
```

#### é›†æˆæµ‹è¯•

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;
    
    // âœ… ä½¿ç”¨æµ‹è¯•å®¹å™¨
    #[tokio::test]
    async fn test_with_testcontainers() {
        let docker = testcontainers::clients::Cli::default();
        let collector = docker.run(testcontainers::images::generic::GenericImage::new("otel/opentelemetry-collector", "latest"));
        
        let config = OtlpConfig::default()
            .with_endpoint(&format!("http://localhost:{}", collector.get_host_port_ipv4(4317)));
        
        let client = OtlpClient::new(config).await.unwrap();
        
        // æµ‹è¯•é€»è¾‘
        let result = client.send_trace("test-operation").await;
        assert!(result.is_ok());
    }
    
    // âœ… æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–
    #[tokio::test]
    async fn test_with_mock_server() {
        let server = mockito::Server::new_async().await;
        let mock = server
            .mock("POST", "/v1/traces")
            .with_status(200)
            .create_async()
            .await;
        
        let config = OtlpConfig::default()
            .with_endpoint(&server.url());
        
        let client = OtlpClient::new(config).await.unwrap();
        let result = client.send_trace("test-operation").await;
        
        assert!(result.is_ok());
        mock.assert_async().await;
    }
}
```

## ğŸš€ éƒ¨ç½²æœ€ä½³å®è·µ

### ç¯å¢ƒé…ç½®

#### é…ç½®ç®¡ç†

```yaml
# âœ… å¥½çš„å®è·µï¼šç¯å¢ƒç‰¹å®šçš„é…ç½®
# config/development.yaml
server:
  host: "0.0.0.0"
  port: 8080
  workers: 2

otlp:
  endpoint: "http://localhost:4317"
  protocol: "grpc"
  timeout: "5s"

logging:
  level: "debug"
  format: "pretty"

# config/production.yaml
server:
  host: "0.0.0.0"
  port: 8080
  workers: 8

otlp:
  endpoint: "http://collector:4317"
  protocol: "grpc"
  timeout: "10s"
  retry:
    max_retries: 5
    initial_delay: "100ms"
    max_delay: "30s"

logging:
  level: "info"
  format: "json"
  output: "stdout"
```

#### ç¯å¢ƒå˜é‡

```bash
# âœ… å¥½çš„å®è·µï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
export RUST_LOG=info
export OTLP_ENDPOINT=http://collector:4317
export OTLP_PROTOCOL=grpc
export OTLP_TIMEOUT=10s
export OTLP_MAX_RETRIES=5
export OTLP_BATCH_SIZE=512
export OTLP_QUEUE_SIZE=2048

# âŒ é¿å…ï¼šç¡¬ç¼–ç é…ç½®
# export OTLP_ENDPOINT=http://localhost:4317
```

### å®¹å™¨åŒ–

#### Dockerfile æœ€ä½³å®è·µ

```dockerfile
# âœ… å¥½çš„å®è·µï¼šå¤šé˜¶æ®µæ„å»º
FROM rust:1.90-alpine AS builder

# å®‰è£…æ„å»ºä¾èµ–
RUN apk add --no-cache musl-dev openssl-dev pkgconfig

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY Cargo.toml Cargo.lock ./

# æ„å»ºä¾èµ–ç¼“å­˜
RUN cargo fetch

# å¤åˆ¶æºä»£ç 
COPY src ./src
COPY otlp ./otlp

# æ„å»ºåº”ç”¨
RUN cargo build --release --target x86_64-unknown-linux-musl

# è¿è¡Œæ—¶é•œåƒ
FROM alpine:latest

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apk --no-cache add ca-certificates tzdata

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S otlp && \
    adduser -u 1001 -S otlp -G otlp

WORKDIR /app

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/target/x86_64-unknown-linux-musl/release/otlp-client ./

# è®¾ç½®æƒé™
RUN chown -R otlp:otlp /app
USER otlp

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨åº”ç”¨
CMD ["./otlp-client"]
```

### Kubernetes éƒ¨ç½²

#### èµ„æºé™åˆ¶

```yaml
# âœ… å¥½çš„å®è·µï¼šåˆç†çš„èµ„æºé™åˆ¶
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otlp-client
spec:
  template:
    spec:
      containers:
      - name: otlp-client
        image: otlp-client:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
```

#### å®‰å…¨é…ç½®

```yaml
# âœ… å¥½çš„å®è·µï¼šå®‰å…¨é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otlp-client
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      containers:
      - name: otlp-client
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1001
          capabilities:
            drop:
            - ALL
```

### ç›‘æ§é…ç½®

#### æŒ‡æ ‡æ”¶é›†

```rust
// âœ… å¥½çš„å®è·µï¼šç»“æ„åŒ–æŒ‡æ ‡
use prometheus::{Counter, Histogram, Gauge, register_counter, register_histogram, register_gauge};

pub struct Metrics {
    pub requests_total: Counter,
    pub request_duration: Histogram,
    pub active_connections: Gauge,
    pub batch_size: Histogram,
    pub errors_total: Counter,
}

impl Metrics {
    pub fn new() -> Self {
        Self {
            requests_total: register_counter!(
                "otlp_requests_total",
                "Total number of requests",
                &["method", "endpoint", "status"]
            ).unwrap(),
            request_duration: register_histogram!(
                "otlp_request_duration_seconds",
                "Request duration in seconds",
                &["method", "endpoint"]
            ).unwrap(),
            active_connections: register_gauge!(
                "otlp_active_connections",
                "Number of active connections"
            ).unwrap(),
            batch_size: register_histogram!(
                "otlp_batch_size",
                "Batch size distribution"
            ).unwrap(),
            errors_total: register_counter!(
                "otlp_errors_total",
                "Total number of errors",
                &["error_type", "endpoint"]
            ).unwrap(),
        }
    }
}
```

## ğŸ”§ è¿ç»´æœ€ä½³å®è·µ

### æ—¥å¿—ç®¡ç†

#### ç»“æ„åŒ–æ—¥å¿—

```rust
// âœ… å¥½çš„å®è·µï¼šç»“æ„åŒ–æ—¥å¿—
use tracing::{info, warn, error, debug};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logging() {
    tracing_subscriber::registry()
        .with(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "otlp_client=info".into()),
        )
        .with(tracing_subscriber::fmt::layer()
            .with_target(false)
            .with_thread_ids(true)
            .with_file(true)
            .with_line_number(true)
            .json()
        )
        .init();
}

// âœ… ä½¿ç”¨ç»“æ„åŒ–å­—æ®µ
pub async fn process_request(request: &Request) -> Result<Response, Error> {
    let span = tracing::info_span!("process_request", 
        request_id = %request.id,
        method = %request.method,
        path = %request.path,
        user_id = %request.user_id
    );
    
    let _enter = span.enter();
    
    info!(
        request_id = %request.id,
        method = %request.method,
        path = %request.path,
        user_id = %request.user_id,
        "Processing request"
    );
    
    // å¤„ç†é€»è¾‘
    let result = handle_request(request).await;
    
    match &result {
        Ok(response) => {
            info!(
                request_id = %request.id,
                status_code = response.status_code,
                duration_ms = response.duration.as_millis(),
                "Request completed successfully"
            );
        }
        Err(error) => {
            error!(
                request_id = %request.id,
                error = %error,
                error_type = %std::any::type_name_of_val(error),
                "Request failed"
            );
        }
    }
    
    result
}
```

### æ€§èƒ½ç›‘æ§

#### æ€§èƒ½æŒ‡æ ‡

```rust
// âœ… å¥½çš„å®è·µï¼šå…¨é¢çš„æ€§èƒ½ç›‘æ§
pub struct PerformanceMonitor {
    metrics: Metrics,
    start_time: Instant,
}

impl PerformanceMonitor {
    pub fn new() -> Self {
        Self {
            metrics: Metrics::new(),
            start_time: Instant::now(),
        }
    }
    
    pub fn record_request(&self, method: &str, endpoint: &str, duration: Duration, status: u16) {
        self.metrics.requests_total
            .with_label_values(&[method, endpoint, &status.to_string()])
            .inc();
        
        self.metrics.request_duration
            .with_label_values(&[method, endpoint])
            .observe(duration.as_secs_f64());
    }
    
    pub fn record_error(&self, error_type: &str, endpoint: &str) {
        self.metrics.errors_total
            .with_label_values(&[error_type, endpoint])
            .inc();
    }
    
    pub fn update_connections(&self, count: usize) {
        self.metrics.active_connections.set(count as f64);
    }
}
```

### æ•…éšœå¤„ç†

#### æ•…éšœæ£€æµ‹

```rust
// âœ… å¥½çš„å®è·µï¼šä¸»åŠ¨æ•…éšœæ£€æµ‹
pub struct HealthChecker {
    checks: Vec<Box<dyn HealthCheck + Send + Sync>>,
    interval: Duration,
}

impl HealthChecker {
    pub fn new(interval: Duration) -> Self {
        Self {
            checks: Vec::new(),
            interval,
        }
    }
    
    pub fn add_check<C>(&mut self, check: C)
    where
        C: HealthCheck + Send + Sync + 'static,
    {
        self.checks.push(Box::new(check));
    }
    
    pub async fn start_monitoring(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut interval = tokio::time::interval(self.interval);
        
        loop {
            interval.tick().await;
            
            for check in &self.checks {
                match check.check().await {
                    Ok(_) => {
                        info!(check_name = %check.name(), "Health check passed");
                    }
                    Err(e) => {
                        error!(check_name = %check.name(), error = %e, "Health check failed");
                        // è§¦å‘å‘Šè­¦æˆ–æ•…éšœå¤„ç†
                    }
                }
            }
        }
    }
}

pub trait HealthCheck {
    fn name(&self) -> &str;
    async fn check(&self) -> Result<(), Box<dyn std::error::Error>>;
}
```

### å®¹é‡è§„åˆ’

#### èµ„æºè§„åˆ’

```rust
// âœ… å¥½çš„å®è·µï¼šåŸºäºæŒ‡æ ‡çš„å®¹é‡è§„åˆ’
pub struct CapacityPlanner {
    metrics: Metrics,
    thresholds: CapacityThresholds,
}

impl CapacityPlanner {
    pub fn new(thresholds: CapacityThresholds) -> Self {
        Self {
            metrics: Metrics::new(),
            thresholds,
        }
    }
    
    pub async fn check_capacity(&self) -> CapacityStatus {
        let cpu_usage = self.get_cpu_usage().await;
        let memory_usage = self.get_memory_usage().await;
        let request_rate = self.get_request_rate().await;
        
        CapacityStatus {
            cpu_usage,
            memory_usage,
            request_rate,
            recommendations: self.generate_recommendations(cpu_usage, memory_usage, request_rate),
        }
    }
    
    fn generate_recommendations(&self, cpu: f64, memory: f64, requests: f64) -> Vec<String> {
        let mut recommendations = Vec::new();
        
        if cpu > self.thresholds.cpu_warning {
            recommendations.push("Consider scaling up CPU resources".to_string());
        }
        
        if memory > self.thresholds.memory_warning {
            recommendations.push("Consider scaling up memory resources".to_string());
        }
        
        if requests > self.thresholds.request_rate_warning {
            recommendations.push("Consider horizontal scaling".to_string());
        }
        
        recommendations
    }
}
```

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

### è®¤è¯æˆæƒ

#### JWT è®¤è¯

```rust
// âœ… å¥½çš„å®è·µï¼šå®‰å…¨çš„ JWT å¤„ç†
use jsonwebtoken::{decode, encode, Algorithm, DecodingKey, EncodingKey, Header, Validation};

pub struct JwtAuth {
    encoding_key: EncodingKey,
    decoding_key: DecodingKey,
    validation: Validation,
}

impl JwtAuth {
    pub fn new(secret: &str) -> Self {
        let encoding_key = EncodingKey::from_secret(secret.as_bytes());
        let decoding_key = DecodingKey::from_secret(secret.as_bytes());
        let mut validation = Validation::new(Algorithm::HS256);
        validation.set_required_spec_claims(&["exp", "iat", "sub"]);
        
        Self {
            encoding_key,
            decoding_key,
            validation,
        }
    }
    
    pub fn generate_token(&self, claims: &Claims) -> Result<String, JwtError> {
        encode(&Header::default(), claims, &self.encoding_key)
    }
    
    pub fn verify_token(&self, token: &str) -> Result<Claims, JwtError> {
        let token_data = decode::<Claims>(token, &self.decoding_key, &self.validation)?;
        Ok(token_data.claims)
    }
}

#[derive(Debug, Serialize, Deserialize)]
pub struct Claims {
    pub sub: String,
    pub exp: usize,
    pub iat: usize,
    pub roles: Vec<String>,
}
```

### æ•°æ®ä¿æŠ¤

#### æ•°æ®åŠ å¯†

```rust
// âœ… å¥½çš„å®è·µï¼šæ•°æ®åŠ å¯†
use aes_gcm::{Aes256Gcm, Key, Nonce};
use aes_gcm::aead::{Aead, NewAead};

pub struct DataEncryption {
    cipher: Aes256Gcm,
}

impl DataEncryption {
    pub fn new(key: &[u8; 32]) -> Self {
        let key = Key::from_slice(key);
        let cipher = Aes256Gcm::new(key);
        
        Self { cipher }
    }
    
    pub fn encrypt(&self, plaintext: &[u8]) -> Result<Vec<u8>, EncryptionError> {
        let nonce = Nonce::from_slice(&[0; 12]); // åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨éšæœº nonce
        self.cipher.encrypt(nonce, plaintext)
            .map_err(|e| EncryptionError::EncryptionFailed(e.to_string()))
    }
    
    pub fn decrypt(&self, ciphertext: &[u8]) -> Result<Vec<u8>, EncryptionError> {
        let nonce = Nonce::from_slice(&[0; 12]);
        self.cipher.decrypt(nonce, ciphertext)
            .map_err(|e| EncryptionError::DecryptionFailed(e.to_string()))
    }
}
```

### ç½‘ç»œå®‰å…¨

#### TLS é…ç½®

```rust
// âœ… å¥½çš„å®è·µï¼šå®‰å…¨çš„ TLS é…ç½®
use rustls::{ClientConfig, RootCertStore};
use std::sync::Arc;

pub fn create_secure_client_config() -> Result<ClientConfig, Box<dyn std::error::Error>> {
    let mut root_store = RootCertStore::empty();
    
    // æ·»åŠ ç³»ç»Ÿæ ¹è¯ä¹¦
    for cert in rustls_native_certs::load_native_certs()? {
        root_store.add(&rustls::Certificate(cert.0))?;
    }
    
    let config = ClientConfig::builder()
        .with_safe_defaults()
        .with_root_certificates(root_store)
        .with_no_client_auth();
    
    Ok(config)
}
```

### å®¡è®¡æ—¥å¿—

#### å®¡è®¡æ—¥å¿—è®°å½•

```rust
// âœ… å¥½çš„å®è·µï¼šå®Œæ•´çš„å®¡è®¡æ—¥å¿—
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};

#[derive(Debug, Serialize, Deserialize)]
pub struct AuditLog {
    pub timestamp: DateTime<Utc>,
    pub user_id: String,
    pub action: String,
    pub resource: String,
    pub result: AuditResult,
    pub ip_address: String,
    pub user_agent: String,
    pub session_id: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum AuditResult {
    Success,
    Failure { reason: String },
}

pub struct AuditLogger {
    writer: Arc<Mutex<dyn std::io::Write + Send>>,
}

impl AuditLogger {
    pub fn new(writer: Box<dyn std::io::Write + Send>) -> Self {
        Self {
            writer: Arc::new(Mutex::new(writer)),
        }
    }
    
    pub async fn log(&self, log: AuditLog) -> Result<(), Box<dyn std::error::Error>> {
        let json = serde_json::to_string(&log)?;
        let mut writer = self.writer.lock().await;
        writeln!(writer, "{}", json)?;
        Ok(())
    }
}
```

## ğŸ“Š æ€§èƒ½æœ€ä½³å®è·µ

### å†…å­˜ç®¡ç†1

#### å†…å­˜æ± ä½¿ç”¨

```rust
// âœ… å¥½çš„å®è·µï¼šé«˜æ•ˆçš„å†…å­˜æ± 
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct MemoryPool {
    pools: Arc<Mutex<Vec<Vec<u8>>>>,
    pool_size: usize,
    buffer_size: usize,
}

impl MemoryPool {
    pub fn new(pool_size: usize, buffer_size: usize) -> Self {
        let mut pools = Vec::with_capacity(pool_size);
        for _ in 0..pool_size {
            pools.push(Vec::with_capacity(buffer_size));
        }
        
        Self {
            pools: Arc::new(Mutex::new(pools)),
            pool_size,
            buffer_size,
        }
    }
    
    pub async fn get_buffer(&self) -> Option<PooledBuffer> {
        let mut pools = self.pools.lock().await;
        pools.pop().map(|mut buffer| {
            buffer.clear();
            PooledBuffer {
                buffer,
                pool: Arc::clone(&self.pools),
            }
        })
    }
}

pub struct PooledBuffer {
    buffer: Vec<u8>,
    pool: Arc<Mutex<Vec<Vec<u8>>>>,
}

impl Drop for PooledBuffer {
    fn drop(&mut self) {
        let pool = Arc::clone(&self.pool);
        let buffer = std::mem::take(&mut self.buffer);
        tokio::spawn(async move {
            let mut pools = pool.lock().await;
            if pools.len() < pools.capacity() {
                pools.push(buffer);
            }
        });
    }
}
```

### CPU ä¼˜åŒ–

#### å¹¶è¡Œå¤„ç†

```rust
// âœ… å¥½çš„å®è·µï¼šåˆç†çš„å¹¶è¡Œå¤„ç†
use rayon::prelude::*;

pub struct ParallelProcessor {
    num_threads: usize,
}

impl ParallelProcessor {
    pub fn new(num_threads: usize) -> Self {
        Self { num_threads }
    }
    
    pub fn process_batch<T, F, R>(&self, items: Vec<T>, processor: F) -> Vec<R>
    where
        T: Send,
        F: Fn(T) -> R + Sync,
        R: Send,
    {
        items.into_par_iter()
            .with_min_len(self.num_threads)
            .map(processor)
            .collect()
    }
}
```

### I/O ä¼˜åŒ–

#### å¼‚æ­¥ I/O

```rust
// âœ… å¥½çš„å®è·µï¼šé«˜æ•ˆçš„å¼‚æ­¥ I/O
use tokio::io::{AsyncRead, AsyncWrite};
use tokio::net::TcpStream;

pub struct AsyncIoProcessor {
    buffer_size: usize,
}

impl AsyncIoProcessor {
    pub fn new(buffer_size: usize) -> Self {
        Self { buffer_size }
    }
    
    pub async fn process_stream<R, W>(
        &self,
        mut reader: R,
        mut writer: W,
    ) -> Result<(), std::io::Error>
    where
        R: AsyncRead + Unpin,
        W: AsyncWrite + Unpin,
    {
        let mut buffer = vec![0u8; self.buffer_size];
        
        loop {
            let bytes_read = reader.read(&mut buffer).await?;
            if bytes_read == 0 {
                break;
            }
            
            writer.write_all(&buffer[..bytes_read]).await?;
        }
        
        writer.flush().await?;
        Ok(())
    }
}
```

### ç½‘ç»œä¼˜åŒ–

#### è¿æ¥å¤ç”¨

```rust
// âœ… å¥½çš„å®è·µï¼šè¿æ¥æ± ç®¡ç†
use std::collections::HashMap;
use tokio::sync::RwLock;

pub struct ConnectionPool<T> {
    connections: Arc<RwLock<HashMap<String, Vec<T>>>>,
    max_connections_per_host: usize,
}

impl<T> ConnectionPool<T> {
    pub fn new(max_connections_per_host: usize) -> Self {
        Self {
            connections: Arc::new(RwLock::new(HashMap::new())),
            max_connections_per_host,
        }
    }
    
    pub async fn get_connection(&self, host: &str) -> Option<PooledConnection<T>> {
        let mut connections = self.connections.write().await;
        let host_connections = connections.entry(host.to_string()).or_insert_with(Vec::new);
        
        host_connections.pop().map(|conn| PooledConnection {
            connection: conn,
            host: host.to_string(),
            pool: Arc::clone(&self.connections),
        })
    }
    
    pub async fn return_connection(&self, host: &str, connection: T) {
        let mut connections = self.connections.write().await;
        let host_connections = connections.entry(host.to_string()).or_insert_with(Vec::new);
        
        if host_connections.len() < self.max_connections_per_host {
            host_connections.push(connection);
        }
    }
}
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](../01_GETTING_STARTED/README.md)
- [API å‚è€ƒæ–‡æ¡£](../03_API_REFERENCE/README.md)
- [æ¶æ„è®¾è®¡æ–‡æ¡£](../04_ARCHITECTURE/README.md)
- [å®ç°æŒ‡å—](../05_IMPLEMENTATION/README.md)
- [éƒ¨ç½²è¿ç»´æŒ‡å—](../06_DEPLOYMENT/README.md)
- [é›†æˆæŒ‡å—](../07_INTEGRATION/README.md)

---

**æœ€ä½³å®è·µæŒ‡å—ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**ç»´æŠ¤è€…**: OTLP Rust å›¢é˜Ÿ
