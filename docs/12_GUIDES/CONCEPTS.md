# æœ€ä½³å®è·µæ ¸å¿ƒæ¦‚å¿µ

**ç‰ˆæœ¬**: 2.0  
**æ—¥æœŸ**: 2025å¹´10æœˆ28æ—¥  
**çŠ¶æ€**: âœ… å®Œæ•´

---

## ğŸ“‹ ç›®å½•

1. [é›¶æ‹·è´è®¾è®¡](#1-é›¶æ‹·è´è®¾è®¡)
2. [å¼‚æ­¥æœ€ä½³å®è·µ](#2-å¼‚æ­¥æœ€ä½³å®è·µ)
3. [é”™è¯¯å¤„ç†æ¨¡å¼](#3-é”™è¯¯å¤„ç†æ¨¡å¼)
4. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#4-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)

---

## 1. é›¶æ‹·è´è®¾è®¡

### 1.1 é›¶æ‹·è´åŸç†

#### å®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**: Zero-Copy ZC = (avoid_copy, share_ownership, lazy_evaluation)

**æ ¸å¿ƒæ€æƒ³**:
```
ä¼ ç»Ÿæ–¹å¼: Source â†’ Buffer1 â†’ Buffer2 â†’ Buffer3 â†’ Destination
é›¶æ‹·è´:   Source â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Destination
```

**é€šä¿—è§£é‡Š**: é¿å…ä¸å¿…è¦çš„æ•°æ®æ‹·è´ï¼Œé€šè¿‡å…±äº«æˆ–å¼•ç”¨ä¼ é€’æ•°æ®ã€‚

#### å†…æ¶µï¼ˆæœ¬è´¨ç‰¹å¾ï¼‰

- **é¿å…æ‹·è´**: ä½¿ç”¨å¼•ç”¨è€Œéå€¼
- **å…±äº«æ‰€æœ‰æƒ**: Arc/Rcå…±äº«æ•°æ®
- **å»¶è¿Ÿæ±‚å€¼**: éœ€è¦æ—¶æ‰æ‹·è´
- **è¿ç»­å†…å­˜**: å‡å°‘ç¢ç‰‡

#### å¤–å»¶ï¼ˆæ¶µç›–èŒƒå›´ï¼‰

- åŒ…å«: å¼•ç”¨ä¼ é€’ã€Arc/Bytesã€å†…å­˜æ˜ å°„
- ä¸åŒ…å«: å¿…é¡»æ‹·è´çš„åœºæ™¯ï¼ˆè·¨çº¿ç¨‹mutï¼‰

#### å±æ€§

| æŠ€æœ¯ | é€‚ç”¨åœºæ™¯ | æ€§èƒ½æå‡ | å¤æ‚åº¦ |
|------|---------|---------|--------|
| å¼•ç”¨ä¼ é€’ | å•çº¿ç¨‹ | +50% | ä½ |
| Arcå…±äº« | å¤šçº¿ç¨‹åªè¯» | +30% | ä¸­ |
| Bytes | ç½‘ç»œI/O | +40% | ä¸­ |
| å†…å­˜æ˜ å°„ | å¤§æ–‡ä»¶ | +80% | é«˜ |

#### å…³ç³»

- ä¸**æ€§èƒ½**çš„å…³ç³»: æ˜¾è‘—å‡å°‘CPUå’Œå†…å­˜
- ä¸**å¹¶å‘**çš„å…³ç³»: Arcå®ç°å®‰å…¨å…±äº«
- ä¸**ç½‘ç»œ**çš„å…³ç³»: Bytesä¼˜åŒ–ç½‘ç»œI/O

#### ç¤ºä¾‹

```rust
// 1. ä½¿ç”¨å¼•ç”¨é¿å…æ‹·è´ï¼ˆæœ€ç®€å•ï¼‰
// âŒ ä¸å¥½ï¼šæ‹·è´å¤§é‡æ•°æ®
fn process_data_bad(data: Vec<u8>) -> Vec<u8> {
    // dataè¢«moveï¼Œè°ƒç”¨è€…å¤±å»æ‰€æœ‰æƒ
    data
}

// âœ… å¥½ï¼šä½¿ç”¨å¼•ç”¨
fn process_data_good(data: &[u8]) -> Vec<u8> {
    // åªè¯»å¼•ç”¨ï¼Œä¸æ‹·è´
    data.iter().map(|&b| b ^ 0xFF).collect()
}

// 2. ä½¿ç”¨Byteså®ç°é›¶æ‹·è´ï¼ˆç½‘ç»œI/Oï¼‰
use bytes::{Bytes, BytesMut};

// âŒ ä¸å¥½ï¼šå¤šæ¬¡æ‹·è´
fn serialize_old(span: &Span) -> Vec<u8> {
    let json = serde_json::to_string(span).unwrap();  // æ‹·è´1: span â†’ String
    let bytes = json.into_bytes();                    // æ‹·è´2: String â†’ Vec
    bytes                                             // æ‹·è´3: Vecä¼ é€’
}

// âœ… å¥½ï¼šé›¶æ‹·è´
fn serialize_new(span: &Span) -> Bytes {
    let mut buf = BytesMut::with_capacity(512);
    serialize_span_into(&mut buf, span);  // ç›´æ¥å†™å…¥buffer
    buf.freeze()  // é›¶æ‹·è´è½¬æ¢ä¸ºä¸å¯å˜Bytes
}

// Byteså¯ä»¥é«˜æ•ˆå…±äº«
let data = serialize_new(&span);
let data1 = data.clone();  // â— åªæ˜¯å¼•ç”¨è®¡æ•°+1ï¼Œä¸æ‹·è´æ•°æ®
let data2 = data.clone();  // â— å†æ¬¡å¼•ç”¨è®¡æ•°+1ï¼Œä¸æ‹·è´æ•°æ®

// 3. ä½¿ç”¨Arcå¤šçº¿ç¨‹å…±äº«ï¼ˆé›¶æ‹·è´ï¼‰
use std::sync::Arc;

// âŒ ä¸å¥½ï¼šæ¯ä¸ªçº¿ç¨‹æ‹·è´æ•°æ®
fn distribute_data_bad(data: Vec<u8>) {
    for _ in 0..10 {
        let data_clone = data.clone();  // æ¯æ¬¡æ‹·è´å…¨éƒ¨æ•°æ®
        tokio::spawn(async move {
            process(data_clone).await;
        });
    }
}

// âœ… å¥½ï¼šArcå…±äº«æ•°æ®
fn distribute_data_good(data: Vec<u8>) {
    let data = Arc::new(data);  // åŒ…è£…ä¸ºArc
    
    for _ in 0..10 {
        let data_clone = Arc::clone(&data);  // åªæ˜¯å¼•ç”¨è®¡æ•°+1
        tokio::spawn(async move {
            process(&data_clone).await;
        });
    }
}

// 4. åˆ‡ç‰‡æ“ä½œï¼ˆé›¶æ‹·è´ï¼‰
let data = Bytes::from(&b"Hello, World!"[..]);

// åˆ‡ç‰‡ä¸æ‹·è´ï¼Œåªæ˜¯å¼•ç”¨
let hello = data.slice(0..5);    // "Hello"
let world = data.slice(7..12);   // "World"

// helloã€worldã€dataå…±äº«åŒä¸€åº•å±‚å†…å­˜

// 5. å®Œæ•´ç¤ºä¾‹ï¼šé›¶æ‹·è´Spanå¯¼å‡ºå™¨
pub struct ZeroCopyExporter {
    buffer: Arc<Mutex<BytesMut>>,
}

impl ZeroCopyExporter {
    pub fn new() -> Self {
        Self {
            buffer: Arc::new(Mutex::new(BytesMut::with_capacity(8192))),
        }
    }
    
    pub async fn export(&self, spans: &[Span]) -> Result<()> {
        // åºåˆ—åŒ–åˆ°å…±äº«buffer
        let mut buf = self.buffer.lock().await;
        buf.clear();
        
        for span in spans {
            serialize_span_into(&mut buf, span)?;  // ç›´æ¥å†™å…¥
        }
        
        // è½¬æ¢ä¸ºä¸å¯å˜Bytesï¼ˆé›¶æ‹·è´ï¼‰
        let data = buf.clone().freeze();
        
        // å¼‚æ­¥å‘é€ï¼ˆByteså¯ä»¥è·¨awaitï¼‰
        self.send(data).await?;
        
        Ok(())
    }
    
    async fn send(&self, data: Bytes) -> Result<()> {
        // Byteså¯ä»¥å¤šæ¬¡cloneç”¨äºé‡è¯•ï¼Œä¸æ‹·è´æ•°æ®
        const MAX_RETRIES: usize = 3;
        
        for attempt in 0..MAX_RETRIES {
            match self.client.post(data.clone()).await {  // cloneåªå¢åŠ å¼•ç”¨è®¡æ•°
                Ok(_) => return Ok(()),
                Err(e) if attempt < MAX_RETRIES - 1 => {
                    warn!("Send failed, retrying: {}", e);
                    continue;
                }
                Err(e) => return Err(e),
            }
        }
        
        unreachable!()
    }
}

// æ€§èƒ½å¯¹æ¯”
/*
åœºæ™¯: å¯¼å‡º1000ä¸ªspansï¼Œæ¯ä¸ªspan 1KB

ä¼ ç»Ÿæ–¹å¼ï¼ˆå¤šæ¬¡æ‹·è´ï¼‰:
- åºåˆ—åŒ–: 1MB
- æ‹·è´åˆ°buffer: 1MB â†’ 2MB
- å‘é€æ‹·è´: 2MB â†’ 3MB
- æ€»å†…å­˜: 3MB
- æ‹·è´æ¬¡æ•°: 3æ¬¡
- æ—¶é—´: 10ms

é›¶æ‹·è´æ–¹å¼:
- åºåˆ—åŒ–: 1MBï¼ˆç›´æ¥å†™å…¥å…±äº«bufferï¼‰
- è½¬Bytes: é›¶æ‹·è´
- å‘é€: é›¶æ‹·è´
- æ€»å†…å­˜: 1MB
- æ‹·è´æ¬¡æ•°: 0æ¬¡
- æ—¶é—´: 3ms

æ€§èƒ½æå‡:
- å†…å­˜: -67% (3MB â†’ 1MB)
- æ—¶é—´: -70% (10ms â†’ 3ms)
- åå: +233%
*/
```

---

## 2. å¼‚æ­¥æœ€ä½³å®è·µ

### 2.1 Tokioè¿è¡Œæ—¶ä¼˜åŒ–

#### å®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**: Async Best Practices ABP = (runtime_config, task_mgmt, resource_pool)

**å¼‚æ­¥æ¨¡å‹**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tokio Runtime                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚Worker 1 â”‚ â”‚Worker 2 â”‚ â”‚Worker N â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â”‚
â”‚      â”‚           â”‚           â”‚     â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚              Task Queue            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é€šä¿—è§£é‡Š**: ä¼˜åŒ–Tokioè¿è¡Œæ—¶é…ç½®ï¼Œåˆç†ç®¡ç†å¼‚æ­¥ä»»åŠ¡ã€‚

#### å†…æ¶µï¼ˆæœ¬è´¨ç‰¹å¾ï¼‰

- **è¿è¡Œæ—¶é…ç½®**: å·¥ä½œçº¿ç¨‹æ•°ã€æ ˆå¤§å°
- **ä»»åŠ¡ç®¡ç†**: ä»»åŠ¡ä¼˜å…ˆçº§ã€å–æ¶ˆ
- **èµ„æºæ± åŒ–**: è¿æ¥æ± ã€å¯¹è±¡æ± 
- **èƒŒå‹æ§åˆ¶**: é™æµã€ç¼“å†²

#### å¤–å»¶ï¼ˆæ¶µç›–èŒƒå›´ï¼‰

- åŒ…å«: è¿è¡Œæ—¶é…ç½®ã€ä»»åŠ¡è°ƒåº¦ã€èµ„æºç®¡ç†
- ä¸åŒ…å«: åŒæ­¥ä»£ç ï¼ˆä½¿ç”¨spawn_blockingï¼‰

#### å±æ€§

| é…ç½®é¡¹ | é»˜è®¤å€¼ | æ¨èå€¼ | åœºæ™¯ |
|--------|--------|--------|------|
| worker_threads | CPUæ ¸å¿ƒæ•° | CPUæ ¸å¿ƒæ•° | CPUå¯†é›† |
| max_blocking_threads | 512 | 100 | I/Oå¯†é›† |
| thread_stack_size | 2MB | 2MB | æ­£å¸¸ |
| event_interval | 61 | 31 | ä½å»¶è¿Ÿ |

#### å…³ç³»

- ä¸**æ€§èƒ½**çš„å…³ç³»: é…ç½®ç›´æ¥å½±å“æ€§èƒ½
- ä¸**å¹¶å‘**çš„å…³ç³»: æ§åˆ¶å¹¶å‘åº¦
- ä¸**èµ„æº**çš„å…³ç³»: ç®¡ç†èµ„æºä½¿ç”¨

#### ç¤ºä¾‹

```rust
// 1. ä¼˜åŒ–Tokioè¿è¡Œæ—¶é…ç½®
use tokio::runtime::Builder;

// âŒ é»˜è®¤é…ç½®ï¼ˆå¯èƒ½ä¸optimalï¼‰
#[tokio::main]
async fn main() {
    // ä½¿ç”¨é»˜è®¤é…ç½®
}

// âœ… è‡ªå®šä¹‰é…ç½®
fn main() {
    let runtime = Builder::new_multi_thread()
        .worker_threads(num_cpus::get())  // CPUæ ¸å¿ƒæ•°
        .thread_name("otlp-worker")       // çº¿ç¨‹åç§°
        .thread_stack_size(2 * 1024 * 1024)  // 2MBæ ˆ
        .max_blocking_threads(100)        // é™åˆ¶é˜»å¡çº¿ç¨‹
        .enable_all()                     // å¯ç”¨æ‰€æœ‰ç‰¹æ€§
        .build()
        .unwrap();
    
    runtime.block_on(async {
        run_application().await;
    });
}

// 2. ä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†
use tokio::task;

// é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆä½¿ç”¨spawnï¼‰
task::spawn(async {
    handle_critical_request().await;
});

// ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆä½¿ç”¨spawn_blockingï¼‰
task::spawn_blocking(|| {
    process_background_job();  // CPUå¯†é›†å‹ï¼Œä¸é˜»å¡async
});

// 3. ä»»åŠ¡å–æ¶ˆ
use tokio::select;
use tokio::time::{sleep, Duration};

async fn with_timeout<F>(fut: F, timeout: Duration) -> Result<F::Output, ()>
where
    F: Future,
{
    select! {
        result = fut => Ok(result),
        _ = sleep(timeout) => Err(()),  // è¶…æ—¶å–æ¶ˆ
    }
}

// ä½¿ç”¨
match with_timeout(slow_operation(), Duration::from_secs(5)).await {
    Ok(result) => println!("Success: {:?}", result),
    Err(_) => println!("Timeout!"),
}

// 4. è¿æ¥æ± ï¼ˆé¿å…é¢‘ç¹åˆ›å»ºï¼‰
use deadpool_postgres::{Config, Manager, Pool};

// âŒ ä¸å¥½ï¼šæ¯æ¬¡åˆ›å»ºè¿æ¥
async fn query_bad() -> Result<()> {
    let (client, conn) = tokio_postgres::connect(&config, NoTls).await?;
    tokio::spawn(async move { conn.await });
    
    // ä½¿ç”¨client
    client.query("SELECT...", &[]).await?;
    
    Ok(())
}  // client dropï¼Œè¿æ¥å…³é—­

// âœ… å¥½ï¼šä½¿ç”¨è¿æ¥æ± 
async fn query_good(pool: &Pool) -> Result<()> {
    let client = pool.get().await?;  // ä»æ± ä¸­è·å–
    
    // ä½¿ç”¨client
    client.query("SELECT...", &[]).await?;
    
    Ok(())
}  // clientè‡ªåŠ¨å½’è¿˜æ± ä¸­

// åˆ›å»ºè¿æ¥æ± 
let pool = Config::new()
    .host("localhost")
    .user("postgres")
    .dbname("mydb")
    .max_size(20)  // æœ€å¤§è¿æ¥æ•°
    .create_pool(Some(Runtime::Tokio1), NoTls)?;

// 5. èƒŒå‹æ§åˆ¶ï¼ˆé™åˆ¶å¹¶å‘ï¼‰
use tokio::sync::Semaphore;

pub struct RateLimiter {
    semaphore: Arc<Semaphore>,
}

impl RateLimiter {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
        }
    }
    
    pub async fn acquire(&self) -> SemaphorePermit {
        self.semaphore.acquire().await.unwrap()
    }
}

// ä½¿ç”¨
let limiter = RateLimiter::new(100);  // æœ€å¤š100å¹¶å‘

for request in requests {
    let limiter = limiter.clone();
    
    tokio::spawn(async move {
        let _permit = limiter.acquire().await;  // è·å–è®¸å¯
        
        // å¤„ç†è¯·æ±‚
        process_request(request).await;
        
        // _permit dropæ—¶è‡ªåŠ¨é‡Šæ”¾
    });
}

// 6. é¿å…åœ¨asyncä¸­é˜»å¡
// âŒ ä¸å¥½ï¼šé˜»å¡asyncä»»åŠ¡
async fn bad() {
    std::thread::sleep(Duration::from_secs(1));  // é˜»å¡æ•´ä¸ªworkerï¼
}

// âœ… å¥½ï¼šä½¿ç”¨async sleep
async fn good() {
    tokio::time::sleep(Duration::from_secs(1)).await;  // ä¸é˜»å¡
}

// âœ… å¥½ï¼šCPUå¯†é›†å‹ä»»åŠ¡ä½¿ç”¨spawn_blocking
async fn cpu_intensive() {
    let result = tokio::task::spawn_blocking(|| {
        // CPUå¯†é›†å‹è®¡ç®—
        expensive_computation()
    }).await.unwrap();
}

// æ€§èƒ½å¯¹æ¯”
/*
åœºæ™¯: 10K QPSï¼Œæ¯ä¸ªè¯·æ±‚æŸ¥è¯¢æ•°æ®åº“

æ— è¿æ¥æ± :
- è¿æ¥åˆ›å»º: 10K/s
- å»¶è¿Ÿ: 50ms (æ¯æ¬¡å»ºè¿30ms)
- CPU: 60%
- æˆåŠŸç‡: 90% (è¿æ¥è€—å°½)

æœ‰è¿æ¥æ± (20è¿æ¥):
- è¿æ¥åˆ›å»º: 20ä¸ªï¼ˆåˆå§‹åŒ–ï¼‰
- å»¶è¿Ÿ: 5ms
- CPU: 20%
- æˆåŠŸç‡: 99.9%

æ€§èƒ½æå‡:
- å»¶è¿Ÿ: -90% (50ms â†’ 5ms)
- CPU: -67% (60% â†’ 20%)
- æˆåŠŸç‡: +10%
*/
```

---

## 3. é”™è¯¯å¤„ç†æ¨¡å¼

### 3.1 åˆ†å±‚é”™è¯¯å¤„ç†

#### å®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**: Error Handling EH = (domain_error, infra_error, recovery)

**é”™è¯¯å±‚æ¬¡**:
```
åº”ç”¨å±‚ â”€â†’ ä¸šåŠ¡é”™è¯¯ï¼ˆç”¨æˆ·å¯è§ï¼‰
     â†“
æœåŠ¡å±‚ â”€â†’ é¢†åŸŸé”™è¯¯ï¼ˆä¸šåŠ¡é€»è¾‘ï¼‰
     â†“
åŸºç¡€å±‚ â”€â†’ åŸºç¡€è®¾æ–½é”™è¯¯ï¼ˆç½‘ç»œ/DBï¼‰
```

**é€šä¿—è§£é‡Š**: æŒ‰å±‚æ¬¡ç»„ç»‡é”™è¯¯ï¼Œä¸åŒå±‚æ¬¡ä¸åŒå¤„ç†ç­–ç•¥ã€‚

#### å†…æ¶µï¼ˆæœ¬è´¨ç‰¹å¾ï¼‰

- **åˆ†å±‚å®šä¹‰**: æ¯å±‚å®šä¹‰è‡ªå·±çš„é”™è¯¯
- **å‘ä¸Šè½¬æ¢**: åº•å±‚é”™è¯¯è½¬æ¢ä¸ºä¸Šå±‚é”™è¯¯
- **ä¸Šä¸‹æ–‡é™„åŠ **: æ¯å±‚æ·»åŠ ä¸Šä¸‹æ–‡
- **æ¢å¤ç­–ç•¥**: ä¸åŒé”™è¯¯ä¸åŒæ¢å¤

#### å¤–å»¶ï¼ˆæ¶µç›–èŒƒå›´ï¼‰

- åŒ…å«: ä¸šåŠ¡é”™è¯¯ã€åŸºç¡€è®¾æ–½é”™è¯¯ã€æ¢å¤é€»è¾‘
- ä¸åŒ…å«: panicï¼ˆåº”æå°‘ä½¿ç”¨ï¼‰

#### å±æ€§

| é”™è¯¯ç±»å‹ | å±‚æ¬¡ | æ¢å¤ | ç”¨æˆ·å¯è§ |
|---------|------|------|----------|
| ä¸šåŠ¡é”™è¯¯ | åº”ç”¨ | âœ… | âœ… |
| éªŒè¯é”™è¯¯ | æœåŠ¡ | âœ… | âœ… |
| ç½‘ç»œé”™è¯¯ | åŸºç¡€ | âœ… | âŒ |
| ç³»ç»Ÿé”™è¯¯ | åŸºç¡€ | âŒ | âŒ |

#### å…³ç³»

- ä¸**å¯ç»´æŠ¤æ€§**çš„å…³ç³»: æ¸…æ™°é”™è¯¯ä¾¿äºç»´æŠ¤
- ä¸**ç”¨æˆ·ä½“éªŒ**çš„å…³ç³»: å‹å¥½é”™è¯¯æç¤º
- ä¸**å¯é æ€§**çš„å…³ç³»: æ°å½“æ¢å¤æé«˜å¯é æ€§

#### ç¤ºä¾‹

```rust
// 1. å®šä¹‰åˆ†å±‚é”™è¯¯
use thiserror::Error;

// åŸºç¡€å±‚é”™è¯¯
#[derive(Error, Debug)]
pub enum InfraError {
    #[error("Database error: {0}")]
    Database(#[from] sqlx::Error),
    
    #[error("Network error: {0}")]
    Network(#[from] reqwest::Error),
    
    #[error("Cache error: {0}")]
    Cache(String),
}

// é¢†åŸŸå±‚é”™è¯¯
#[derive(Error, Debug)]
pub enum DomainError {
    #[error("User not found: {0}")]
    UserNotFound(i64),
    
    #[error("Invalid order status: {current} cannot transition to {target}")]
    InvalidStatusTransition {
        current: String,
        target: String,
    },
    
    #[error("Insufficient balance: have {have}, need {need}")]
    InsufficientBalance {
        have: f64,
        need: f64,
    },
    
    #[error("Infrastructure error")]
    Infrastructure(#[from] InfraError),
}

// åº”ç”¨å±‚é”™è¯¯ï¼ˆç”¨æˆ·å¯è§ï¼‰
#[derive(Error, Debug)]
pub enum AppError {
    #[error("Bad request: {0}")]
    BadRequest(String),
    
    #[error("Not found: {0}")]
    NotFound(String),
    
    #[error("Internal server error")]
    Internal,  // ä¸æš´éœ²å†…éƒ¨ç»†èŠ‚
}

// é”™è¯¯è½¬æ¢
impl From<DomainError> for AppError {
    fn from(err: DomainError) -> Self {
        match err {
            DomainError::UserNotFound(id) => {
                AppError::NotFound(format!("User {} not found", id))
            }
            DomainError::InvalidStatusTransition { .. } => {
                AppError::BadRequest(err.to_string())
            }
            DomainError::InsufficientBalance { .. } => {
                AppError::BadRequest(err.to_string())
            }
            DomainError::Infrastructure(_) => {
                // ä¸æš´éœ²åŸºç¡€è®¾æ–½é”™è¯¯ç»†èŠ‚
                AppError::Internal
            }
        }
    }
}

// 2. ä½¿ç”¨anyhowæ·»åŠ ä¸Šä¸‹æ–‡
use anyhow::{Context, Result};

async fn load_user(id: i64) -> Result<User> {
    let user = sqlx::query_as("SELECT * FROM users WHERE id = $1")
        .bind(id)
        .fetch_one(&pool)
        .await
        .context(format!("Failed to load user {}", id))?;  // æ·»åŠ ä¸Šä¸‹æ–‡
    
    Ok(user)
}

async fn process_order(order_id: i64) -> Result<()> {
    let order = load_order(order_id)
        .await
        .context("Failed to load order")?;  // ä¸Šä¸‹æ–‡1
    
    let user = load_user(order.user_id)
        .await
        .context("Failed to load user")?;  // ä¸Šä¸‹æ–‡2
    
    validate_order(&order, &user)
        .context("Order validation failed")?;  // ä¸Šä¸‹æ–‡3
    
    Ok(())
}

// é”™è¯¯é“¾ç¤ºä¾‹ï¼š
/*
Error: Order validation failed
Caused by:
    0: Failed to load user
    1: Failed to load user 123
    2: connection timed out
*/

// 3. æ¢å¤ç­–ç•¥
async fn export_with_fallback(spans: Vec<Span>) -> Result<()> {
    // ä¸»è¦å¯¼å‡ºå™¨
    match primary_exporter.export(&spans).await {
        Ok(_) => return Ok(()),
        Err(e) => warn!("Primary exporter failed: {}", e),
    }
    
    // å¤‡ç”¨å¯¼å‡ºå™¨
    match secondary_exporter.export(&spans).await {
        Ok(_) => {
            warn!("Used secondary exporter");
            return Ok(());
        }
        Err(e) => warn!("Secondary exporter failed: {}", e),
    }
    
    // ä¿å­˜åˆ°ç£ç›˜
    save_to_disk(&spans).await.context("All export methods failed")?;
    
    Ok(())
}

// 4. é‡è¯•ç­–ç•¥
use backoff::{ExponentialBackoff, future::retry};

async fn export_with_retry(spans: Vec<Span>) -> Result<()> {
    let backoff = ExponentialBackoff {
        max_elapsed_time: Some(Duration::from_secs(60)),
        ..Default::default()
    };
    
    retry(backoff, || async {
        exporter.export(&spans).await.map_err(|e| {
            if e.is_transient() {
                backoff::Error::transient(e)  // é‡è¯•
            } else {
                backoff::Error::permanent(e)  // ä¸é‡è¯•
            }
        })
    }).await
}

// 5. Resultæ‰©å±•
pub trait ResultExt<T> {
    /// è®°å½•é”™è¯¯ä½†ä¸ä¼ æ’­
    fn log_error(self, msg: &str) -> Option<T>;
    
    /// é”™è¯¯æ—¶ä½¿ç”¨é»˜è®¤å€¼
    fn or_default(self) -> T where T: Default;
}

impl<T, E: std::fmt::Display> ResultExt<T> for Result<T, E> {
    fn log_error(self, msg: &str) -> Option<T> {
        match self {
            Ok(v) => Some(v),
            Err(e) => {
                error!("{}: {}", msg, e);
                None
            }
        }
    }
    
    fn or_default(self) -> T where T: Default {
        self.unwrap_or_default()
    }
}

// ä½¿ç”¨
let config = load_config()
    .log_error("Failed to load config, using default")
    .or_default();
```

---

## 4. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 4.1 ç³»ç»Ÿæ€§ä¼˜åŒ–æ–¹æ³•

#### å®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**: Optimization Strategy OS = (measure, analyze, optimize, verify)

**ä¼˜åŒ–å¾ªç¯**:
```
åŸºå‡†æµ‹è¯• â†’ æ€§èƒ½åˆ†æ â†’ è¯†åˆ«ç“¶é¢ˆ â†’ ä¼˜åŒ–å®æ–½ â†’ éªŒè¯æ•ˆæœ â†’ é‡å¤
```

**é€šä¿—è§£é‡Š**: æ•°æ®é©±åŠ¨çš„ç³»ç»Ÿæ€§æ€§èƒ½ä¼˜åŒ–æ–¹æ³•ã€‚

#### ç¤ºä¾‹

```rust
// è¯¦ç»†ç¤ºä¾‹è§ CONCEPTS.md ç¬¬2èŠ‚
// è¿™é‡Œä»…åˆ—å‡ºå…³é”®ç­–ç•¥

// 1. ç®—æ³•ä¼˜åŒ– (æœ€é«˜ä¼˜å…ˆçº§)
// O(nÂ²) â†’ O(n log n) â†’ O(n)

// 2. æ•°æ®ç»“æ„ä¼˜åŒ–
// Vec â†’ HashMap â†’ BTreeMap

// 3. å†…å­˜æ± åŒ–
// è§ä¸Šæ–‡å¯¹è±¡æ± ç¤ºä¾‹

// 4. æ‰¹å¤„ç†
// å•ä¸ªè¯·æ±‚ â†’ æ‰¹é‡å¤„ç†

// 5. å¹¶è¡ŒåŒ–
// ä¸²è¡Œ â†’ å¹¶è¡Œï¼ˆrayonï¼‰

// 6. ç¼“å­˜
// é‡å¤è®¡ç®— â†’ ç¼“å­˜ç»“æœ
```

---

## ğŸ”— ç›¸å…³èµ„æº

- [çŸ¥è¯†å›¾è°±](./KNOWLEDGE_GRAPH.md)
- [å¯¹æ¯”çŸ©é˜µ](./COMPARISON_MATRIX.md)
- [æŒ‡å—README](./README.md)
- [æ€§èƒ½ä¼˜åŒ–æ‰‹å†Œ](../../PERFORMANCE_OPTIMIZATION_COOKBOOK_2025.md)
- [Rustæœ€ä½³å®è·µ](https://rust-lang.github.io/api-guidelines/)

---

**ç‰ˆæœ¬**: 2.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-28  
**æœ€åæ›´æ–°**: 2025-10-28  
**ç»´æŠ¤å›¢é˜Ÿ**: OTLP_rustæŒ‡å—å›¢é˜Ÿ

---

> **ğŸ’¡ æç¤º**: æœ€ä½³å®è·µä¸æ˜¯æ­»æ¿çš„è§„åˆ™ï¼Œè€Œæ˜¯ç»è¿‡éªŒè¯çš„é«˜æ•ˆæ¨¡å¼ã€‚æ ¹æ®å®é™…åœºæ™¯çµæ´»åº”ç”¨ï¼Œå¹¶æŒç»­æµ‹é‡æ•ˆæœã€‚
