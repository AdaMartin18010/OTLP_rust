# ğŸ”¬ OTLP è®¡ç®—ä¸åˆ†ææ¨¡å‹:æ•°æ®æ£€ç´¢ã€å®šä½ä¸è®¡ç®—ç³»ç»Ÿ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ9æ—¥  
> **å¯¹æ ‡æ ‡å‡†**: OTLP v1.3.0 + PostgreSQL 17 + ClickHouse 24.x + Apache Flink 1.18  
> **ç†è®ºåŸºç¡€**: å…³ç³»ä»£æ•°ã€æ•°æ®æµè®¡ç®—ã€ç´¢å¼•ç†è®ºã€åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹

---

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

### æ ¸å¿ƒç« èŠ‚

- [ğŸ”¬ OTLP è®¡ç®—ä¸åˆ†ææ¨¡å‹:æ•°æ®æ£€ç´¢ã€å®šä½ä¸è®¡ç®—ç³»ç»Ÿ](#-otlp-è®¡ç®—ä¸åˆ†ææ¨¡å‹æ•°æ®æ£€ç´¢å®šä½ä¸è®¡ç®—ç³»ç»Ÿ)
  - [ğŸ“‹ æ–‡æ¡£å¯¼èˆª](#-æ–‡æ¡£å¯¼èˆª)
    - [æ ¸å¿ƒç« èŠ‚](#æ ¸å¿ƒç« èŠ‚)
  - [1. OTLP æ•°æ®æ£€ç´¢æ¨¡å‹](#1-otlp-æ•°æ®æ£€ç´¢æ¨¡å‹)
    - [1.1 å…³ç³»ä»£æ•°è§†è§’çš„ OTLP æŸ¥è¯¢](#11-å…³ç³»ä»£æ•°è§†è§’çš„-otlp-æŸ¥è¯¢)
      - [1.1.1 åŸºæœ¬æŸ¥è¯¢æ“ä½œå½¢å¼åŒ–](#111-åŸºæœ¬æŸ¥è¯¢æ“ä½œå½¢å¼åŒ–)
      - [1.1.2 å¤æ‚æŸ¥è¯¢è¡¨è¾¾å¼](#112-å¤æ‚æŸ¥è¯¢è¡¨è¾¾å¼)
    - [1.2 ç´¢å¼•ç­–ç•¥ä¸æŸ¥è¯¢ä¼˜åŒ–](#12-ç´¢å¼•ç­–ç•¥ä¸æŸ¥è¯¢ä¼˜åŒ–)
      - [1.2.1 å¤šç»´ç´¢å¼•æ¨¡å‹](#121-å¤šç»´ç´¢å¼•æ¨¡å‹)
      - [1.2.2 æŸ¥è¯¢ä¼˜åŒ–å™¨ä¸æ‰§è¡Œè®¡åˆ’](#122-æŸ¥è¯¢ä¼˜åŒ–å™¨ä¸æ‰§è¡Œè®¡åˆ’)
    - [1.3 åˆ—å¼å­˜å‚¨ä¸ OLAP æŸ¥è¯¢](#13-åˆ—å¼å­˜å‚¨ä¸-olap-æŸ¥è¯¢)
      - [1.3.1 ClickHouse æ•°æ®æ¨¡å‹](#131-clickhouse-æ•°æ®æ¨¡å‹)
      - [1.3.2 ClickHouse OLAP æŸ¥è¯¢ç¤ºä¾‹](#132-clickhouse-olap-æŸ¥è¯¢ç¤ºä¾‹)
      - [1.3.3 åˆ—å¼å­˜å‚¨æ€§èƒ½ä¼˜åŠ¿åˆ†æ](#133-åˆ—å¼å­˜å‚¨æ€§èƒ½ä¼˜åŠ¿åˆ†æ)
  - [2. OTLP æ•°æ®å®šä½ç³»ç»Ÿ](#2-otlp-æ•°æ®å®šä½ç³»ç»Ÿ)
    - [2.1 Trace å®šä½ä¸å¯¼èˆª](#21-trace-å®šä½ä¸å¯¼èˆª)
      - [2.1.1 TraceId ç”Ÿæˆä¸å†²çªæ¦‚ç‡](#211-traceid-ç”Ÿæˆä¸å†²çªæ¦‚ç‡)
      - [2.1.2 åŸºäº TraceId çš„å¿«é€Ÿå®šä½](#212-åŸºäº-traceid-çš„å¿«é€Ÿå®šä½)
    - [2.2 åŸºäºå±æ€§çš„å¤šç»´æ£€ç´¢](#22-åŸºäºå±æ€§çš„å¤šç»´æ£€ç´¢)
      - [2.2.1 å€’æ’ç´¢å¼•æ¨¡å‹ (Inverted Index)](#221-å€’æ’ç´¢å¼•æ¨¡å‹-inverted-index)
      - [2.2.2 PostgreSQL JSONB GIN ç´¢å¼•å®ç°](#222-postgresql-jsonb-gin-ç´¢å¼•å®ç°)
      - [2.2.3 Bitmap Index Scan (ä½å›¾ç´¢å¼•æ‰«æ)](#223-bitmap-index-scan-ä½å›¾ç´¢å¼•æ‰«æ)
    - [2.3 å…¨æ–‡æœç´¢ä¸æ¨¡ç³ŠåŒ¹é…](#23-å…¨æ–‡æœç´¢ä¸æ¨¡ç³ŠåŒ¹é…)
  - [3. OTLP è®¡ç®—æ¨¡å‹](#3-otlp-è®¡ç®—æ¨¡å‹)
    - [3.1 æ‰¹é‡è®¡ç®—æ¨¡å‹ (Batch Processing)](#31-æ‰¹é‡è®¡ç®—æ¨¡å‹-batch-processing)
      - [3.1.1 MapReduce èŒƒå¼](#311-mapreduce-èŒƒå¼)
      - [3.1.2 SQL æ‰¹é‡åˆ†æ (ClickHouse)](#312-sql-æ‰¹é‡åˆ†æ-clickhouse)
    - [3.2 æµå¼è®¡ç®—æ¨¡å‹ (Stream Processing)](#32-æµå¼è®¡ç®—æ¨¡å‹-stream-processing)
      - [3.2.1 Apache Flink å®æ—¶åˆ†æ](#321-apache-flink-å®æ—¶åˆ†æ)
      - [3.2.2 çª—å£èšåˆæ¨¡å‹](#322-çª—å£èšåˆæ¨¡å‹)
    - [3.3 å¢é‡è®¡ç®—æ¨¡å‹ (Incremental Computation)](#33-å¢é‡è®¡ç®—æ¨¡å‹-incremental-computation)
  - [4. åˆ†å¸ƒå¼è®¡ç®—æ¶æ„](#4-åˆ†å¸ƒå¼è®¡ç®—æ¶æ„)
    - [4.1 æ•°æ®åˆ†ç‰‡ä¸è´Ÿè½½å‡è¡¡](#41-æ•°æ®åˆ†ç‰‡ä¸è´Ÿè½½å‡è¡¡)
    - [4.2 ä¸€è‡´æ€§å“ˆå¸Œä¸æ•°æ®è¿ç§»](#42-ä¸€è‡´æ€§å“ˆå¸Œä¸æ•°æ®è¿ç§»)
    - [4.3 åˆ†å¸ƒå¼æŸ¥è¯¢ä¼˜åŒ–](#43-åˆ†å¸ƒå¼æŸ¥è¯¢ä¼˜åŒ–)
  - [5. æ€§èƒ½ä¼˜åŒ–ä¸è°ƒä¼˜](#5-æ€§èƒ½ä¼˜åŒ–ä¸è°ƒä¼˜)
    - [5.1 ç´¢å¼•é€‰æ‹©ä¸è°ƒä¼˜](#51-ç´¢å¼•é€‰æ‹©ä¸è°ƒä¼˜)
    - [5.2 æŸ¥è¯¢æ€§èƒ½è°ƒä¼˜](#52-æŸ¥è¯¢æ€§èƒ½è°ƒä¼˜)
    - [5.3 æ•°æ®å‹ç¼©ä¸å­˜å‚¨ä¼˜åŒ–](#53-æ•°æ®å‹ç¼©ä¸å­˜å‚¨ä¼˜åŒ–)
  - [6. æ€»ç»“ä¸æœ€ä½³å®è·µ](#6-æ€»ç»“ä¸æœ€ä½³å®è·µ)
    - [6.1 æ•°æ®æ¨¡å‹é€‰æ‹©æŒ‡å—](#61-æ•°æ®æ¨¡å‹é€‰æ‹©æŒ‡å—)
    - [6.2 æ€§èƒ½ä¼˜åŒ–æ¸…å•](#62-æ€§èƒ½ä¼˜åŒ–æ¸…å•)
    - [6.3 ç›‘æ§ä¸è°ƒä¼˜](#63-ç›‘æ§ä¸è°ƒä¼˜)
  - [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## 1. OTLP æ•°æ®æ£€ç´¢æ¨¡å‹

### 1.1 å…³ç³»ä»£æ•°è§†è§’çš„ OTLP æŸ¥è¯¢

#### 1.1.1 åŸºæœ¬æŸ¥è¯¢æ“ä½œå½¢å¼åŒ–

```text
å…³ç³»ä»£æ•°åŸºæœ¬æ“ä½œ:
===============

1. Selection (é€‰æ‹©, Ïƒ):
   Ïƒ_condition(Relation)
   
   OTLP åº”ç”¨:
   Ïƒ_(service_name='api-gateway' âˆ§ duration_ns>1000000000)(Spans)
   
   SQL ç­‰ä»·:
   SELECT * FROM otlp_spans s
   JOIN otlp_resources r ON s.resource_id = r.resource_id
   WHERE r.service_name = 'api-gateway'
     AND s.duration_ns > 1000000000;

2. Projection (æŠ•å½±, Ï€):
   Ï€_attributes(Relation)
   
   OTLP åº”ç”¨:
   Ï€_(trace_id, span_id, name, duration_ns)(Spans)
   
   SQL ç­‰ä»·:
   SELECT trace_id, span_id, name, duration_ns
   FROM otlp_spans;

3. Join (è¿æ¥, â‹ˆ):
   Relation1 â‹ˆ_condition Relation2
   
   OTLP åº”ç”¨ (çˆ¶å­ Span è¿æ¥):
   Spans â‹ˆ_(parent.span_id = child.parent_span_id) Spans
   
   SQL ç­‰ä»·:
   SELECT 
     parent.name AS parent_name,
     child.name AS child_name,
     child.duration_ns
   FROM otlp_spans parent
   JOIN otlp_spans child ON parent.span_id = child.parent_span_id
   WHERE parent.trace_id = child.trace_id;

4. Aggregation (èšåˆ, Î³):
   Î³_(grouping_attrs; aggregate_functions)(Relation)
   
   OTLP åº”ç”¨ (æŒ‰æœåŠ¡ç»Ÿè®¡ P99 å»¶è¿Ÿ):
   Î³_(service_name; PERCENTILE(0.99, duration_ns) AS p99)(Spans â‹ˆ Resources)
   
   SQL ç­‰ä»·:
   SELECT 
     r.service_name,
     PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY s.duration_ns) AS p99_latency_ns
   FROM otlp_spans s
   JOIN otlp_resources r ON s.resource_id = r.resource_id
   GROUP BY r.service_name;

5. Set Operations (é›†åˆæ“ä½œ):
   - Union (âˆª): ErrorSpans âˆª SlowSpans
   - Intersection (âˆ©): ErrorSpans âˆ© SlowSpans
   - Difference (âˆ’): AllSpans âˆ’ HealthySpans
```

#### 1.1.2 å¤æ‚æŸ¥è¯¢è¡¨è¾¾å¼

```sql
-- ç¤ºä¾‹ 1: æŸ¥è¯¢è°ƒç”¨é“¾ä¸­æœ€æ…¢çš„å­æ“ä½œ
-- å…³ç³»ä»£æ•°è¡¨è¾¾å¼:
-- Ï€_(trace_id, span_name, max_duration)(
--   Î³_(trace_id; MAX(duration_ns) AS max_duration)(
--     Ïƒ_(parent_span_id IS NOT NULL)(Spans)
--   ) â‹ˆ Spans
-- )

WITH child_spans AS (
  SELECT trace_id, span_id, name, duration_ns
  FROM otlp_spans
  WHERE parent_span_id IS NOT NULL
),
max_durations AS (
  SELECT trace_id, MAX(duration_ns) AS max_duration
  FROM child_spans
  GROUP BY trace_id
)
SELECT 
  cs.trace_id,
  cs.name AS slowest_child_span,
  cs.duration_ns / 1000000 AS duration_ms,
  md.max_duration / 1000000 AS trace_max_child_ms
FROM child_spans cs
JOIN max_durations md ON cs.trace_id = md.trace_id AND cs.duration_ns = md.max_duration
ORDER BY cs.duration_ns DESC
LIMIT 20;

-- ç¤ºä¾‹ 2: æŸ¥è¯¢æœåŠ¡ä¾èµ–å…³ç³»å›¾ (éœ€è¦é€’å½’æŸ¥è¯¢)
-- å…³ç³»ä»£æ•°æ— æ³•ç›´æ¥è¡¨è¾¾é€’å½’,éœ€è¦æ‰©å±• (Datalog æˆ– Recursive CTE)

WITH RECURSIVE service_deps AS (
  -- Base case: ç›´æ¥è°ƒç”¨
  SELECT DISTINCT
    caller_r.service_name AS caller,
    callee_r.service_name AS callee,
    1 AS depth
  FROM otlp_spans caller_s
  JOIN otlp_spans callee_s ON caller_s.span_id = callee_s.parent_span_id
  JOIN otlp_resources caller_r ON caller_s.resource_id = caller_r.resource_id
  JOIN otlp_resources callee_r ON callee_s.resource_id = callee_r.resource_id
  WHERE caller_r.service_name != callee_r.service_name
  
  UNION
  
  -- Recursive case: ä¼ é€’ä¾èµ–
  SELECT 
    sd.caller,
    callee_r.service_name AS callee,
    sd.depth + 1
  FROM service_deps sd
  JOIN otlp_spans caller_s ON caller_s.resource_id IN (
    SELECT resource_id FROM otlp_resources WHERE service_name = sd.callee
  )
  JOIN otlp_spans callee_s ON caller_s.span_id = callee_s.parent_span_id
  JOIN otlp_resources callee_r ON callee_s.resource_id = callee_r.resource_id
  WHERE callee_r.service_name != sd.callee
    AND sd.depth < 10  -- é˜²æ­¢æ— é™é€’å½’
)
SELECT caller, callee, MIN(depth) AS shortest_path
FROM service_deps
GROUP BY caller, callee
ORDER BY caller, shortest_path;

-- ç¤ºä¾‹ 3: åŸºäº JSONB çš„é«˜çº§è¿‡æ»¤
-- æŸ¥è¯¢æ‰€æœ‰ HTTP 500 é”™è¯¯,ä¸”åŒ…å«ç‰¹å®š user_id

-- å…³ç³»ä»£æ•° + åŠç»“æ„åŒ–æ•°æ®æŸ¥è¯¢:
-- Ïƒ_(attributes @> '{"http.status_code": 500}' âˆ§ 
--    attributes->>'user.id' = '123456')(Spans)

SELECT 
  s.trace_id,
  s.span_id,
  s.name,
  s.start_time_ns,
  s.attributes->>'http.method' AS http_method,
  s.attributes->>'http.route' AS http_route,
  s.attributes->>'user.id' AS user_id,
  s.status_message
FROM otlp_spans s
WHERE s.attributes @> '{"http.status_code": "500"}'::jsonb
  AND s.attributes->>'user.id' = '123456'
  AND s.start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '24 hours') * 1000000000)::BIGINT
ORDER BY s.start_time_ns DESC;
```

### 1.2 ç´¢å¼•ç­–ç•¥ä¸æŸ¥è¯¢ä¼˜åŒ–

#### 1.2.1 å¤šç»´ç´¢å¼•æ¨¡å‹

```sql
-- OTLP æ•°æ®çš„å¤šç»´åº¦ç´¢å¼•ç­–ç•¥

-- 1. ä¸»é”®ç´¢å¼• (Primary Key Index)
-- ä½œç”¨: å”¯ä¸€æ ‡è¯† Span
CREATE UNIQUE INDEX pk_spans ON otlp_spans(span_id);

-- 2. Trace èšåˆç´¢å¼• (Clustering Index)
-- ä½œç”¨: åŒä¸€ Trace çš„æ‰€æœ‰ Span ç‰©ç†ç›¸é‚»,åŠ é€Ÿ Trace æŸ¥è¯¢
CREATE INDEX idx_spans_trace_clustered ON otlp_spans(trace_id, start_time_ns)
  INCLUDE (span_id, parent_span_id, name, duration_ns, status_code);
-- å¯é€‰: ç‰©ç†æ’åº (PostgreSQL 15+)
CLUSTER otlp_spans USING idx_spans_trace_clustered;

-- 3. æ—¶é—´èŒƒå›´ç´¢å¼• (Time Range Index)
-- ä½œç”¨: æ”¯æŒé«˜æ•ˆçš„æ—¶é—´èŒƒå›´æŸ¥è¯¢ (æœ€å¸¸è§æŸ¥è¯¢åœºæ™¯)
CREATE INDEX idx_spans_time_desc ON otlp_spans(start_time_ns DESC);
-- ä½¿ç”¨ BRIN ç´¢å¼• (Block Range Index) ä¼˜åŒ–å¤§è¡¨
CREATE INDEX idx_spans_time_brin ON otlp_spans USING BRIN(start_time_ns)
  WITH (pages_per_range = 128);

-- 4. æœåŠ¡ç»´åº¦ç´¢å¼• (Resource Index)
-- ä½œç”¨: æŒ‰æœåŠ¡è¿‡æ»¤
CREATE INDEX idx_spans_resource_time ON otlp_spans(resource_id, start_time_ns DESC);

-- 5. çŠ¶æ€ç ç´¢å¼• (Partial Index for Errors)
-- ä½œç”¨: å¿«é€ŸæŸ¥è¯¢é”™è¯¯ Span (é”™è¯¯ç‡é€šå¸¸ < 1%,éƒ¨åˆ†ç´¢å¼•èŠ‚çœç©ºé—´)
CREATE INDEX idx_spans_errors ON otlp_spans(status_code, start_time_ns DESC)
  WHERE status_code = 2;

-- 6. çˆ¶å­å…³ç³»ç´¢å¼• (Parent-Child Index)
-- ä½œç”¨: é€’å½’æŸ¥è¯¢è°ƒç”¨æ ‘
CREATE INDEX idx_spans_parent ON otlp_spans(parent_span_id, trace_id)
  WHERE parent_span_id IS NOT NULL;

-- 7. JSONB GIN ç´¢å¼• (Attribute Index)
-- ä½œç”¨: æ”¯æŒçµæ´»çš„å±æ€§æŸ¥è¯¢
CREATE INDEX idx_spans_attributes_gin ON otlp_spans USING GIN(attributes);
-- ä¼˜åŒ–ç‰¹å®šå±æ€§æŸ¥è¯¢ (è¡¨è¾¾å¼ç´¢å¼•)
CREATE INDEX idx_spans_http_status ON otlp_spans((attributes->>'http.status_code'))
  WHERE attributes ? 'http.status_code';
CREATE INDEX idx_spans_user_id ON otlp_spans((attributes->>'user.id'))
  WHERE attributes ? 'user.id';

-- 8. å…¨æ–‡æœç´¢ç´¢å¼• (é’ˆå¯¹ Span name å’Œ status_message)
CREATE INDEX idx_spans_name_fts ON otlp_spans USING GIN(to_tsvector('english', name));
CREATE INDEX idx_spans_status_msg_fts ON otlp_spans USING GIN(to_tsvector('english', status_message))
  WHERE status_message IS NOT NULL;

-- 9. è¦†ç›–ç´¢å¼• (Covering Index)
-- ä½œç”¨: åªè®¿é—®ç´¢å¼•å³å¯è¿”å›ç»“æœ,é¿å…å›è¡¨
CREATE INDEX idx_spans_covering_summary ON otlp_spans(
  trace_id, start_time_ns
) INCLUDE (
  span_id, parent_span_id, name, duration_ns, status_code, resource_id
);
```

#### 1.2.2 æŸ¥è¯¢ä¼˜åŒ–å™¨ä¸æ‰§è¡Œè®¡åˆ’

```sql
-- ç¤ºä¾‹æŸ¥è¯¢: æŸ¥è¯¢æœ€è¿‘ 1 å°æ—¶æ‰€æœ‰æœåŠ¡çš„ P99 å»¶è¿Ÿ

-- æŸ¥è¯¢è¯­å¥
EXPLAIN (ANALYZE, BUFFERS, VERBOSE, FORMAT JSON)
SELECT 
  r.service_name,
  COUNT(*) AS request_count,
  AVG(s.duration_ns) / 1000000 AS avg_latency_ms,
  PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY s.duration_ns) / 1000000 AS p99_latency_ms,
  SUM(CASE WHEN s.status_code = 2 THEN 1 ELSE 0 END) AS error_count
FROM otlp_spans s
JOIN otlp_resources r ON s.resource_id = r.resource_id
WHERE s.start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '1 hour') * 1000000000)::BIGINT
  AND s.kind IN (1, 2)  -- SERVER or CLIENT
GROUP BY r.service_name
ORDER BY p99_latency_ms DESC;

-- ä¼˜åŒ–åçš„æ‰§è¡Œè®¡åˆ’ (é¢„æœŸ):
/*
[
  {
    "Plan": {
      "Node Type": "Sort",
      "Sort Key": ["p99_latency_ms DESC"],
      "Plans": [
        {
          "Node Type": "HashAggregate",
          "Group Key": ["r.service_name"],
          "Plans": [
            {
              "Node Type": "Hash Join",
              "Join Type": "Inner",
              "Hash Cond": "(s.resource_id = r.resource_id)",
              "Plans": [
                {
                  "Node Type": "Index Scan",
                  "Index Name": "idx_spans_time_desc",
                  "Index Cond": "(start_time_ns >= ...)",
                  "Filter": "(kind = ANY ('{1,2}'::integer[]))",
                  "Rows": 1000000,
                  "Shared Hit Blocks": 5000  -- ç´¢å¼•ç¼“å­˜å‘½ä¸­
                },
                {
                  "Node Type": "Hash",
                  "Plans": [
                    {
                      "Node Type": "Seq Scan",
                      "Relation Name": "otlp_resources",
                      "Rows": 100
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    },
    "Execution Time": 235.12  // ms
  }
]
*/

-- ä¼˜åŒ–æŠ€å·§åˆ†æ:
-- ===============

-- 1. åˆ©ç”¨æ—¶é—´ç´¢å¼• (idx_spans_time_desc)
-- é¿å…å…¨è¡¨æ‰«æ,åªæ‰«ææœ€è¿‘ 1 å°æ—¶çš„æ•°æ®

-- 2. å“ˆå¸Œè¿æ¥ (Hash Join)
-- otlp_resources è¡¨è¾ƒå° (é€šå¸¸ < 1000 è¡Œ),æ„å»ºå“ˆå¸Œè¡¨æˆæœ¬ä½

-- 3. éƒ¨åˆ†èšåˆ (Partial Aggregation)
-- PostgreSQL å¯èƒ½ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢,å…ˆåœ¨æ¯ä¸ª worker ä¸­éƒ¨åˆ†èšåˆ,å†åˆå¹¶

-- 4. åˆ—å¼è®¿é—® (Columnar Access)
-- å¦‚æœä½¿ç”¨ Citus æˆ– TimescaleDB çš„åˆ—å¼å‹ç¼©,åªè¯»å–éœ€è¦çš„åˆ—:
--   - resource_id, start_time_ns, duration_ns, status_code, kind
-- ä¸è¯»å–:
--   - attributes (JSONB, é€šå¸¸å¾ˆå¤§)
--   - name, trace_id, span_id (ä¸éœ€è¦)

-- 5. ç‰©åŒ–è§†å›¾åŠ é€Ÿ (Materialized View)
-- å¯¹äºé¢‘ç¹æŸ¥è¯¢,å¯ä»¥é¢„èšåˆ
CREATE MATERIALIZED VIEW otlp_service_latency_hourly AS
SELECT 
  time_bucket('1 hour', to_timestamp(s.start_time_ns / 1000000000.0)) AS time_hour,
  r.service_name,
  COUNT(*) AS request_count,
  AVG(s.duration_ns) AS avg_latency_ns,
  PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY s.duration_ns) AS p50_latency_ns,
  PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY s.duration_ns) AS p99_latency_ns,
  SUM(CASE WHEN s.status_code = 2 THEN 1 ELSE 0 END) AS error_count
FROM otlp_spans s
JOIN otlp_resources r ON s.resource_id = r.resource_id
WHERE s.kind IN (1, 2)
GROUP BY time_hour, r.service_name;

CREATE INDEX idx_mv_service_latency ON otlp_service_latency_hourly(time_hour DESC, service_name);

-- åˆ·æ–°ç­–ç•¥: æ¯å°æ—¶å¢é‡åˆ·æ–°
CREATE OR REPLACE FUNCTION refresh_service_latency_hourly()
RETURNS void AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY otlp_service_latency_hourly;
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶ä»»åŠ¡ (ä½¿ç”¨ pg_cron)
SELECT cron.schedule('refresh_service_latency', '0 * * * *', 
  'SELECT refresh_service_latency_hourly()');
```

### 1.3 åˆ—å¼å­˜å‚¨ä¸ OLAP æŸ¥è¯¢

#### 1.3.1 ClickHouse æ•°æ®æ¨¡å‹

```sql
-- ClickHouse è¡¨ç»“æ„è®¾è®¡ (é’ˆå¯¹ OTLP Span æ•°æ®)

CREATE TABLE otlp_spans_clickhouse (
  -- æ—¶é—´ç»´åº¦ (æ’åºé”®çš„ç¬¬ä¸€åˆ—,æ”¯æŒé«˜æ•ˆæ—¶é—´èŒƒå›´æŸ¥è¯¢)
  start_time DateTime64(9, 'UTC') CODEC(Delta, ZSTD(1)),
  end_time DateTime64(9, 'UTC') CODEC(Delta, ZSTD(1)),
  duration_ns UInt64 CODEC(Gorilla, ZSTD(1)),
  
  -- æ ‡è¯†ç¬¦
  trace_id FixedString(16) CODEC(ZSTD(1)),
  span_id FixedString(8) CODEC(ZSTD(1)),
  parent_span_id FixedString(8) CODEC(ZSTD(1)),
  
  -- èµ„æºç»´åº¦
  service_name LowCardinality(String) CODEC(ZSTD(1)),
  service_version LowCardinality(String) CODEC(ZSTD(1)),
  deployment_environment LowCardinality(String) CODEC(ZSTD(1)),
  host_name LowCardinality(String) CODEC(ZSTD(1)),
  
  -- Span å±æ€§
  span_name String CODEC(ZSTD(1)),
  span_kind Enum8(
    'UNSPECIFIED' = 0,
    'INTERNAL' = 1,
    'SERVER' = 2,
    'CLIENT' = 3,
    'PRODUCER' = 4,
    'CONSUMER' = 5
  ) CODEC(ZSTD(1)),
  status_code Enum8('UNSET' = 0, 'OK' = 1, 'ERROR' = 2) CODEC(ZSTD(1)),
  status_message String CODEC(ZSTD(1)),
  
  -- åŠ¨æ€å±æ€§ (Map ç±»å‹)
  attributes Map(String, String) CODEC(ZSTD(1)),
  
  -- æ€§èƒ½å­—æ®µ
  is_error UInt8 MATERIALIZED if(status_code = 'ERROR', 1, 0),
  is_root UInt8 MATERIALIZED if(parent_span_id = '\0\0\0\0\0\0\0\0', 1, 0),
  duration_ms Float64 MATERIALIZED duration_ns / 1000000.0
  
) ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(start_time)  -- æŒ‰å¤©åˆ†åŒº
ORDER BY (service_name, start_time, trace_id, span_id)  -- æ’åºé”® (å‹ç¼© + æŸ¥è¯¢ä¼˜åŒ–)
TTL start_time + INTERVAL 30 DAY DELETE  -- è‡ªåŠ¨åˆ é™¤ 30 å¤©å‰çš„æ•°æ®
SETTINGS 
  index_granularity = 8192,
  storage_policy = 'hot_cold_storage';  -- çƒ­å†·åˆ†å±‚å­˜å‚¨

-- äºŒçº§ç´¢å¼• (Data Skipping Indexes)
-- 1. Bloom Filter ç´¢å¼•: å¿«é€Ÿåˆ¤æ–­ trace_id æ˜¯å¦å­˜åœ¨
ALTER TABLE otlp_spans_clickhouse 
  ADD INDEX idx_trace_id_bloom trace_id TYPE bloom_filter GRANULARITY 4;

-- 2. MinMax ç´¢å¼•: åŠ é€Ÿæ•°å€¼èŒƒå›´æŸ¥è¯¢
ALTER TABLE otlp_spans_clickhouse 
  ADD INDEX idx_duration_minmax duration_ns TYPE minmax GRANULARITY 4;

-- 3. Set ç´¢å¼•: åŠ é€Ÿä½åŸºæ•°åˆ—çš„ IN æŸ¥è¯¢
ALTER TABLE otlp_spans_clickhouse 
  ADD INDEX idx_status_set status_code TYPE set(100) GRANULARITY 4;

-- ç‰©åŒ–åˆ—ç´¢å¼•: åŠ é€Ÿå±æ€§æŸ¥è¯¢
ALTER TABLE otlp_spans_clickhouse 
  ADD INDEX idx_http_status (attributes['http.status_code']) TYPE set(0) GRANULARITY 4;
```

#### 1.3.2 ClickHouse OLAP æŸ¥è¯¢ç¤ºä¾‹

```sql
-- Q1: é«˜æ€§èƒ½èšåˆæŸ¥è¯¢ (P50/P95/P99 å»¶è¿Ÿ)
SELECT 
  service_name,
  toStartOfHour(start_time) AS time_hour,
  count() AS request_count,
  avg(duration_ms) AS avg_latency_ms,
  quantile(0.50)(duration_ms) AS p50_latency_ms,
  quantile(0.95)(duration_ms) AS p95_latency_ms,
  quantile(0.99)(duration_ms) AS p99_latency_ms,
  countIf(is_error = 1) AS error_count,
  error_count / request_count * 100 AS error_rate_pct
FROM otlp_spans_clickhouse
WHERE start_time >= now() - INTERVAL 24 HOUR
  AND span_kind IN ('SERVER', 'CLIENT')
GROUP BY service_name, time_hour
ORDER BY time_hour DESC, p99_latency_ms DESC
LIMIT 100;

-- Q2: æœåŠ¡ä¾èµ–å…³ç³»åˆ†æ (é«˜æ•ˆ JOIN)
SELECT 
  parent.service_name AS caller_service,
  child.service_name AS callee_service,
  count() AS call_count,
  avg(child.duration_ms) AS avg_latency_ms,
  quantile(0.99)(child.duration_ms) AS p99_latency_ms,
  countIf(child.is_error = 1) AS error_count
FROM otlp_spans_clickhouse AS child
INNER JOIN otlp_spans_clickhouse AS parent 
  ON child.parent_span_id = parent.span_id 
  AND child.trace_id = parent.trace_id
WHERE child.start_time >= now() - INTERVAL 1 HOUR
  AND parent.service_name != child.service_name
GROUP BY caller_service, callee_service
ORDER BY call_count DESC
LIMIT 50;

-- Q3: åŸºäº Map ç±»å‹çš„å±æ€§è¿‡æ»¤
SELECT 
  service_name,
  attributes['http.route'] AS http_route,
  attributes['http.method'] AS http_method,
  count() AS request_count,
  quantile(0.99)(duration_ms) AS p99_latency_ms
FROM otlp_spans_clickhouse
WHERE start_time >= now() - INTERVAL 1 HOUR
  AND attributes['http.status_code'] >= '500'  -- Map å€¼éƒ½æ˜¯ String
  AND span_kind = 'SERVER'
GROUP BY service_name, http_route, http_method
HAVING request_count > 10
ORDER BY p99_latency_ms DESC
LIMIT 20;

-- Q4: çª—å£å‡½æ•° + Trace åˆ†æ
SELECT 
  trace_id,
  span_name,
  duration_ms,
  -- è®¡ç®—æ¯ä¸ª Span å æ•´ä¸ª Trace çš„ç™¾åˆ†æ¯”
  duration_ms / sum(duration_ms) OVER (PARTITION BY trace_id) * 100 AS pct_of_trace,
  -- åŒä¸€ Trace å†…æŒ‰æ—¶é—´æ’åº
  row_number() OVER (PARTITION BY trace_id ORDER BY start_time) AS span_seq,
  -- Trace çš„æ€»å»¶è¿Ÿ
  sum(duration_ms) OVER (PARTITION BY trace_id) AS total_trace_duration
FROM otlp_spans_clickhouse
WHERE start_time >= now() - INTERVAL 1 HOUR
  AND is_root = 0  -- æ’é™¤ Root Span
  AND trace_id IN (
    -- æ‰¾å‡ºæœ€æ…¢çš„ 10 ä¸ª Trace
    SELECT trace_id
    FROM (
      SELECT trace_id, max(end_time) - min(start_time) AS trace_duration
      FROM otlp_spans_clickhouse
      WHERE start_time >= now() - INTERVAL 1 HOUR
      GROUP BY trace_id
      ORDER BY trace_duration DESC
      LIMIT 10
    )
  )
ORDER BY trace_id, span_seq;

-- Q5: æ—¶åºåˆ†æ + å¼‚å¸¸æ£€æµ‹ (ç§»åŠ¨å¹³å‡)
SELECT 
  service_name,
  toStartOfMinute(start_time) AS time_minute,
  count() AS request_count,
  avg(duration_ms) AS avg_latency,
  -- è®¡ç®— 5 åˆ†é’Ÿç§»åŠ¨å¹³å‡
  avg(avg_latency) OVER (
    PARTITION BY service_name 
    ORDER BY time_minute 
    ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
  ) AS moving_avg_5min,
  -- æ£€æµ‹å¼‚å¸¸ (å½“å‰å€¼ > ç§»åŠ¨å¹³å‡ * 2)
  if(avg_latency > moving_avg_5min * 2, 1, 0) AS is_anomaly
FROM otlp_spans_clickhouse
WHERE start_time >= now() - INTERVAL 2 HOUR
  AND span_kind = 'SERVER'
GROUP BY service_name, time_minute
ORDER BY service_name, time_minute DESC;
```

#### 1.3.3 åˆ—å¼å­˜å‚¨æ€§èƒ½ä¼˜åŠ¿åˆ†æ

```text
åˆ—å¼ vs è¡Œå¼å­˜å‚¨æ€§èƒ½å¯¹æ¯”:
=======================

åœºæ™¯ 1: èšåˆæŸ¥è¯¢ (SELECT AVG(duration_ns), COUNT(*) ...)
-------------------------------------------------------
è¡Œå¼å­˜å‚¨ (PostgreSQL):
  - éœ€è¦è¯»å–æ•´è¡Œæ•°æ® (åŒ…æ‹¬ä¸éœ€è¦çš„åˆ—: attributes, name, trace_id...)
  - I/O é‡: å‡è®¾æ¯è¡Œ 1KB, 100M è¡Œ = 100GB
  - æŸ¥è¯¢æ—¶é—´: ~30-60ç§’ (å³ä½¿æœ‰ç´¢å¼•)

åˆ—å¼å­˜å‚¨ (ClickHouse):
  - åªè¯»å–éœ€è¦çš„åˆ—: duration_ns (8 bytes), status_code (1 byte)
  - å‹ç¼©ç‡: ~10x (Delta + Gorilla + ZSTD)
  - I/O é‡: 100M * 9 bytes / 10 = 90MB
  - æŸ¥è¯¢æ—¶é—´: ~1-3ç§’

æ€§èƒ½æå‡: **10-30x**

åœºæ™¯ 2: æ—¶é—´èŒƒå›´è¿‡æ»¤ + åˆ†ç»„èšåˆ
---------------------------
è¡Œå¼å­˜å‚¨:
  - é€šè¿‡æ—¶é—´ç´¢å¼•å¿«é€Ÿå®šä½è¡ŒèŒƒå›´
  - ä½†ä»éœ€è¯»å–å®Œæ•´è¡Œæ•°æ®è¿›è¡Œèšåˆ
  - æŸ¥è¯¢æ—¶é—´: ~10-20ç§’

åˆ—å¼å­˜å‚¨:
  - æ•°æ®æŒ‰ (service_name, start_time) æ’åº
  - åŒä¸€æœåŠ¡çš„æ•°æ®ç‰©ç†ç›¸é‚»,å‡å°‘éšæœº I/O
  - å‘é‡åŒ–æ‰§è¡Œ (SIMD): æ¯æ¬¡å¤„ç†å¤šä¸ªå€¼
  - æŸ¥è¯¢æ—¶é—´: ~0.5-2ç§’

æ€§èƒ½æå‡: **5-20x**

åœºæ™¯ 3: å…¨è¡¨æ‰«æ (æ— ç´¢å¼•)
-----------------------
è¡Œå¼å­˜å‚¨:
  - å¿…é¡»è¯»å–æ‰€æœ‰æ•°æ®
  - æŸ¥è¯¢æ—¶é—´: ~2-5åˆ†é’Ÿ (100GB æ•°æ®)

åˆ—å¼å­˜å‚¨:
  - åˆ©ç”¨ Data Skipping Indexes (MinMax, BloomFilter)
  - è·³è¿‡ä¸ç¬¦åˆæ¡ä»¶çš„ Granule (é»˜è®¤ 8192 è¡Œ)
  - å¹¶è¡ŒæŸ¥è¯¢: åˆ©ç”¨å¤šæ ¸ CPU
  - æŸ¥è¯¢æ—¶é—´: ~10-30ç§’

æ€§èƒ½æå‡: **5-15x**

å­˜å‚¨æˆæœ¬å¯¹æ¯”:
===========

è¡Œå¼å­˜å‚¨ (PostgreSQL + JSONB):
  - åŸå§‹æ•°æ®å¤§å°: ~1KB/span
  - å‹ç¼©ç‡: ~3x (TOAST å‹ç¼©)
  - ç´¢å¼•å¼€é”€: ~30-50% (å¤šä¸ª B-tree + GIN ç´¢å¼•)
  - æ€»å­˜å‚¨: 1KB / 3 * 1.4 â‰ˆ 467 bytes/span

åˆ—å¼å­˜å‚¨ (ClickHouse):
  - åŸå§‹æ•°æ®å¤§å°: ~1KB/span
  - å‹ç¼©ç‡: ~10x (Delta + Gorilla + ZSTD)
  - ç´¢å¼•å¼€é”€: ~5-10% (Sparse Index + Data Skipping)
  - æ€»å­˜å‚¨: 1KB / 10 * 1.08 â‰ˆ 108 bytes/span

å­˜å‚¨èŠ‚çœ: **75%**
```

---

## 2. OTLP æ•°æ®å®šä½ç³»ç»Ÿ

### 2.1 Trace å®šä½ä¸å¯¼èˆª

#### 2.1.1 TraceId ç”Ÿæˆä¸å†²çªæ¦‚ç‡

```text
TraceId ç”Ÿæˆç®—æ³•åˆ†æ:
===================

æ ‡å‡†: W3C Trace Context
æ ¼å¼: 128-bit éšæœºæ•° (16 bytes)
è¡¨ç¤º: 32 ä¸ªåå…­è¿›åˆ¶å­—ç¬¦

ç”Ÿæˆæ–¹æ³•:
  - æ–¹æ³• 1: UUID v4 (ä¼ªéšæœº)
  - æ–¹æ³• 2: Secure Random (å¯†ç å­¦å®‰å…¨éšæœºæ•°)
  - æ–¹æ³• 3: æ—¶é—´æˆ³ + éšæœºæ•° æ··åˆ (Twitter Snowflake å˜ä½“)

å†²çªæ¦‚ç‡åˆ†æ (ç”Ÿæ—¥æ‚–è®º):
=====================

å‡è®¾å·²ç”Ÿæˆ n ä¸ª TraceId, ç”Ÿæˆç¬¬ (n+1) ä¸ªæ—¶å‘ç”Ÿå†²çªçš„æ¦‚ç‡:
  P(å†²çª) â‰ˆ 1 - e^(-nÂ²/(2 * 2^128))

å…·ä½“è®¡ç®—:
  n = 10^9  (10 äº¿ Trace):  P â‰ˆ 1.47 Ã— 10^-21  (å‡ ä¹ä¸º 0)
  n = 10^12 (1 ä¸‡äº¿ Trace): P â‰ˆ 1.47 Ã— 10^-15  (ä»ç„¶æå°)
  n = 10^15 (1 åƒä¸‡äº¿):     P â‰ˆ 1.47 Ã— 10^-9   (åäº¿åˆ†ä¹‹ä¸€)

ç»“è®º: åœ¨å®é™…åº”ç”¨ä¸­ (< 10^12 Trace), TraceId å†²çªæ¦‚ç‡å¯å¿½ç•¥ä¸è®¡
```

#### 2.1.2 åŸºäº TraceId çš„å¿«é€Ÿå®šä½

```sql
-- PostgreSQL å®ç°

-- æ–¹æ³• 1: ä¸»é”®æŸ¥è¯¢ (O(log n) å¤æ‚åº¦)
SELECT * FROM otlp_spans
WHERE trace_id = decode('0af7651916cd43dd8448eb211c80319c', 'hex');

-- æ‰§è¡Œè®¡åˆ’:
-- Index Scan using idx_spans_trace_clustered on otlp_spans
--   Index Cond: (trace_id = '\x0af7651916cd43dd8448eb211c80319c'::bytea)
-- Planning Time: 0.05 ms
-- Execution Time: 0.12 ms  (æå¿«)

-- æ–¹æ³• 2: Bloom Filter ç´¢å¼• (ClickHouse)
SELECT * FROM otlp_spans_clickhouse
WHERE trace_id = unhex('0af7651916cd43dd8448eb211c80319c');

-- ClickHouse æ‰§è¡Œæµç¨‹:
-- 1. æ£€æŸ¥ Bloom Filter ç´¢å¼• (æ¯ä¸ª Granule 4096 è¡Œ)
-- 2. è·³è¿‡ä¸åŒ…å«è¯¥ trace_id çš„ Granule (99.9% çš„æ•°æ®å—)
-- 3. åªæ‰«æå¯èƒ½åŒ…å«çš„ Granule (~1-2 ä¸ª)
-- Planning Time: 0.01 ms
-- Execution Time: 0.05 ms  (æ›´å¿«)

-- æ–¹æ³• 3: åˆ†å¸ƒå¼æŸ¥è¯¢ (Span å¯èƒ½åˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹)
-- ä½¿ç”¨ Distributed Table (ClickHouse)
CREATE TABLE otlp_spans_distributed AS otlp_spans_clickhouse
ENGINE = Distributed(cluster_name, database_name, otlp_spans_clickhouse, rand());

-- æŸ¥è¯¢è‡ªåŠ¨è·¯ç”±åˆ°æ‰€æœ‰èŠ‚ç‚¹,å¹¶è¡Œæ‰§è¡Œ
SELECT * FROM otlp_spans_distributed
WHERE trace_id = unhex('0af7651916cd43dd8448eb211c80319c');

-- æ‰§è¡Œæ—¶é—´: ~0.1-0.5 ms (å–å†³äºç½‘ç»œå»¶è¿Ÿå’Œæ•°æ®åˆ†å¸ƒ)
```

### 2.2 åŸºäºå±æ€§çš„å¤šç»´æ£€ç´¢

#### 2.2.1 å€’æ’ç´¢å¼•æ¨¡å‹ (Inverted Index)

```text
ç±»æ¯” Elasticsearch çš„å€’æ’ç´¢å¼•:
============================

æ­£æ’ç´¢å¼• (Forward Index):
  Span1: {service.name: "api-gateway", http.method: "GET", http.status_code: 200}
  Span2: {service.name: "user-service", http.method: "POST", http.status_code: 500}
  Span3: {service.name: "api-gateway", http.method: "POST", http.status_code: 201}

å€’æ’ç´¢å¼• (Inverted Index):
  service.name = "api-gateway" â†’ [Span1, Span3]
  service.name = "user-service" â†’ [Span2]
  http.method = "GET" â†’ [Span1]
  http.method = "POST" â†’ [Span2, Span3]
  http.status_code = 200 â†’ [Span1]
  http.status_code = 500 â†’ [Span2]
  http.status_code = 201 â†’ [Span3]

æŸ¥è¯¢ç¤ºä¾‹: service.name = "api-gateway" AND http.method = "POST"
æ­¥éª¤:
  1. æŸ¥æ‰¾ service.name = "api-gateway" â†’ [Span1, Span3]
  2. æŸ¥æ‰¾ http.method = "POST" â†’ [Span2, Span3]
  3. æ±‚äº¤é›†: [Span1, Span3] âˆ© [Span2, Span3] = [Span3]

æ—¶é—´å¤æ‚åº¦: O(k1 + k2 + k1 log k2)  (k1, k2 æ˜¯ç»“æœé›†å¤§å°)
```

#### 2.2.2 PostgreSQL JSONB GIN ç´¢å¼•å®ç°

```sql
-- GIN (Generalized Inverted Index) ç´¢å¼•

CREATE INDEX idx_spans_attributes_gin ON otlp_spans USING GIN(attributes);

-- ç´¢å¼•å†…éƒ¨ç»“æ„ (ç®€åŒ–):
-- =====================
-- Key: "service.name" â†’ Value: "api-gateway" â†’ Posting List: [span_id1, span_id3, ...]
-- Key: "http.method" â†’ Value: "GET" â†’ Posting List: [span_id1, span_id5, ...]
-- Key: "http.status_code" â†’ Value: "500" â†’ Posting List: [span_id2, span_id7, ...]

-- æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:

-- 1. åŒ…å«æŸ¥è¯¢ (@>)
SELECT * FROM otlp_spans
WHERE attributes @> '{"http.method": "POST", "http.status_code": "500"}'::jsonb;

-- GIN ç´¢å¼•æ‰§è¡Œ:
--   1. æŸ¥æ‰¾ http.method=POST â†’ Posting List A
--   2. æŸ¥æ‰¾ http.status_code=500 â†’ Posting List B
--   3. æ±‚äº¤é›†: A âˆ© B
--   4. å›è¡¨è·å–å®Œæ•´è¡Œ

-- 2. é”®å­˜åœ¨æŸ¥è¯¢ (?)
SELECT * FROM otlp_spans
WHERE attributes ? 'user.id';

-- 3. ä»»æ„é”®å­˜åœ¨æŸ¥è¯¢ (?|)
SELECT * FROM otlp_spans
WHERE attributes ?| ARRAY['error.type', 'exception.type'];

-- 4. æ‰€æœ‰é”®å­˜åœ¨æŸ¥è¯¢ (?&)
SELECT * FROM otlp_spans
WHERE attributes ?& ARRAY['user.id', 'session.id'];

-- 5. è·¯å¾„æå–æŸ¥è¯¢ (->>, #>)
SELECT * FROM otlp_spans
WHERE attributes->>'http.route' = '/api/v1/users/:id';

-- æ³¨æ„: ->> æ“ä½œç¬¦ä¸èƒ½ç›´æ¥ä½¿ç”¨ GIN ç´¢å¼•,éœ€è¦è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_spans_http_route ON otlp_spans((attributes->>'http.route'));

-- æ€§èƒ½å¯¹æ¯”:
-- ========

-- æ— ç´¢å¼• (å…¨è¡¨æ‰«æ):
-- Planning Time: 0.1 ms
-- Execution Time: 5000 ms  (æ‰«æ 1000 ä¸‡è¡Œ)

-- ä½¿ç”¨ GIN ç´¢å¼•:
-- Planning Time: 0.5 ms
-- Execution Time: 10 ms  (åªæ‰«æåŒ¹é…çš„ 1000 è¡Œ)

-- æ€§èƒ½æå‡: **500x**
```

#### 2.2.3 Bitmap Index Scan (ä½å›¾ç´¢å¼•æ‰«æ)

```sql
-- å¤šæ¡ä»¶æŸ¥è¯¢ä¼˜åŒ– (PostgreSQL è‡ªåŠ¨ä¼˜åŒ–)

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM otlp_spans
WHERE resource_id = '123e4567-e89b-12d3-a456-426614174000'
  AND start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '1 hour') * 1000000000)::BIGINT
  AND status_code = 2
  AND attributes @> '{"http.status_code": "500"}'::jsonb;

-- æ‰§è¡Œè®¡åˆ’ (ä¼˜åŒ–å):
/*
Bitmap Heap Scan on otlp_spans
  Recheck Cond: (resource_id = '...' AND start_time_ns >= ... AND status_code = 2)
  Filter: (attributes @> '{"http.status_code": "500"}'::jsonb)
  ->  BitmapAnd
        ->  Bitmap Index Scan on idx_spans_resource_time
              Index Cond: (resource_id = '...' AND start_time_ns >= ...)
        ->  Bitmap Index Scan on idx_spans_errors
              Index Cond: (status_code = 2)
        ->  Bitmap Index Scan on idx_spans_attributes_gin
              Index Cond: (attributes @> '{"http.status_code": "500"}'::jsonb)
*/

-- Bitmap Index Scan å·¥ä½œåŸç†:
-- ==========================
-- 1. åˆ†åˆ«æ‰«æ 3 ä¸ªç´¢å¼•,ç”Ÿæˆ 3 ä¸ª Bitmap (ä½å›¾)
--    Bitmap1: resource_id + time æ¡ä»¶åŒ¹é…çš„ Span (ä¾‹å¦‚ 10,000 è¡Œ)
--    Bitmap2: status_code = 2 çš„ Span (ä¾‹å¦‚ 5,000 è¡Œ)
--    Bitmap3: attributes æ¡ä»¶åŒ¹é…çš„ Span (ä¾‹å¦‚ 8,000 è¡Œ)
-- 
-- 2. å¯¹ 3 ä¸ª Bitmap è¿›è¡Œ AND æ“ä½œ (ä½ä¸)
--    Result Bitmap: åŒæ—¶æ»¡è¶³ 3 ä¸ªæ¡ä»¶çš„ Span (ä¾‹å¦‚ 100 è¡Œ)
-- 
-- 3. æŒ‰ç…§ Bitmap é¡ºåºå›è¡¨ (Bitmap Heap Scan)
--    ä¼˜åŠ¿: é¡ºåº I/O,è€Œééšæœº I/O (æ›´é«˜æ•ˆ)

-- æ€§èƒ½åˆ†æ:
-- ========
-- æ¡ä»¶ 1 åŒ¹é…: 10,000 è¡Œ
-- æ¡ä»¶ 2 åŒ¹é…: 5,000 è¡Œ
-- æ¡ä»¶ 3 åŒ¹é…: 8,000 è¡Œ
-- æœ€ç»ˆç»“æœ: 100 è¡Œ

-- å¦‚æœåˆ†åˆ«æŸ¥è¯¢å†åˆå¹¶:
--   æˆæœ¬ = 10,000 + 5,000 + 8,000 = 23,000 æ¬¡ç´¢å¼•æŸ¥æ‰¾ + å›è¡¨

-- ä½¿ç”¨ Bitmap Index Scan:
--   æˆæœ¬ = 3 æ¬¡ä½å›¾ç”Ÿæˆ + 1 æ¬¡ä½ä¸ + 100 æ¬¡å›è¡¨
--   èŠ‚çœ: ~99% çš„ I/O
```

### 2.3 å…¨æ–‡æœç´¢ä¸æ¨¡ç³ŠåŒ¹é…

```sql
-- åœºæ™¯: æœç´¢åŒ…å« "connection timeout" çš„é”™è¯¯æ—¥å¿—å’Œ Span

-- æ–¹æ³• 1: PostgreSQL å…¨æ–‡æœç´¢ (FTS)

-- 1.1 åˆ›å»º tsvector åˆ—å’Œç´¢å¼•
ALTER TABLE otlp_spans
  ADD COLUMN name_tsv tsvector 
  GENERATED ALWAYS AS (to_tsvector('english', name)) STORED;

ALTER TABLE otlp_spans
  ADD COLUMN status_msg_tsv tsvector 
  GENERATED ALWAYS AS (to_tsvector('english', COALESCE(status_message, ''))) STORED;

CREATE INDEX idx_spans_name_fts ON otlp_spans USING GIN(name_tsv);
CREATE INDEX idx_spans_status_fts ON otlp_spans USING GIN(status_msg_tsv);

-- 1.2 å…¨æ–‡æœç´¢æŸ¥è¯¢
SELECT 
  span_id,
  name,
  status_message,
  ts_rank(name_tsv, query) + ts_rank(status_msg_tsv, query) AS rank
FROM otlp_spans, 
  plainto_tsquery('english', 'connection timeout') AS query
WHERE name_tsv @@ query OR status_msg_tsv @@ query
ORDER BY rank DESC
LIMIT 50;

-- 1.3 é«˜çº§æŸ¥è¯¢: çŸ­è¯­æœç´¢ + é€šé…ç¬¦
SELECT * FROM otlp_spans
WHERE name_tsv @@ phraseto_tsquery('english', 'database connection')
   OR status_msg_tsv @@ to_tsquery('english', 'timeout & (database | connection)');

-- æ–¹æ³• 2: PostgreSQL pg_trgm (ä¸‰å…ƒç»„) æ¨¡ç³ŠåŒ¹é…

-- 2.1 å¯ç”¨æ‰©å±•å’Œåˆ›å»ºç´¢å¼•
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX idx_spans_name_trgm ON otlp_spans USING GIN(name gin_trgm_ops);
CREATE INDEX idx_spans_status_trgm ON otlp_spans USING GIN(status_message gin_trgm_ops);

-- 2.2 ç›¸ä¼¼åº¦æœç´¢ (Fuzzy Match)
SELECT 
  span_id,
  name,
  similarity(name, 'database conection') AS sim_score  -- æ³¨æ„æ‹¼å†™é”™è¯¯
FROM otlp_spans
WHERE name % 'database conection'  -- % æ“ä½œç¬¦: ç›¸ä¼¼åº¦ > é˜ˆå€¼ (é»˜è®¤ 0.3)
ORDER BY sim_score DESC
LIMIT 10;

-- 2.3 å‰ç¼€åŒ¹é… (LIKE ä¼˜åŒ–)
SELECT * FROM otlp_spans
WHERE name ILIKE 'http.server%'  -- ILIKE å¯ä»¥åˆ©ç”¨ pg_trgm ç´¢å¼•
ORDER BY start_time_ns DESC
LIMIT 100;

-- æ€§èƒ½å¯¹æ¯”:
-- ========
-- LIKE '%keyword%' (æ— ç´¢å¼•): å…¨è¡¨æ‰«æ ~5000ms
-- GIN FTS ç´¢å¼•: ~10-50ms  (50-500x æå‡)
-- GIN pg_trgm ç´¢å¼•: ~20-100ms  (50-250x æå‡)
```

---

## 3. OTLP è®¡ç®—æ¨¡å‹

### 3.1 æ‰¹é‡è®¡ç®—æ¨¡å‹ (Batch Processing)

#### 3.1.1 MapReduce èŒƒå¼

```python
# ä½¿ç”¨ PySpark å®ç° OTLP æ•°æ®æ‰¹é‡åˆ†æ

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.window import Window

spark = SparkSession.builder \
    .appName("OTLP Batch Analytics") \
    .config("spark.sql.adaptive.enabled", "true") \
    .getOrCreate()

# è¯»å– OTLP Span æ•°æ® (ä» Parquet æ–‡ä»¶)
spans_df = spark.read.parquet("s3://otlp-data/spans/year=2025/month=10/day=09/")

# Map é˜¶æ®µ: æå–å’Œè½¬æ¢
spans_mapped = spans_df.select(
    col("trace_id"),
    col("span_id"),
    col("parent_span_id"),
    col("name"),
    col("resource.service.name").alias("service_name"),
    col("start_time_unix_nano"),
    col("end_time_unix_nano"),
    ((col("end_time_unix_nano") - col("start_time_unix_nano")) / 1_000_000).alias("duration_ms"),
    col("status.code").alias("status_code"),
    col("kind"),
    col("attributes")
)

# Reduce é˜¶æ®µ 1: èšåˆè®¡ç®—æœåŠ¡çº§åˆ«æŒ‡æ ‡
service_metrics = spans_mapped \
    .where(col("kind").isin(["SERVER", "CLIENT"])) \
    .groupBy("service_name") \
    .agg(
        count("*").alias("total_requests"),
        avg("duration_ms").alias("avg_latency_ms"),
        expr("percentile_approx(duration_ms, 0.50)").alias("p50_latency_ms"),
        expr("percentile_approx(duration_ms, 0.95)").alias("p95_latency_ms"),
        expr("percentile_approx(duration_ms, 0.99)").alias("p99_latency_ms"),
        sum(when(col("status_code") == 2, 1).otherwise(0)).alias("error_count"),
        (sum(when(col("status_code") == 2, 1).otherwise(0)) / count("*") * 100).alias("error_rate_pct")
    )

# Reduce é˜¶æ®µ 2: æœåŠ¡ä¾èµ–å…³ç³»
service_dependencies = spans_mapped.alias("child") \
    .join(
        spans_mapped.alias("parent"),
        (col("child.parent_span_id") == col("parent.span_id")) &
        (col("child.trace_id") == col("parent.trace_id"))
    ) \
    .where(col("child.service_name") != col("parent.service_name")) \
    .groupBy("parent.service_name", "child.service_name") \
    .agg(
        count("*").alias("call_count"),
        avg("child.duration_ms").alias("avg_latency_ms"),
        sum(when(col("child.status_code") == 2, 1).otherwise(0)).alias("error_count")
    ) \
    .withColumnRenamed("parent.service_name", "caller") \
    .withColumnRenamed("child.service_name", "callee")

# ä¿å­˜ç»“æœ
service_metrics.write.mode("overwrite").parquet("s3://otlp-analytics/service_metrics/date=2025-10-09/")
service_dependencies.write.mode("overwrite").parquet("s3://otlp-analytics/service_deps/date=2025-10-09/")

# æ€§èƒ½åˆ†æ:
# ========
# è¾“å…¥æ•°æ®é‡: 10 äº¿ Span (1TB Parquet å‹ç¼©å ~200GB)
# Spark é›†ç¾¤: 50 èŠ‚ç‚¹ (æ¯èŠ‚ç‚¹ 16 æ ¸, 64GB RAM)
# æ‰§è¡Œæ—¶é—´: ~5-10 åˆ†é’Ÿ
# ååé‡: ~100-200 GB/min, ~1.6-3.3 ç™¾ä¸‡ Span/sec
```

#### 3.1.2 SQL æ‰¹é‡åˆ†æ (ClickHouse)

```sql
-- åœºæ™¯: æ¯å¤©æ‰¹é‡è®¡ç®—æœåŠ¡å¥åº·åº¦æŠ¥å‘Š

-- åˆ›å»ºç›®æ ‡è¡¨ (å­˜å‚¨æ¯æ—¥æŠ¥å‘Š)
CREATE TABLE otlp_daily_service_health (
  report_date Date,
  service_name LowCardinality(String),
  deployment_environment LowCardinality(String),
  
  total_requests UInt64,
  total_errors UInt64,
  error_rate_pct Float64,
  
  avg_latency_ms Float64,
  p50_latency_ms Float64,
  p95_latency_ms Float64,
  p99_latency_ms Float64,
  p999_latency_ms Float64,
  
  apdex_score Float64,  -- Application Performance Index
  health_score Float64  -- ç»¼åˆå¥åº·åº¦ (0-100)
) ENGINE = MergeTree()
PARTITION BY report_date
ORDER BY (report_date, service_name, deployment_environment);

-- æ‰¹é‡è®¡ç®— (INSERT ... SELECT)
INSERT INTO otlp_daily_service_health
SELECT 
  toDate(start_time) AS report_date,
  service_name,
  deployment_environment,
  
  -- è¯·æ±‚é‡å’Œé”™è¯¯ç‡
  count() AS total_requests,
  countIf(is_error = 1) AS total_errors,
  total_errors / total_requests * 100 AS error_rate_pct,
  
  -- å»¶è¿Ÿåˆ†å¸ƒ
  avg(duration_ms) AS avg_latency_ms,
  quantile(0.50)(duration_ms) AS p50_latency_ms,
  quantile(0.95)(duration_ms) AS p95_latency_ms,
  quantile(0.99)(duration_ms) AS p99_latency_ms,
  quantile(0.999)(duration_ms) AS p999_latency_ms,
  
  -- Apdex Score (T = 500ms)
  (countIf(duration_ms <= 500) + countIf(duration_ms > 500 AND duration_ms <= 2000) * 0.5) / total_requests AS apdex_score,
  
  -- Health Score = æƒé‡ç»„åˆ
  GREATEST(0, LEAST(100, 
    100 * (1 - error_rate_pct / 100) * 0.4 +  -- é”™è¯¯ç‡æƒé‡ 40%
    100 * (1 - LEAST(1, p99_latency_ms / 5000)) * 0.3 +  -- P99 å»¶è¿Ÿæƒé‡ 30%
    apdex_score * 100 * 0.3  -- Apdex æƒé‡ 30%
  )) AS health_score

FROM otlp_spans_clickhouse
WHERE toDate(start_time) = '2025-10-09'  -- è®¡ç®—æ˜¨å¤©çš„æ•°æ®
  AND span_kind IN ('SERVER', 'CLIENT')
GROUP BY report_date, service_name, deployment_environment;

-- æ‰§è¡Œæ€§èƒ½:
-- ========
-- è¾“å…¥æ•°æ®: 1 å¤© = çº¦ 10 äº¿ Span
-- ClickHouse é›†ç¾¤: 10 èŠ‚ç‚¹
-- æ‰§è¡Œæ—¶é—´: ~1-2 åˆ†é’Ÿ
-- ååé‡: ~8-16 ç™¾ä¸‡ Span/sec
```

### 3.2 æµå¼è®¡ç®—æ¨¡å‹ (Stream Processing)

#### 3.2.1 Apache Flink å®æ—¶åˆ†æ

```java
// Flink å®æ—¶è®¡ç®— OTLP æŒ‡æ ‡

import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.api.common.functions.AggregateFunction;

public class OTLPRealtimeAnalytics {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.enableCheckpointing(5000); // 5 ç§’checkpoint
        
        // 1. æ•°æ®æº: Kafka (OTLP Collector -> Kafka)
        FlinkKafkaConsumer<Span> spanConsumer = new FlinkKafkaConsumer<>(
            "otlp-spans",
            new SpanDeserializationSchema(),
            kafkaProperties
        );
        DataStream<Span> spanStream = env.addSource(spanConsumer);
        
        // 2. æµå¼è®¡ç®—: æ»‘åŠ¨çª—å£ P99 å»¶è¿Ÿ (1 åˆ†é’Ÿçª—å£, 10 ç§’æ»‘åŠ¨)
        DataStream<ServiceLatency> p99Latency = spanStream
            .filter(span -> span.getKind() == SpanKind.SERVER)
            .keyBy(span -> span.getResource().getServiceName())
            .timeWindow(Time.minutes(1), Time.seconds(10))  // æ»‘åŠ¨çª—å£
            .aggregate(new LatencyAggregateFunction())
            .map(result -> new ServiceLatency(
                result.serviceName,
                result.windowEnd,
                result.p99LatencyMs,
                result.requestCount,
                result.errorCount
            ));
        
        // 3. å®æ—¶å‘Šè­¦: P99 > é˜ˆå€¼
        DataStream<Alert> alerts = p99Latency
            .filter(latency -> latency.getP99LatencyMs() > 1000)  // > 1 ç§’
            .map(latency -> new Alert(
                AlertLevel.WARNING,
                latency.getServiceName(),
                "High P99 latency: " + latency.getP99LatencyMs() + "ms"
            ));
        
        // 4. è¾“å‡ºåˆ°å‘Šè­¦ç³»ç»Ÿ (Kafka, Webhooks, etc.)
        alerts.addSink(new AlertSinkFunction());
        
        // 5. æŒä¹…åŒ–åˆ°æ—¶åºæ•°æ®åº“ (InfluxDB, Prometheus)
        p99Latency.addSink(new InfluxDBSinkFunction());
        
        env.execute("OTLP Realtime Analytics");
    }
    
    // è‡ªå®šä¹‰èšåˆå‡½æ•°: è®¡ç®— P99 å»¶è¿Ÿ
    public static class LatencyAggregateFunction 
        implements AggregateFunction<Span, LatencyAccumulator, LatencyResult> {
        
        @Override
        public LatencyAccumulator createAccumulator() {
            return new LatencyAccumulator();
        }
        
        @Override
        public LatencyAccumulator add(Span span, LatencyAccumulator acc) {
            acc.addLatency(span.getDurationNs() / 1_000_000.0);  // è½¬æ¢ä¸ºæ¯«ç§’
            if (span.getStatus().getCode() == StatusCode.ERROR) {
                acc.incrementErrorCount();
            }
            return acc;
        }
        
        @Override
        public LatencyResult getResult(LatencyAccumulator acc) {
            return new LatencyResult(
                acc.serviceName,
                acc.windowEnd,
                acc.calculateP99(),
                acc.requestCount,
                acc.errorCount
            );
        }
        
        @Override
        public LatencyAccumulator merge(LatencyAccumulator a, LatencyAccumulator b) {
            // åˆå¹¶ä¸¤ä¸ªç´¯åŠ å™¨ (ç”¨äºå¹¶è¡Œè®¡ç®—)
            a.merge(b);
            return a;
        }
    }
}

// æ€§èƒ½ç‰¹ç‚¹:
// ========
// - å»¶è¿Ÿ: äºšç§’çº§ (é€šå¸¸ 100-500ms)
// - ååé‡: å•èŠ‚ç‚¹ ~10-50 ä¸‡äº‹ä»¶/ç§’
// - å‡†ç¡®æ€§: è¿‘ä¼¼ç®—æ³• (t-digest for P99), è¯¯å·® < 1%
// - å®¹é”™æ€§: Exactly-once è¯­ä¹‰ (é€šè¿‡ checkpoint)
```

#### 3.2.2 çª—å£èšåˆæ¨¡å‹

```text
æµå¼çª—å£ç±»å‹:
===========

1. Tumbling Window (æ»šåŠ¨çª—å£):
   [0-60s] [60-120s] [120-180s] ...
   ç‰¹ç‚¹: ä¸é‡å , æ¯ä¸ªäº‹ä»¶åªå±äºä¸€ä¸ªçª—å£
   ç”¨é€”: æ¯åˆ†é’Ÿç»Ÿè®¡è¯·æ±‚é‡, é”™è¯¯ç‡

2. Sliding Window (æ»‘åŠ¨çª—å£):
   [0-60s] 
       [10-70s] 
           [20-80s] ...
   ç‰¹ç‚¹: é‡å , å¹³æ»‘çš„è¶‹åŠ¿å˜åŒ–
   ç”¨é€”: ç§»åŠ¨å¹³å‡, å¼‚å¸¸æ£€æµ‹

3. Session Window (ä¼šè¯çª—å£):
   äº‹ä»¶ä¹‹é—´é—´éš” > gap åˆ™åˆ†å‰²çª—å£
   ç‰¹ç‚¹: åŠ¨æ€çª—å£å¤§å°
   ç”¨é€”: ç”¨æˆ·ä¼šè¯åˆ†æ

4. Global Window (å…¨å±€çª—å£):
   æ‰€æœ‰äº‹ä»¶å±äºåŒä¸€çª—å£, éœ€è¦è‡ªå®šä¹‰è§¦å‘å™¨
   ç‰¹ç‚¹: æ— é™çª—å£
   ç”¨é€”: å…¨å±€è®¡æ•°å™¨, ç´¯ç§¯èšåˆ

Watermark (æ°´ä½çº¿):
==================
ç”¨äºå¤„ç†ä¹±åºäº‹ä»¶

å®šä¹‰: Watermark(t) = max_seen_timestamp - allowed_lateness

ç¤ºä¾‹:
  å½“å‰æ—¶é—´: 12:00:10
  æœ€å¤§äº‹ä»¶æ—¶é—´: 12:00:08
  å…è®¸å»¶è¿Ÿ: 5 ç§’
  Watermark: 12:00:08 - 5s = 12:00:03
  
  å«ä¹‰: æ—¶é—´æˆ³ <= 12:00:03 çš„çª—å£å¯ä»¥è§¦å‘è®¡ç®—
  
  è¿Ÿåˆ°äº‹ä»¶å¤„ç†:
    - 12:00:01 çš„äº‹ä»¶åœ¨ 12:00:10 åˆ°è¾¾ â†’ è¢«åŒ…å« (åœ¨å…è®¸èŒƒå›´å†…)
    - 11:59:58 çš„äº‹ä»¶åœ¨ 12:00:10 åˆ°è¾¾ â†’ å¯é€‰: ä¸¢å¼ƒæˆ–å‘é€åˆ°ä¾§è¾“å‡ºæµ
```

### 3.3 å¢é‡è®¡ç®—æ¨¡å‹ (Incremental Computation)

```python
# ä½¿ç”¨ Apache Flink + RocksDB çŠ¶æ€åç«¯å®ç°å¢é‡ P99 è®¡ç®—

from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.window import TumblingProcessingTimeWindows
from pyflink.common.time import Time
from pyflink.datastream.functions import ProcessWindowFunction

class IncrementalP99Calculator(ProcessWindowFunction):
    """å¢é‡è®¡ç®— P99 å»¶è¿Ÿ (ä½¿ç”¨ t-digest ç®—æ³•)"""
    
    def __init__(self):
        self.t_digest = None  # t-digest æ•°æ®ç»“æ„
    
    def open(self, runtime_context):
        # åˆå§‹åŒ–çŠ¶æ€
        from tdigest import TDigest
        self.t_digest = TDigest()
    
    def process(self, key, context, elements):
        # å¢é‡æ›´æ–° t-digest
        for span in elements:
            duration_ms = span.duration_ns / 1_000_000
            self.t_digest.update(duration_ms)
        
        # è®¡ç®— P99
        p99_latency = self.t_digest.percentile(99)
        request_count = len(elements)
        
        # è¾“å‡ºç»“æœ
        yield (
            key,  # service_name
            context.window().end,  # window_end_time
            p99_latency,
            request_count
        )
    
    def clear(self, context):
        # çª—å£ç»“æŸåæ¸…ç†çŠ¶æ€
        self.t_digest = TDigest()

# t-digest ç®—æ³•ä¼˜åŠ¿:
# =================
# - ç©ºé—´å¤æ‚åº¦: O(Î´), Î´ â‰ˆ 100-200 (å‹ç¼©å‚æ•°)
# - æ—¶é—´å¤æ‚åº¦: O(log Î´) per update
# - è¯¯å·®: < 1% for P99
# - å¯åˆå¹¶: æ”¯æŒåˆ†å¸ƒå¼èšåˆ

# å¯¹æ¯”ç²¾ç¡®è®¡ç®—:
# ============
# ç²¾ç¡®ç®—æ³• (æ’åº):
#   - ç©ºé—´: O(n), n = çª—å£å†…äº‹ä»¶æ•°
#   - æ—¶é—´: O(n log n)
#   - å¯¹äº 1 åˆ†é’Ÿçª—å£, n â‰ˆ 100,000 â†’ ä¸å¯è¡Œ

# t-digest è¿‘ä¼¼ç®—æ³•:
#   - ç©ºé—´: O(200) â‰ˆ 3.2 KB
#   - æ—¶é—´: O(log 200) â‰ˆ 7.6 æ¯”è¾ƒ
#   - æ€§èƒ½æå‡: ~1000x
```

---

## 4. åˆ†å¸ƒå¼è®¡ç®—æ¶æ„

### 4.1 æ•°æ®åˆ†ç‰‡ä¸è´Ÿè½½å‡è¡¡

```text
Span æ•°æ®åˆ†ç‰‡ç­–ç•¥:
================

ç­–ç•¥ 1: Hash Partitioning by TraceId
  partition = hash(trace_id) % num_partitions
  
  ä¼˜ç‚¹:
    - åŒä¸€ Trace çš„æ‰€æœ‰ Span è½åˆ°åŒä¸€åˆ†åŒº
    - ä¾¿äº Trace çº§åˆ«çš„æŸ¥è¯¢å’Œåˆ†æ
  
  ç¼ºç‚¹:
    - å¦‚æœæŸä¸ª Trace ç‰¹åˆ«å¤§ (æ•°åƒ Span), å¯èƒ½å¯¼è‡´åˆ†åŒºå€¾æ–œ
    - ä¸æ”¯æŒé«˜æ•ˆçš„æ—¶é—´èŒƒå›´æŸ¥è¯¢

ç­–ç•¥ 2: Range Partitioning by Time
  partition = floor(timestamp / partition_interval)
  
  ä¼˜ç‚¹:
    - æ—¶é—´èŒƒå›´æŸ¥è¯¢é«˜æ•ˆ (ç›´æ¥å®šä½åˆ†åŒº)
    - è€æ•°æ®å¯ä»¥å½’æ¡£æˆ–åˆ é™¤
  
  ç¼ºç‚¹:
    - åŒä¸€ Trace çš„ Span å¯èƒ½åˆ†æ•£åœ¨å¤šä¸ªåˆ†åŒº
    - Trace çº§åˆ«æŸ¥è¯¢éœ€è¦è·¨åˆ†åŒºèšåˆ

ç­–ç•¥ 3: Composite Partitioning (æ—¶é—´ + å“ˆå¸Œ)
  primary_partition = date(timestamp)
  secondary_partition = hash(trace_id) % sub_partitions
  
  å®ç°:
    table_name = f"otlp_spans_{date}_{hash_bucket}"
    ä¾‹å¦‚: otlp_spans_2025_10_09_03
  
  ä¼˜ç‚¹:
    - ç»“åˆä¸¤ç§ç­–ç•¥çš„ä¼˜ç‚¹
    - æ—¶é—´æŸ¥è¯¢å’Œ Trace æŸ¥è¯¢éƒ½è¾ƒé«˜æ•ˆ
  
  ç¼ºç‚¹:
    - åˆ†åŒºæ•°é‡å¢åŠ  (ç®¡ç†å¤æ‚åº¦)

æ¨èå®ç° (ClickHouse Distributed Table):
======================================

-- æœ¬åœ°è¡¨ (æ¯ä¸ªèŠ‚ç‚¹)
CREATE TABLE otlp_spans_local ON CLUSTER '{cluster}' (
  ...
) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/otlp_spans', '{replica}')
PARTITION BY toYYYYMMDD(start_time)
ORDER BY (service_name, start_time, trace_id);

-- åˆ†å¸ƒå¼è¡¨ (å…¨å±€è§†å›¾)
CREATE TABLE otlp_spans_distributed ON CLUSTER '{cluster}' AS otlp_spans_local
ENGINE = Distributed('{cluster}', 'default', 'otlp_spans_local', cityHash64(trace_id));

-- æ•°æ®å†™å…¥: è‡ªåŠ¨æ ¹æ® trace_id å“ˆå¸Œåˆ†ç‰‡
INSERT INTO otlp_spans_distributed VALUES (...);

-- æ•°æ®æŸ¥è¯¢: è‡ªåŠ¨è·¯ç”±åˆ°ç›¸å…³èŠ‚ç‚¹
SELECT * FROM otlp_spans_distributed
WHERE trace_id = unhex('...');  -- åªæŸ¥è¯¢ 1 ä¸ªèŠ‚ç‚¹

SELECT * FROM otlp_spans_distributed
WHERE start_time >= now() - INTERVAL 1 HOUR;  -- æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹,å¹¶è¡Œèšåˆ
```

### 4.2 ä¸€è‡´æ€§å“ˆå¸Œä¸æ•°æ®è¿ç§»

```python
# ä¸€è‡´æ€§å“ˆå¸Œå®ç° (ç”¨äºåŠ¨æ€æ‰©ç¼©å®¹)

import hashlib
import bisect

class ConsistentHash:
    """ä¸€è‡´æ€§å“ˆå¸Œç¯ (Consistent Hashing Ring)"""
    
    def __init__(self, nodes=None, virtual_nodes=150):
        self.virtual_nodes = virtual_nodes  # è™šæ‹ŸèŠ‚ç‚¹æ•°é‡
        self.ring = {}  # å“ˆå¸Œç¯: {hash_value: node_id}
        self.sorted_keys = []  # æ’åºçš„å“ˆå¸Œå€¼åˆ—è¡¨
        
        if nodes:
            for node in nodes:
                self.add_node(node)
    
    def _hash(self, key: str) -> int:
        """è®¡ç®—å“ˆå¸Œå€¼ (ä½¿ç”¨ MD5)"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)
    
    def add_node(self, node_id: str):
        """æ·»åŠ èŠ‚ç‚¹ (åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹)"""
        for i in range(self.virtual_nodes):
            virtual_key = f"{node_id}:vnode:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node_id
            bisect.insort(self.sorted_keys, hash_value)
    
    def remove_node(self, node_id: str):
        """ç§»é™¤èŠ‚ç‚¹"""
        for i in range(self.virtual_nodes):
            virtual_key = f"{node_id}:vnode:{i}"
            hash_value = self._hash(virtual_key)
            del self.ring[hash_value]
            self.sorted_keys.remove(hash_value)
    
    def get_node(self, trace_id: str) -> str:
        """è·å– trace_id å¯¹åº”çš„èŠ‚ç‚¹"""
        if not self.ring:
            return None
        
        hash_value = self._hash(trace_id)
        # é¡ºæ—¶é’ˆæŸ¥æ‰¾ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
        idx = bisect.bisect_right(self.sorted_keys, hash_value)
        if idx == len(self.sorted_keys):
            idx = 0  # ç¯å½¢ç»“æ„
        
        return self.ring[self.sorted_keys[idx]]

# ä½¿ç”¨ç¤ºä¾‹:
ch = ConsistentHash(nodes=["node1", "node2", "node3"])

# Trace è·¯ç”±
trace_id = "0af7651916cd43dd8448eb211c80319c"
node = ch.get_node(trace_id)
print(f"Trace {trace_id} -> {node}")

# æ·»åŠ æ–°èŠ‚ç‚¹ (æ‰©å®¹)
ch.add_node("node4")
# åªæœ‰çº¦ 25% çš„æ•°æ®éœ€è¦è¿ç§» (ç†æƒ³æƒ…å†µ 1/4)

# ç§»é™¤èŠ‚ç‚¹ (ç¼©å®¹)
ch.remove_node("node2")
# åªæœ‰çº¦ 33% çš„æ•°æ®éœ€è¦è¿ç§» (ç†æƒ³æƒ…å†µ 1/3)

# å¯¹æ¯”ç®€å•å“ˆå¸Œ:
# ============
# ç®€å•å“ˆå¸Œ: node = hash(trace_id) % num_nodes
# é—®é¢˜: æ·»åŠ /åˆ é™¤èŠ‚ç‚¹æ—¶, æ‰€æœ‰æ•°æ®éƒ½éœ€è¦é‡æ–°åˆ†é… (100% è¿ç§»)

# ä¸€è‡´æ€§å“ˆå¸Œ:
# æ·»åŠ èŠ‚ç‚¹: ~1/n æ•°æ®è¿ç§» (n = èŠ‚ç‚¹æ•°é‡)
# åˆ é™¤èŠ‚ç‚¹: ~1/(n-1) æ•°æ®è¿ç§»
```

### 4.3 åˆ†å¸ƒå¼æŸ¥è¯¢ä¼˜åŒ–

```sql
-- åœºæ™¯: è·¨å¤šä¸ª ClickHouse èŠ‚ç‚¹æŸ¥è¯¢ Trace

-- æŸ¥è¯¢ 1: ç²¾ç¡® Trace æŸ¥è¯¢ (å•åˆ†ç‰‡)
SELECT * FROM otlp_spans_distributed
WHERE trace_id = unhex('0af7651916cd43dd8448eb211c80319c');

-- æ‰§è¡Œè®¡åˆ’:
-- 1. è®¡ç®— trace_id å“ˆå¸Œ: cityHash64('0af7651916cd...') â†’ åˆ†ç‰‡ 2
-- 2. åªæŸ¥è¯¢åˆ†ç‰‡ 2 çš„èŠ‚ç‚¹
-- 3. è¿”å›ç»“æœ
-- ç½‘ç»œå¼€é”€: 1 æ¬¡ RPC è°ƒç”¨
-- æŸ¥è¯¢æ—¶é—´: ~0.1-0.5 ms

-- æŸ¥è¯¢ 2: èšåˆæŸ¥è¯¢ (æ‰€æœ‰åˆ†ç‰‡)
SELECT 
  service_name,
  count() AS request_count,
  quantile(0.99)(duration_ms) AS p99_latency_ms
FROM otlp_spans_distributed
WHERE start_time >= now() - INTERVAL 1 HOUR
GROUP BY service_name;

-- æ‰§è¡Œè®¡åˆ’ (MapReduce æ¨¡å¼):
-- Map é˜¶æ®µ (æ¯ä¸ªåˆ†ç‰‡å¹¶è¡Œ):
--   SELECT service_name, count(), quantile(0.99)(duration_ms)
--   FROM otlp_spans_local
--   WHERE ...
--   GROUP BY service_name
-- 
-- Reduce é˜¶æ®µ (Coordinator èŠ‚ç‚¹):
--   åˆå¹¶å„åˆ†ç‰‡çš„éƒ¨åˆ†ç»“æœ:
--   - count(): ç›´æ¥æ±‚å’Œ
--   - quantile(0.99): ä½¿ç”¨ quantileMerge å‡½æ•°

-- ç½‘ç»œå¼€é”€: N æ¬¡ RPC (N = åˆ†ç‰‡æ•°)
-- æŸ¥è¯¢æ—¶é—´: ~50-200 ms (å–å†³äºåˆ†ç‰‡æ•°å’Œæ•°æ®é‡)

-- ä¼˜åŒ–æŠ€å·§:
-- ========

-- 1. æœ¬åœ°èšåˆ (Local Aggregation)
-- å‡å°‘ç½‘ç»œä¼ è¾“æ•°æ®é‡
SELECT 
  service_name,
  sum(local_count) AS total_count,
  quantileMerge(0.99)(local_p99) AS global_p99
FROM (
  SELECT 
    service_name,
    count() AS local_count,
    quantileState(0.99)(duration_ms) AS local_p99
  FROM otlp_spans_local
  WHERE start_time >= now() - INTERVAL 1 HOUR
  GROUP BY service_name
)
GROUP BY service_name;

-- 2. Predicate Pushdown (è°“è¯ä¸‹æ¨)
-- WHERE æ¡ä»¶ä¸‹æ¨åˆ°å„åˆ†ç‰‡,å‡å°‘æ‰«ææ•°æ®é‡
-- ClickHouse è‡ªåŠ¨ä¼˜åŒ–

-- 3. Parallel Execution (å¹¶è¡Œæ‰§è¡Œ)
-- åˆ©ç”¨å¤šæ ¸ CPU, æ¯ä¸ªåˆ†ç‰‡å†…éƒ¨å¹¶è¡Œæ‰«æ
SET max_threads = 16;

-- 4. Result Caching (ç»“æœç¼“å­˜)
-- ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ
SET use_query_cache = 1;
SET query_cache_ttl = 300;  -- ç¼“å­˜ 5 åˆ†é’Ÿ
```

---

## 5. æ€§èƒ½ä¼˜åŒ–ä¸è°ƒä¼˜

### 5.1 ç´¢å¼•é€‰æ‹©ä¸è°ƒä¼˜

```sql
-- ç´¢å¼•æ€§èƒ½åˆ†æå·¥å…· (PostgreSQL)

-- 1. æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT 
  schemaname,
  tablename,
  indexname,
  idx_scan,  -- ç´¢å¼•æ‰«ææ¬¡æ•°
  idx_tup_read,  -- é€šè¿‡ç´¢å¼•è¯»å–çš„è¡Œæ•°
  idx_tup_fetch,  -- é€šè¿‡ç´¢å¼•è·å–çš„è¡Œæ•°
  pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE schemaname = 'public' AND tablename = 'otlp_spans'
ORDER BY idx_scan DESC;

-- åˆ†æç»“æœ:
-- ========
-- idx_scan = 0 â†’ æœªä½¿ç”¨çš„ç´¢å¼• (è€ƒè™‘åˆ é™¤)
-- idx_scan > 10000 â†’ é«˜é¢‘ä½¿ç”¨çš„ç´¢å¼• (ä¿ç•™)
-- index_size > 10GB â†’ å¤§ç´¢å¼• (è¯„ä¼°æ˜¯å¦å¿…è¦)

-- 2. è¯†åˆ«ç¼ºå¤±çš„ç´¢å¼•
SELECT 
  schemaname,
  tablename,
  seq_scan,  -- é¡ºåºæ‰«ææ¬¡æ•°
  seq_tup_read,  -- é¡ºåºæ‰«æè¯»å–çš„è¡Œæ•°
  idx_scan,  -- ç´¢å¼•æ‰«ææ¬¡æ•°
  seq_tup_read / NULLIF(seq_scan, 0) AS avg_seq_read,
  pg_size_pretty(pg_relation_size(relid)) AS table_size
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY seq_tup_read DESC;

-- åˆ†æç»“æœ:
-- ========
-- seq_scan > idx_scan ä¸” avg_seq_read > 1000 â†’ å¯èƒ½éœ€è¦æ·»åŠ ç´¢å¼•

-- 3. ç´¢å¼•è†¨èƒ€æ£€æµ‹
SELECT 
  schemaname,
  tablename,
  indexname,
  pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
  pg_size_pretty(
    pg_relation_size(indexrelid) - 
    pg_relation_size(indexrelid, 'main')
  ) AS bloat_size,
  (pg_relation_size(indexrelid) - pg_relation_size(indexrelid, 'main'))::float / 
    NULLIF(pg_relation_size(indexrelid), 0) * 100 AS bloat_pct
FROM pg_stat_user_indexes
WHERE schemaname = 'public' AND tablename = 'otlp_spans'
ORDER BY bloat_pct DESC;

-- ä¿®å¤ç´¢å¼•è†¨èƒ€:
REINDEX INDEX CONCURRENTLY idx_spans_trace_clustered;

-- 4. ç´¢å¼•ç¢ç‰‡æ•´ç† (PostgreSQL 14+)
VACUUM (ANALYZE, VERBOSE) otlp_spans;

-- å¯¹æ¯” ClickHouse:
-- ==============
-- ClickHouse ä½¿ç”¨ MergeTree å¼•æ“, åå°è‡ªåŠ¨åˆå¹¶å’Œä¼˜åŒ–
-- ä¸éœ€è¦æ‰‹åŠ¨ REINDEX æˆ– VACUUM
```

### 5.2 æŸ¥è¯¢æ€§èƒ½è°ƒä¼˜

```sql
-- æ…¢æŸ¥è¯¢ä¼˜åŒ–æ¡ˆä¾‹

-- åŸå§‹æŸ¥è¯¢ (æ…¢):
EXPLAIN (ANALYZE, BUFFERS)
SELECT 
  r.service_name,
  COUNT(*) AS error_count,
  STRING_AGG(s.status_message, ', ' ORDER BY s.start_time_ns DESC) AS error_messages
FROM otlp_spans s
JOIN otlp_resources r ON s.resource_id = r.resource_id
WHERE s.status_code = 2
  AND s.start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '24 hours') * 1000000000)::BIGINT
GROUP BY r.service_name
ORDER BY error_count DESC;

-- æ‰§è¡Œè®¡åˆ’é—®é¢˜:
-- ============
-- 1. STRING_AGG éœ€è¦æ’åº, å¼€é”€å¤§
-- 2. å¯èƒ½æ²¡æœ‰ä½¿ç”¨ idx_spans_errors éƒ¨åˆ†ç´¢å¼•

-- ä¼˜åŒ–åæŸ¥è¯¢:
EXPLAIN (ANALYZE, BUFFERS)
SELECT 
  r.service_name,
  COUNT(*) AS error_count,
  -- åªèšåˆå‰ 10 æ¡é”™è¯¯æ¶ˆæ¯ (å‡å°‘æ’åºå¼€é”€)
  STRING_AGG(
    s.status_message, 
    ', ' 
    ORDER BY s.start_time_ns DESC
  ) FILTER (WHERE row_num <= 10) AS sample_error_messages
FROM (
  SELECT 
    s.resource_id,
    s.status_message,
    s.start_time_ns,
    ROW_NUMBER() OVER (PARTITION BY s.resource_id ORDER BY s.start_time_ns DESC) AS row_num
  FROM otlp_spans s
  WHERE s.status_code = 2
    AND s.start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '24 hours') * 1000000000)::BIGINT
) s
JOIN otlp_resources r ON s.resource_id = r.resource_id
WHERE row_num <= 10
GROUP BY r.service_name
ORDER BY error_count DESC;

-- è¿›ä¸€æ­¥ä¼˜åŒ–: ä½¿ç”¨ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW otlp_recent_errors AS
SELECT 
  s.resource_id,
  r.service_name,
  s.status_message,
  s.start_time_ns,
  ROW_NUMBER() OVER (PARTITION BY s.resource_id ORDER BY s.start_time_ns DESC) AS row_num
FROM otlp_spans s
JOIN otlp_resources r ON s.resource_id = r.resource_id
WHERE s.status_code = 2
  AND s.start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '24 hours') * 1000000000)::BIGINT;

CREATE INDEX idx_mv_recent_errors ON otlp_recent_errors(service_name, row_num);

-- ç®€åŒ–æŸ¥è¯¢:
SELECT 
  service_name,
  COUNT(*) AS error_count,
  STRING_AGG(status_message, ', ' ORDER BY start_time_ns DESC) AS sample_errors
FROM otlp_recent_errors
WHERE row_num <= 10
GROUP BY service_name
ORDER BY error_count DESC;

-- æ€§èƒ½å¯¹æ¯”:
-- ========
-- åŸå§‹æŸ¥è¯¢: ~5-10 ç§’
-- ä¼˜åŒ–åæŸ¥è¯¢: ~500ms-1s
-- ç‰©åŒ–è§†å›¾æŸ¥è¯¢: ~50-100ms

-- æ€§èƒ½æå‡: **50-200x**
```

### 5.3 æ•°æ®å‹ç¼©ä¸å­˜å‚¨ä¼˜åŒ–

```sql
-- ClickHouse å‹ç¼©ç­–ç•¥

-- 1. åˆ—å‹ç¼© Codec é€‰æ‹©

-- æ—¶é—´åˆ—: Delta + ZSTD
ALTER TABLE otlp_spans_clickhouse
  MODIFY COLUMN start_time CODEC(Delta(8), ZSTD(1));

-- Delta ç¼–ç : å­˜å‚¨å·®å€¼è€Œéç»å¯¹å€¼
-- ç¤ºä¾‹: [1728432000, 1728432001, 1728432003]
-- Delta: [1728432000, +1, +2]  (å‹ç¼©ç‡ ~8x)

-- æ•°å€¼åˆ—: Gorilla + ZSTD
ALTER TABLE otlp_spans_clickhouse
  MODIFY COLUMN duration_ns CODEC(Gorilla, ZSTD(1));

-- Gorilla ç¼–ç : é’ˆå¯¹æ—¶åºæ•°æ®çš„ XOR å‹ç¼©
-- é€‚åˆç¼“æ…¢å˜åŒ–çš„æ•°å€¼ (å¦‚å»¶è¿Ÿ, CPU ä½¿ç”¨ç‡)
-- å‹ç¼©ç‡: ~10-20x

-- å­—ç¬¦ä¸²åˆ—: LowCardinality + ZSTD
ALTER TABLE otlp_spans_clickhouse
  MODIFY COLUMN service_name LowCardinality(String) CODEC(ZSTD(1));

-- LowCardinality: å­—å…¸ç¼–ç  (Dictionary Encoding)
-- é€‚åˆåŸºæ•°ä½çš„åˆ— (å¦‚ service_name, é€šå¸¸ < 1000 ä¸ªå”¯ä¸€å€¼)
-- å‹ç¼©ç‡: ~50-100x

-- Map ç±»å‹: ZSTD(3) (é«˜å‹ç¼©ç‡)
ALTER TABLE otlp_spans_clickhouse
  MODIFY COLUMN attributes Map(String, String) CODEC(ZSTD(3));

-- 2. åˆ†åŒºç­–ç•¥ä¼˜åŒ–

-- æŒ‰å¤©åˆ†åŒº (é»˜è®¤)
PARTITION BY toYYYYMMDD(start_time)
-- ä¼˜ç‚¹: è‡ªåŠ¨ TTL åˆ é™¤, æŸ¥è¯¢å¯ä»¥è·³è¿‡æ•´ä¸ªåˆ†åŒº
-- ç¼ºç‚¹: å¦‚æœå•å¤©æ•°æ®é‡ > 100GB, åˆ†åŒºè¿‡å¤§

-- æŒ‰å°æ—¶åˆ†åŒº (é«˜åååœºæ™¯)
PARTITION BY (toYYYYMMDD(start_time), toHour(start_time))
-- ä¼˜ç‚¹: æ›´ç»†ç²’åº¦çš„åˆ†åŒºå‰ªæ
-- ç¼ºç‚¹: åˆ†åŒºæ•°é‡å¢åŠ , ç®¡ç†å¼€é”€

-- 3. TTL (Time To Live) è‡ªåŠ¨æ¸…ç†

ALTER TABLE otlp_spans_clickhouse
  MODIFY TTL start_time + INTERVAL 30 DAY DELETE,
             start_time + INTERVAL 7 DAY TO VOLUME 'cold_storage';

-- ç­–ç•¥:
-- - 7 å¤©å†…: çƒ­å­˜å‚¨ (SSD)
-- - 7-30 å¤©: å†·å­˜å‚¨ (HDD)
-- - 30 å¤©å: è‡ªåŠ¨åˆ é™¤

-- 4. åˆ—è£å‰ª (Projection)

ALTER TABLE otlp_spans_clickhouse
  ADD PROJECTION proj_service_latency (
    SELECT 
      service_name,
      toStartOfHour(start_time) AS time_hour,
      count() AS request_count,
      quantileState(0.99)(duration_ms) AS p99_state
    GROUP BY service_name, time_hour
  );

-- è‡ªåŠ¨ç»´æŠ¤é¢„èšåˆæ•°æ®, åŠ é€Ÿå¸¸è§æŸ¥è¯¢

-- å‹ç¼©æ•ˆæœå¯¹æ¯”:
-- ============
-- åŸå§‹æ•°æ®: 1 TB (10 äº¿ Span, ~1KB/span)
-- 
-- æ— å‹ç¼©: 1 TB
-- ZSTD(1): ~200 GB (5x å‹ç¼©)
-- Delta + ZSTD: ~100 GB (10x å‹ç¼©)
-- LowCardinality + Gorilla + ZSTD: ~50 GB (20x å‹ç¼©)
-- 
-- å­˜å‚¨æˆæœ¬èŠ‚çœ: **95%**
```

---

## 6. æ€»ç»“ä¸æœ€ä½³å®è·µ

### 6.1 æ•°æ®æ¨¡å‹é€‰æ‹©æŒ‡å—

```text
åœºæ™¯                    | æ¨èæ–¹æ¡ˆ                | ç†ç”±
-----------------------|------------------------|--------------------
å®æ—¶æŸ¥è¯¢ (< 1s å»¶è¿Ÿ)   | ClickHouse + Distributed | åˆ—å¼å­˜å‚¨, é«˜å¹¶å‘
Trace å®Œæ•´é“¾è·¯æŸ¥è¯¢     | PostgreSQL + JSONB      | å…³ç³»æŸ¥è¯¢, äº‹åŠ¡æ”¯æŒ
å…¨æ–‡æœç´¢              | PostgreSQL + GIN FTS     | ä¸°å¯Œçš„æ–‡æœ¬æŸ¥è¯¢èƒ½åŠ›
å¤§è§„æ¨¡æ‰¹é‡åˆ†æ         | Spark + Parquet         | åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
æµå¼å®æ—¶è®¡ç®—           | Flink + Kafka           | ä½å»¶è¿Ÿ, çŠ¶æ€ç®¡ç†
é•¿æœŸå½’æ¡£              | S3 + Parquet + Athena   | ä½æˆæœ¬, æŒ‰éœ€æŸ¥è¯¢
```

### 6.2 æ€§èƒ½ä¼˜åŒ–æ¸…å•

```text
âœ… ç´¢å¼•ä¼˜åŒ–
  - åˆ›å»º æ—¶é—´èŒƒå›´ + æœåŠ¡ çš„å¤åˆç´¢å¼•
  - ä½¿ç”¨ Partial Index è¿‡æ»¤é”™è¯¯ Span
  - JSONB å±æ€§ä½¿ç”¨ GIN ç´¢å¼•
  - å®šæœŸ REINDEX ä¿®å¤ç´¢å¼•è†¨èƒ€

âœ… æŸ¥è¯¢ä¼˜åŒ–
  - ä½¿ç”¨ EXPLAIN ANALYZE åˆ†ææ‰§è¡Œè®¡åˆ’
  - é¿å… SELECT *, åªæŸ¥è¯¢éœ€è¦çš„åˆ—
  - ä½¿ç”¨ Materialized View é¢„èšåˆå¸¸è§æŸ¥è¯¢
  - ä½¿ç”¨ Connection Pooling å‡å°‘è¿æ¥å¼€é”€

âœ… æ•°æ®åˆ†åŒº
  - æŒ‰æ—¶é—´åˆ†åŒº (å¤©æˆ–å°æ—¶)
  - ä½¿ç”¨ Partition Pruning è·³è¿‡ä¸ç›¸å…³åˆ†åŒº
  - å®šæœŸå½’æ¡£æˆ–åˆ é™¤è€æ•°æ®

âœ… å‹ç¼©ç­–ç•¥
  - æ—¶é—´åˆ—: Delta + ZSTD
  - æ•°å€¼åˆ—: Gorilla + ZSTD
  - å­—ç¬¦ä¸²åˆ—: LowCardinality + ZSTD
  - è®¾ç½®åˆç†çš„å‹ç¼©çº§åˆ« (ZSTD(1-3))

âœ… åˆ†å¸ƒå¼ä¼˜åŒ–
  - ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œå®ç°è´Ÿè½½å‡è¡¡
  - æœ¬åœ°èšåˆå‡å°‘ç½‘ç»œä¼ è¾“
  - ä½¿ç”¨ Result Caching ç¼“å­˜å¸¸è§æŸ¥è¯¢
  - é…ç½®åˆç†çš„ Replication Factor (é€šå¸¸ 2-3)
```

### 6.3 ç›‘æ§ä¸è°ƒä¼˜

```sql
-- å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)

-- 1. æŸ¥è¯¢å»¶è¿Ÿ (P50, P95, P99)
SELECT 
  query_type,
  approx_percentile(0.50, query_duration_ms) AS p50_ms,
  approx_percentile(0.95, query_duration_ms) AS p95_ms,
  approx_percentile(0.99, query_duration_ms) AS p99_ms
FROM query_logs
WHERE timestamp >= now() - INTERVAL 1 HOUR
GROUP BY query_type;

-- ç›®æ ‡: P95 < 100ms, P99 < 500ms

-- 2. æ•°æ®æ‘„å…¥ååé‡
SELECT 
  count(*) / 3600 AS spans_per_second,
  sum(pg_column_size(span)) / 1024 / 1024 / 3600 AS mb_per_second
FROM otlp_spans
WHERE start_time_ns >= (EXTRACT(EPOCH FROM NOW() - INTERVAL '1 hour') * 1000000000)::BIGINT;

-- ç›®æ ‡: > 100,000 spans/sec

-- 3. ç´¢å¼•å‘½ä¸­ç‡
SELECT 
  sum(idx_blks_hit) / NULLIF(sum(idx_blks_hit + idx_blks_read), 0) * 100 AS index_hit_rate
FROM pg_statio_user_indexes;

-- ç›®æ ‡: > 95%

-- 4. è¡¨è†¨èƒ€ç‡
SELECT 
  pg_size_pretty(pg_total_relation_size('otlp_spans')) AS total_size,
  pg_size_pretty(pg_relation_size('otlp_spans')) AS table_size,
  pg_size_pretty(pg_total_relation_size('otlp_spans') - pg_relation_size('otlp_spans')) AS index_size,
  (pg_total_relation_size('otlp_spans') - pg_relation_size('otlp_spans'))::float / 
    NULLIF(pg_relation_size('otlp_spans'), 0) * 100 AS index_overhead_pct;

-- ç›®æ ‡: index_overhead_pct < 50%
```

---

## å‚è€ƒæ–‡çŒ®

1. **PostgreSQL 17 Documentation**, PostgreSQL Global Development Group, 2025
2. **ClickHouse Documentation**, ClickHouse Inc., 2024
3. **Apache Flink Documentation**, Apache Software Foundation, 2024
4. **Designing Data-Intensive Applications**, Martin Kleppmann, O'Reilly 2017
5. **Database Internals**, Alex Petrov, O'Reilly 2019
6. **Streaming Systems**, Tyler Akidau et al., O'Reilly 2018
7. **The Data Warehouse Toolkit**, Ralph Kimball, Wiley 2013
8. **Consistent Hashing and Random Trees**, Karger et al., STOC 1997
9. **The Log-Structured Merge-Tree (LSM-Tree)**, O'Neil et al., Acta Informatica 1996
10. **Gorilla: A Fast, Scalable, In-Memory Time Series Database**, Facebook, VLDB 2015

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæ•´ | ğŸ“… æœ€åæ›´æ–°: 2025-10-09
