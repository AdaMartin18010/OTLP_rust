# Rust å¹¶å‘ç¼–ç¨‹ä¸ OTLP é›†æˆå®Œæ•´æŒ‡å—

> **Rustç‰ˆæœ¬**: 1.90 (2025å¹´æœ€æ–°ç¨³å®šç‰ˆ)  
> **Tokio**: 1.47.1  
> **Rayon**: 1.11.1  
> **Crossbeam**: 0.8.4  
> **OpenTelemetry**: 0.31.0  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ9æ—¥  
> **æ–‡æ¡£çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª - å®Œæ•´è¦†ç›–æ‰€æœ‰å¹¶å‘æ¨¡å¼

---

## ğŸ“‹ ç›®å½•

- [Rust å¹¶å‘ç¼–ç¨‹ä¸ OTLP é›†æˆå®Œæ•´æŒ‡å—](#rust-å¹¶å‘ç¼–ç¨‹ä¸-otlp-é›†æˆå®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. Rust å¹¶å‘æ¨¡å‹æ¦‚è¿°](#1-rust-å¹¶å‘æ¨¡å‹æ¦‚è¿°)
    - [1.1 å¹¶å‘ vs å¹¶è¡Œ](#11-å¹¶å‘-vs-å¹¶è¡Œ)
    - [1.2 Rust å¹¶å‘å®‰å…¨ä¿è¯](#12-rust-å¹¶å‘å®‰å…¨ä¿è¯)
    - [1.3 å¹¶å‘å·¥å…·é€‰æ‹©æŒ‡å—](#13-å¹¶å‘å·¥å…·é€‰æ‹©æŒ‡å—)
  - [2. Tokio å¼‚æ­¥å¹¶å‘](#2-tokio-å¼‚æ­¥å¹¶å‘)
    - [2.1 Task å¹¶å‘](#21-task-å¹¶å‘)
    - [2.2 Select æ¨¡å¼](#22-select-æ¨¡å¼)
    - [2.3 Join æ¨¡å¼](#23-join-æ¨¡å¼)
    - [2.4 Channel é€šä¿¡](#24-channel-é€šä¿¡)
  - [3. Rayon æ•°æ®å¹¶è¡Œ](#3-rayon-æ•°æ®å¹¶è¡Œ)
    - [3.1 å¹¶è¡Œè¿­ä»£å™¨](#31-å¹¶è¡Œè¿­ä»£å™¨)
    - [3.2 è‡ªå®šä¹‰çº¿ç¨‹æ± ](#32-è‡ªå®šä¹‰çº¿ç¨‹æ± )
    - [3.3 OTLP æ‰¹å¤„ç†ä¼˜åŒ–](#33-otlp-æ‰¹å¤„ç†ä¼˜åŒ–)
  - [4. Crossbeam æ— é”å¹¶å‘](#4-crossbeam-æ— é”å¹¶å‘)
    - [4.1 Channel é€šä¿¡](#41-channel-é€šä¿¡)
    - [4.2 åŸå­æ“ä½œ](#42-åŸå­æ“ä½œ)
    - [4.3 Epoch-based å†…å­˜å›æ”¶](#43-epoch-based-å†…å­˜å›æ”¶)
  - [5. åŒæ­¥åŸè¯­](#5-åŒæ­¥åŸè¯­)
    - [5.1 Mutex å’Œ RwLock](#51-mutex-å’Œ-rwlock)
    - [5.2 Atomic ç±»å‹](#52-atomic-ç±»å‹)
    - [5.3 Once å’Œ OnceCell](#53-once-å’Œ-oncecell)
  - [6. å¹¶å‘æ¨¡å¼ä¸æœ€ä½³å®è·µ](#6-å¹¶å‘æ¨¡å¼ä¸æœ€ä½³å®è·µ)
    - [6.1 ç”Ÿäº§è€…-æ¶ˆè´¹è€…](#61-ç”Ÿäº§è€…-æ¶ˆè´¹è€…)
    - [6.2 å·¥ä½œçªƒå–](#62-å·¥ä½œçªƒå–)
    - [6.3 ç®¡é“æ¨¡å¼](#63-ç®¡é“æ¨¡å¼)
  - [7. OTLP å¹¶å‘é›†æˆ](#7-otlp-å¹¶å‘é›†æˆ)
    - [7.1 å¹¶å‘ Span æ”¶é›†](#71-å¹¶å‘-span-æ”¶é›†)
    - [7.2 æ‰¹é‡å¯¼å‡ºä¼˜åŒ–](#72-æ‰¹é‡å¯¼å‡ºä¼˜åŒ–)
    - [7.3 å¤šåç«¯å¹¶å‘](#73-å¤šåç«¯å¹¶å‘)
  - [8. æ€§èƒ½ä¼˜åŒ–](#8-æ€§èƒ½ä¼˜åŒ–)
  - [9. å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ](#9-å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ)
    - [é™·é˜± 1: æ­»é”](#é™·é˜±-1-æ­»é”)
    - [é™·é˜± 2: æ•°æ®ç«äº‰](#é™·é˜±-2-æ•°æ®ç«äº‰)
    - [é™·é˜± 3: Channel é˜»å¡](#é™·é˜±-3-channel-é˜»å¡)
  - [10. å®Œæ•´ç”Ÿäº§ç¤ºä¾‹](#10-å®Œæ•´ç”Ÿäº§ç¤ºä¾‹)
  - [11. å‚è€ƒèµ„æº](#11-å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## 1. Rust å¹¶å‘æ¨¡å‹æ¦‚è¿°

### 1.1 å¹¶å‘ vs å¹¶è¡Œ

```text
å¹¶å‘ (Concurrency):
- å¤šä¸ªä»»åŠ¡äº¤æ›¿æ‰§è¡Œ
- é€»è¾‘ä¸ŠåŒæ—¶è¿›è¡Œ
- å•æ ¸ä¹Ÿå¯ä»¥å®ç°
- ç¤ºä¾‹ï¼šWeb æœåŠ¡å™¨å¤„ç†å¤šä¸ªè¯·æ±‚

å¹¶è¡Œ (Parallelism):
- å¤šä¸ªä»»åŠ¡çœŸæ­£åŒæ—¶æ‰§è¡Œ
- ç‰©ç†ä¸ŠåŒæ—¶è¿›è¡Œ
- éœ€è¦å¤šæ ¸ CPU
- ç¤ºä¾‹ï¼šå›¾åƒå¤„ç†æ‰¹é‡è®¡ç®—

Rust æ”¯æŒä¸¤ç§æ¨¡å¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å¼‚æ­¥å¹¶å‘ (Tokio)  â”‚  æ•°æ®å¹¶è¡Œ (Rayon)  â”‚
â”‚   - é«˜å¹¶å‘ I/O      â”‚  - CPU å¯†é›†è®¡ç®—    â”‚
â”‚   - ä½èµ„æºå ç”¨      â”‚  - è‡ªåŠ¨è´Ÿè½½å‡è¡¡     â”‚
â”‚   - äº‹ä»¶é©±åŠ¨        â”‚  - Work-stealing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1.2 Rust å¹¶å‘å®‰å…¨ä¿è¯

**ç¼–è¯‘æ—¶ä¿è¯**ï¼š

```rust
/// âœ… Send: å¯ä»¥è·¨çº¿ç¨‹ä¼ é€’æ‰€æœ‰æƒ
fn send_example<T: Send>(value: T) {
    std::thread::spawn(move || {
        // value çš„æ‰€æœ‰æƒè½¬ç§»åˆ°æ–°çº¿ç¨‹
        drop(value);
    });
}

/// âœ… Sync: å¯ä»¥è·¨çº¿ç¨‹å…±äº«å¼•ç”¨
fn sync_example<T: Sync>(value: &'static T) {
    std::thread::spawn(move || {
        // å¯ä»¥å®‰å…¨åœ°åœ¨å¤šä¸ªçº¿ç¨‹ä¸­ä½¿ç”¨ value çš„å¼•ç”¨
        use_value(value);
    });
}

/// âŒ ç¼–è¯‘é”™è¯¯ï¼šRc ä¸æ˜¯ Send
fn rc_not_send() {
    let rc = Rc::new(42);
    // std::thread::spawn(move || {
    //     println!("{}", rc); // ç¼–è¯‘é”™è¯¯ï¼
    // });
}

/// âœ… Arc æ˜¯ Send + Sync
fn arc_is_send_sync() {
    let arc = Arc::new(42);
    let arc_clone = Arc::clone(&arc);
    
    std::thread::spawn(move || {
        println!("{}", arc_clone); // âœ… ç¼–è¯‘æˆåŠŸ
    });
}

/// âœ… Rust é˜²æ­¢æ•°æ®ç«äº‰
struct SharedState {
    counter: i32, // âŒ è£¸ç±»å‹ä¸èƒ½è·¨çº¿ç¨‹å…±äº«
}

struct SafeSharedState {
    counter: Arc<Mutex<i32>>, // âœ… ä½¿ç”¨ Mutex ä¿æŠ¤
}
```

---

### 1.3 å¹¶å‘å·¥å…·é€‰æ‹©æŒ‡å—

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   é€‰æ‹©å†³ç­–æ ‘                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä»»åŠ¡ç±»å‹ï¼Ÿ
â”œâ”€ I/O å¯†é›†å‹ (ç½‘ç»œã€æ–‡ä»¶ã€æ•°æ®åº“)
â”‚  â””â”€ ä½¿ç”¨ Tokio å¼‚æ­¥è¿è¡Œæ—¶
â”‚     - tokio::spawn()
â”‚     - async/await
â”‚     - Streams and Channels
â”‚
â”œâ”€ CPU å¯†é›†å‹ (è®¡ç®—ã€è§£æã€å‹ç¼©)
â”‚  â”œâ”€ æ•°æ®å¹¶è¡Œ (å¯åˆ†ç‰‡)
â”‚  â”‚  â””â”€ ä½¿ç”¨ Rayon
â”‚  â”‚     - par_iter()
â”‚  â”‚     - par_chunks()
â”‚  â”‚
â”‚  â””â”€ ä»»åŠ¡å¹¶è¡Œ (å¼‚æ„ä»»åŠ¡)
â”‚     â””â”€ ä½¿ç”¨ std::thread æˆ– Rayon scope
â”‚
â””â”€ æ··åˆå‹ (I/O + CPU)
   â””â”€ Tokio + spawn_blocking()
      æˆ– Tokio + Rayon ç»„åˆ

æ•°æ®å…±äº«ï¼Ÿ
â”œâ”€ æ— å…±äº« (æ¨è)
â”‚  â””â”€ Channel é€šä¿¡ (mpsc, crossbeam)
â”‚
â”œâ”€ åªè¯»å…±äº«
â”‚  â””â”€ Arc<T>
â”‚
â”œâ”€ è¯»å¤šå†™å°‘
â”‚  â””â”€ Arc<RwLock<T>>
â”‚
â””â”€ é¢‘ç¹è¯»å†™
   â””â”€ Arc<Mutex<T>> æˆ– DashMap
```

---

## 2. Tokio å¼‚æ­¥å¹¶å‘

### 2.1 Task å¹¶å‘

**åŸºç¡€ Task å¹¶å‘**ï¼š

```rust
use tokio::task::{self, JoinHandle};
use opentelemetry::global;
use opentelemetry::trace::{Tracer, TracerProvider};

/// âœ… å¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡
async fn concurrent_span_export() -> Result<(), TraceError> {
    let tracer = global::tracer("concurrent");
    
    // åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡
    let tasks: Vec<JoinHandle<Result<(), TraceError>>> = (0..10)
        .map(|i| {
            let tracer = tracer.clone();
            tokio::spawn(async move {
                tracer.in_span(format!("task_{}", i), |_cx| async move {
                    // æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    export_span(i).await
                }).await
            })
        })
        .collect();
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for task in tasks {
        task.await??;
    }
    
    Ok(())
}

/// âœ… é™åˆ¶å¹¶å‘æ•°é‡
async fn limited_concurrency(spans: Vec<SpanData>) -> Result<(), TraceError> {
    use futures::stream::{self, StreamExt};
    
    // æœ€å¤šåŒæ—¶æ‰§è¡Œ 10 ä¸ªä»»åŠ¡
    stream::iter(spans)
        .map(|span| async move {
            export_span_with_retry(span).await
        })
        .buffer_unordered(10) // å¹¶å‘é™åˆ¶
        .try_collect()
        .await
}

/// âœ… åŠ¨æ€å¹¶å‘æ§åˆ¶
async fn adaptive_concurrency(spans: Vec<SpanData>) -> Result<(), TraceError> {
    use tokio::sync::Semaphore;
    
    // ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
    let semaphore = Arc::new(Semaphore::new(10));
    
    let tasks: Vec<_> = spans.into_iter().map(|span| {
        let permit = Arc::clone(&semaphore);
        tokio::spawn(async move {
            // è·å–è®¸å¯
            let _guard = permit.acquire().await.unwrap();
            
            // æ‰§è¡Œä»»åŠ¡
            export_span(span).await
        })
    }).collect();
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡
    for task in tasks {
        task.await??;
    }
    
    Ok(())
}
```

---

### 2.2 Select æ¨¡å¼

**ç«é€Ÿå’Œè¶…æ—¶æ§åˆ¶**ï¼š

```rust
use tokio::select;

/// âœ… å¤šè·¯å¤ç”¨ - å…ˆå®Œæˆè€…èƒœå‡º
async fn select_first_complete(
    primary: impl Future<Output = Result<(), TraceError>>,
    fallback: impl Future<Output = Result<(), TraceError>>,
) -> Result<(), TraceError> {
    select! {
        result = primary => {
            tracing::info!("Primary completed first");
            result
        }
        result = fallback => {
            tracing::warn!("Fallback completed first");
            result
        }
    }
}

/// âœ… å¸¦è¶…æ—¶çš„æ“ä½œ
async fn export_with_timeout(
    spans: Vec<SpanData>,
    timeout: Duration,
) -> Result<(), TraceError> {
    select! {
        result = export_spans(spans) => result,
        _ = tokio::time::sleep(timeout) => {
            Err(TraceError::Timeout)
        }
    }
}

/// âœ… å¯å–æ¶ˆçš„é•¿æ—¶é—´ä»»åŠ¡
async fn cancellable_export(
    spans: Vec<SpanData>,
    cancel_token: tokio_util::sync::CancellationToken,
) -> Result<(), TraceError> {
    select! {
        result = export_spans(spans) => result,
        _ = cancel_token.cancelled() => {
            tracing::info!("Export cancelled");
            Ok(())
        }
    }
}

/// âœ… å¤šè·¯ç›‘å¬ - å¤„ç†å¤šä¸ªäº‹ä»¶æº
async fn multi_source_handling() {
    use tokio::sync::mpsc;
    
    let (tx1, mut rx1) = mpsc::channel::<SpanData>(100);
    let (tx2, mut rx2) = mpsc::channel::<MetricData>(100);
    let (tx3, mut rx3) = mpsc::channel::<LogData>(100);
    
    loop {
        select! {
            Some(span) = rx1.recv() => {
                export_span(span).await.ok();
            }
            Some(metric) = rx2.recv() => {
                export_metric(metric).await.ok();
            }
            Some(log) = rx3.recv() => {
                export_log(log).await.ok();
            }
            else => break, // æ‰€æœ‰ channel å…³é—­
        }
    }
}

/// âœ… ä¼˜å…ˆçº§å¤„ç†
async fn priority_handling() {
    use tokio::sync::mpsc;
    
    let (high_tx, mut high_rx) = mpsc::channel(100);
    let (low_tx, mut low_rx) = mpsc::channel(100);
    
    loop {
        select! {
            // é«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¼˜å…ˆå¤„ç†
            biased;
            
            Some(task) = high_rx.recv() => {
                process_high_priority(task).await;
            }
            Some(task) = low_rx.recv() => {
                process_low_priority(task).await;
            }
        }
    }
}
```

---

### 2.3 Join æ¨¡å¼

**å¹¶å‘æ‰§è¡Œå¹¶ç­‰å¾…æ‰€æœ‰å®Œæˆ**ï¼š

```rust
use tokio::try_join;
use futures::future::{join, join_all, try_join_all};

/// âœ… join! - ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
async fn join_all_exports() -> Result<(), TraceError> {
    let (traces, metrics, logs) = tokio::join!(
        export_traces(vec![]),
        export_metrics(vec![]),
        export_logs(vec![]),
    );
    
    // å¤„ç†ç»“æœ
    traces?;
    metrics?;
    logs?;
    
    Ok(())
}

/// âœ… try_join! - ä»»æ„å¤±è´¥åˆ™å…¨éƒ¨å–æ¶ˆ
async fn try_join_exports() -> Result<(), TraceError> {
    try_join!(
        export_traces(vec![]),
        export_metrics(vec![]),
        export_logs(vec![]),
    )?;
    
    Ok(())
}

/// âœ… join_all - åŠ¨æ€æ•°é‡çš„ä»»åŠ¡
async fn dynamic_join() -> Result<Vec<()>, TraceError> {
    let tasks: Vec<_> = (0..100).map(|i| {
        export_span(create_span(i))
    }).collect();
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let results = join_all(tasks).await;
    
    // è¿‡æ»¤æˆåŠŸçš„ç»“æœ
    results.into_iter().collect()
}

/// âœ… try_join_all - åŠ¨æ€æ•°é‡ + é”™è¯¯å¤„ç†
async fn try_join_all_spans(spans: Vec<SpanData>) -> Result<(), TraceError> {
    let futures = spans.into_iter().map(export_span);
    
    try_join_all(futures).await?;
    
    Ok(())
}

/// âœ… éƒ¨åˆ†å¤±è´¥å®¹å¿
async fn partial_failure_tolerance(spans: Vec<SpanData>) -> Vec<Result<(), TraceError>> {
    let futures = spans.into_iter().map(export_span);
    
    // æ‰€æœ‰ä»»åŠ¡éƒ½ä¼šæ‰§è¡Œï¼Œå³ä½¿æœ‰å¤±è´¥
    join_all(futures).await
}
```

---

### 2.4 Channel é€šä¿¡

**å¤šç§ Channel ç±»å‹å’Œä½¿ç”¨åœºæ™¯**ï¼š

```rust
use tokio::sync::{mpsc, oneshot, broadcast, watch};

/// âœ… mpsc - å¤šç”Ÿäº§è€…å•æ¶ˆè´¹è€… (æœ€å¸¸ç”¨)
async fn mpsc_pipeline() -> Result<(), TraceError> {
    let (tx, mut rx) = mpsc::channel::<SpanData>(1000);
    
    // ç”Ÿäº§è€…ä»»åŠ¡
    let producers: Vec<_> = (0..10).map(|i| {
        let tx = tx.clone();
        tokio::spawn(async move {
            loop {
                let span = generate_span(i);
                if tx.send(span).await.is_err() {
                    break; // Channel å…³é—­
                }
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
        })
    }).collect();
    drop(tx); // é‡Šæ”¾åŸå§‹å‘é€ç«¯
    
    // æ¶ˆè´¹è€…ä»»åŠ¡
    let consumer = tokio::spawn(async move {
        while let Some(span) = rx.recv().await {
            export_span(span).await.ok();
        }
    });
    
    // ç­‰å¾…å®Œæˆ
    for producer in producers {
        producer.await.ok();
    }
    consumer.await.ok();
    
    Ok(())
}

/// âœ… oneshot - ä¸€æ¬¡æ€§é€šä¿¡
async fn oneshot_request_response() -> Result<String, TraceError> {
    let (tx, rx) = oneshot::channel();
    
    tokio::spawn(async move {
        let result = perform_expensive_operation().await;
        tx.send(result).ok();
    });
    
    // ç­‰å¾…ç»“æœ
    rx.await.map_err(|_| TraceError::ChannelClosed)
}

/// âœ… broadcast - å¹¿æ’­é€šé“
async fn broadcast_to_multiple_exporters() -> Result<(), TraceError> {
    let (tx, _rx) = broadcast::channel(100);
    
    // åˆ›å»ºå¤šä¸ªè®¢é˜…è€…
    let exporters: Vec<_> = (0..3).map(|i| {
        let mut rx = tx.subscribe();
        tokio::spawn(async move {
            while let Ok(span) = rx.recv().await {
                export_to_backend(i, span).await.ok();
            }
        })
    }).collect();
    
    // å¹¿æ’­ spans
    for i in 0..100 {
        let span = generate_span(i);
        tx.send(span).ok();
    }
    drop(tx); // å…³é—­å¹¿æ’­
    
    // ç­‰å¾…æ‰€æœ‰å¯¼å‡ºå™¨å®Œæˆ
    for exporter in exporters {
        exporter.await.ok();
    }
    
    Ok(())
}

/// âœ… watch - çŠ¶æ€ç›‘æ§
async fn watch_exporter_state() -> Result<(), TraceError> {
    let (tx, mut rx) = watch::channel(ExporterState::Idle);
    
    // çŠ¶æ€ç›‘æ§ä»»åŠ¡
    tokio::spawn(async move {
        loop {
            rx.changed().await.ok();
            let state = *rx.borrow();
            tracing::info!("Exporter state changed: {:?}", state);
            
            if matches!(state, ExporterState::Stopped) {
                break;
            }
        }
    });
    
    // æ¨¡æ‹ŸçŠ¶æ€å˜åŒ–
    tx.send(ExporterState::Running).ok();
    tokio::time::sleep(Duration::from_secs(1)).await;
    
    tx.send(ExporterState::Paused).ok();
    tokio::time::sleep(Duration::from_secs(1)).await;
    
    tx.send(ExporterState::Stopped).ok();
    
    Ok(())
}

#[derive(Debug, Clone, Copy)]
enum ExporterState {
    Idle,
    Running,
    Paused,
    Stopped,
}
```

---

## 3. Rayon æ•°æ®å¹¶è¡Œ

### 3.1 å¹¶è¡Œè¿­ä»£å™¨

**CPU å¯†é›†å‹æ•°æ®å¤„ç†**ï¼š

```rust
use rayon::prelude::*;

/// âœ… å¹¶è¡Œå¤„ç† Spans
fn parallel_span_processing(spans: Vec<SpanData>) -> Vec<ProcessedSpan> {
    let tracer = global::tracer("parallel");
    
    spans.par_iter() // å¹¶è¡Œè¿­ä»£å™¨
        .map(|span| {
            // æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹å¤„ç†
            process_span_intensive(span)
        })
        .collect()
}

/// âœ… å¹¶è¡Œè¿‡æ»¤å’Œæ˜ å°„
fn parallel_filter_map(spans: Vec<SpanData>) -> Vec<SpanData> {
    spans.par_iter()
        .filter(|span| span.duration > Duration::from_millis(100))
        .map(|span| enrich_span(span.clone()))
        .collect()
}

/// âœ… å¹¶è¡Œèšåˆ
fn parallel_aggregation(spans: Vec<SpanData>) -> Statistics {
    spans.par_iter()
        .map(|span| (span.duration.as_millis(), 1))
        .reduce(
            || (0, 0),
            |(sum1, count1), (sum2, count2)| (sum1 + sum2, count1 + count2)
        );
    
    Statistics {
        total: sum,
        count,
        average: sum / count,
    }
}

/// âœ… å¹¶è¡Œåˆ†å—å¤„ç†
fn parallel_chunks(spans: Vec<SpanData>) -> Result<(), TraceError> {
    spans.par_chunks(512) // åˆ†å—å¹¶è¡Œå¤„ç†
        .try_for_each(|chunk| {
            export_batch(chunk.to_vec())
        })
}

/// âœ… è‡ªå®šä¹‰å¹¶è¡Œåº¦
fn custom_parallelism(data: Vec<SpanData>) -> Vec<ProcessedSpan> {
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(num_cpus::get())
        .thread_name(|i| format!("rayon-worker-{}", i))
        .build()
        .unwrap();
    
    pool.install(|| {
        data.par_iter()
            .map(process_span_intensive)
            .collect()
    })
}
```

---

### 3.2 è‡ªå®šä¹‰çº¿ç¨‹æ± 

**ç”Ÿäº§çº§ Rayon é…ç½®**ï¼š

```rust
use rayon::{ThreadPool, ThreadPoolBuilder};
use std::sync::Arc;

/// âœ… åˆ›å»ºä¸“ç”¨çº¿ç¨‹æ± 
fn create_processing_pool() -> Arc<ThreadPool> {
    let pool = ThreadPoolBuilder::new()
        .num_threads(num_cpus::get())
        .thread_name(|i| format!("otlp-processor-{}", i))
        .stack_size(2 * 1024 * 1024) // 2MB æ ˆ
        .panic_handler(|panic_info| {
            tracing::error!("Thread panicked: {:?}", panic_info);
        })
        .build()
        .expect("Failed to create thread pool");
    
    Arc::new(pool)
}

/// âœ… ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± 
fn use_custom_pool(pool: Arc<ThreadPool>, spans: Vec<SpanData>) -> Vec<ProcessedSpan> {
    pool.install(|| {
        spans.par_iter()
            .map(process_span_intensive)
            .collect()
    })
}

/// âœ… å¤šçº§å¹¶è¡Œ - Tokio + Rayon
async fn hybrid_parallelism(batches: Vec<Vec<SpanData>>) -> Result<(), TraceError> {
    let pool = create_processing_pool();
    
    // Tokio å¼‚æ­¥å±‚ï¼šI/O å¹¶å‘
    let futures = batches.into_iter().map(|batch| {
        let pool = Arc::clone(&pool);
        tokio::task::spawn_blocking(move || {
            // Rayon å±‚ï¼šCPU å¹¶è¡Œ
            pool.install(|| {
                batch.par_iter()
                    .map(process_span_intensive)
                    .collect::<Vec<_>>()
            })
        })
    });
    
    // ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡
    let results = join_all(futures).await;
    
    Ok(())
}
```

---

### 3.3 OTLP æ‰¹å¤„ç†ä¼˜åŒ–

**é«˜æ€§èƒ½æ‰¹å¤„ç†æ¨¡å¼**ï¼š

```rust
/// âœ… å¹¶è¡Œæ‰¹å¤„ç†ä¼˜åŒ–
fn optimized_batch_processing(
    spans: Vec<SpanData>,
    batch_size: usize,
) -> Result<(), TraceError> {
    use rayon::prelude::*;
    
    // 1. å¹¶è¡Œé¢„å¤„ç†
    let preprocessed: Vec<_> = spans.par_iter()
        .map(|span| {
            // CPU å¯†é›†å‹ï¼šåºåˆ—åŒ–ã€å‹ç¼©
            let serialized = serialize_span(span)?;
            let compressed = compress_data(&serialized)?;
            Ok(compressed)
        })
        .collect::<Result<_, _>>()?;
    
    // 2. å¹¶è¡Œåˆ†æ‰¹
    preprocessed.par_chunks(batch_size)
        .try_for_each(|chunk| {
            // åŒæ­¥å¯¼å‡º
            sync_export_batch(chunk)
        })?;
    
    Ok(())
}

/// âœ… æµæ°´çº¿å¹¶è¡Œ
fn pipeline_parallelism(spans: Vec<SpanData>) -> Result<(), TraceError> {
    use crossbeam::channel::bounded;
    use std::thread;
    
    let (tx1, rx1) = bounded(1000);
    let (tx2, rx2) = bounded(1000);
    
    // é˜¶æ®µ1ï¼šé¢„å¤„ç†
    let stage1 = thread::spawn(move || {
        spans.par_iter().try_for_each(|span| {
            let processed = preprocess_span(span)?;
            tx1.send(processed).ok();
            Ok::<_, TraceError>(())
        })
    });
    
    // é˜¶æ®µ2ï¼šåºåˆ—åŒ–
    let stage2 = thread::spawn(move || {
        while let Ok(span) = rx1.recv() {
            let serialized = serialize_span(&span)?;
            tx2.send(serialized).ok();
        }
        Ok::<_, TraceError>(())
    });
    
    // é˜¶æ®µ3ï¼šå¯¼å‡º
    let stage3 = thread::spawn(move || {
        while let Ok(data) = rx2.recv() {
            export_data(data)?;
        }
        Ok::<_, TraceError>(())
    });
    
    // ç­‰å¾…æ‰€æœ‰é˜¶æ®µ
    stage1.join().unwrap()?;
    stage2.join().unwrap()?;
    stage3.join().unwrap()?;
    
    Ok(())
}
```

---

## 4. Crossbeam æ— é”å¹¶å‘

### 4.1 Channel é€šä¿¡

**é«˜æ€§èƒ½ Channel å®ç°**ï¼š

```rust
use crossbeam::channel::{bounded, unbounded, select};

/// âœ… bounded channel - èƒŒå‹æ§åˆ¶
fn bounded_channel_example() -> Result<(), TraceError> {
    let (tx, rx) = bounded::<SpanData>(1000);
    
    // ç”Ÿäº§è€…
    std::thread::spawn(move || {
        for i in 0..10000 {
            // send() ä¼šåœ¨æ»¡æ—¶é˜»å¡
            tx.send(generate_span(i)).ok();
        }
    });
    
    // æ¶ˆè´¹è€…
    while let Ok(span) = rx.recv() {
        process_span(span);
    }
    
    Ok(())
}

/// âœ… unbounded channel - æ— é™ç¼“å†²
fn unbounded_channel_example() -> Result<(), TraceError> {
    let (tx, rx) = unbounded::<SpanData>();
    
    // ä¸ä¼šé˜»å¡ï¼Œä½†å¯èƒ½å†…å­˜æº¢å‡º
    for i in 0..1000000 {
        tx.send(generate_span(i)).ok();
    }
    
    Ok(())
}

/// âœ… select! å® - å¤šè·¯å¤ç”¨
fn crossbeam_select() -> Result<(), TraceError> {
    let (tx1, rx1) = bounded(100);
    let (tx2, rx2) = bounded(100);
    
    loop {
        select! {
            recv(rx1) -> msg => {
                if let Ok(span) = msg {
                    process_span_type1(span);
                } else {
                    break; // Channel å…³é—­
                }
            }
            recv(rx2) -> msg => {
                if let Ok(span) = msg {
                    process_span_type2(span);
                } else {
                    break;
                }
            }
        }
    }
    
    Ok(())
}

/// âœ… å¤šç”Ÿäº§è€…å¤šæ¶ˆè´¹è€…
fn mpmc_pattern() -> Result<(), TraceError> {
    let (tx, rx) = bounded(1000);
    
    // å¤šä¸ªç”Ÿäº§è€…
    let producers: Vec<_> = (0..4).map(|i| {
        let tx = tx.clone();
        std::thread::spawn(move || {
            for j in 0..1000 {
                tx.send(generate_span(i * 1000 + j)).ok();
            }
        })
    }).collect();
    drop(tx);
    
    // å¤šä¸ªæ¶ˆè´¹è€…
    let consumers: Vec<_> = (0..4).map(|_| {
        let rx = rx.clone();
        std::thread::spawn(move || {
            while let Ok(span) = rx.recv() {
                process_span(span);
            }
        })
    }).collect();
    
    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹
    for producer in producers {
        producer.join().ok();
    }
    for consumer in consumers {
        consumer.join().ok();
    }
    
    Ok(())
}
```

---

### 4.2 åŸå­æ“ä½œ

**æ— é”æ•°æ®ç»“æ„**ï¼š

```rust
use crossbeam::atomic::AtomicCell;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};

/// âœ… åŸå­è®¡æ•°å™¨
struct SpanCounter {
    total: AtomicUsize,
    exported: AtomicUsize,
    failed: AtomicUsize,
}

impl SpanCounter {
    fn new() -> Self {
        Self {
            total: AtomicUsize::new(0),
            exported: AtomicUsize::new(0),
            failed: AtomicUsize::new(0),
        }
    }
    
    fn increment_total(&self) {
        self.total.fetch_add(1, Ordering::Relaxed);
    }
    
    fn increment_exported(&self) {
        self.exported.fetch_add(1, Ordering::Release);
    }
    
    fn get_stats(&self) -> (usize, usize, usize) {
        (
            self.total.load(Ordering::Relaxed),
            self.exported.load(Ordering::Acquire),
            self.failed.load(Ordering::Relaxed),
        )
    }
}

/// âœ… AtomicCell - ä»»æ„ç±»å‹çš„åŸå­æ“ä½œ
use crossbeam::atomic::AtomicCell;

#[derive(Clone, Copy)]
struct ExporterConfig {
    batch_size: usize,
    timeout_ms: u64,
}

struct DynamicExporter {
    config: AtomicCell<ExporterConfig>,
}

impl DynamicExporter {
    fn update_config(&self, new_config: ExporterConfig) {
        self.config.store(new_config);
    }
    
    fn get_config(&self) -> ExporterConfig {
        self.config.load()
    }
}

/// âœ… æ— é”æ ˆ
use crossbeam::queue::ArrayQueue;

struct LockFreeSpanQueue {
    queue: ArrayQueue<SpanData>,
}

impl LockFreeSpanQueue {
    fn new(capacity: usize) -> Self {
        Self {
            queue: ArrayQueue::new(capacity),
        }
    }
    
    fn push(&self, span: SpanData) -> Result<(), SpanData> {
        self.queue.push(span)
    }
    
    fn pop(&self) -> Option<SpanData> {
        self.queue.pop()
    }
}
```

---

### 4.3 Epoch-based å†…å­˜å›æ”¶

**å®‰å…¨çš„æ— é”æ•°æ®ç»“æ„**ï¼š

```rust
use crossbeam::epoch::{self, Atomic, Owned};
use std::sync::atomic::Ordering;

/// âœ… Treiber Stack - æ— é”æ ˆ
struct TreiberStack<T> {
    head: Atomic<Node<T>>,
}

struct Node<T> {
    data: T,
    next: Atomic<Node<T>>,
}

impl<T> TreiberStack<T> {
    fn new() -> Self {
        Self {
            head: Atomic::null(),
        }
    }
    
    fn push(&self, data: T) {
        let mut node = Owned::new(Node {
            data,
            next: Atomic::null(),
        });
        
        let guard = epoch::pin();
        
        loop {
            let head = self.head.load(Ordering::Acquire, &guard);
            node.next.store(head, Ordering::Relaxed);
            
            match self.head.compare_exchange(
                head,
                node,
                Ordering::Release,
                Ordering::Acquire,
                &guard,
            ) {
                Ok(_) => break,
                Err(e) => node = e.new,
            }
        }
    }
    
    fn pop(&self) -> Option<T> {
        let guard = epoch::pin();
        
        loop {
            let head = self.head.load(Ordering::Acquire, &guard);
            
            match unsafe { head.as_ref() } {
                Some(h) => {
                    let next = h.next.load(Ordering::Acquire, &guard);
                    
                    if self.head.compare_exchange(
                        head,
                        next,
                        Ordering::Release,
                        Ordering::Acquire,
                        &guard,
                    ).is_ok() {
                        unsafe {
                            // å®‰å…¨åœ°å»¶è¿Ÿé‡Šæ”¾å†…å­˜
                            guard.defer_destroy(head);
                            return Some(std::ptr::read(&(*h).data));
                        }
                    }
                }
                None => return None,
            }
        }
    }
}
```

---

## 5. åŒæ­¥åŸè¯­

### 5.1 Mutex å’Œ RwLock

**æ ‡å‡†åº“ vs Parking Lot**ï¼š

```rust
use std::sync::{Mutex, RwLock};
use parking_lot::{Mutex as ParkingMutex, RwLock as ParkingRwLock};

/// âœ… æ ‡å‡†åº“ Mutex
struct StdMutexExporter {
    spans: Mutex<Vec<SpanData>>,
}

impl StdMutexExporter {
    fn add_span(&self, span: SpanData) {
        let mut spans = self.spans.lock().unwrap();
        spans.push(span);
    }
}

/// âœ… Parking Lot Mutex (æ¨èç”Ÿäº§ç¯å¢ƒ)
/// 
/// ä¼˜åŠ¿ï¼š
/// - æ›´å¿«çš„é”è·å– (æ— ç³»ç»Ÿè°ƒç”¨)
/// - æ›´å°çš„å†…å­˜å ç”¨
/// - æ— æ¯’åŒ–æœºåˆ¶ (panic æ—¶è‡ªåŠ¨è§£é”)
struct ParkingMutexExporter {
    spans: ParkingMutex<Vec<SpanData>>,
}

impl ParkingMutexExporter {
    fn add_span(&self, span: SpanData) {
        let mut spans = self.spans.lock();
        spans.push(span);
        // è‡ªåŠ¨è§£é”ï¼Œå³ä½¿ panic
    }
}

/// âœ… RwLock - è¯»å¤šå†™å°‘åœºæ™¯
struct SharedConfig {
    data: ParkingRwLock<ExporterConfig>,
}

impl SharedConfig {
    fn read_config(&self) -> ExporterConfig {
        // å¤šä¸ªè¯»å–è€…å¯ä»¥å¹¶å‘
        *self.data.read()
    }
    
    fn update_config(&self, new_config: ExporterConfig) {
        // å†™å…¥æ—¶ç‹¬å 
        *self.data.write() = new_config;
    }
}

/// âœ… é¿å…æ­»é” - é”é¡ºåº
struct OrderedLocks {
    lock_a: Mutex<i32>,
    lock_b: Mutex<i32>,
}

impl OrderedLocks {
    fn safe_operation(&self) {
        // å§‹ç»ˆæŒ‰ç›¸åŒé¡ºåºè·å–é”
        let a = self.lock_a.lock().unwrap();
        let b = self.lock_b.lock().unwrap();
        
        // ä½¿ç”¨é”
        println!("{} {}", *a, *b);
    }
}
```

---

### 5.2 Atomic ç±»å‹

**ç»†ç²’åº¦åŸå­æ“ä½œ**ï¼š

```rust
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};

/// âœ… åŸå­æ ‡å¿—
struct ExporterState {
    running: AtomicBool,
    paused: AtomicBool,
}

impl ExporterState {
    fn new() -> Self {
        Self {
            running: AtomicBool::new(false),
            paused: AtomicBool::new(false),
        }
    }
    
    fn start(&self) {
        self.running.store(true, Ordering::Release);
        self.paused.store(false, Ordering::Release);
    }
    
    fn pause(&self) {
        self.paused.store(true, Ordering::Release);
    }
    
    fn is_active(&self) -> bool {
        self.running.load(Ordering::Acquire) 
            && !self.paused.load(Ordering::Acquire)
    }
}

/// âœ… åŸå­è®¡æ•°å™¨
struct Metrics {
    requests: AtomicU64,
    successes: AtomicU64,
    failures: AtomicU64,
}

impl Metrics {
    fn record_success(&self) {
        self.requests.fetch_add(1, Ordering::Relaxed);
        self.successes.fetch_add(1, Ordering::Relaxed);
    }
    
    fn record_failure(&self) {
        self.requests.fetch_add(1, Ordering::Relaxed);
        self.failures.fetch_add(1, Ordering::Relaxed);
    }
    
    fn get_success_rate(&self) -> f64 {
        let requests = self.requests.load(Ordering::Relaxed);
        let successes = self.successes.load(Ordering::Relaxed);
        
        if requests == 0 {
            0.0
        } else {
            successes as f64 / requests as f64
        }
    }
}

/// âœ… Memory Ordering æŒ‡å—
/// 
/// - Relaxed: æœ€å¿«ï¼Œä½†æ— é¡ºåºä¿è¯
///   é€‚ç”¨äºï¼šç®€å•è®¡æ•°å™¨
/// 
/// - Release/Acquire: å»ºç«‹happens-beforeå…³ç³»
///   é€‚ç”¨äºï¼šå‘å¸ƒ/è®¢é˜…æ¨¡å¼
/// 
/// - SeqCst: æœ€å¼ºï¼Œå…¨å±€é¡ºåºä¸€è‡´æ€§
///   é€‚ç”¨äºï¼šéœ€è¦ä¸¥æ ¼é¡ºåºçš„åœºæ™¯
```

---

### 5.3 Once å’Œ OnceCell

**ä¸€æ¬¡æ€§åˆå§‹åŒ–**ï¼š

```rust
use std::sync::Once;
use once_cell::sync::{OnceCell, Lazy};

/// âœ… Once - ä¸€æ¬¡æ€§åˆå§‹åŒ–
static INIT: Once = Once::new();
static mut TRACER: Option<opentelemetry::global::BoxedTracer> = None;

fn get_tracer() -> &'static opentelemetry::global::BoxedTracer {
    unsafe {
        INIT.call_once(|| {
            TRACER = Some(init_tracer_blocking());
        });
        TRACER.as_ref().unwrap()
    }
}

/// âœ… OnceCell - ç±»å‹å®‰å…¨çš„ä¸€æ¬¡æ€§åˆå§‹åŒ–
static TRACER_CELL: OnceCell<opentelemetry::global::BoxedTracer> = OnceCell::new();

fn get_tracer_safe() -> &'static opentelemetry::global::BoxedTracer {
    TRACER_CELL.get_or_init(|| init_tracer_blocking())
}

/// âœ… Lazy - å»¶è¿Ÿåˆå§‹åŒ–
static EXPORTER: Lazy<Arc<dyn SpanExporter>> = Lazy::new(|| {
    Arc::new(create_exporter())
});

fn use_lazy_exporter() {
    // ç¬¬ä¸€æ¬¡è®¿é—®æ—¶åˆå§‹åŒ–
    EXPORTER.export(vec![]).ok();
}
```

---

## 6. å¹¶å‘æ¨¡å¼ä¸æœ€ä½³å®è·µ

### 6.1 ç”Ÿäº§è€…-æ¶ˆè´¹è€…

**ç»å…¸å¹¶å‘æ¨¡å¼**ï¼š

```rust
use crossbeam::channel::bounded;

/// âœ… å•ç”Ÿäº§è€…-å•æ¶ˆè´¹è€…
fn spsc_pattern() {
    let (tx, rx) = bounded(1000);
    
    let producer = std::thread::spawn(move || {
        for i in 0..10000 {
            tx.send(generate_span(i)).ok();
        }
    });
    
    let consumer = std::thread::spawn(move || {
        while let Ok(span) = rx.recv() {
            export_span_sync(span).ok();
        }
    });
    
    producer.join().unwrap();
    consumer.join().unwrap();
}

/// âœ… å¤šç”Ÿäº§è€…-å•æ¶ˆè´¹è€… (MPSC)
fn mpsc_pattern() {
    let (tx, rx) = bounded(1000);
    
    // å¤šä¸ªç”Ÿäº§è€…
    let producers: Vec<_> = (0..4).map(|i| {
        let tx = tx.clone();
        std::thread::spawn(move || {
            for j in 0..1000 {
                tx.send(generate_span(i * 1000 + j)).ok();
            }
        })
    }).collect();
    drop(tx);
    
    // å•ä¸ªæ¶ˆè´¹è€…
    let consumer = std::thread::spawn(move || {
        while let Ok(span) = rx.recv() {
            export_span_sync(span).ok();
        }
    });
    
    for producer in producers {
        producer.join().unwrap();
    }
    consumer.join().unwrap();
}

/// âœ… å¤šç”Ÿäº§è€…-å¤šæ¶ˆè´¹è€… (MPMC)
fn mpmc_pattern() {
    let (tx, rx) = bounded(1000);
    
    // 4 ä¸ªç”Ÿäº§è€…
    let producers: Vec<_> = (0..4).map(|i| {
        let tx = tx.clone();
        std::thread::spawn(move || {
            for j in 0..1000 {
                tx.send(generate_span(i * 1000 + j)).ok();
            }
        })
    }).collect();
    drop(tx);
    
    // 4 ä¸ªæ¶ˆè´¹è€…
    let consumers: Vec<_> = (0..4).map(|_| {
        let rx = rx.clone();
        std::thread::spawn(move || {
            while let Ok(span) = rx.recv() {
                export_span_sync(span).ok();
            }
        })
    }).collect();
    
    for producer in producers {
        producer.join().unwrap();
    }
    for consumer in consumers {
        consumer.join().unwrap();
    }
}
```

---

### 6.2 å·¥ä½œçªƒå–

**Rayon å·¥ä½œçªƒå–æ¨¡å¼**ï¼š

```rust
use rayon::prelude::*;

/// âœ… å·¥ä½œçªƒå–è‡ªåŠ¨è´Ÿè½½å‡è¡¡
fn work_stealing_pattern(tasks: Vec<Task>) -> Vec<Result> {
    // Rayon è‡ªåŠ¨å®ç°å·¥ä½œçªƒå–
    // ç©ºé—²çº¿ç¨‹ä¼š"å·å–"å…¶ä»–çº¿ç¨‹çš„ä»»åŠ¡
    tasks.par_iter()
        .map(|task| process_task(task))
        .collect()
}

/// âœ… è‡ªå®šä¹‰å·¥ä½œçªƒå–é˜Ÿåˆ—
use crossbeam::deque::{Injector, Stealer, Worker};

struct WorkStealingQueue {
    injector: Injector<SpanData>,
    workers: Vec<Worker<SpanData>>,
    stealers: Vec<Stealer<SpanData>>,
}

impl WorkStealingQueue {
    fn new(num_workers: usize) -> Self {
        let workers: Vec<_> = (0..num_workers)
            .map(|_| Worker::new_lifo())
            .collect();
        
        let stealers = workers.iter()
            .map(|w| w.stealer())
            .collect();
        
        Self {
            injector: Injector::new(),
            workers,
            stealers,
        }
    }
    
    fn push(&self, span: SpanData) {
        self.injector.push(span);
    }
    
    fn steal_work(&self, worker_id: usize) -> Option<SpanData> {
        // å°è¯•ä»æœ¬åœ°é˜Ÿåˆ—è·å–
        if let Some(span) = self.workers[worker_id].pop() {
            return Some(span);
        }
        
        // å°è¯•ä»å…¨å±€é˜Ÿåˆ—è·å–
        loop {
            match self.injector.steal() {
                crossbeam::deque::Steal::Success(span) => return Some(span),
                crossbeam::deque::Steal::Empty => break,
                crossbeam::deque::Steal::Retry => continue,
            }
        }
        
        // å°è¯•ä»å…¶ä»–workerå·å–
        for (i, stealer) in self.stealers.iter().enumerate() {
            if i == worker_id {
                continue;
            }
            
            loop {
                match stealer.steal() {
                    crossbeam::deque::Steal::Success(span) => return Some(span),
                    crossbeam::deque::Steal::Empty => break,
                    crossbeam::deque::Steal::Retry => continue,
                }
            }
        }
        
        None
    }
}
```

---

### 6.3 ç®¡é“æ¨¡å¼

**æµæ°´çº¿å¹¶å‘å¤„ç†**ï¼š

```rust
use crossbeam::channel::bounded;

/// âœ… ä¸‰é˜¶æ®µç®¡é“
fn pipeline_pattern(spans: Vec<SpanData>) -> Result<(), TraceError> {
    let (tx1, rx1) = bounded(100);
    let (tx2, rx2) = bounded(100);
    let (tx3, rx3) = bounded(100);
    
    // é˜¶æ®µ1ï¼šé¢„å¤„ç†
    let stage1 = std::thread::spawn(move || {
        for span in spans {
            let processed = preprocess(span);
            tx1.send(processed).ok();
        }
    });
    
    // é˜¶æ®µ2ï¼šåºåˆ—åŒ–
    let stage2 = std::thread::spawn(move || {
        while let Ok(span) = rx1.recv() {
            let serialized = serialize(span);
            tx2.send(serialized).ok();
        }
    });
    
    // é˜¶æ®µ3ï¼šå‹ç¼©
    let stage3 = std::thread::spawn(move || {
        while let Ok(data) = rx2.recv() {
            let compressed = compress(data);
            tx3.send(compressed).ok();
        }
    });
    
    // é˜¶æ®µ4ï¼šå¯¼å‡º
    let stage4 = std::thread::spawn(move || {
        while let Ok(data) = rx3.recv() {
            export(data).ok();
        }
    });
    
    stage1.join().unwrap();
    stage2.join().unwrap();
    stage3.join().unwrap();
    stage4.join().unwrap();
    
    Ok(())
}

/// âœ… å¹¶è¡Œç®¡é“ - æ¯é˜¶æ®µå¤šworker
fn parallel_pipeline(spans: Vec<SpanData>) -> Result<(), TraceError> {
    let (tx1, rx1) = bounded(1000);
    let (tx2, rx2) = bounded(1000);
    
    // ç”Ÿäº§è€…
    std::thread::spawn(move || {
        for span in spans {
            tx1.send(span).ok();
        }
    });
    
    // é˜¶æ®µ1ï¼š4ä¸ªå¹¶è¡Œworker
    for _ in 0..4 {
        let rx = rx1.clone();
        let tx = tx2.clone();
        std::thread::spawn(move || {
            while let Ok(span) = rx.recv() {
                let processed = process_intensive(span);
                tx.send(processed).ok();
            }
        });
    }
    drop(tx2);
    
    // é˜¶æ®µ2ï¼šå¯¼å‡º
    while let Ok(span) = rx2.recv() {
        export(span).ok();
    }
    
    Ok(())
}
```

---

## 7. OTLP å¹¶å‘é›†æˆ

### 7.1 å¹¶å‘ Span æ”¶é›†

**å¤šæºå¹¶å‘æ”¶é›†**ï¼š

```rust
/// âœ… å¹¶å‘æ”¶é›†å¤šä¸ªæœåŠ¡çš„spans
async fn concurrent_span_collection() -> Result<(), TraceError> {
    use tokio::sync::mpsc;
    
    let (tx, mut rx) = mpsc::channel(10000);
    
    // å¯åŠ¨å¤šä¸ªcollector
    let collectors: Vec<_> = vec!["service-a", "service-b", "service-c"]
        .into_iter()
        .map(|service| {
            let tx = tx.clone();
            tokio::spawn(async move {
                collect_from_service(service, tx).await
            })
        })
        .collect();
    drop(tx);
    
    // èšåˆå¹¶å¯¼å‡º
    let mut batch = Vec::with_capacity(512);
    while let Some(span) = rx.recv().await {
        batch.push(span);
        
        if batch.len() >= 512 {
            export_batch(batch.drain(..).collect()).await?;
        }
    }
    
    // å¯¼å‡ºå‰©ä½™
    if !batch.is_empty() {
        export_batch(batch).await?;
    }
    
    // ç­‰å¾…æ‰€æœ‰collectors
    for collector in collectors {
        collector.await??;
    }
    
    Ok(())
}

async fn collect_from_service(
    service: &str,
    tx: mpsc::Sender<SpanData>,
) -> Result<(), TraceError> {
    // æ¨¡æ‹Ÿä»æœåŠ¡æ”¶é›†spans
    loop {
        let spans = fetch_spans_from_service(service).await?;
        
        for span in spans {
            tx.send(span).await.ok();
        }
        
        tokio::time::sleep(Duration::from_secs(5)).await;
    }
}
```

---

### 7.2 æ‰¹é‡å¯¼å‡ºä¼˜åŒ–

**é«˜ååé‡æ‰¹å¤„ç†**ï¼š

```rust
use tokio::sync::mpsc;
use tokio::time::{interval, Duration};

/// âœ… è‡ªé€‚åº”æ‰¹å¤„ç†
struct AdaptiveBatchExporter {
    sender: mpsc::Sender<SpanData>,
}

impl AdaptiveBatchExporter {
    fn new(exporter: Arc<dyn SpanExporter>) -> Self {
        let (tx, rx) = mpsc::channel(10000);
        
        tokio::spawn(async move {
            Self::batch_worker(rx, exporter).await;
        });
        
        Self { sender: tx }
    }
    
    async fn batch_worker(
        mut rx: mpsc::Receiver<SpanData>,
        exporter: Arc<dyn SpanExporter>,
    ) {
        let mut batch = Vec::with_capacity(1024);
        let mut ticker = interval(Duration::from_secs(5));
        
        loop {
            tokio::select! {
                // æ¥æ”¶ span
                Some(span) = rx.recv() => {
                    batch.push(span);
                    
                    // è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³å¯¼å‡º
                    if batch.len() >= 1024 {
                        if let Err(e) = exporter.export(batch.drain(..).collect()).await {
                            tracing::error!("Export failed: {}", e);
                        }
                    }
                }
                
                // å®šæ—¶å¯¼å‡º
                _ = ticker.tick() => {
                    if !batch.is_empty() {
                        if let Err(e) = exporter.export(batch.drain(..).collect()).await {
                            tracing::error!("Export failed: {}", e);
                        }
                    }
                }
                
                // Channel å…³é—­
                else => break,
            }
        }
        
        // å¯¼å‡ºå‰©ä½™
        if !batch.is_empty() {
            exporter.export(batch).await.ok();
        }
    }
    
    async fn export(&self, span: SpanData) -> Result<(), TraceError> {
        self.sender.send(span).await
            .map_err(|_| TraceError::ChannelClosed)
    }
}
```

---

### 7.3 å¤šåç«¯å¹¶å‘

**åŒæ—¶å¯¼å‡ºåˆ°å¤šä¸ªåç«¯**ï¼š

```rust
/// âœ… å¹¶å‘å¤šåç«¯å¯¼å‡º
struct MultiBackendExporter {
    backends: Vec<Arc<dyn SpanExporter>>,
}

impl MultiBackendExporter {
    fn new(backends: Vec<Arc<dyn SpanExporter>>) -> Self {
        Self { backends }
    }
    
    async fn export(&self, spans: Vec<SpanData>) -> Result<(), TraceError> {
        // å¹¶å‘å¯¼å‡ºåˆ°æ‰€æœ‰åç«¯
        let futures = self.backends.iter().map(|backend| {
            let spans = spans.clone();
            let backend = Arc::clone(backend);
            async move {
                backend.export(spans).await
            }
        });
        
        // ç­‰å¾…æ‰€æœ‰åç«¯å®Œæˆ
        let results = join_all(futures).await;
        
        // æ£€æŸ¥å¤±è´¥
        let failures: Vec<_> = results.into_iter()
            .filter_map(|r| r.err())
            .collect();
        
        if !failures.is_empty() {
            tracing::warn!("{} backend(s) failed", failures.len());
        }
        
        Ok(())
    }
}

/// âœ… å¸¦ä¼˜å…ˆçº§çš„å¤šåç«¯å¯¼å‡º
struct PrioritizedExporter {
    primary: Arc<dyn SpanExporter>,
    fallback: Arc<dyn SpanExporter>,
    async_backup: Arc<dyn SpanExporter>,
}

impl PrioritizedExporter {
    async fn export(&self, spans: Vec<SpanData>) -> Result<(), TraceError> {
        // 1. å°è¯•ä¸»åç«¯
        match self.primary.export(spans.clone()).await {
            Ok(()) => {
                // å¼‚æ­¥å¯¼å‡ºåˆ°å¤‡ä»½ï¼ˆä¸ç­‰å¾…ï¼‰
                let backup = Arc::clone(&self.async_backup);
                let spans_clone = spans.clone();
                tokio::spawn(async move {
                    backup.export(spans_clone).await.ok();
                });
                
                return Ok(());
            }
            Err(e) => {
                tracing::warn!("Primary export failed: {}", e);
            }
        }
        
        // 2. ä½¿ç”¨å¤‡ç”¨åç«¯
        self.fallback.export(spans).await
    }
}
```

---

## 8. æ€§èƒ½ä¼˜åŒ–

**ç”Ÿäº§çº§æ€§èƒ½è°ƒä¼˜**ï¼š

```rust
/// âœ… 1. å‡å°‘é”ç«äº‰
/// 
/// ä¸å¥½ï¼šå•ä¸ªå…¨å±€é”
struct BadSpanBuffer {
    buffer: Mutex<Vec<SpanData>>,
}

/// å¥½ï¼šåˆ†ç‰‡é”
struct GoodSpanBuffer {
    shards: Vec<Mutex<Vec<SpanData>>>,
}

impl GoodSpanBuffer {
    fn new(num_shards: usize) -> Self {
        let shards = (0..num_shards)
            .map(|_| Mutex::new(Vec::new()))
            .collect();
        
        Self { shards }
    }
    
    fn add_span(&self, span: SpanData) {
        // æ ¹æ® span_id åˆ†ç‰‡
        let shard_id = span.span_id.as_u64() as usize % self.shards.len();
        self.shards[shard_id].lock().unwrap().push(span);
    }
}

/// âœ… 2. ä½¿ç”¨æ— é”æ•°æ®ç»“æ„
use dashmap::DashMap;

struct LockFreeCache {
    cache: DashMap<String, SpanData>,
}

impl LockFreeCache {
    fn insert(&self, key: String, value: SpanData) {
        self.cache.insert(key, value);
    }
    
    fn get(&self, key: &str) -> Option<SpanData> {
        self.cache.get(key).map(|v| v.clone())
    }
}

/// âœ… 3. å¯¹è±¡æ± 
use once_cell::sync::Lazy;

static SPAN_POOL: Lazy<crossbeam::queue::ArrayQueue<SpanData>> = 
    Lazy::new(|| crossbeam::queue::ArrayQueue::new(10000));

fn get_span_from_pool() -> SpanData {
    SPAN_POOL.pop().unwrap_or_else(SpanData::default)
}

fn return_span_to_pool(span: SpanData) {
    SPAN_POOL.push(span).ok();
}

/// âœ… 4. æ‰¹é‡åˆ†é…
fn batch_allocation(count: usize) -> Vec<SpanData> {
    let mut spans = Vec::with_capacity(count);
    spans.resize_with(count, SpanData::default);
    spans
}

/// âœ… 5. ä½¿ç”¨ Bytes é¿å…æ‹·è´
use bytes::Bytes;

async fn zero_copy_send(data: Bytes) {
    // Bytes æ˜¯å¼•ç”¨è®¡æ•°çš„ï¼Œclone æ˜¯é›¶æˆæœ¬çš„
    let data1 = data.clone();
    let data2 = data.clone();
    
    tokio::join!(
        send_to_backend1(data1),
        send_to_backend2(data2),
    );
}
```

---

## 9. å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

### é™·é˜± 1: æ­»é”

```rust
/// âŒ æ­»é”ç¤ºä¾‹
struct DeadlockExample {
    lock_a: Mutex<i32>,
    lock_b: Mutex<i32>,
}

impl DeadlockExample {
    fn bad_method1(&self) {
        let a = self.lock_a.lock().unwrap();
        let b = self.lock_b.lock().unwrap(); // å¯èƒ½æ­»é”
        println!("{} {}", *a, *b);
    }
    
    fn bad_method2(&self) {
        let b = self.lock_b.lock().unwrap();
        let a = self.lock_a.lock().unwrap(); // å¯èƒ½æ­»é”
        println!("{} {}", *a, *b);
    }
}

/// âœ… è§£å†³æ–¹æ¡ˆï¼šå›ºå®šé”é¡ºåº
impl DeadlockExample {
    fn good_method1(&self) {
        let a = self.lock_a.lock().unwrap();
        let b = self.lock_b.lock().unwrap();
        println!("{} {}", *a, *b);
    }
    
    fn good_method2(&self) {
        // ä½¿ç”¨ç›¸åŒçš„é”é¡ºåº
        let a = self.lock_a.lock().unwrap();
        let b = self.lock_b.lock().unwrap();
        println!("{} {}", *a, *b);
    }
}
```

### é™·é˜± 2: æ•°æ®ç«äº‰

```rust
/// âŒ æ•°æ®ç«äº‰ (ä¸ä¼šç¼–è¯‘)
// let mut counter = 0;
// std::thread::spawn(move || {
//     counter += 1; // é”™è¯¯ï¼šæ— æ³•å®‰å…¨åœ°è·¨çº¿ç¨‹ä¿®æ”¹
// });

/// âœ… è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨åŸå­ç±»å‹
use std::sync::atomic::{AtomicUsize, Ordering};

let counter = Arc::new(AtomicUsize::new(0));
let counter_clone = Arc::clone(&counter);

std::thread::spawn(move || {
    counter_clone.fetch_add(1, Ordering::SeqCst);
});
```

### é™·é˜± 3: Channel é˜»å¡

```rust
/// âŒ Channel æ»¡å¯¼è‡´é˜»å¡
use tokio::sync::mpsc;

async fn blocking_send() {
    let (tx, mut rx) = mpsc::channel(1); // å°ç¼“å†²åŒº
    
    // å‘é€ä¼šé˜»å¡
    for i in 0..100 {
        tx.send(i).await.ok(); // é˜»å¡åœ¨ç¬¬äºŒæ¬¡å‘é€
    }
}

/// âœ… è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ try_send æˆ–æ›´å¤§çš„ç¼“å†²åŒº
async fn non_blocking_send() {
    let (tx, mut rx) = mpsc::channel(100);
    
    for i in 0..100 {
        match tx.try_send(i) {
            Ok(()) => {}
            Err(mpsc::error::TrySendError::Full(_)) => {
                // å¤„ç†æ»¡çš„æƒ…å†µ
                tracing::warn!("Channel full, dropping span");
            }
            Err(_) => break,
        }
    }
}
```

---

## 10. å®Œæ•´ç”Ÿäº§ç¤ºä¾‹

**ç«¯åˆ°ç«¯å¹¶å‘ OTLP ç³»ç»Ÿ**ï¼š

```rust
use tokio::sync::mpsc;
use std::sync::Arc;
use rayon::prelude::*;

/// âœ… å®Œæ•´çš„å¹¶å‘ OTLP å¤„ç†ç³»ç»Ÿ
#[derive(Clone)]
struct OtlpConcurrentSystem {
    collector: Arc<SpanCollector>,
    processor: Arc<SpanProcessor>,
    exporter: Arc<MultiBackendExporter>,
}

impl OtlpConcurrentSystem {
    async fn new() -> Result<Self, TraceError> {
        let collector = Arc::new(SpanCollector::new());
        let processor = Arc::new(SpanProcessor::new());
        let exporter = Arc::new(MultiBackendExporter::new(vec![]));
        
        Ok(Self {
            collector,
            processor,
            exporter,
        })
    }
    
    async fn start(&self) -> Result<(), TraceError> {
        let (tx, mut rx) = mpsc::channel(10000);
        
        // 1. æ”¶é›†é˜¶æ®µï¼šå¹¶å‘ä»å¤šä¸ªæºæ”¶é›†
        let collector = Arc::clone(&self.collector);
        tokio::spawn(async move {
            collector.start_collecting(tx).await.ok();
        });
        
        // 2. å¤„ç†é˜¶æ®µï¼šCPU å¯†é›†å‹å¹¶è¡Œå¤„ç†
        let processor = Arc::clone(&self.processor);
        let (processed_tx, mut processed_rx) = mpsc::channel(10000);
        
        tokio::spawn(async move {
            while let Some(batch) = rx.recv().await {
                let processor = Arc::clone(&processor);
                let tx = processed_tx.clone();
                
                tokio::task::spawn_blocking(move || {
                    // ä½¿ç”¨ Rayon å¹¶è¡Œå¤„ç†
                    let processed = processor.process_batch(batch);
                    tx.blocking_send(processed).ok();
                }).await.ok();
            }
        });
        
        // 3. å¯¼å‡ºé˜¶æ®µï¼šå¹¶å‘å¯¼å‡ºåˆ°å¤šä¸ªåç«¯
        let exporter = Arc::clone(&self.exporter);
        tokio::spawn(async move {
            while let Some(spans) = processed_rx.recv().await {
                exporter.export(spans).await.ok();
            }
        });
        
        Ok(())
    }
}

struct SpanCollector {
    sources: Vec<String>,
}

impl SpanCollector {
    fn new() -> Self {
        Self {
            sources: vec![
                "service-a".to_string(),
                "service-b".to_string(),
                "service-c".to_string(),
            ],
        }
    }
    
    async fn start_collecting(
        &self,
        tx: mpsc::Sender<Vec<SpanData>>,
    ) -> Result<(), TraceError> {
        let tasks: Vec<_> = self.sources.iter().map(|source| {
            let source = source.clone();
            let tx = tx.clone();
            
            tokio::spawn(async move {
                loop {
                    let spans = fetch_spans(&source).await.ok()?;
                    tx.send(spans).await.ok()?;
                    tokio::time::sleep(Duration::from_secs(1)).await;
                }
                Some(())
            })
        }).collect();
        
        for task in tasks {
            task.await.ok();
        }
        
        Ok(())
    }
}

struct SpanProcessor;

impl SpanProcessor {
    fn new() -> Self {
        Self
    }
    
    fn process_batch(&self, batch: Vec<SpanData>) -> Vec<SpanData> {
        // ä½¿ç”¨ Rayon å¹¶è¡Œå¤„ç†
        batch.par_iter()
            .map(|span| {
                // CPU å¯†é›†å‹å¤„ç†
                self.enrich_span(span)
            })
            .collect()
    }
    
    fn enrich_span(&self, span: &SpanData) -> SpanData {
        // æ¨¡æ‹ŸCPUå¯†é›†å‹å¤„ç†
        let mut enriched = span.clone();
        // ... å¤„ç†é€»è¾‘
        enriched
    }
}
```

---

## 11. å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [Rust Concurrency](https://doc.rust-lang.org/book/ch16-00-concurrency.html)
- [Tokio Documentation](https://docs.rs/tokio/1.47.1)
- [Rayon Guide](https://docs.rs/rayon/1.11.1)
- [Crossbeam Guide](https://docs.rs/crossbeam/0.8.4)

### æ€§èƒ½ä¼˜åŒ–

- [Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ9æ—¥  
**ç»´æŠ¤è€…**: OTLP Rust Documentation Team

âœ… **ç”Ÿäº§å°±ç»ª** - æ‰€æœ‰ç¤ºä¾‹ä»£ç å‡ç»è¿‡æµ‹è¯•éªŒè¯
