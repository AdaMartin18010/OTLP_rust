# Rust OTLP åˆ†å¸ƒå¼è¿½è¸ªå¯è§†åŒ–å®Œæ•´æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **Rust ç‰ˆæœ¬**: 1.90  
> **OpenTelemetry**: 0.31.0  
> **æœ€åæ›´æ–°**: 2025-10-08  
> **æ–‡æ¡£çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

---

## ğŸ“‹ ç›®å½•

- [Rust OTLP åˆ†å¸ƒå¼è¿½è¸ªå¯è§†åŒ–å®Œæ•´æŒ‡å—](#rust-otlp-åˆ†å¸ƒå¼è¿½è¸ªå¯è§†åŒ–å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [ä¸ºä»€ä¹ˆéœ€è¦è¿½è¸ªå¯è§†åŒ–ï¼Ÿ](#ä¸ºä»€ä¹ˆéœ€è¦è¿½è¸ªå¯è§†åŒ–)
    - [ä¸»æµå¯è§†åŒ–å·¥å…·å¯¹æ¯”](#ä¸»æµå¯è§†åŒ–å·¥å…·å¯¹æ¯”)
  - [Jaeger é›†æˆ](#jaeger-é›†æˆ)
    - [Jaeger æ¶æ„](#jaeger-æ¶æ„)
    - [Rust å®¢æˆ·ç«¯é…ç½®](#rust-å®¢æˆ·ç«¯é…ç½®)
    - [ç›´æ¥å¯¼å‡ºåˆ° Jaegerï¼ˆAgentï¼‰](#ç›´æ¥å¯¼å‡ºåˆ°-jaegeragent)
    - [é€šè¿‡ OTLP å¯¼å‡ºåˆ° Jaeger Collector](#é€šè¿‡-otlp-å¯¼å‡ºåˆ°-jaeger-collector)
    - [é›†æˆ tracing å®](#é›†æˆ-tracing-å®)
    - [Docker Compose éƒ¨ç½² Jaeger](#docker-compose-éƒ¨ç½²-jaeger)
    - [Jaeger é«˜çº§é…ç½®](#jaeger-é«˜çº§é…ç½®)
  - [Grafana Tempo é›†æˆ](#grafana-tempo-é›†æˆ)
    - [Tempo æ¶æ„](#tempo-æ¶æ„)
    - [Rust é…ç½®ï¼ˆä¸ Jaeger ç±»ä¼¼ï¼‰](#rust-é…ç½®ä¸-jaeger-ç±»ä¼¼)
    - [Docker Compose éƒ¨ç½² Tempo](#docker-compose-éƒ¨ç½²-tempo)
    - [Tempo é…ç½®æ–‡ä»¶](#tempo-é…ç½®æ–‡ä»¶)
    - [Grafana æ•°æ®æºé…ç½®](#grafana-æ•°æ®æºé…ç½®)
    - [TraceQL æŸ¥è¯¢ç¤ºä¾‹](#traceql-æŸ¥è¯¢ç¤ºä¾‹)
  - [Zipkin é›†æˆ](#zipkin-é›†æˆ)
    - [Zipkin æ¶æ„](#zipkin-æ¶æ„)
    - [Rust é…ç½®](#rust-é…ç½®)
    - [Docker Compose éƒ¨ç½² Zipkin](#docker-compose-éƒ¨ç½²-zipkin)
  - [è‡ªå®šä¹‰å¯è§†åŒ–](#è‡ªå®šä¹‰å¯è§†åŒ–)
    - [ä½¿ç”¨ D3.js æ„å»ºè‡ªå®šä¹‰è¿½è¸ªå›¾](#ä½¿ç”¨-d3js-æ„å»ºè‡ªå®šä¹‰è¿½è¸ªå›¾)
    - [Web API ç«¯ç‚¹](#web-api-ç«¯ç‚¹)
    - [HTML å¯è§†åŒ–é¡µé¢](#html-å¯è§†åŒ–é¡µé¢)
  - [è¿½è¸ªåˆ†æå·¥å…·](#è¿½è¸ªåˆ†æå·¥å…·)
    - [å…³é”®è·¯å¾„åˆ†æ](#å…³é”®è·¯å¾„åˆ†æ)
    - [æœåŠ¡ä¾èµ–åˆ†æ](#æœåŠ¡ä¾èµ–åˆ†æ)
  - [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
    - [å»¶è¿Ÿåˆ†æ](#å»¶è¿Ÿåˆ†æ)
    - [çƒ­ç‚¹åˆ†æ](#çƒ­ç‚¹åˆ†æ)
  - [å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹](#å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹)
    - [å¼‚å¸¸æ£€æµ‹è§„åˆ™](#å¼‚å¸¸æ£€æµ‹è§„åˆ™)
    - [Prometheus å‘Šè­¦é›†æˆ](#prometheus-å‘Šè­¦é›†æˆ)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. é‡‡æ ·ç­–ç•¥](#1-é‡‡æ ·ç­–ç•¥)
    - [2. å±æ€§æ ‡å‡†åŒ–](#2-å±æ€§æ ‡å‡†åŒ–)
    - [3. å­˜å‚¨ä¼˜åŒ–](#3-å­˜å‚¨ä¼˜åŒ–)
    - [4. æŸ¥è¯¢ä¼˜åŒ–](#4-æŸ¥è¯¢ä¼˜åŒ–)
  - [æ€»ç»“](#æ€»ç»“)
    - [å·¥å…·é€‰æ‹©å»ºè®®](#å·¥å…·é€‰æ‹©å»ºè®®)
    - [å…³é”®æŒ‡æ ‡](#å…³é”®æŒ‡æ ‡)
    - [ä¸‹ä¸€æ­¥è¡ŒåŠ¨](#ä¸‹ä¸€æ­¥è¡ŒåŠ¨)

---

## æ¦‚è¿°

### ä¸ºä»€ä¹ˆéœ€è¦è¿½è¸ªå¯è§†åŒ–ï¼Ÿ

åˆ†å¸ƒå¼è¿½è¸ªå¯è§†åŒ–å¸®åŠ©æˆ‘ä»¬ï¼š

- âœ… **ç†è§£ç³»ç»Ÿè¡Œä¸º**: å¯è§†åŒ–æœåŠ¡é—´è°ƒç”¨å…³ç³»
- âœ… **å®šä½æ€§èƒ½ç“¶é¢ˆ**: è¯†åˆ«æ…¢æŸ¥è¯¢å’Œå»¶è¿Ÿ
- âœ… **æ•…éšœæ’æŸ¥**: å¿«é€Ÿå®šä½é”™è¯¯æ ¹å› 
- âœ… **ä¼˜åŒ–è·¯å¾„**: å‘ç°ä¸å¿…è¦çš„è°ƒç”¨é“¾
- âœ… **å®¹é‡è§„åˆ’**: åˆ†æç³»ç»Ÿè´Ÿè½½å’Œç“¶é¢ˆ

### ä¸»æµå¯è§†åŒ–å·¥å…·å¯¹æ¯”

| å·¥å…· | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **Jaeger** | æˆç†Ÿã€åŠŸèƒ½ä¸°å¯Œã€UIå‹å¥½ | å­˜å‚¨å¼€é”€å¤§ | ä¸­å°è§„æ¨¡ã€åŠŸèƒ½ä¼˜å…ˆ |
| **Tempo** | Grafanaç”Ÿæ€ã€æˆæœ¬ä½ | æŸ¥è¯¢åŠŸèƒ½æœ‰é™ | æˆæœ¬æ•æ„Ÿã€å·²ç”¨Grafana |
| **Zipkin** | ç®€å•æ˜“ç”¨ã€å†å²æ‚ ä¹… | åŠŸèƒ½ç›¸å¯¹åŸºç¡€ | ç®€å•åœºæ™¯ã€å¿«é€Ÿä¸Šæ‰‹ |

---

## Jaeger é›†æˆ

### Jaeger æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Rust App  â”‚â”€â”€â”€â”€â–¶â”‚   Jaeger   â”‚â”€â”€â”€â”€â–¶â”‚  Storage    â”‚
â”‚   (OTLP)    â”‚     â”‚  Collector  â”‚     â”‚ (ES/Badger) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Jaeger    â”‚
                    â”‚     UI      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rust å®¢æˆ·ç«¯é…ç½®

```toml
[dependencies]
opentelemetry = "0.31.0"
opentelemetry_sdk = { version = "0.31.0", features = ["rt-tokio", "trace"] }
opentelemetry-otlp = { version = "0.31.0", features = ["grpc-tonic", "trace"] }
opentelemetry-jaeger = "0.31.0"
tracing = "0.1.41"
tracing-subscriber = { version = "0.3.19", features = ["env-filter", "json"] }
tracing-opentelemetry = "0.29.0"
```

### ç›´æ¥å¯¼å‡ºåˆ° Jaegerï¼ˆAgentï¼‰

```rust
// src/tracing/jaeger_agent.rs
use opentelemetry::{global, trace::TracerProvider};
use opentelemetry_sdk::trace::{Config, Tracer};
use opentelemetry_jaeger::JaegerPropagator;

pub fn init_jaeger_agent(service_name: &str) -> Result<Tracer, Box<dyn std::error::Error>> {
    // è®¾ç½®ä¼ æ’­å™¨
    global::set_text_map_propagator(JaegerPropagator::new());

    // é…ç½® Jaeger Agent å¯¼å‡ºå™¨
    let tracer = opentelemetry_jaeger::new_agent_pipeline()
        .with_service_name(service_name)
        .with_endpoint("localhost:6831") // Jaeger Agent UDP ç«¯ç‚¹
        .with_max_packet_size(9_216)     // æœ€å¤§ UDP åŒ…å¤§å°
        .install_batch(opentelemetry_sdk::runtime::Tokio)?;

    Ok(tracer)
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ– Jaeger
    let tracer = init_jaeger_agent("my-rust-service")?;

    // åˆ›å»º Span
    let span = tracer.span_builder("my-operation").start(&tracer);
    let cx = opentelemetry::Context::current_with_span(span);

    // æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    tracer.in_span("sub-operation", |_cx| {
        // ä¸šåŠ¡ä»£ç 
        std::thread::sleep(std::time::Duration::from_millis(100));
    });

    // å…³é—­
    global::shutdown_tracer_provider();

    Ok(())
}
```

### é€šè¿‡ OTLP å¯¼å‡ºåˆ° Jaeger Collector

```rust
// src/tracing/jaeger_otlp.rs
use opentelemetry::trace::TracerProvider;
use opentelemetry_otlp::WithExportConfig;
use opentelemetry_sdk::trace::Config;
use std::time::Duration;

pub fn init_jaeger_otlp(service_name: &str) -> Result<opentelemetry_sdk::trace::Tracer, Box<dyn std::error::Error>> {
    // Jaeger 0.14+ æ”¯æŒ OTLP
    let exporter = opentelemetry_otlp::SpanExporter::builder()
        .with_tonic()
        .with_endpoint("http://localhost:4317") // Jaeger Collector OTLP ç«¯ç‚¹
        .with_timeout(Duration::from_secs(3))
        .build()?;

    let provider = opentelemetry_sdk::trace::TracerProvider::builder()
        .with_config(Config::default().with_resource(
            opentelemetry_sdk::Resource::new(vec![
                opentelemetry::KeyValue::new("service.name", service_name.to_string()),
                opentelemetry::KeyValue::new("service.version", "1.0.0"),
                opentelemetry::KeyValue::new("deployment.environment", "production"),
            ])
        ))
        .with_batch_exporter(exporter, opentelemetry_sdk::runtime::Tokio)
        .build();

    let tracer = provider.tracer(service_name);

    Ok(tracer)
}
```

### é›†æˆ tracing å®

```rust
// src/tracing/integration.rs
use tracing_subscriber::{layer::SubscriberExt, Registry};
use tracing_opentelemetry::OpenTelemetryLayer;

pub fn init_tracing_with_jaeger(service_name: &str) -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ– Jaeger
    let tracer = init_jaeger_otlp(service_name)?;

    // åˆ›å»º OpenTelemetry layer
    let opentelemetry = OpenTelemetryLayer::new(tracer);

    // åˆ›å»º subscriber
    let subscriber = Registry::default()
        .with(tracing_subscriber::fmt::layer().with_target(true))
        .with(tracing_subscriber::EnvFilter::from_default_env())
        .with(opentelemetry);

    tracing::subscriber::set_global_default(subscriber)?;

    Ok(())
}

// ä½¿ç”¨ç¤ºä¾‹ - ä½¿ç”¨ tracing å®
#[tracing::instrument]
async fn process_order(order_id: u64) -> Result<(), Box<dyn std::error::Error>> {
    tracing::info!(order_id, "Processing order");

    // å­ Span
    fetch_user_info(order_id).await?;
    validate_payment(order_id).await?;
    update_inventory(order_id).await?;

    tracing::info!(order_id, "Order processed successfully");
    Ok(())
}

#[tracing::instrument]
async fn fetch_user_info(order_id: u64) -> Result<(), Box<dyn std::error::Error>> {
    tracing::debug!("Fetching user info");
    tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
    Ok(())
}
```

### Docker Compose éƒ¨ç½² Jaeger

```yaml
# docker-compose.jaeger.yml
version: '3.8'

services:
  jaeger:
    image: jaegertracing/all-in-one:1.67
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # Jaeger Collector HTTP
      - "4317:4317"    # OTLP gRPC
      - "4318:4318"    # OTLP HTTP
      - "6831:6831/udp" # Jaeger Agent (UDP)
    volumes:
      - jaeger-badger:/badger
    networks:
      - tracing

  # Rust åº”ç”¨ç¤ºä¾‹
  rust-app:
    build: .
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - OTEL_SERVICE_NAME=my-rust-service
    depends_on:
      - jaeger
    networks:
      - tracing

volumes:
  jaeger-badger:

networks:
  tracing:
```

### Jaeger é«˜çº§é…ç½®

```rust
// src/tracing/jaeger_advanced.rs
use opentelemetry::trace::{Sampler, SamplerResult};

/// è‡ªå®šä¹‰é‡‡æ ·å™¨ï¼šåªé‡‡æ ·é”™è¯¯å’Œæ…¢è¯·æ±‚
struct ErrorAndSlowSampler {
    slow_threshold_ms: u64,
}

impl Sampler for ErrorAndSlowSampler {
    fn should_sample(
        &self,
        parent_context: Option<&opentelemetry::Context>,
        trace_id: opentelemetry::trace::TraceId,
        name: &str,
        span_kind: &opentelemetry::trace::SpanKind,
        attributes: &[opentelemetry::KeyValue],
        links: &[opentelemetry::trace::Link],
    ) -> SamplerResult {
        // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å±æ€§
        let has_error = attributes.iter().any(|kv| {
            kv.key.as_str() == "error" && kv.value.as_str() == "true"
        });

        // æ£€æŸ¥æ˜¯å¦æœ‰ HTTP çŠ¶æ€ç  >= 500
        let is_server_error = attributes.iter().any(|kv| {
            if kv.key.as_str() == "http.status_code" {
                if let Some(code) = kv.value.as_i64() {
                    return code >= 500;
                }
            }
            false
        });

        // å¦‚æœæ˜¯é”™è¯¯æˆ–æœåŠ¡å™¨é”™è¯¯ï¼Œé‡‡æ ·
        if has_error || is_server_error {
            return SamplerResult {
                decision: opentelemetry::trace::SamplingDecision::RecordAndSample,
                attributes: vec![],
                trace_state: Default::default(),
            };
        }

        // é»˜è®¤é‡‡æ · 10%
        SamplerResult {
            decision: if rand::random::<f64>() < 0.1 {
                opentelemetry::trace::SamplingDecision::RecordAndSample
            } else {
                opentelemetry::trace::SamplingDecision::Drop
            },
            attributes: vec![],
            trace_state: Default::default(),
        }
    }
}

pub fn init_jaeger_with_custom_sampler(
    service_name: &str,
) -> Result<opentelemetry_sdk::trace::Tracer, Box<dyn std::error::Error>> {
    let sampler = ErrorAndSlowSampler {
        slow_threshold_ms: 1000,
    };

    let exporter = opentelemetry_otlp::SpanExporter::builder()
        .with_tonic()
        .with_endpoint("http://localhost:4317")
        .build()?;

    let provider = opentelemetry_sdk::trace::TracerProvider::builder()
        .with_config(
            Config::default()
                .with_sampler(Box::new(sampler))
                .with_resource(opentelemetry_sdk::Resource::new(vec![
                    opentelemetry::KeyValue::new("service.name", service_name.to_string()),
                ]))
        )
        .with_batch_exporter(exporter, opentelemetry_sdk::runtime::Tokio)
        .build();

    Ok(provider.tracer(service_name))
}
```

---

## Grafana Tempo é›†æˆ

### Tempo æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Rust App  â”‚â”€â”€â”€â”€â–¶â”‚    Tempo    â”‚â”€â”€â”€â”€â–¶â”‚  S3/GCS/    â”‚
â”‚   (OTLP)    â”‚     â”‚ Distributor â”‚     â”‚  MinIO      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Grafana   â”‚
                    â”‚   (Query)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rust é…ç½®ï¼ˆä¸ Jaeger ç±»ä¼¼ï¼‰

```rust
// src/tracing/tempo.rs
use opentelemetry_otlp::WithExportConfig;

pub fn init_tempo(service_name: &str) -> Result<opentelemetry_sdk::trace::Tracer, Box<dyn std::error::Error>> {
    let exporter = opentelemetry_otlp::SpanExporter::builder()
        .with_tonic()
        .with_endpoint("http://localhost:4317") // Tempo OTLP ç«¯ç‚¹
        .build()?;

    let provider = opentelemetry_sdk::trace::TracerProvider::builder()
        .with_config(Config::default().with_resource(
            opentelemetry_sdk::Resource::new(vec![
                opentelemetry::KeyValue::new("service.name", service_name.to_string()),
                opentelemetry::KeyValue::new("cluster", "production"),
                opentelemetry::KeyValue::new("namespace", "default"),
            ])
        ))
        .with_batch_exporter(exporter, opentelemetry_sdk::runtime::Tokio)
        .build();

    Ok(provider.tracer(service_name))
}
```

### Docker Compose éƒ¨ç½² Tempo

```yaml
# docker-compose.tempo.yml
version: '3.8'

services:
  tempo:
    image: grafana/tempo:2.7.0
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml
      - tempo-data:/tmp/tempo
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
      - "3200:3200"   # Tempo HTTP
    networks:
      - tracing

  grafana:
    image: grafana/grafana:11.4.0
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    volumes:
      - ./grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
    ports:
      - "3000:3000"
    depends_on:
      - tempo
    networks:
      - tracing

volumes:
  tempo-data:

networks:
  tracing:
```

### Tempo é…ç½®æ–‡ä»¶

```yaml
# tempo.yaml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

ingester:
  max_block_duration: 5m

compactor:
  compaction:
    block_retention: 48h

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/blocks
    wal:
      path: /tmp/tempo/wal
    pool:
      max_workers: 100
      queue_depth: 10000
```

### Grafana æ•°æ®æºé…ç½®

```yaml
# grafana-datasources.yaml
apiVersion: 1

datasources:
  - name: Tempo
    type: tempo
    access: proxy
    url: http://tempo:3200
    uid: tempo
    editable: true
    jsonData:
      httpMethod: GET
      tracesToLogs:
        datasourceUid: 'loki'
        tags: ['job', 'instance', 'pod', 'namespace']
        mappedTags: [{ key: 'service.name', value: 'service' }]
        mapTagNamesEnabled: true
        spanStartTimeShift: '1h'
        spanEndTimeShift: '1h'
```

### TraceQL æŸ¥è¯¢ç¤ºä¾‹

```go
// Grafana Explore ä¸­ä½¿ç”¨ TraceQL
{
  service.name = "my-rust-service" &&
  http.status_code >= 500
}

// æŸ¥è¯¢æ…¢è¯·æ±‚
{
  service.name = "my-rust-service" &&
  duration > 1s
}

// æŸ¥è¯¢ç‰¹å®šç”¨æˆ·çš„è¿½è¸ª
{
  user.id = "123" &&
  span.kind = "server"
}
```

---

## Zipkin é›†æˆ

### Zipkin æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Rust App  â”‚â”€â”€â”€â”€â–¶â”‚   Zipkin    â”‚â”€â”€â”€â”€â–¶â”‚  Storage    â”‚
â”‚  (Zipkin)   â”‚     â”‚   Server    â”‚     â”‚  (MySQL/ES) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Zipkin    â”‚
                    â”‚     UI      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rust é…ç½®

```toml
[dependencies]
opentelemetry-zipkin = "0.31.0"
```

```rust
// src/tracing/zipkin.rs
use opentelemetry::trace::TracerProvider;
use opentelemetry_sdk::trace::Config;
use opentelemetry_zipkin::ZipkinPropagator;

pub fn init_zipkin(service_name: &str) -> Result<opentelemetry_sdk::trace::Tracer, Box<dyn std::error::Error>> {
    // è®¾ç½®ä¼ æ’­å™¨
    opentelemetry::global::set_text_map_propagator(ZipkinPropagator::new());

    // é…ç½® Zipkin
    let tracer = opentelemetry_zipkin::new_pipeline()
        .with_service_name(service_name)
        .with_service_address("127.0.0.1:8080".parse()?)
        .with_collector_endpoint("http://localhost:9411/api/v2/spans")
        .install_batch(opentelemetry_sdk::runtime::Tokio)?;

    Ok(tracer)
}
```

### Docker Compose éƒ¨ç½² Zipkin

```yaml
# docker-compose.zipkin.yml
version: '3.8'

services:
  zipkin:
    image: openzipkin/zipkin:3.4.3
    environment:
      - STORAGE_TYPE=mem
      # æˆ–ä½¿ç”¨ Elasticsearch
      # - STORAGE_TYPE=elasticsearch
      # - ES_HOSTS=elasticsearch:9200
    ports:
      - "9411:9411"
    networks:
      - tracing

  # å¯é€‰ï¼šElasticsearch å­˜å‚¨
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.2
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    networks:
      - tracing

networks:
  tracing:
```

---

## è‡ªå®šä¹‰å¯è§†åŒ–

### ä½¿ç”¨ D3.js æ„å»ºè‡ªå®šä¹‰è¿½è¸ªå›¾

```rust
// src/visualization/trace_graph.rs
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Serialize, Deserialize)]
pub struct TraceNode {
    pub span_id: String,
    pub name: String,
    pub service: String,
    pub duration_ms: u64,
    pub start_time: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TraceEdge {
    pub from: String,
    pub to: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TraceGraph {
    pub nodes: Vec<TraceNode>,
    pub edges: Vec<TraceEdge>,
}

impl TraceGraph {
    pub fn from_spans(spans: Vec<SpanData>) -> Self {
        let mut nodes = Vec::new();
        let mut edges = Vec::new();
        let mut parent_map: HashMap<String, String> = HashMap::new();

        for span in spans {
            let span_id = span.span_id().to_hex();
            
            nodes.push(TraceNode {
                span_id: span_id.clone(),
                name: span.name().to_string(),
                service: span.resource()
                    .get("service.name")
                    .map(|v| v.to_string())
                    .unwrap_or_default(),
                duration_ms: span.end_time()
                    .duration_since(span.start_time())
                    .unwrap()
                    .as_millis() as u64,
                start_time: span.start_time()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_millis() as u64,
            });

            if let Some(parent_id) = span.parent_span_id() {
                let parent_id_hex = parent_id.to_hex();
                edges.push(TraceEdge {
                    from: parent_id_hex.clone(),
                    to: span_id.clone(),
                });
                parent_map.insert(span_id, parent_id_hex);
            }
        }

        TraceGraph { nodes, edges }
    }

    pub fn to_json(&self) -> Result<String, serde_json::Error> {
        serde_json::to_string_pretty(self)
    }
}
```

### Web API ç«¯ç‚¹

```rust
// src/api/trace_visualization.rs
use axum::{
    Router,
    routing::get,
    extract::{Path, Query},
    response::Json,
    http::StatusCode,
};
use serde::Deserialize;

#[derive(Deserialize)]
struct TraceQueryParams {
    service: Option<String>,
    start_time: Option<u64>,
    end_time: Option<u64>,
}

async fn get_trace(
    Path(trace_id): Path<String>,
) -> Result<Json<TraceGraph>, StatusCode> {
    // ä»å­˜å‚¨ä¸­è·å– Trace
    let spans = fetch_spans_by_trace_id(&trace_id)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    let graph = TraceGraph::from_spans(spans);
    Ok(Json(graph))
}

async fn search_traces(
    Query(params): Query<TraceQueryParams>,
) -> Result<Json<Vec<TraceSummary>>, StatusCode> {
    // æœç´¢ Traces
    let traces = search_traces_in_storage(params)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(traces))
}

pub fn visualization_routes() -> Router {
    Router::new()
        .route("/api/traces/:trace_id", get(get_trace))
        .route("/api/traces/search", get(search_traces))
}
```

### HTML å¯è§†åŒ–é¡µé¢

```html
<!-- static/trace-viewer.html -->
<!DOCTYPE html>
<html>
<head>
    <title>Trace Viewer</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        .node {
            stroke: #fff;
            stroke-width: 1.5px;
        }
        .link {
            stroke: #999;
            stroke-opacity: 0.6;
        }
        .tooltip {
            position: absolute;
            background: #fff;
            border: 1px solid #ddd;
            padding: 10px;
            border-radius: 5px;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div id="trace-graph"></div>

    <script>
        async function loadTrace(traceId) {
            const response = await fetch(`/api/traces/${traceId}`);
            const data = await response.json();
            renderTraceGraph(data);
        }

        function renderTraceGraph(data) {
            const width = 1200;
            const height = 800;

            const svg = d3.select("#trace-graph")
                .append("svg")
                .attr("width", width)
                .attr("height", height);

            const simulation = d3.forceSimulation(data.nodes)
                .force("link", d3.forceLink(data.edges).id(d => d.span_id))
                .force("charge", d3.forceManyBody().strength(-300))
                .force("center", d3.forceCenter(width / 2, height / 2));

            const link = svg.append("g")
                .selectAll("line")
                .data(data.edges)
                .enter().append("line")
                .attr("class", "link")
                .attr("stroke-width", 2);

            const node = svg.append("g")
                .selectAll("circle")
                .data(data.nodes)
                .enter().append("circle")
                .attr("class", "node")
                .attr("r", d => Math.sqrt(d.duration_ms) + 5)
                .attr("fill", d => colorByService(d.service))
                .call(d3.drag()
                    .on("start", dragstarted)
                    .on("drag", dragged)
                    .on("end", dragended));

            node.append("title")
                .text(d => `${d.name}\n${d.duration_ms}ms`);

            simulation.on("tick", () => {
                link
                    .attr("x1", d => d.source.x)
                    .attr("y1", d => d.source.y)
                    .attr("x2", d => d.target.x)
                    .attr("y2", d => d.target.y);

                node
                    .attr("cx", d => d.x)
                    .attr("cy", d => d.y);
            });
        }

        function colorByService(service) {
            const colors = {
                "user-service": "#1f77b4",
                "order-service": "#ff7f0e",
                "payment-service": "#2ca02c",
            };
            return colors[service] || "#8c564b";
        }

        // åŠ è½½ç¤ºä¾‹ Trace
        loadTrace("trace-id-example");
    </script>
</body>
</html>
```

---

## è¿½è¸ªåˆ†æå·¥å…·

### å…³é”®è·¯å¾„åˆ†æ

```rust
// src/analysis/critical_path.rs
use std::collections::{HashMap, HashSet};

#[derive(Debug)]
pub struct CriticalPath {
    pub spans: Vec<SpanData>,
    pub total_duration_ms: u64,
}

impl CriticalPath {
    pub fn analyze(spans: Vec<SpanData>) -> Self {
        // æ„å»ºä¾èµ–å›¾
        let mut children_map: HashMap<String, Vec<usize>> = HashMap::new();
        let mut span_index_map: HashMap<String, usize> = HashMap::new();

        for (idx, span) in spans.iter().enumerate() {
            let span_id = span.span_id().to_hex();
            span_index_map.insert(span_id.clone(), idx);

            if let Some(parent_id) = span.parent_span_id() {
                let parent_id_hex = parent_id.to_hex();
                children_map
                    .entry(parent_id_hex)
                    .or_insert_with(Vec::new)
                    .push(idx);
            }
        }

        // æ‰¾åˆ°æ ¹ Span
        let root_span_idx = spans.iter()
            .position(|s| s.parent_span_id().is_none())
            .unwrap_or(0);

        // é€’å½’æŸ¥æ‰¾å…³é”®è·¯å¾„
        let critical_path_indices = Self::find_critical_path_recursive(
            root_span_idx,
            &spans,
            &children_map,
        );

        let critical_spans: Vec<SpanData> = critical_path_indices
            .into_iter()
            .map(|idx| spans[idx].clone())
            .collect();

        let total_duration_ms = critical_spans
            .iter()
            .map(|s| s.end_time().duration_since(s.start_time()).unwrap().as_millis() as u64)
            .sum();

        CriticalPath {
            spans: critical_spans,
            total_duration_ms,
        }
    }

    fn find_critical_path_recursive(
        span_idx: usize,
        spans: &[SpanData],
        children_map: &HashMap<String, Vec<usize>>,
    ) -> Vec<usize> {
        let span_id = spans[span_idx].span_id().to_hex();
        let mut path = vec![span_idx];

        if let Some(children) = children_map.get(&span_id) {
            // æ‰¾åˆ°è€—æ—¶æœ€é•¿çš„å­ Span
            let longest_child = children.iter()
                .max_by_key(|&&child_idx| {
                    spans[child_idx].end_time()
                        .duration_since(spans[child_idx].start_time())
                        .unwrap()
                })
                .copied();

            if let Some(child_idx) = longest_child {
                path.extend(Self::find_critical_path_recursive(child_idx, spans, children_map));
            }
        }

        path
    }
}
```

### æœåŠ¡ä¾èµ–åˆ†æ

```rust
// src/analysis/service_dependency.rs
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone)]
pub struct ServiceDependency {
    pub from: String,
    pub to: String,
    pub call_count: u64,
    pub total_duration_ms: u64,
    pub error_count: u64,
}

pub fn analyze_service_dependencies(spans: Vec<SpanData>) -> Vec<ServiceDependency> {
    let mut dependencies: HashMap<(String, String), ServiceDependency> = HashMap::new();

    for span in spans {
        if span.span_kind() == opentelemetry::trace::SpanKind::Server {
            continue; // è·³è¿‡æœåŠ¡ç«¯ Span
        }

        let from_service = span.resource()
            .get("service.name")
            .map(|v| v.to_string())
            .unwrap_or_default();

        // æŸ¥æ‰¾å¯¹åº”çš„æœåŠ¡ç«¯ Spanï¼ˆé€šè¿‡ parent_span_idï¼‰
        if let Some(parent_id) = span.parent_span_id() {
            // è¿™é‡Œéœ€è¦æŸ¥è¯¢å­˜å‚¨æ¥æ‰¾åˆ° parent span
            // ç®€åŒ–ç¤ºä¾‹
            let to_service = span.attributes()
                .iter()
                .find(|(k, _)| k.as_str() == "peer.service")
                .map(|(_, v)| v.to_string())
                .unwrap_or_default();

            let key = (from_service.clone(), to_service.clone());
            let entry = dependencies.entry(key.clone()).or_insert(ServiceDependency {
                from: from_service,
                to: to_service,
                call_count: 0,
                total_duration_ms: 0,
                error_count: 0,
            });

            entry.call_count += 1;
            entry.total_duration_ms += span.end_time()
                .duration_since(span.start_time())
                .unwrap()
                .as_millis() as u64;

            if span.status() == opentelemetry::trace::Status::error("") {
                entry.error_count += 1;
            }
        }
    }

    dependencies.into_values().collect()
}
```

---

## æ€§èƒ½åˆ†æ

### å»¶è¿Ÿåˆ†æ

```rust
// src/analysis/latency.rs
use std::collections::HashMap;

#[derive(Debug)]
pub struct LatencyStats {
    pub operation: String,
    pub count: u64,
    pub min_ms: u64,
    pub max_ms: u64,
    pub avg_ms: u64,
    pub p50_ms: u64,
    pub p95_ms: u64,
    pub p99_ms: u64,
}

pub fn analyze_latency(spans: Vec<SpanData>) -> Vec<LatencyStats> {
    let mut latencies_by_operation: HashMap<String, Vec<u64>> = HashMap::new();

    for span in spans {
        let operation = span.name().to_string();
        let duration_ms = span.end_time()
            .duration_since(span.start_time())
            .unwrap()
            .as_millis() as u64;

        latencies_by_operation
            .entry(operation)
            .or_insert_with(Vec::new)
            .push(duration_ms);
    }

    latencies_by_operation
        .into_iter()
        .map(|(operation, mut latencies)| {
            latencies.sort_unstable();
            
            let count = latencies.len() as u64;
            let min_ms = latencies[0];
            let max_ms = latencies[latencies.len() - 1];
            let avg_ms = latencies.iter().sum::<u64>() / count;
            
            let p50_ms = percentile(&latencies, 0.50);
            let p95_ms = percentile(&latencies, 0.95);
            let p99_ms = percentile(&latencies, 0.99);

            LatencyStats {
                operation,
                count,
                min_ms,
                max_ms,
                avg_ms,
                p50_ms,
                p95_ms,
                p99_ms,
            }
        })
        .collect()
}

fn percentile(sorted_data: &[u64], percentile: f64) -> u64 {
    let idx = (sorted_data.len() as f64 * percentile) as usize;
    sorted_data[idx.min(sorted_data.len() - 1)]
}
```

### çƒ­ç‚¹åˆ†æ

```rust
// src/analysis/hotspot.rs

#[derive(Debug)]
pub struct Hotspot {
    pub operation: String,
    pub total_time_ms: u64,
    pub percentage: f64,
}

pub fn find_hotspots(spans: Vec<SpanData>) -> Vec<Hotspot> {
    let mut operation_times: HashMap<String, u64> = HashMap::new();
    let mut total_time_ms = 0u64;

    for span in spans {
        let operation = span.name().to_string();
        let duration_ms = span.end_time()
            .duration_since(span.start_time())
            .unwrap()
            .as_millis() as u64;

        *operation_times.entry(operation).or_insert(0) += duration_ms;
        total_time_ms += duration_ms;
    }

    let mut hotspots: Vec<Hotspot> = operation_times
        .into_iter()
        .map(|(operation, time_ms)| {
            let percentage = (time_ms as f64 / total_time_ms as f64) * 100.0;
            Hotspot {
                operation,
                total_time_ms: time_ms,
                percentage,
            }
        })
        .collect();

    hotspots.sort_by(|a, b| b.total_time_ms.cmp(&a.total_time_ms));
    hotspots
}
```

---

## å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹

### å¼‚å¸¸æ£€æµ‹è§„åˆ™

```rust
// src/alerting/anomaly_detection.rs
use chrono::{DateTime, Utc};

#[derive(Debug)]
pub enum Anomaly {
    HighLatency {
        operation: String,
        actual_ms: u64,
        threshold_ms: u64,
    },
    HighErrorRate {
        service: String,
        error_rate: f64,
        threshold: f64,
    },
    UnusualPattern {
        description: String,
    },
}

pub struct AnomalyDetector {
    latency_thresholds: HashMap<String, u64>,
    error_rate_threshold: f64,
}

impl AnomalyDetector {
    pub fn new() -> Self {
        Self {
            latency_thresholds: HashMap::from([
                ("database_query".to_string(), 1000),
                ("api_call".to_string(), 500),
            ]),
            error_rate_threshold: 0.05, // 5%
        }
    }

    pub fn detect(&self, spans: &[SpanData]) -> Vec<Anomaly> {
        let mut anomalies = Vec::new();

        // æ£€æµ‹é«˜å»¶è¿Ÿ
        for span in spans {
            let operation = span.name();
            let duration_ms = span.end_time()
                .duration_since(span.start_time())
                .unwrap()
                .as_millis() as u64;

            if let Some(&threshold_ms) = self.latency_thresholds.get(operation) {
                if duration_ms > threshold_ms {
                    anomalies.push(Anomaly::HighLatency {
                        operation: operation.to_string(),
                        actual_ms: duration_ms,
                        threshold_ms,
                    });
                }
            }
        }

        // æ£€æµ‹é«˜é”™è¯¯ç‡
        let service_stats = self.calculate_service_error_rates(spans);
        for (service, error_rate) in service_stats {
            if error_rate > self.error_rate_threshold {
                anomalies.push(Anomaly::HighErrorRate {
                    service,
                    error_rate,
                    threshold: self.error_rate_threshold,
                });
            }
        }

        anomalies
    }

    fn calculate_service_error_rates(&self, spans: &[SpanData]) -> HashMap<String, f64> {
        let mut service_stats: HashMap<String, (u64, u64)> = HashMap::new();

        for span in spans {
            let service = span.resource()
                .get("service.name")
                .map(|v| v.to_string())
                .unwrap_or_default();

            let stats = service_stats.entry(service).or_insert((0, 0));
            stats.0 += 1; // æ€»æ•°

            if span.status() == opentelemetry::trace::Status::error("") {
                stats.1 += 1; // é”™è¯¯æ•°
            }
        }

        service_stats
            .into_iter()
            .map(|(service, (total, errors))| {
                let error_rate = errors as f64 / total as f64;
                (service, error_rate)
            })
            .collect()
    }
}
```

### Prometheus å‘Šè­¦é›†æˆ

```yaml
# prometheus-alerts.yml
groups:
  - name: tracing
    interval: 30s
    rules:
      - alert: HighTraceLatency
        expr: |
          histogram_quantile(0.99,
            sum(rate(otlp_span_duration_seconds_bucket[5m])) by (le, span_name)
          ) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High trace latency detected"
          description: "P99 latency for {{ $labels.span_name }} is {{ $value }}s"

      - alert: HighErrorRate
        expr: |
          sum(rate(otlp_span_errors_total[5m])) by (service_name)
          /
          sum(rate(otlp_spans_total[5m])) by (service_name)
          > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate for {{ $labels.service_name }} is {{ $value | humanizePercentage }}"
```

---

## æœ€ä½³å®è·µ

### 1. é‡‡æ ·ç­–ç•¥

```rust
// ç”Ÿäº§ç¯å¢ƒé‡‡æ ·ç­–ç•¥
pub fn production_sampler() -> Box<dyn Sampler> {
    // 1. å§‹ç»ˆé‡‡æ ·é”™è¯¯
    // 2. æ…¢è¯·æ±‚ï¼ˆ>1sï¼‰100% é‡‡æ ·
    // 3. å…¶ä»–è¯·æ±‚ 10% é‡‡æ ·
    Box::new(CustomSampler::new())
}
```

### 2. å±æ€§æ ‡å‡†åŒ–

```rust
// ç¡®ä¿æ‰€æœ‰æœåŠ¡ä½¿ç”¨ä¸€è‡´çš„å±æ€§å
pub const STANDARD_ATTRIBUTES: &[&str] = &[
    "service.name",
    "service.version",
    "deployment.environment",
    "http.method",
    "http.status_code",
    "db.system",
    "db.operation",
];
```

### 3. å­˜å‚¨ä¼˜åŒ–

```text
âœ… ä½¿ç”¨é‡‡æ ·å‡å°‘æ•°æ®é‡
âœ… è®¾ç½®åˆç†çš„æ•°æ®ä¿ç•™æœŸï¼ˆå¦‚ 7å¤©ï¼‰
âœ… ä½¿ç”¨å‹ç¼©å­˜å‚¨
âœ… å†·çƒ­æ•°æ®åˆ†ç¦»ï¼ˆTempo + S3ï¼‰
```

### 4. æŸ¥è¯¢ä¼˜åŒ–

```text
âœ… ä¸ºå¸¸ç”¨å­—æ®µåˆ›å»ºç´¢å¼•
âœ… ä½¿ç”¨æ—¶é—´èŒƒå›´é™åˆ¶æŸ¥è¯¢
âœ… ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ
âœ… ä½¿ç”¨ TraceQL ç²¾ç¡®æŸ¥è¯¢
```

---

## æ€»ç»“

### å·¥å…·é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èå·¥å…· | åŸå›  |
|------|---------|------|
| å¿«é€Ÿä¸Šæ‰‹ | Jaeger | UIå‹å¥½ã€åŠŸèƒ½å®Œæ•´ |
| æˆæœ¬ä¼˜å…ˆ | Tempo | å¯¹è±¡å­˜å‚¨æˆæœ¬ä½ |
| å·²æœ‰Grafana | Tempo | æ— ç¼é›†æˆ |
| ç®€å•åœºæ™¯ | Zipkin | è½»é‡çº§ã€æ˜“éƒ¨ç½² |

### å…³é”®æŒ‡æ ‡

```text
âœ… P50/P95/P99 å»¶è¿Ÿ
âœ… é”™è¯¯ç‡
âœ… ååé‡ï¼ˆRPSï¼‰
âœ… æœåŠ¡ä¾èµ–å¥åº·åº¦
âœ… å…³é”®è·¯å¾„è€—æ—¶
```

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **é€‰æ‹©å¯è§†åŒ–å·¥å…·**: æ ¹æ®éœ€æ±‚é€‰æ‹© Jaeger/Tempo/Zipkin
2. **é…ç½®é‡‡æ ·**: å¹³è¡¡æ•°æ®é‡å’Œå¯è§æ€§
3. **è®¾ç½®å‘Šè­¦**: å®šä¹‰å…³é”®é˜ˆå€¼
4. **å®šæœŸReview**: åˆ†æçƒ­ç‚¹å’Œç“¶é¢ˆ
5. **æŒç»­ä¼˜åŒ–**: æ ¹æ®æ•°æ®è°ƒæ•´ç³»ç»Ÿ

---

**æ–‡æ¡£ä½œè€…**: OTLP Rust Team  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-08  
**è®¸å¯è¯**: MIT OR Apache-2.0  
**ç›¸å…³æ–‡æ¡£**:

- [ç›‘æ§ä¸å‘Šè­¦](../20_ç›‘æ§ä¸å‘Šè­¦/01_Prometheus_Grafanaå®Œæ•´é›†æˆæŒ‡å—.md)
- [æ€§èƒ½åŸºå‡†æµ‹è¯•](../14_æ€§èƒ½ä¸åŸºå‡†æµ‹è¯•/02_Rust_OTLPæ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæ•´æ¡†æ¶.md)
- [Collectoræ‰©å±•](../22_Collectoræ‰©å±•/01_Rust_OTLP_Collectorè‡ªå®šä¹‰æ‰©å±•å¼€å‘æŒ‡å—.md)
