# 📘 OpenTelemetry性能优化速查手册

> **最后更新**: 2025年10月9日  
> **用途**: 快速优化OpenTelemetry性能,降低开销

---

## 🎯 速查目录

- [📘 OpenTelemetry性能优化速查手册](#-opentelemetry性能优化速查手册)
  - [🎯 速查目录](#-速查目录)
  - [🎯 性能目标](#-性能目标)
    - [合理的性能基准](#合理的性能基准)
    - [性能优化ROI](#性能优化roi)
  - [📱 SDK优化](#-sdk优化)
    - [1. 使用批处理导出器 (必须!)](#1-使用批处理导出器-必须)
    - [2. 合理配置批处理参数](#2-合理配置批处理参数)
    - [3. 采样优化](#3-采样优化)
      - [父级采样 (默认,性能最优)](#父级采样-默认性能最优)
      - [概率采样对比](#概率采样对比)
    - [4. 避免高基数属性](#4-避免高基数属性)
    - [5. 延迟初始化](#5-延迟初始化)
  - [🔧 Collector优化](#-collector优化)
    - [1. 批处理配置 (核心优化)](#1-批处理配置-核心优化)
    - [2. 内存限制器 (防止OOM)](#2-内存限制器-防止oom)
    - [3. 并发导出](#3-并发导出)
    - [4. 资源配置建议](#4-资源配置建议)
      - [小规模 (\< 100 req/s)](#小规模--100-reqs)
      - [中等规模 (100-1000 req/s)](#中等规模-100-1000-reqs)
      - [大规模 (\> 1000 req/s)](#大规模--1000-reqs)
    - [5. Pipeline精简](#5-pipeline精简)
  - [🌐 网络优化](#-网络优化)
    - [1. 启用压缩 (必须!)](#1-启用压缩-必须)
      - [压缩效果对比](#压缩效果对比)
    - [2. 使用gRPC (生产推荐)](#2-使用grpc-生产推荐)
    - [3. 连接池配置](#3-连接池配置)
  - [🎲 采样策略](#-采样策略)
    - [1. 采样策略对比](#1-采样策略对比)
    - [2. Head Sampling (SDK层,性能最优)](#2-head-sampling-sdk层性能最优)
    - [3. Tail Sampling (Collector层,智能采样)](#3-tail-sampling-collector层智能采样)
    - [4. 混合采样 (推荐生产)](#4-混合采样-推荐生产)
  - [💰 成本优化](#-成本优化)
    - [1. 存储成本优化](#1-存储成本优化)
      - [数据量对比](#数据量对比)
      - [成本计算示例](#成本计算示例)
    - [2. 网络成本优化](#2-网络成本优化)
    - [3. 计算成本优化](#3-计算成本优化)
      - [Collector横向扩展策略](#collector横向扩展策略)
  - [📊 监控指标](#-监控指标)
    - [关键性能指标](#关键性能指标)
      - [SDK层](#sdk层)
      - [Collector层](#collector层)
      - [告警规则](#告警规则)
  - [✅ 优化清单](#-优化清单)
    - [快速优化 (投入1小时,收益80%)](#快速优化-投入1小时收益80)
    - [进阶优化 (投入1天,收益15%)](#进阶优化-投入1天收益15)
    - [高级优化 (投入1周,收益5%)](#高级优化-投入1周收益5)
  - [🎯 最佳实践总结](#-最佳实践总结)
  - [📚 参考资源](#-参考资源)

---

## 🎯 性能目标

### 合理的性能基准

| 指标 | 目标值 | 优秀值 | 备注 |
|-----|--------|--------|------|
| **SDK延迟** | < 1ms | < 0.5ms | 应用代码到SDK |
| **Collector延迟** | < 100ms | < 50ms | SDK到Collector |
| **端到端延迟** | < 1s | < 500ms | 应用到后端 |
| **CPU开销** | < 5% | < 2% | 应用额外CPU |
| **内存开销** | < 100MB | < 50MB | 应用额外内存 |
| **数据丢失率** | < 0.1% | 0% | 生产环境 |

### 性能优化ROI

```text
优先级 (投入产出比):
P0: 批处理         (投入: 低, 收益: 高)  🔥
P0: 压缩           (投入: 低, 收益: 高)  🔥
P1: 采样           (投入: 中, 收益: 高)  ✅
P1: 队列配置       (投入: 低, 收益: 中)  ✅
P2: 并发优化       (投入: 中, 收益: 中)  ⚠️
P3: 自定义Exporter (投入: 高, 收益: 低)  ❌
```

---

## 📱 SDK优化

### 1. 使用批处理导出器 (必须!)

```go
// ❌ 不推荐: 同步导出器 (每次都发送)
exporter, _ := stdouttrace.New()
tp := trace.NewTracerProvider(
    trace.WithSyncer(exporter),  // ❌ 每个Span立即发送!
)

// ✅ 推荐: 批处理导出器
exporter, _ := otlptracegrpc.New(ctx)
tp := trace.NewTracerProvider(
    trace.WithBatcher(exporter,
        trace.WithMaxExportBatchSize(2048),   // 批次大小
        trace.WithBatchTimeout(10*time.Second), // 批处理间隔
    ),
)
```

**性能提升**: 吞吐量提升 **50-100x**, 延迟降低 **90%**

---

### 2. 合理配置批处理参数

| 场景 | batch_size | timeout | queue_size |
|-----|-----------|---------|-----------|
| **低延迟** (实时性要求高) | 256 | 1s | 2048 |
| **均衡** (通用场景) | 1024 | 5s | 4096 |
| **高吞吐** (批处理场景) | 2048 | 10s | 8192 |

```yaml
# Go SDK
trace.WithBatcher(exporter,
    trace.WithMaxExportBatchSize(1024),
    trace.WithBatchTimeout(5*time.Second),
    trace.WithMaxQueueSize(4096),
)

# Python SDK
BatchSpanProcessor(
    exporter,
    max_export_batch_size=1024,
    schedule_delay_millis=5000,
    max_queue_size=4096,
)
```

---

### 3. 采样优化

#### 父级采样 (默认,性能最优)

```go
tp := trace.NewTracerProvider(
    trace.WithSampler(trace.ParentBased(
        trace.TraceIDRatioBased(0.1),  // 采样10%
    )),
)
```

#### 概率采样对比

| 采样率 | 数据量 | CPU降低 | 网络降低 | 适用场景 |
|--------|--------|---------|---------|---------|
| 100% | 100% | 0% | 0% | 开发/小流量 |
| 10% | 10% | ~85% | ~90% | 中等流量 |
| 1% | 1% | ~95% | ~99% | 高流量 |
| 0.1% | 0.1% | ~99% | ~99.9% | 超高流量 |

**建议**:

- 开发环境: 100%
- 测试环境: 10%
- 生产环境: 1-10% (视流量而定)
- 超高流量: 0.1-1%

---

### 4. 避免高基数属性

```go
// ❌ 糟糕: 高基数属性 (每个请求都不同)
span.SetAttributes(
    attribute.String("user.id", "12345"),        // ❌ 高基数
    attribute.String("request.id", uuid.New()),  // ❌ 高基数
    attribute.String("timestamp", time.Now()),   // ❌ 高基数
)

// ✅ 推荐: 低基数属性
span.SetAttributes(
    attribute.String("http.method", "GET"),           // ✅ 低基数
    attribute.String("http.route", "/api/users/{id}"), // ✅ 低基数
    attribute.Int("http.status_code", 200),           // ✅ 低基数
)

// 高基数数据放在Resource或事件中
resource.NewWithAttributes(
    semconv.ServiceNameKey.String("my-service"),
    attribute.String("user.id", "12345"),  // 在Resource中
)
```

**影响**: 高基数属性会导致:

- 存储成本增加 **10-100x**
- 查询性能下降 **5-10x**
- 索引大小增加 **10-50x**

---

### 5. 延迟初始化

```go
// ❌ 不推荐: 启动时立即初始化
func init() {
    initTracer()  // 阻塞启动
}

// ✅ 推荐: 按需初始化
var (
    tracerOnce sync.Once
    tracer     trace.Tracer
)

func getTracer() trace.Tracer {
    tracerOnce.Do(func() {
        tracer = initTracer()
    })
    return tracer
}
```

---

## 🔧 Collector优化

### 1. 批处理配置 (核心优化)

```yaml
processors:
  batch:
    timeout: 10s
    send_batch_size: 2048
    send_batch_max_size: 4096
```

**性能提升**: 吞吐量提升 **20-50x**, 网络请求减少 **95%+**

---

### 2. 内存限制器 (防止OOM)

```yaml
processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 2048        # 2GB内存上限
    spike_limit_mib: 512   # 512MB峰值
```

**作用**: 超过限制时自动丢弃数据,防止Collector崩溃

---

### 3. 并发导出

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      enabled: true
      num_consumers: 20    # 并发导出20个goroutine
      queue_size: 10000
```

**性能提升**: 导出吞吐量提升 **10-20x** (取决于后端延迟)

---

### 4. 资源配置建议

#### 小规模 (< 100 req/s)

```yaml
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 200m
    memory: 256Mi

processors:
  batch:
    send_batch_size: 512
  memory_limiter:
    limit_mib: 256

exporters:
  otlp:
    sending_queue:
      num_consumers: 5
      queue_size: 2000
```

#### 中等规模 (100-1000 req/s)

```yaml
resources:
  limits:
    cpu: 2000m
    memory: 2Gi
  requests:
    cpu: 1000m
    memory: 1Gi

processors:
  batch:
    send_batch_size: 1024
  memory_limiter:
    limit_mib: 1024

exporters:
  otlp:
    sending_queue:
      num_consumers: 10
      queue_size: 5000
```

#### 大规模 (> 1000 req/s)

```yaml
resources:
  limits:
    cpu: 4000m
    memory: 8Gi
  requests:
    cpu: 2000m
    memory: 4Gi

processors:
  batch:
    send_batch_size: 2048
  memory_limiter:
    limit_mib: 4096

exporters:
  otlp:
    sending_queue:
      num_consumers: 20
      queue_size: 10000
```

---

### 5. Pipeline精简

```yaml
# ❌ 不推荐: 过多处理器
service:
  pipelines:
    traces:
      processors:
        - memory_limiter
        - attributes          # 1
        - resource            # 2
        - transform           # 3
        - filter              # 4
        - tail_sampling       # 5
        - batch               # 6
        - attributes/again    # 7 重复!

# ✅ 推荐: 精简Pipeline
service:
  pipelines:
    traces:
      processors:
        - memory_limiter   # 必需
        - resource         # 合并资源属性
        - tail_sampling    # 采样
        - batch            # 批处理 (最后)
```

**性能提升**: CPU降低 **30-50%**

---

## 🌐 网络优化

### 1. 启用压缩 (必须!)

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    compression: gzip  # 或 zstd (v1.1.0+)
```

#### 压缩效果对比

| 压缩算法 | 压缩率 | CPU开销 | 推荐场景 |
|---------|--------|---------|---------|
| **none** | 0% | 无 | 仅本地开发 |
| **gzip** | 60-70% | 中等 | 通用场景 ✅ |
| **zstd** | 70-80% | 低-中等 | 高吞吐量 🔥 |

**网络流量节省**: **60-80%**

---

### 2. 使用gRPC (生产推荐)

| 协议 | 延迟 | 吞吐量 | 连接复用 |
|------|------|--------|---------|
| **gRPC** | 低 | 高 | ✅ HTTP/2 |
| **HTTP/1.1** | 中等 | 中等 | ❌ 每请求1连接 |

```yaml
# ✅ 推荐: gRPC
exporters:
  otlp:
    endpoint: backend:4317
    compression: gzip

# ⚠️ 备选: HTTP (防火墙限制时)
exporters:
  otlphttp:
    endpoint: https://backend:4318
    compression: gzip
```

**性能差异**: gRPC比HTTP/1.1快 **20-50%**

---

### 3. 连接池配置

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    balancer_name: round_robin
    keepalive:
      time: 30s
      timeout: 10s
      permit_without_stream: true
```

---

## 🎲 采样策略

### 1. 采样策略对比

| 策略 | 数据保留 | CPU节省 | 适用场景 |
|-----|---------|---------|---------|
| **Head Sampling (SDK)** | 固定比例 | ✅ 高 (95%+) | 高流量场景 |
| **Tail Sampling (Collector)** | 智能选择 | ⚠️ 中等 (50%) | 中等流量 |
| **混合采样** | 最优 | ✅ 高 | 大规模生产 |

---

### 2. Head Sampling (SDK层,性能最优)

```go
// 采样10%
tp := trace.NewTracerProvider(
    trace.WithSampler(trace.ParentBased(
        trace.TraceIDRatioBased(0.1),
    )),
)
```

**优势**:

- ✅ CPU节省 **95%**
- ✅ 网络节省 **90%**
- ✅ 零延迟
- ❌ 可能丢失重要Trace (错误/慢请求)

---

### 3. Tail Sampling (Collector层,智能采样)

```yaml
processors:
  tail_sampling:
    decision_wait: 10s
    policies:
      # 保留所有错误
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      
      # 保留慢请求 (>500ms)
      - name: slow
        type: latency
        latency:
          threshold_ms: 500
      
      # 采样10%正常请求
      - name: normal
        type: probabilistic
        probabilistic:
          sampling_percentage: 10
```

**优势**:

- ✅ 保留重要Trace (错误/慢请求)
- ✅ 采样率可达 **90%+**
- ⚠️ Collector CPU增加 **50%**
- ⚠️ 需缓存10s数据 (内存开销)

---

### 4. 混合采样 (推荐生产)

```text
┌──────────┐   Head Sampling (10%)   ┌──────────┐
│   SDK    │ ───────────────────────> │ Collector│
└──────────┘                          └──────────┘
                                           │
                                      Tail Sampling
                                      (保留错误100%,
                                       正常20%)
                                           │
                                           ▼
                                      ┌──────────┐
                                      │  Backend │
                                      └──────────┘

最终采样率: 10% * 20% + 10% * 100%(错误) = 2% + 错误
数据节省: 98%
CPU节省: 95%
```

---

## 💰 成本优化

### 1. 存储成本优化

#### 数据量对比

| 优化措施 | 数据量 | 成本节省 |
|---------|--------|---------|
| 基准 (无优化) | 100% | 0% |
| 启用压缩 (gzip) | 30% | **70%** |
| 采样10% | 10% | **90%** |
| 采样10% + 压缩 | 3% | **97%** |
| 采样1% + 压缩 | 0.3% | **99.7%** |

#### 成本计算示例

```text
假设:
- 流量: 1000 req/s
- 每Trace: 10 Spans
- 每Span: 2 KB
- 存储成本: $0.10/GB/月

无优化:
  数据量 = 1000 * 10 * 2KB * 86400 * 30 = 51.84 TB/月
  成本 = $5,184/月

采样10% + gzip压缩:
  数据量 = 51.84 TB * 10% * 30% = 1.56 TB/月
  成本 = $156/月
  节省 = $5,028/月 (97%)  🔥
```

---

### 2. 网络成本优化

```yaml
# 启用压缩
exporters:
  otlp:
    compression: gzip

# 增大批次,减少请求次数
processors:
  batch:
    send_batch_size: 2048
    timeout: 10s
```

**网络流量节省**: **90%+**

---

### 3. 计算成本优化

#### Collector横向扩展策略

```text
场景1: 高流量,简单处理
  策略: 多个小Collector (1 CPU, 1 GB)
  优势: 成本低,故障隔离

场景2: 中等流量,复杂处理 (Tail Sampling)
  策略: 少数大Collector (4 CPU, 8 GB)
  优势: 减少实例数,降低管理成本
```

---

## 📊 监控指标

### 关键性能指标

#### SDK层

| 指标 | 目标 | 告警阈值 |
|-----|------|---------|
| Span创建延迟 | < 1ms | > 5ms |
| 队列使用率 | < 50% | > 80% |
| 数据丢失率 | 0% | > 0.1% |

#### Collector层

```bash
# 查看Collector指标
curl http://localhost:8888/metrics

# 关键指标:
otelcol_receiver_accepted_spans_total       # 接收Span数
otelcol_processor_batch_batch_send_size_sum # 批次大小
otelcol_exporter_sent_spans_total           # 发送Span数
otelcol_exporter_send_failed_spans_total    # 失败Span数
otelcol_exporter_queue_size                 # 队列大小
```

#### 告警规则

```yaml
# Prometheus告警规则
groups:
  - name: otel_collector
    rules:
      # 数据丢失率 > 1%
      - alert: HighDataLossRate
        expr: |
          rate(otelcol_processor_dropped_spans_total[5m]) /
          rate(otelcol_receiver_accepted_spans_total[5m]) > 0.01
        for: 5m
        annotations:
          summary: "Collector丢失数据 > 1%"
      
      # 队列接近满
      - alert: QueueNearFull
        expr: otelcol_exporter_queue_size / otelcol_exporter_queue_capacity > 0.8
        for: 5m
        annotations:
          summary: "导出队列使用率 > 80%"
      
      # 导出失败率 > 5%
      - alert: HighExportFailureRate
        expr: |
          rate(otelcol_exporter_send_failed_spans_total[5m]) /
          rate(otelcol_exporter_sent_spans_total[5m]) > 0.05
        for: 5m
        annotations:
          summary: "导出失败率 > 5%"
```

---

## ✅ 优化清单

### 快速优化 (投入1小时,收益80%)

```text
✅ 启用批处理导出器 (BatchSpanProcessor)
✅ 配置合理的批处理参数 (batch_size=1024-2048)
✅ 启用压缩 (gzip或zstd)
✅ 配置内存限制器 (memory_limiter)
✅ 启用Head Sampling (采样10%)
✅ 过滤健康检查等噪音数据
```

### 进阶优化 (投入1天,收益15%)

```text
✅ 配置Tail Sampling (保留错误和慢请求)
✅ 精简Pipeline (移除不必要的Processor)
✅ 配置并发导出 (num_consumers=10-20)
✅ 避免高基数属性
✅ 使用gRPC替代HTTP
✅ 监控Collector指标并设置告警
```

### 高级优化 (投入1周,收益5%)

```text
✅ 实施混合采样策略
✅ 自定义采样策略 (基于业务规则)
✅ 优化资源配置 (CPU/内存)
✅ 实施多级缓存 (Edge → Gateway → Backend)
✅ 使用专用网络 (VPC Peering)
✅ 定期审查和调整采样率
```

---

## 🎯 最佳实践总结

```text
✅ 始终使用BatchProcessor (性能提升50-100x)
✅ 启用压缩 (网络节省60-80%)
✅ 配置采样 (成本节省90%+)
✅ 避免高基数属性 (存储节省10-100x)
✅ 精简Pipeline (CPU节省30-50%)
✅ 监控关键指标 (及时发现问题)
✅ 定期审查配置 (持续优化)
✅ 测试后再应用 (避免生产事故)
✅ 保留错误和慢请求 (保证可观测性)
✅ 逐步优化 (避免过度优化)
```

---

## 📚 参考资源

| 资源 | 链接 |
|------|------|
| **性能优化指南** | <https://opentelemetry.io/docs/specs/otel/performance/> |
| **采样策略** | <https://opentelemetry.io/docs/specs/otel/trace/sdk/#sampling> |
| **Collector性能** | <https://opentelemetry.io/docs/collector/scaling/> |
| **最佳实践** | <https://opentelemetry.io/docs/best-practices/> |

---

**最后更新**: 2025年10月9日  
**上一篇**: [故障排查速查手册](./04_故障排查速查手册.md)  
**下一篇**: [安全配置速查手册](./06_安全配置速查手册.md)
