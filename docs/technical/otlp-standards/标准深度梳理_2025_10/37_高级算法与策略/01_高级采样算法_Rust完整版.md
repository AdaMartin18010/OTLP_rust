# é«˜çº§é‡‡æ ·ç®—æ³• - Rustå®Œæ•´å®ç°

> **Rustç‰ˆæœ¬**: 1.90+  
> **æ ¸å¿ƒä¾èµ–**: tokio 1.47.1, rand 0.8  
> **OpenTelemetry**: 0.31.0  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ9æ—¥

---

## ğŸ“‹ ç›®å½•

- [é«˜çº§é‡‡æ ·ç®—æ³• - Rustå®Œæ•´å®ç°](#é«˜çº§é‡‡æ ·ç®—æ³•---rustå®Œæ•´å®ç°)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. é‡‡æ ·ç®—æ³•æ¦‚è¿°](#1-é‡‡æ ·ç®—æ³•æ¦‚è¿°)
    - [1.1 é‡‡æ ·ç±»å‹å¯¹æ¯”](#11-é‡‡æ ·ç±»å‹å¯¹æ¯”)
    - [1.2 é‡‡æ ·å™¨trait](#12-é‡‡æ ·å™¨trait)
  - [2. å›ºå®šæ¯”ä¾‹é‡‡æ ·](#2-å›ºå®šæ¯”ä¾‹é‡‡æ ·)
    - [2.1 TraceIDå“ˆå¸Œé‡‡æ ·](#21-traceidå“ˆå¸Œé‡‡æ ·)
    - [2.2 æ¦‚ç‡é‡‡æ ·å™¨](#22-æ¦‚ç‡é‡‡æ ·å™¨)
  - [3. è‡ªé€‚åº”é‡‡æ ·](#3-è‡ªé€‚åº”é‡‡æ ·)
    - [3.1 åŠ¨æ€é€Ÿç‡é‡‡æ ·å™¨](#31-åŠ¨æ€é€Ÿç‡é‡‡æ ·å™¨)
    - [3.2 è´Ÿè½½æ„ŸçŸ¥é‡‡æ ·å™¨](#32-è´Ÿè½½æ„ŸçŸ¥é‡‡æ ·å™¨)
  - [4. å°¾éƒ¨é‡‡æ ·](#4-å°¾éƒ¨é‡‡æ ·)
    - [4.1 åŸºäºçª—å£çš„å°¾éƒ¨é‡‡æ ·](#41-åŸºäºçª—å£çš„å°¾éƒ¨é‡‡æ ·)
  - [5. ä¼˜å…ˆçº§é‡‡æ ·](#5-ä¼˜å…ˆçº§é‡‡æ ·)
    - [5.1 åŸºäºä¼˜å…ˆçº§çš„é‡‡æ ·å™¨](#51-åŸºäºä¼˜å…ˆçº§çš„é‡‡æ ·å™¨)
  - [6. ä¸€è‡´æ€§é‡‡æ ·](#6-ä¸€è‡´æ€§é‡‡æ ·)
    - [6.1 ä¸€è‡´æ€§å“ˆå¸Œé‡‡æ ·å™¨](#61-ä¸€è‡´æ€§å“ˆå¸Œé‡‡æ ·å™¨)
  - [7. æœºå™¨å­¦ä¹ é‡‡æ ·](#7-æœºå™¨å­¦ä¹ é‡‡æ ·)
    - [7.1 ç‰¹å¾æå–](#71-ç‰¹å¾æå–)
  - [8. å®Œæ•´å®ç°](#8-å®Œæ•´å®ç°)
    - [8.1 ç»¼åˆé‡‡æ ·ç­–ç•¥](#81-ç»¼åˆé‡‡æ ·ç­–ç•¥)
  - [æ€»ç»“](#æ€»ç»“)

---

## 1. é‡‡æ ·ç®—æ³•æ¦‚è¿°

### 1.1 é‡‡æ ·ç±»å‹å¯¹æ¯”

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é‡‡æ ·ç±»å‹          â”‚  å†³ç­–æ—¶æœº   â”‚  ä¸Šä¸‹æ–‡    â”‚  å‡†ç¡®æ€§    â”‚  æˆæœ¬      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Head-based       â”‚  Spanå¼€å§‹  â”‚  éƒ¨åˆ†      â”‚  ä¸­ç­‰      â”‚  ä½        â”‚
â”‚ Tail-based       â”‚  Traceç»“æŸ â”‚  å®Œæ•´      â”‚  é«˜        â”‚  é«˜        â”‚
â”‚ Adaptive         â”‚  åŠ¨æ€      â”‚  è¿è¡Œæ—¶    â”‚  ä¸­ç­‰      â”‚  ä¸­ç­‰      â”‚
â”‚ Priority-based   â”‚  Spanå¼€å§‹  â”‚  ä¸šåŠ¡è§„åˆ™  â”‚  é«˜        â”‚  ä¸­ç­‰      â”‚
â”‚ Consistent       â”‚  Spanå¼€å§‹  â”‚  TraceID   â”‚  é«˜        â”‚  ä½        â”‚
â”‚ ML-based         â”‚  åŠ¨æ€      â”‚  å†å²æ•°æ®  â”‚  å¾ˆé«˜      â”‚  å¾ˆé«˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 é‡‡æ ·å™¨trait

```rust
use opentelemetry::trace::{SpanId, TraceId, TraceFlags};
use std::sync::Arc;

/// é‡‡æ ·å†³ç­–
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SamplingDecision {
    /// é‡‡æ ·
    Sample,
    
    /// ä¸é‡‡æ ·
    Drop,
    
    /// å»¶è¿Ÿå†³ç­–(ç”¨äºå°¾éƒ¨é‡‡æ ·)
    Defer,
}

/// é‡‡æ ·ç»“æœ
#[derive(Debug, Clone)]
pub struct SamplingResult {
    pub decision: SamplingDecision,
    pub trace_flags: TraceFlags,
    pub attributes: Vec<(String, AttributeValue)>,
}

/// é‡‡æ ·ä¸Šä¸‹æ–‡
#[derive(Debug, Clone)]
pub struct SamplingContext {
    pub trace_id: TraceId,
    pub parent_span_id: Option<SpanId>,
    pub name: String,
    pub kind: SpanKind,
    pub attributes: Vec<(String, AttributeValue)>,
    pub parent_sampled: Option<bool>,
}

/// é‡‡æ ·å™¨trait
#[async_trait::async_trait]
pub trait Sampler: Send + Sync {
    /// é‡‡æ ·å†³ç­–
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult;
    
    /// é‡‡æ ·å™¨æè¿°
    fn description(&self) -> String;
}

use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AttributeValue {
    String(String),
    Int(i64),
    Double(f64),
    Bool(bool),
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SpanKind {
    Internal,
    Server,
    Client,
    Producer,
    Consumer,
}
```

---

## 2. å›ºå®šæ¯”ä¾‹é‡‡æ ·

### 2.1 TraceIDå“ˆå¸Œé‡‡æ ·

```rust
/// TraceIDå“ˆå¸Œé‡‡æ ·å™¨
pub struct TraceIdRatioSampler {
    /// é‡‡æ ·ç‡ (0.0 - 1.0)
    sampling_rate: f64,
    
    /// é˜ˆå€¼ (ç”¨äºå¿«é€Ÿæ¯”è¾ƒ)
    threshold: u64,
    
    /// æè¿°
    description: String,
}

impl TraceIdRatioSampler {
    pub fn new(sampling_rate: f64) -> Self {
        assert!((0.0..=1.0).contains(&sampling_rate), "Sampling rate must be between 0.0 and 1.0");
        
        let threshold = (sampling_rate * u64::MAX as f64) as u64;
        
        Self {
            sampling_rate,
            threshold,
            description: format!("TraceIdRatioSampler({})", sampling_rate),
        }
    }
    
    /// ä»TraceIDè®¡ç®—å“ˆå¸Œ
    fn hash_trace_id(&self, trace_id: &TraceId) -> u64 {
        let bytes = trace_id.to_bytes();
        
        // ä½¿ç”¨ä½64ä½ä½œä¸ºå“ˆå¸Œ
        let mut hash = 0u64;
        for i in 0..8 {
            hash = (hash << 8) | bytes[i + 8] as u64;
        }
        
        hash
    }
}

#[async_trait::async_trait]
impl Sampler for TraceIdRatioSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        let hash = self.hash_trace_id(&ctx.trace_id);
        
        let decision = if hash < self.threshold {
            SamplingDecision::Sample
        } else {
            SamplingDecision::Drop
        };
        
        SamplingResult {
            decision,
            trace_flags: if decision == SamplingDecision::Sample {
                TraceFlags::SAMPLED
            } else {
                TraceFlags::default()
            },
            attributes: vec![],
        }
    }
    
    fn description(&self) -> String {
        self.description.clone()
    }
}
```

### 2.2 æ¦‚ç‡é‡‡æ ·å™¨

```rust
use rand::Rng;

/// æ¦‚ç‡é‡‡æ ·å™¨
pub struct ProbabilitySampler {
    /// é‡‡æ ·ç‡
    sampling_rate: f64,
    
    /// éšæœºæ•°ç”Ÿæˆå™¨
    rng: Arc<Mutex<rand::rngs::ThreadRng>>,
}

impl ProbabilitySampler {
    pub fn new(sampling_rate: f64) -> Self {
        Self {
            sampling_rate,
            rng: Arc::new(Mutex::new(rand::thread_rng())),
        }
    }
}

#[async_trait::async_trait]
impl Sampler for ProbabilitySampler {
    async fn should_sample(&self, _ctx: &SamplingContext) -> SamplingResult {
        let mut rng = self.rng.lock().await;
        let random: f64 = rng.gen();
        
        let decision = if random < self.sampling_rate {
            SamplingDecision::Sample
        } else {
            SamplingDecision::Drop
        };
        
        SamplingResult {
            decision,
            trace_flags: if decision == SamplingDecision::Sample {
                TraceFlags::SAMPLED
            } else {
                TraceFlags::default()
            },
            attributes: vec![],
        }
    }
    
    fn description(&self) -> String {
        format!("ProbabilitySampler({})", self.sampling_rate)
    }
}
```

---

## 3. è‡ªé€‚åº”é‡‡æ ·

### 3.1 åŠ¨æ€é€Ÿç‡é‡‡æ ·å™¨

```rust
use std::sync::atomic::{AtomicU64, Ordering};

/// åŠ¨æ€é€Ÿç‡é‡‡æ ·å™¨
pub struct DynamicRateSampler {
    /// ç›®æ ‡QPS
    target_qps: Arc<AtomicU64>,
    
    /// å½“å‰é‡‡æ ·ç‡
    current_rate: Arc<RwLock<f64>>,
    
    /// ç»Ÿè®¡çª—å£
    stats: Arc<RwLock<SamplingStats>>,
    
    /// è°ƒæ•´é—´éš”
    adjustment_interval: Duration,
}

#[derive(Debug, Default)]
struct SamplingStats {
    /// çª—å£å†…çš„spanæ•°
    span_count: u64,
    
    /// çª—å£å†…é‡‡æ ·çš„spanæ•°
    sampled_count: u64,
    
    /// çª—å£å¼€å§‹æ—¶é—´
    window_start: Option<Instant>,
}

impl DynamicRateSampler {
    pub fn new(initial_rate: f64, target_qps: u64) -> Arc<Self> {
        let sampler = Arc::new(Self {
            target_qps: Arc::new(AtomicU64::new(target_qps)),
            current_rate: Arc::new(RwLock::new(initial_rate)),
            stats: Arc::new(RwLock::new(SamplingStats::default())),
            adjustment_interval: Duration::from_secs(10),
        });
        
        // å¯åŠ¨è‡ªé€‚åº”è°ƒæ•´
        let sampler_clone = Arc::clone(&sampler);
        tokio::spawn(async move {
            sampler_clone.adjust_sampling_rate_loop().await;
        });
        
        sampler
    }
    
    /// è‡ªé€‚åº”è°ƒæ•´å¾ªç¯
    async fn adjust_sampling_rate_loop(&self) {
        let mut ticker = tokio::time::interval(self.adjustment_interval);
        
        loop {
            ticker.tick().await;
            
            self.adjust_sampling_rate().await;
        }
    }
    
    /// è°ƒæ•´é‡‡æ ·ç‡
    async fn adjust_sampling_rate(&self) {
        let mut stats = self.stats.write().await;
        
        if let Some(window_start) = stats.window_start {
            let elapsed = window_start.elapsed();
            let elapsed_secs = elapsed.as_secs_f64();
            
            if elapsed_secs > 0.0 {
                // è®¡ç®—å½“å‰QPS
                let current_qps = stats.sampled_count as f64 / elapsed_secs;
                let target_qps = self.target_qps.load(Ordering::Relaxed) as f64;
                
                // è®¡ç®—æ–°çš„é‡‡æ ·ç‡
                let mut current_rate = self.current_rate.write().await;
                let adjustment_factor = target_qps / current_qps.max(1.0);
                let new_rate = (*current_rate * adjustment_factor).clamp(0.001, 1.0);
                
                tracing::info!(
                    "Adjusting sampling rate: {:.4} -> {:.4} (current_qps={:.2}, target_qps={:.2})",
                    *current_rate,
                    new_rate,
                    current_qps,
                    target_qps
                );
                
                *current_rate = new_rate;
            }
            
            // é‡ç½®ç»Ÿè®¡
            stats.span_count = 0;
            stats.sampled_count = 0;
            stats.window_start = Some(Instant::now());
        } else {
            stats.window_start = Some(Instant::now());
        }
    }
    
    /// æ›´æ–°ç»Ÿè®¡
    async fn record_decision(&self, sampled: bool) {
        let mut stats = self.stats.write().await;
        stats.span_count += 1;
        if sampled {
            stats.sampled_count += 1;
        }
    }
}

#[async_trait::async_trait]
impl Sampler for DynamicRateSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        let current_rate = *self.current_rate.read().await;
        
        // ä½¿ç”¨TraceIDå“ˆå¸Œå†³ç­–
        let trace_id_sampler = TraceIdRatioSampler::new(current_rate);
        let result = trace_id_sampler.should_sample(ctx).await;
        
        // è®°å½•ç»Ÿè®¡
        self.record_decision(result.decision == SamplingDecision::Sample).await;
        
        result
    }
    
    fn description(&self) -> String {
        "DynamicRateSampler".to_string()
    }
}
```

### 3.2 è´Ÿè½½æ„ŸçŸ¥é‡‡æ ·å™¨

```rust
/// è´Ÿè½½æ„ŸçŸ¥é‡‡æ ·å™¨
pub struct LoadAwareSampler {
    /// åŸºç¡€é‡‡æ ·ç‡
    base_rate: f64,
    
    /// å½“å‰é‡‡æ ·ç‡
    current_rate: Arc<RwLock<f64>>,
    
    /// è´Ÿè½½ç›‘æ§å™¨
    load_monitor: Arc<LocalLoadMonitor>,
    
    /// é™çº§é˜ˆå€¼
    degradation_thresholds: DegradationThresholds,
}

#[derive(Debug, Clone)]
pub struct DegradationThresholds {
    pub cpu_warning: f64,
    pub cpu_critical: f64,
    pub memory_warning: f64,
    pub memory_critical: f64,
}

impl LoadAwareSampler {
    pub fn new(
        base_rate: f64,
        load_monitor: Arc<LocalLoadMonitor>,
        thresholds: DegradationThresholds,
    ) -> Arc<Self> {
        let sampler = Arc::new(Self {
            base_rate,
            current_rate: Arc::new(RwLock::new(base_rate)),
            load_monitor,
            degradation_thresholds: thresholds,
        });
        
        // å¯åŠ¨è´Ÿè½½ç›‘æ§
        let sampler_clone = Arc::clone(&sampler);
        tokio::spawn(async move {
            sampler_clone.monitor_load_loop().await;
        });
        
        sampler
    }
    
    /// è´Ÿè½½ç›‘æ§å¾ªç¯
    async fn monitor_load_loop(&self) {
        let mut ticker = tokio::time::interval(Duration::from_secs(5));
        
        loop {
            ticker.tick().await;
            
            self.adjust_rate_based_on_load().await;
        }
    }
    
    /// æ ¹æ®è´Ÿè½½è°ƒæ•´é‡‡æ ·ç‡
    async fn adjust_rate_based_on_load(&self) {
        let load = self.load_monitor.get_current_load().await;
        
        // è®¡ç®—é™çº§å› å­
        let cpu_factor = self.calculate_degradation_factor(
            load.cpu_usage,
            self.degradation_thresholds.cpu_warning,
            self.degradation_thresholds.cpu_critical,
        );
        
        let memory_factor = self.calculate_degradation_factor(
            load.memory_usage,
            self.degradation_thresholds.memory_warning,
            self.degradation_thresholds.memory_critical,
        );
        
        // ä½¿ç”¨æœ€å°å› å­
        let degradation_factor = cpu_factor.min(memory_factor);
        
        let new_rate = self.base_rate * degradation_factor;
        
        let mut current_rate = self.current_rate.write().await;
        if (*current_rate - new_rate).abs() > 0.01 {
            tracing::info!(
                "Load-aware rate adjustment: {:.4} -> {:.4} (CPU={:.2}%, MEM={:.2}%)",
                *current_rate,
                new_rate,
                load.cpu_usage,
                load.memory_usage
            );
            *current_rate = new_rate;
        }
    }
    
    /// è®¡ç®—é™çº§å› å­
    fn calculate_degradation_factor(&self, current: f64, warning: f64, critical: f64) -> f64 {
        if current < warning {
            1.0
        } else if current < critical {
            // çº¿æ€§é™çº§
            1.0 - (current - warning) / (critical - warning) * 0.9
        } else {
            0.1 // æœ€å°10%
        }
    }
}

#[async_trait::async_trait]
impl Sampler for LoadAwareSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        let current_rate = *self.current_rate.read().await;
        
        let trace_id_sampler = TraceIdRatioSampler::new(current_rate);
        trace_id_sampler.should_sample(ctx).await
    }
    
    fn description(&self) -> String {
        "LoadAwareSampler".to_string()
    }
}

// ç®€åŒ–çš„è´Ÿè½½ç›‘æ§å™¨
use tokio::sync::Mutex;
use std::collections::HashMap;

pub struct LocalLoadMonitor {
    current_load: Arc<Mutex<Load>>,
}

#[derive(Debug, Clone, Default)]
pub struct Load {
    pub cpu_usage: f64,
    pub memory_usage: f64,
    pub qps: u64,
    pub bps: u64,
    pub queue_depth: u64,
    pub error_rate: f64,
    pub avg_latency_ms: f64,
}

impl LocalLoadMonitor {
    pub fn new(_history_size: usize) -> Self {
        Self {
            current_load: Arc::new(Mutex::new(Load::default())),
        }
    }
    
    pub async fn get_current_load(&self) -> Load {
        self.current_load.lock().await.clone()
    }
}
```

---

## 4. å°¾éƒ¨é‡‡æ ·

### 4.1 åŸºäºçª—å£çš„å°¾éƒ¨é‡‡æ ·

```rust
use std::collections::VecDeque;

/// å°¾éƒ¨é‡‡æ ·å™¨
pub struct TailSampler {
    /// å®Œæ•´çš„traceç¼“å­˜
    trace_cache: Arc<RwLock<HashMap<TraceId, CachedTrace>>>,
    
    /// é‡‡æ ·è§„åˆ™
    rules: Arc<Vec<TailSamplingRule>>,
    
    /// ç¼“å­˜è¶…æ—¶
    cache_timeout: Duration,
    
    /// æœ€å¤§ç¼“å­˜å¤§å°
    max_cache_size: usize,
}

/// ç¼“å­˜çš„Trace
#[derive(Debug, Clone)]
struct CachedTrace {
    trace_id: TraceId,
    spans: Vec<CachedSpan>,
    first_seen: Instant,
    is_complete: bool,
}

#[derive(Debug, Clone)]
struct CachedSpan {
    span_id: SpanId,
    name: String,
    kind: SpanKind,
    start_time: u64,
    end_time: u64,
    attributes: HashMap<String, AttributeValue>,
    status: SpanStatus,
}

#[derive(Debug, Clone)]
struct SpanStatus {
    code: StatusCode,
    message: String,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum StatusCode {
    Ok,
    Error,
}

/// å°¾éƒ¨é‡‡æ ·è§„åˆ™
#[derive(Debug, Clone)]
pub enum TailSamplingRule {
    /// æ‰€æœ‰é”™è¯¯trace
    AllErrors,
    
    /// æ…¢trace
    SlowTraces { threshold_ms: u64 },
    
    /// ç‰¹å®šæœåŠ¡
    SpecificService { service_name: String },
    
    /// é‡‡æ ·ç‡
    SampleRate { rate: f64 },
    
    /// å¤åˆè§„åˆ™
    Composite { rules: Vec<TailSamplingRule>, operator: RuleOperator },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RuleOperator {
    And,
    Or,
}

impl TailSampler {
    pub fn new(
        rules: Vec<TailSamplingRule>,
        cache_timeout: Duration,
        max_cache_size: usize,
    ) -> Arc<Self> {
        let sampler = Arc::new(Self {
            trace_cache: Arc::new(RwLock::new(HashMap::new())),
            rules: Arc::new(rules),
            cache_timeout,
            max_cache_size,
        });
        
        // å¯åŠ¨ç¼“å­˜æ¸…ç†
        let sampler_clone = Arc::clone(&sampler);
        tokio::spawn(async move {
            sampler_clone.cleanup_loop().await;
        });
        
        // å¯åŠ¨é‡‡æ ·å†³ç­–
        let sampler_clone = Arc::clone(&sampler);
        tokio::spawn(async move {
            sampler_clone.sampling_decision_loop().await;
        });
        
        sampler
    }
    
    /// æ·»åŠ spanåˆ°ç¼“å­˜
    pub async fn add_span(&self, span: CachedSpan, trace_id: TraceId) {
        let mut cache = self.trace_cache.write().await;
        
        // æ£€æŸ¥ç¼“å­˜å¤§å°
        if cache.len() >= self.max_cache_size {
            // ç§»é™¤æœ€è€çš„trace
            if let Some(oldest_trace_id) = cache.iter()
                .min_by_key(|(_, trace)| trace.first_seen)
                .map(|(id, _)| *id)
            {
                cache.remove(&oldest_trace_id);
            }
        }
        
        cache.entry(trace_id)
            .or_insert_with(|| CachedTrace {
                trace_id,
                spans: Vec::new(),
                first_seen: Instant::now(),
                is_complete: false,
            })
            .spans.push(span);
    }
    
    /// æ ‡è®°traceä¸ºå®Œæˆ
    pub async fn mark_complete(&self, trace_id: TraceId) {
        let mut cache = self.trace_cache.write().await;
        if let Some(trace) = cache.get_mut(&trace_id) {
            trace.is_complete = true;
        }
    }
    
    /// é‡‡æ ·å†³ç­–å¾ªç¯
    async fn sampling_decision_loop(&self) {
        let mut ticker = tokio::time::interval(Duration::from_millis(100));
        
        loop {
            ticker.tick().await;
            
            let mut cache = self.trace_cache.write().await;
            let mut to_remove = Vec::new();
            
            for (trace_id, trace) in cache.iter() {
                if trace.is_complete || trace.first_seen.elapsed() > self.cache_timeout {
                    // æ‰§è¡Œé‡‡æ ·å†³ç­–
                    let should_sample = self.evaluate_rules(trace).await;
                    
                    if should_sample {
                        tracing::debug!("Tail sampling: keeping trace {:?}", trace_id);
                        // å®é™…åº”è¯¥å¯¼å‡ºtrace
                    } else {
                        tracing::debug!("Tail sampling: dropping trace {:?}", trace_id);
                    }
                    
                    to_remove.push(*trace_id);
                }
            }
            
            for trace_id in to_remove {
                cache.remove(&trace_id);
            }
        }
    }
    
    /// è¯„ä¼°è§„åˆ™
    async fn evaluate_rules(&self, trace: &CachedTrace) -> bool {
        for rule in self.rules.iter() {
            if self.evaluate_rule(rule, trace).await {
                return true;
            }
        }
        false
    }
    
    /// è¯„ä¼°å•ä¸ªè§„åˆ™
    async fn evaluate_rule(&self, rule: &TailSamplingRule, trace: &CachedTrace) -> bool {
        match rule {
            TailSamplingRule::AllErrors => {
                trace.spans.iter().any(|span| span.status.code == StatusCode::Error)
            }
            
            TailSamplingRule::SlowTraces { threshold_ms } => {
                if let Some(duration) = self.calculate_trace_duration(trace) {
                    duration > *threshold_ms
                } else {
                    false
                }
            }
            
            TailSamplingRule::SpecificService { service_name } => {
                trace.spans.iter().any(|span| {
                    span.attributes.get("service.name")
                        .and_then(|v| match v {
                            AttributeValue::String(s) => Some(s == service_name),
                            _ => None,
                        })
                        .unwrap_or(false)
                })
            }
            
            TailSamplingRule::SampleRate { rate } => {
                let trace_id_sampler = TraceIdRatioSampler::new(*rate);
                let ctx = SamplingContext {
                    trace_id: trace.trace_id,
                    parent_span_id: None,
                    name: "".to_string(),
                    kind: SpanKind::Internal,
                    attributes: vec![],
                    parent_sampled: None,
                };
                
                let result = trace_id_sampler.should_sample(&ctx).await;
                result.decision == SamplingDecision::Sample
            }
            
            TailSamplingRule::Composite { rules, operator } => {
                match operator {
                    RuleOperator::And => {
                        for rule in rules {
                            if !self.evaluate_rule(rule, trace).await {
                                return false;
                            }
                        }
                        true
                    }
                    RuleOperator::Or => {
                        for rule in rules {
                            if self.evaluate_rule(rule, trace).await {
                                return true;
                            }
                        }
                        false
                    }
                }
            }
        }
    }
    
    /// è®¡ç®—traceæŒç»­æ—¶é—´
    fn calculate_trace_duration(&self, trace: &CachedTrace) -> Option<u64> {
        if trace.spans.is_empty() {
            return None;
        }
        
        let min_start = trace.spans.iter().map(|s| s.start_time).min()?;
        let max_end = trace.spans.iter().map(|s| s.end_time).max()?;
        
        Some((max_end - min_start) / 1_000_000) // è½¬æ¢ä¸ºæ¯«ç§’
    }
    
    /// ç¼“å­˜æ¸…ç†å¾ªç¯
    async fn cleanup_loop(&self) {
        let mut ticker = tokio::time::interval(Duration::from_secs(60));
        
        loop {
            ticker.tick().await;
            
            let mut cache = self.trace_cache.write().await;
            cache.retain(|_, trace| {
                trace.first_seen.elapsed() < self.cache_timeout * 2
            });
            
            tracing::debug!("Cache size after cleanup: {}", cache.len());
        }
    }
}
```

---

## 5. ä¼˜å…ˆçº§é‡‡æ ·

### 5.1 åŸºäºä¼˜å…ˆçº§çš„é‡‡æ ·å™¨

```rust
/// ä¼˜å…ˆçº§é‡‡æ ·å™¨
pub struct PrioritySampler {
    /// ä¼˜å…ˆçº§è§„åˆ™
    priority_rules: Arc<Vec<PriorityRule>>,
    
    /// é»˜è®¤é‡‡æ ·ç‡
    default_rate: f64,
}

/// ä¼˜å…ˆçº§è§„åˆ™
#[derive(Debug, Clone)]
pub struct PriorityRule {
    /// ä¼˜å…ˆçº§
    pub priority: Priority,
    
    /// åŒ¹é…æ¡ä»¶
    pub condition: RuleCondition,
    
    /// é‡‡æ ·ç‡
    pub sampling_rate: f64,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum Priority {
    Critical = 3,
    High = 2,
    Normal = 1,
    Low = 0,
}

#[derive(Debug, Clone)]
pub enum RuleCondition {
    /// æœåŠ¡ååŒ¹é…
    ServiceName(String),
    
    /// æ“ä½œååŒ¹é…
    OperationName(String),
    
    /// å±æ€§åŒ¹é…
    Attribute { key: String, value: AttributeValue },
    
    /// Spanç±»å‹
    SpanKind(SpanKind),
    
    /// å¤åˆæ¡ä»¶
    Composite {
        conditions: Vec<RuleCondition>,
        operator: RuleOperator,
    },
}

impl PrioritySampler {
    pub fn new(priority_rules: Vec<PriorityRule>, default_rate: f64) -> Self {
        // æŒ‰ä¼˜å…ˆçº§æ’åºè§„åˆ™
        let mut rules = priority_rules;
        rules.sort_by(|a, b| b.priority.cmp(&a.priority));
        
        Self {
            priority_rules: Arc::new(rules),
            default_rate,
        }
    }
    
    /// åŒ¹é…è§„åˆ™
    fn match_rule(&self, ctx: &SamplingContext) -> Option<&PriorityRule> {
        for rule in self.priority_rules.iter() {
            if self.evaluate_condition(&rule.condition, ctx) {
                return Some(rule);
            }
        }
        None
    }
    
    /// è¯„ä¼°æ¡ä»¶
    fn evaluate_condition(&self, condition: &RuleCondition, ctx: &SamplingContext) -> bool {
        match condition {
            RuleCondition::ServiceName(name) => {
                ctx.attributes.iter().any(|(k, v)| {
                    k == "service.name" && matches!(v, AttributeValue::String(s) if s == name)
                })
            }
            
            RuleCondition::OperationName(name) => {
                &ctx.name == name
            }
            
            RuleCondition::Attribute { key, value } => {
                ctx.attributes.iter().any(|(k, v)| {
                    k == key && self.match_attribute_value(v, value)
                })
            }
            
            RuleCondition::SpanKind(kind) => {
                ctx.kind == *kind
            }
            
            RuleCondition::Composite { conditions, operator } => {
                match operator {
                    RuleOperator::And => {
                        conditions.iter().all(|c| self.evaluate_condition(c, ctx))
                    }
                    RuleOperator::Or => {
                        conditions.iter().any(|c| self.evaluate_condition(c, ctx))
                    }
                }
            }
        }
    }
    
    fn match_attribute_value(&self, actual: &AttributeValue, expected: &AttributeValue) -> bool {
        match (actual, expected) {
            (AttributeValue::String(a), AttributeValue::String(e)) => a == e,
            (AttributeValue::Int(a), AttributeValue::Int(e)) => a == e,
            (AttributeValue::Double(a), AttributeValue::Double(e)) => (a - e).abs() < f64::EPSILON,
            (AttributeValue::Bool(a), AttributeValue::Bool(e)) => a == e,
            _ => false,
        }
    }
}

#[async_trait::async_trait]
impl Sampler for PrioritySampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        let sampling_rate = if let Some(rule) = self.match_rule(ctx) {
            tracing::debug!(
                "Matched priority rule: priority={:?}, rate={}",
                rule.priority,
                rule.sampling_rate
            );
            rule.sampling_rate
        } else {
            self.default_rate
        };
        
        let trace_id_sampler = TraceIdRatioSampler::new(sampling_rate);
        trace_id_sampler.should_sample(ctx).await
    }
    
    fn description(&self) -> String {
        "PrioritySampler".to_string()
    }
}
```

---

## 6. ä¸€è‡´æ€§é‡‡æ ·

### 6.1 ä¸€è‡´æ€§å“ˆå¸Œé‡‡æ ·å™¨

```rust
use std::collections::BTreeMap;

/// ä¸€è‡´æ€§é‡‡æ ·å™¨
pub struct ConsistentSampler {
    /// é‡‡æ ·ç‡
    sampling_rate: f64,
    
    /// ä¸€è‡´æ€§å“ˆå¸Œç¯
    hash_ring: Arc<RwLock<ConsistentHashRing>>,
}

/// ä¸€è‡´æ€§å“ˆå¸Œç¯
struct ConsistentHashRing {
    /// è™šæ‹ŸèŠ‚ç‚¹æ•°
    virtual_nodes: usize,
    
    /// å“ˆå¸Œç¯
    ring: BTreeMap<u64, String>,
    
    /// èŠ‚ç‚¹é‡‡æ ·ç‡
    node_rates: HashMap<String, f64>,
}

impl ConsistentHashRing {
    fn new(virtual_nodes: usize) -> Self {
        Self {
            virtual_nodes,
            ring: BTreeMap::new(),
            node_rates: HashMap::new(),
        }
    }
    
    /// æ·»åŠ èŠ‚ç‚¹
    fn add_node(&mut self, node_id: String, sampling_rate: f64) {
        for i in 0..self.virtual_nodes {
            let key = format!("{}:{}", node_id, i);
            let hash = self.hash_key(&key);
            self.ring.insert(hash, node_id.clone());
        }
        
        self.node_rates.insert(node_id, sampling_rate);
    }
    
    /// è·å–èŠ‚ç‚¹
    fn get_node(&self, key: &str) -> Option<&String> {
        if self.ring.is_empty() {
            return None;
        }
        
        let hash = self.hash_key(key);
        
        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhashçš„èŠ‚ç‚¹
        self.ring.range(hash..)
            .next()
            .or_else(|| self.ring.iter().next())
            .map(|(_, node)| node)
    }
    
    /// è·å–é‡‡æ ·ç‡
    fn get_sampling_rate(&self, node_id: &str) -> f64 {
        self.node_rates.get(node_id).copied().unwrap_or(0.0)
    }
    
    /// å“ˆå¸Œå‡½æ•°
    fn hash_key(&self, key: &str) -> u64 {
        use std::hash::{Hash, Hasher};
        use std::collections::hash_map::DefaultHasher;
        
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish()
    }
}

impl ConsistentSampler {
    pub fn new(sampling_rate: f64, num_buckets: usize) -> Self {
        let mut ring = ConsistentHashRing::new(100);
        
        // åˆ›å»ºé‡‡æ ·æ¡¶
        for i in 0..num_buckets {
            let rate = if i < (num_buckets as f64 * sampling_rate) as usize {
                1.0
            } else {
                0.0
            };
            ring.add_node(format!("bucket-{}", i), rate);
        }
        
        Self {
            sampling_rate,
            hash_ring: Arc::new(RwLock::new(ring)),
        }
    }
}

#[async_trait::async_trait]
impl Sampler for ConsistentSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        let trace_id_str = format!("{:?}", ctx.trace_id);
        
        let ring = self.hash_ring.read().await;
        let node = ring.get_node(&trace_id_str);
        
        let sampling_rate = node
            .map(|n| ring.get_sampling_rate(n))
            .unwrap_or(0.0);
        
        let decision = if sampling_rate >= 1.0 {
            SamplingDecision::Sample
        } else {
            SamplingDecision::Drop
        };
        
        SamplingResult {
            decision,
            trace_flags: if decision == SamplingDecision::Sample {
                TraceFlags::SAMPLED
            } else {
                TraceFlags::default()
            },
            attributes: vec![],
        }
    }
    
    fn description(&self) -> String {
        format!("ConsistentSampler({})", self.sampling_rate)
    }
}
```

---

## 7. æœºå™¨å­¦ä¹ é‡‡æ ·

### 7.1 ç‰¹å¾æå–

```rust
/// MLé‡‡æ ·å™¨
pub struct MlSampler {
    /// æ¨¡å‹
    model: Arc<RwLock<SamplingModel>>,
    
    /// ç‰¹å¾æå–å™¨
    feature_extractor: Arc<FeatureExtractor>,
    
    /// è®­ç»ƒæ•°æ®æ”¶é›†å™¨
    training_collector: Arc<Mutex<TrainingDataCollector>>,
}

/// é‡‡æ ·æ¨¡å‹(ç®€åŒ–ç‰ˆ)
struct SamplingModel {
    /// æƒé‡
    weights: Vec<f64>,
    
    /// åç½®
    bias: f64,
}

impl SamplingModel {
    fn new() -> Self {
        Self {
            weights: vec![0.0; 10], // 10ä¸ªç‰¹å¾
            bias: 0.0,
        }
    }
    
    /// é¢„æµ‹
    fn predict(&self, features: &[f64]) -> f64 {
        let mut score = self.bias;
        
        for (w, f) in self.weights.iter().zip(features.iter()) {
            score += w * f;
        }
        
        // Sigmoidæ¿€æ´»
        1.0 / (1.0 + (-score).exp())
    }
    
    /// è®­ç»ƒ(ç®€åŒ–ç‰ˆ)
    fn train(&mut self, samples: &[(Vec<f64>, bool)], learning_rate: f64) {
        for (features, label) in samples {
            let prediction = self.predict(features);
            let error = if *label { 1.0 } else { 0.0 } - prediction;
            
            // æ›´æ–°æƒé‡
            for (w, f) in self.weights.iter_mut().zip(features.iter()) {
                *w += learning_rate * error * f;
            }
            
            self.bias += learning_rate * error;
        }
    }
}

/// ç‰¹å¾æå–å™¨
struct FeatureExtractor;

impl FeatureExtractor {
    /// æå–ç‰¹å¾
    fn extract_features(&self, ctx: &SamplingContext) -> Vec<f64> {
        let mut features = Vec::with_capacity(10);
        
        // 1. TraceIDå“ˆå¸Œå½’ä¸€åŒ–
        let trace_hash = self.hash_trace_id(&ctx.trace_id);
        features.push(trace_hash as f64 / u64::MAX as f64);
        
        // 2. Spanç±»å‹
        features.push(ctx.kind as i32 as f64);
        
        // 3. åç§°é•¿åº¦
        features.push(ctx.name.len() as f64 / 100.0);
        
        // 4. å±æ€§æ•°é‡
        features.push(ctx.attributes.len() as f64 / 10.0);
        
        // 5-10. ç‰¹å®šå±æ€§å­˜åœ¨æ€§
        features.push(if self.has_error_attribute(ctx) { 1.0 } else { 0.0 });
        features.push(if self.has_db_attribute(ctx) { 1.0 } else { 0.0 });
        features.push(if self.has_http_attribute(ctx) { 1.0 } else { 0.0 });
        features.push(if self.has_rpc_attribute(ctx) { 1.0 } else { 0.0 });
        features.push(if ctx.parent_sampled.unwrap_or(false) { 1.0 } else { 0.0 });
        features.push(if ctx.parent_span_id.is_some() { 1.0 } else { 0.0 });
        
        features
    }
    
    fn hash_trace_id(&self, trace_id: &TraceId) -> u64 {
        let bytes = trace_id.to_bytes();
        let mut hash = 0u64;
        for i in 0..8 {
            hash = (hash << 8) | bytes[i] as u64;
        }
        hash
    }
    
    fn has_error_attribute(&self, ctx: &SamplingContext) -> bool {
        ctx.attributes.iter().any(|(k, _)| k.contains("error"))
    }
    
    fn has_db_attribute(&self, ctx: &SamplingContext) -> bool {
        ctx.attributes.iter().any(|(k, _)| k.starts_with("db."))
    }
    
    fn has_http_attribute(&self, ctx: &SamplingContext) -> bool {
        ctx.attributes.iter().any(|(k, _)| k.starts_with("http."))
    }
    
    fn has_rpc_attribute(&self, ctx: &SamplingContext) -> bool {
        ctx.attributes.iter().any(|(k, _)| k.starts_with("rpc."))
    }
}

/// è®­ç»ƒæ•°æ®æ”¶é›†å™¨
struct TrainingDataCollector {
    samples: VecDeque<(Vec<f64>, bool)>,
    max_samples: usize,
}

impl TrainingDataCollector {
    fn new(max_samples: usize) -> Self {
        Self {
            samples: VecDeque::with_capacity(max_samples),
            max_samples,
        }
    }
    
    fn add_sample(&mut self, features: Vec<f64>, label: bool) {
        if self.samples.len() >= self.max_samples {
            self.samples.pop_front();
        }
        self.samples.push_back((features, label));
    }
    
    fn get_samples(&self) -> Vec<(Vec<f64>, bool)> {
        self.samples.iter().cloned().collect()
    }
}

impl MlSampler {
    pub fn new() -> Arc<Self> {
        let sampler = Arc::new(Self {
            model: Arc::new(RwLock::new(SamplingModel::new())),
            feature_extractor: Arc::new(FeatureExtractor),
            training_collector: Arc::new(Mutex::new(TrainingDataCollector::new(10000))),
        });
        
        // å¯åŠ¨å®šæœŸè®­ç»ƒ
        let sampler_clone = Arc::clone(&sampler);
        tokio::spawn(async move {
            sampler_clone.training_loop().await;
        });
        
        sampler
    }
    
    /// è®­ç»ƒå¾ªç¯
    async fn training_loop(&self) {
        let mut ticker = tokio::time::interval(Duration::from_secs(300)); // æ¯5åˆ†é’Ÿ
        
        loop {
            ticker.tick().await;
            
            let samples = {
                let collector = self.training_collector.lock().await;
                collector.get_samples()
            };
            
            if samples.len() >= 100 {
                let mut model = self.model.write().await;
                model.train(&samples, 0.01);
                
                tracing::info!("Model trained with {} samples", samples.len());
            }
        }
    }
}

#[async_trait::async_trait]
impl Sampler for MlSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        // æå–ç‰¹å¾
        let features = self.feature_extractor.extract_features(ctx);
        
        // æ¨¡å‹é¢„æµ‹
        let model = self.model.read().await;
        let probability = model.predict(&features);
        
        // æ¦‚ç‡é‡‡æ ·
        let decision = if rand::random::<f64>() < probability {
            SamplingDecision::Sample
        } else {
            SamplingDecision::Drop
        };
        
        // æ”¶é›†è®­ç»ƒæ•°æ®(ç®€åŒ–ï¼šåŸºäºç®€å•è§„åˆ™)
        let label = self.should_be_sampled_for_training(ctx);
        let mut collector = self.training_collector.lock().await;
        collector.add_sample(features, label);
        
        SamplingResult {
            decision,
            trace_flags: if decision == SamplingDecision::Sample {
                TraceFlags::SAMPLED
            } else {
                TraceFlags::default()
            },
            attributes: vec![],
        }
    }
    
    fn description(&self) -> String {
        "MlSampler".to_string()
    }
}

impl MlSampler {
    fn should_be_sampled_for_training(&self, ctx: &SamplingContext) -> bool {
        // ç®€åŒ–çš„æ ‡ç­¾é€»è¾‘
        ctx.attributes.iter().any(|(k, _)| k.contains("error"))
            || ctx.kind == SpanKind::Server
    }
}
```

---

## 8. å®Œæ•´å®ç°

### 8.1 ç»¼åˆé‡‡æ ·ç­–ç•¥

```rust
/// ç»„åˆé‡‡æ ·å™¨
pub struct CompositeSampler {
    samplers: Vec<(String, Arc<dyn Sampler>)>,
    strategy: CompositeStrategy,
}

pub enum CompositeStrategy {
    /// ç¬¬ä¸€ä¸ªé‡‡æ ·å³é‡‡æ ·
    Any,
    
    /// æ‰€æœ‰é‡‡æ ·å™¨éƒ½é‡‡æ ·
    All,
    
    /// æŒ‰ä¼˜å…ˆçº§
    Priority,
}

impl CompositeSampler {
    pub fn new(samplers: Vec<(String, Arc<dyn Sampler>)>, strategy: CompositeStrategy) -> Self {
        Self {
            samplers,
            strategy,
        }
    }
}

#[async_trait::async_trait]
impl Sampler for CompositeSampler {
    async fn should_sample(&self, ctx: &SamplingContext) -> SamplingResult {
        match self.strategy {
            CompositeStrategy::Any => {
                for (name, sampler) in &self.samplers {
                    let result = sampler.should_sample(ctx).await;
                    if result.decision == SamplingDecision::Sample {
                        tracing::debug!("Sampled by: {}", name);
                        return result;
                    }
                }
                
                SamplingResult {
                    decision: SamplingDecision::Drop,
                    trace_flags: TraceFlags::default(),
                    attributes: vec![],
                }
            }
            
            CompositeStrategy::All => {
                for (name, sampler) in &self.samplers {
                    let result = sampler.should_sample(ctx).await;
                    if result.decision != SamplingDecision::Sample {
                        tracing::debug!("Not sampled by: {}", name);
                        return result;
                    }
                }
                
                SamplingResult {
                    decision: SamplingDecision::Sample,
                    trace_flags: TraceFlags::SAMPLED,
                    attributes: vec![],
                }
            }
            
            CompositeStrategy::Priority => {
                // ä½¿ç”¨ç¬¬ä¸€ä¸ªé‡‡æ ·å™¨
                if let Some((name, sampler)) = self.samplers.first() {
                    tracing::debug!("Using priority sampler: {}", name);
                    sampler.should_sample(ctx).await
                } else {
                    SamplingResult {
                        decision: SamplingDecision::Drop,
                        trace_flags: TraceFlags::default(),
                        attributes: vec![],
                    }
                }
            }
        }
    }
    
    fn description(&self) -> String {
        format!("CompositeSampler({:?})", self.strategy)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt::init();
    
    // åˆ›å»ºå„ç§é‡‡æ ·å™¨
    let samplers: Vec<(String, Arc<dyn Sampler>)> = vec![
        (
            "base_rate".to_string(),
            Arc::new(TraceIdRatioSampler::new(0.1)),
        ),
        (
            "priority".to_string(),
            Arc::new(PrioritySampler::new(
                vec![
                    PriorityRule {
                        priority: Priority::Critical,
                        condition: RuleCondition::ServiceName("payment".to_string()),
                        sampling_rate: 1.0,
                    },
                ],
                0.1,
            )),
        ),
    ];
    
    let composite = CompositeSampler::new(samplers, CompositeStrategy::Any);
    
    // æµ‹è¯•é‡‡æ ·
    let ctx = SamplingContext {
        trace_id: TraceId::from_bytes([1u8; 16]),
        parent_span_id: None,
        name: "test".to_string(),
        kind: SpanKind::Server,
        attributes: vec![
            ("service.name".to_string(), AttributeValue::String("payment".to_string())),
        ],
        parent_sampled: None,
    };
    
    let result = composite.should_sample(&ctx).await;
    println!("Sampling decision: {:?}", result.decision);
    
    Ok(())
}
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†é«˜çº§é‡‡æ ·ç®—æ³•çš„å®Œæ•´Rustå®ç°ï¼ŒåŒ…æ‹¬:

âœ… **å›ºå®šæ¯”ä¾‹é‡‡æ ·**:

- TraceIDå“ˆå¸Œé‡‡æ ·
- æ¦‚ç‡é‡‡æ ·

âœ… **è‡ªé€‚åº”é‡‡æ ·**:

- åŠ¨æ€é€Ÿç‡è°ƒæ•´
- è´Ÿè½½æ„ŸçŸ¥é‡‡æ ·

âœ… **å°¾éƒ¨é‡‡æ ·**:

- åŸºäºçª—å£çš„ç¼“å­˜
- è§„åˆ™è¯„ä¼°å¼•æ“

âœ… **ä¼˜å…ˆçº§é‡‡æ ·**:

- å¤šä¼˜å…ˆçº§è§„åˆ™
- å¤åˆæ¡ä»¶åŒ¹é…

âœ… **ä¸€è‡´æ€§é‡‡æ ·**:

- ä¸€è‡´æ€§å“ˆå¸Œç¯
- è·¨æœåŠ¡ä¸€è‡´æ€§

âœ… **æœºå™¨å­¦ä¹ é‡‡æ ·**:

- ç‰¹å¾æå–
- åœ¨çº¿å­¦ä¹ 

---

**å‚è€ƒèµ„æº**:

- [OpenTelemetry Sampling](https://opentelemetry.io/docs/specs/otel/trace/sdk/#sampling)
- [Consistent Hashing](https://en.wikipedia.org/wiki/Consistent_hashing)
- [Machine Learning Systems](https://ml-ops.org/)
