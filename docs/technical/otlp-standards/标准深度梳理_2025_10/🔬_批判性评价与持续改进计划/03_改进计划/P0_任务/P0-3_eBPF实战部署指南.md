# ğŸ› ï¸ eBPFå®æˆ˜éƒ¨ç½²æŒ‡å— - Pixie/Beyla/Tetragon/Parca

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-09  
**çŠ¶æ€**: ğŸŸ¡ è¿›è¡Œä¸­ (P0-3ä»»åŠ¡)  
**ç›®æ ‡**: æä¾›å®Œæ•´çš„eBPFå¯è§‚æµ‹æ€§å·¥å…·éƒ¨ç½²ä¸å®æˆ˜æŒ‡å—

---

## ğŸ“‹ ç›®å½•

- [ğŸ› ï¸ eBPFå®æˆ˜éƒ¨ç½²æŒ‡å— - Pixie/Beyla/Tetragon/Parca](#ï¸-ebpfå®æˆ˜éƒ¨ç½²æŒ‡å—---pixiebeylatetragonparca)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ“Š æ‰§è¡Œæ‘˜è¦](#-æ‰§è¡Œæ‘˜è¦)
  - [ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©eBPFå¯è§‚æµ‹æ€§?](#-ä¸ºä»€ä¹ˆé€‰æ‹©ebpfå¯è§‚æµ‹æ€§)
    - [eBPF vs ä¼ ç»ŸAPMå¯¹æ¯”](#ebpf-vs-ä¼ ç»Ÿapmå¯¹æ¯”)
    - [æŠ€æœ¯é€‰å‹å†³ç­–æ ‘](#æŠ€æœ¯é€‰å‹å†³ç­–æ ‘)
  - [ğŸ”· Pixie - KubernetesåŸç”Ÿå¯è§‚æµ‹æ€§å¹³å°](#-pixie---kubernetesåŸç”Ÿå¯è§‚æµ‹æ€§å¹³å°)
    - [1.1 æ ¸å¿ƒç‰¹æ€§](#11-æ ¸å¿ƒç‰¹æ€§)
    - [1.2 å¿«é€Ÿéƒ¨ç½² (5åˆ†é’Ÿä¸Šæ‰‹)](#12-å¿«é€Ÿéƒ¨ç½²-5åˆ†é’Ÿä¸Šæ‰‹)
    - [1.3 å®æˆ˜æ¡ˆä¾‹: HTTPè¿½è¸ª](#13-å®æˆ˜æ¡ˆä¾‹-httpè¿½è¸ª)
    - [1.4 å®æˆ˜æ¡ˆä¾‹: MySQLæŸ¥è¯¢åˆ†æ](#14-å®æˆ˜æ¡ˆä¾‹-mysqlæŸ¥è¯¢åˆ†æ)
    - [1.5 ä¸OTLPé›†æˆ](#15-ä¸otlpé›†æˆ)
    - [1.6 ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ](#16-ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ)
  - [ğŸ”¶ Grafana Beyla - é›¶ä»£ç HTTP/gRPCè¿½è¸ª](#-grafana-beyla---é›¶ä»£ç httpgrpcè¿½è¸ª)
    - [2.1 æ ¸å¿ƒç‰¹æ€§](#21-æ ¸å¿ƒç‰¹æ€§)
    - [2.2 å¿«é€Ÿéƒ¨ç½²](#22-å¿«é€Ÿéƒ¨ç½²)
    - [2.3 å®æˆ˜æ¡ˆä¾‹: GoæœåŠ¡è¿½è¸ª](#23-å®æˆ˜æ¡ˆä¾‹-goæœåŠ¡è¿½è¸ª)
    - [2.4 å®æˆ˜æ¡ˆä¾‹: Python Flaskåº”ç”¨](#24-å®æˆ˜æ¡ˆä¾‹-python-flaskåº”ç”¨)
    - [2.5 OTLPå¯¼å‡ºé…ç½®](#25-otlpå¯¼å‡ºé…ç½®)
    - [2.6 ä¸Grafana Cloudé›†æˆ](#26-ä¸grafana-cloudé›†æˆ)
  - [ğŸ”· Cilium Tetragon - å®‰å…¨å¯è§‚æµ‹æ€§ä¸è¿è¡Œæ—¶åŠ å›º](#-cilium-tetragon---å®‰å…¨å¯è§‚æµ‹æ€§ä¸è¿è¡Œæ—¶åŠ å›º)
    - [3.1 æ ¸å¿ƒç‰¹æ€§](#31-æ ¸å¿ƒç‰¹æ€§)
    - [3.2 å¿«é€Ÿéƒ¨ç½²](#32-å¿«é€Ÿéƒ¨ç½²)
    - [3.3 å®æˆ˜æ¡ˆä¾‹: æ£€æµ‹æ•æ„Ÿæ–‡ä»¶è®¿é—®](#33-å®æˆ˜æ¡ˆä¾‹-æ£€æµ‹æ•æ„Ÿæ–‡ä»¶è®¿é—®)
    - [3.4 å®æˆ˜æ¡ˆä¾‹: ç½‘ç»œè¿æ¥ç›‘æ§](#34-å®æˆ˜æ¡ˆä¾‹-ç½‘ç»œè¿æ¥ç›‘æ§)
    - [3.5 è¿è¡Œæ—¶ç­–ç•¥å¼ºåˆ¶æ‰§è¡Œ](#35-è¿è¡Œæ—¶ç­–ç•¥å¼ºåˆ¶æ‰§è¡Œ)
    - [3.6 ä¸Falcoå¯¹æ¯”](#36-ä¸falcoå¯¹æ¯”)
  - [ğŸ”¶ Parca - æŒç»­æ€§èƒ½å‰–æ (Continuous Profiling)](#-parca---æŒç»­æ€§èƒ½å‰–æ-continuous-profiling)
    - [4.1 æ ¸å¿ƒç‰¹æ€§](#41-æ ¸å¿ƒç‰¹æ€§)
    - [4.2 å¿«é€Ÿéƒ¨ç½²](#42-å¿«é€Ÿéƒ¨ç½²)
    - [4.3 å®æˆ˜æ¡ˆä¾‹: CPUæ€§èƒ½åˆ†æ](#43-å®æˆ˜æ¡ˆä¾‹-cpuæ€§èƒ½åˆ†æ)
    - [4.4 å®æˆ˜æ¡ˆä¾‹: å†…å­˜æ³„æ¼å®šä½](#44-å®æˆ˜æ¡ˆä¾‹-å†…å­˜æ³„æ¼å®šä½)
    - [4.5 Flame Graphè§£è¯»](#45-flame-graphè§£è¯»)
    - [4.6 ä¸Pyroscopeå¯¹æ¯”](#46-ä¸pyroscopeå¯¹æ¯”)
  - [ğŸ¯ ç»¼åˆå®æˆ˜: å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ](#-ç»¼åˆå®æˆ˜-å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ)
    - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
    - [éƒ¨ç½²æ¸…å•](#éƒ¨ç½²æ¸…å•)
    - [ç»Ÿä¸€æ•°æ®æµ](#ç»Ÿä¸€æ•°æ®æµ)
  - [ğŸ”§ æ•…éšœæ’æŸ¥ä¸è°ƒä¼˜](#-æ•…éšœæ’æŸ¥ä¸è°ƒä¼˜)
    - [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
    - [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
  - [ğŸ“Š æ€§èƒ½å¼€é”€å¯¹æ¯”](#-æ€§èƒ½å¼€é”€å¯¹æ¯”)
  - [ğŸ†š å·¥å…·é€‰å‹å»ºè®®](#-å·¥å…·é€‰å‹å»ºè®®)
  - [ğŸ“š ç›¸å…³æ–‡æ¡£](#-ç›¸å…³æ–‡æ¡£)
  - [ğŸ’¼ ä¼ä¸šè½åœ°è·¯çº¿å›¾](#-ä¼ä¸šè½åœ°è·¯çº¿å›¾)
    - [é˜¶æ®µ1: PoCéªŒè¯ (Week 1-2)](#é˜¶æ®µ1-pocéªŒè¯-week-1-2)
    - [é˜¶æ®µ2: è¯•ç‚¹ä¸Šçº¿ (Week 3-6)](#é˜¶æ®µ2-è¯•ç‚¹ä¸Šçº¿-week-3-6)
    - [é˜¶æ®µ3: å…¨é¢æ¨å¹¿ (Week 7-12)](#é˜¶æ®µ3-å…¨é¢æ¨å¹¿-week-7-12)
    - [é˜¶æ®µ4: æŒç»­ä¼˜åŒ– (Ongoing)](#é˜¶æ®µ4-æŒç»­ä¼˜åŒ–-ongoing)
  - [ğŸ¯ å®Œæˆæ€»ç»“ä¸åç»­å±•æœ›](#-å®Œæˆæ€»ç»“ä¸åç»­å±•æœ›)

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬æŒ‡å—æä¾›4ä¸ªä¸»æµeBPFå¯è§‚æµ‹æ€§å·¥å…·çš„å®Œæ•´éƒ¨ç½²ä¸å®æˆ˜æ•™ç¨‹:

| å·¥å…· | å®šä½ | é€‚ç”¨åœºæ™¯ | å­¦ä¹ æ›²çº¿ |
|-----|------|---------|---------|
| **Pixie** | å®Œæ•´å¯è§‚æµ‹æ€§å¹³å° | Kubernetesç¯å¢ƒ,å¿«é€Ÿä¸Šæ‰‹ | â­â­ ç®€å• |
| **Beyla** | HTTP/gRPCè¿½è¸ª | å•ä½“åº”ç”¨,é›¶ä»£ç è¿½è¸ª | â­ æç®€ |
| **Tetragon** | å®‰å…¨å¯è§‚æµ‹æ€§ | è¿è¡Œæ—¶å®‰å…¨,åˆè§„å®¡è®¡ | â­â­â­ ä¸­ç­‰ |
| **Parca** | æŒç»­æ€§èƒ½å‰–æ | æ€§èƒ½ä¼˜åŒ–,å†…å­˜æ³„æ¼ | â­â­â­ ä¸­ç­‰ |

**æ ¸å¿ƒä»·å€¼**:

- ğŸš€ é›¶ä»£ç ä¾µå…¥ - æ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç 
- âš¡ æä½å¼€é”€ - < 1% CPU,< 100MBå†…å­˜
- ğŸ” æ·±åº¦å¯è§æ€§ - å†…æ ¸çº§è¿½è¸ª
- ğŸ”— OTLPåŸç”Ÿæ”¯æŒ - æ— ç¼é›†æˆå¯è§‚æµ‹æ€§ç”Ÿæ€

**é¢„æœŸæ”¶ç›Š**:

- ğŸ“‰ éƒ¨ç½²æ—¶é—´: 30åˆ†é’Ÿ â†’ 5åˆ†é’Ÿ (å‡å°‘83%)
- ğŸ¯ è¦†ç›–ç‡: 50% â†’ 100% (æœªæ”¹é€ åº”ç”¨ä¹Ÿå¯è§‚æµ‹)
- ğŸ’° æˆæœ¬: èŠ‚çœ80% (vs å•†ä¸šAPM)
- ğŸ”§ ç»´æŠ¤æˆæœ¬: é™ä½70%

---

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©eBPFå¯è§‚æµ‹æ€§?

### eBPF vs ä¼ ç»ŸAPMå¯¹æ¯”

```mermaid
graph LR
    subgraph "ä¼ ç»ŸAPM (SDK/Agent)"
        A1[åº”ç”¨ä»£ç ] -->|SDKä¾µå…¥| A2[APM Agent]
        A2 -->|å¤§é‡æ•°æ®| A3[APMåç«¯]
        A1 -->|æ€§èƒ½å¼€é”€3-10%| A4[å½±å“ç”Ÿäº§]
    end
    
    subgraph "eBPFæ–¹æ¡ˆ"
        B1[åº”ç”¨ä»£ç ] -->|é›¶ä¾µå…¥| B2[å†…æ ¸eBPF]
        B2 -->|å†…æ ¸èšåˆ| B3[ç”¨æˆ·æ€Agent]
        B3 -->|ç²¾ç®€æ•°æ®| B4[OTLP Collector]
        B1 -->|æ€§èƒ½å¼€é”€<1%| B5[å‡ ä¹æ— å½±å“]
    end
```

**å…³é”®ä¼˜åŠ¿**:

| ç»´åº¦ | ä¼ ç»ŸAPM | eBPFæ–¹æ¡ˆ |
|-----|---------|---------|
| **ä»£ç ä¾µå…¥** | âŒ éœ€è¦SDK | âœ… é›¶ä¾µå…¥ |
| **è¯­è¨€æ”¯æŒ** | âš ï¸ éœ€è¦SDK | âœ… è¯­è¨€æ— å…³ |
| **æ€§èƒ½å¼€é”€** | 3-10% | <1% |
| **éƒ¨ç½²éš¾åº¦** | ä¸­é«˜ (éœ€æ”¹ä»£ç ) | ä½ (é…ç½®å³å¯) |
| **æœªæ”¹é€ åº”ç”¨** | âŒ æ— æ³•è¿½è¸ª | âœ… å®Œå…¨æ”¯æŒ |
| **å†…æ ¸å¯è§æ€§** | âŒ æ—  | âœ… å®Œæ•´ |
| **æˆæœ¬** | é«˜ (æŒ‰hostæ”¶è´¹) | ä½ (å¼€æº) |

### æŠ€æœ¯é€‰å‹å†³ç­–æ ‘

```text
å¼€å§‹
  â”‚
  â”œâ”€ ä¸»è¦éœ€æ±‚?
  â”‚    â”œâ”€ å¿«é€Ÿå…¨æ ˆå¯è§‚æµ‹æ€§ (K8s) â†’ Pixie âœ…
  â”‚    â”œâ”€ HTTP/gRPCé›¶ä»£ç è¿½è¸ª â†’ Beyla âœ…
  â”‚    â”œâ”€ å®‰å…¨åˆè§„å®¡è®¡ â†’ Tetragon âœ…
  â”‚    â””â”€ æ€§èƒ½ä¼˜åŒ–/å†…å­˜æ³„æ¼ â†’ Parca âœ…
  â”‚
  â””â”€ æ˜¯å¦å·²æœ‰Grafanaæ ˆ?
       â”œâ”€ æ˜¯ â†’ Beyla + Parca (åŸç”Ÿé›†æˆ)
       â””â”€ å¦ â†’ Pixie (ç‹¬ç«‹å¹³å°) æˆ– Tetragon (å®‰å…¨èšç„¦)
```

---

## ğŸ”· Pixie - KubernetesåŸç”Ÿå¯è§‚æµ‹æ€§å¹³å°

### 1.1 æ ¸å¿ƒç‰¹æ€§

Pixieæ˜¯New Relicå¼€æºçš„KubernetesåŸç”Ÿå¯è§‚æµ‹æ€§å¹³å°,æä¾›**è‡ªåŠ¨åŒ–è¿½è¸ªã€æŒ‡æ ‡å’Œæ—¥å¿—é‡‡é›†**ã€‚

**ç‰¹è‰²åŠŸèƒ½**:

- âœ… **è‡ªåŠ¨åè®®è§£æ**: HTTP, HTTPS, gRPC, MySQL, PostgreSQL, Redis, Kafka, DNS, Cassandra
- âœ… **å³æ—¶æŸ¥è¯¢**: åŸºäºPxL(Pixie Language)çš„å®æ—¶æŸ¥è¯¢
- âœ… **Service Map**: è‡ªåŠ¨ç”ŸæˆæœåŠ¡æ‹“æ‰‘å›¾
- âœ… **åˆ†å¸ƒå¼è¿½è¸ª**: è‡ªåŠ¨å…³è”è¯·æ±‚é“¾è·¯
- âœ… **ç½‘ç»œç›‘æ§**: TCP/UDPè¿æ¥ã€ä¸¢åŒ…ã€å»¶è¿Ÿ

**æ¶æ„**:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Pixie Cloud (ç®¡ç†å¹³é¢)               â”‚
â”‚       æˆ– Self-Hosted Pixie (ç§æœ‰åŒ–)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ gRPC
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Pixie Vizier (K8sé›†ç¾¤å†…æ•°æ®å¹³é¢)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Kelvin (Query Engine)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   PEM (Pixie Edge Module) - DaemonSetâ”‚   â”‚
â”‚  â”‚   - eBPF Data Collection              â”‚   â”‚
â”‚  â”‚   - Protocol Parsing                  â”‚   â”‚
â”‚  â”‚   - Local Storage (çŸ­æœŸ)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å¿«é€Ÿéƒ¨ç½² (5åˆ†é’Ÿä¸Šæ‰‹)

**å‰ææ¡ä»¶**:

- Kubernetes 1.19+
- å†…æ ¸ç‰ˆæœ¬ 4.14+ (æ¨è 5.4+)
- æ¯èŠ‚ç‚¹ 1GB+ å¯ç”¨å†…å­˜

**æ–¹æ³•1: Pixie Cloud (æ¨è,æœ€ç®€å•)**:

```bash
# 1. å®‰è£…Pixie CLI
bash -c "$(curl -fsSL https://withpixie.ai/install.sh)"

# 2. éƒ¨ç½²åˆ°K8sé›†ç¾¤
px deploy

# 3. æˆæƒå¹¶å¯åŠ¨
# ä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨è¿›è¡ŒOAuthæˆæƒ

# 4. æŸ¥çœ‹çŠ¶æ€
px get viziers
px get pems
```

**æ–¹æ³•2: Helméƒ¨ç½² (è‡ªå®šä¹‰é…ç½®)**:

```bash
# 1. æ·»åŠ Helmä»“åº“
helm repo add pixie https://pixie-operator-charts.storage.googleapis.com
helm repo update

# 2. åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace px-operator

# 3. éƒ¨ç½²Operator
helm install pixie pixie/pixie-operator-chart \
  --namespace px-operator \
  --set deployKey=<YOUR_DEPLOY_KEY> \
  --set clusterName=my-cluster

# 4. éªŒè¯éƒ¨ç½²
kubectl get pods -n pl
kubectl get pods -n px-operator
```

**æ–¹æ³•3: Self-Hosted Pixie (ç§æœ‰åŒ–éƒ¨ç½²)**:

```yaml
# pixie-values.yaml
# å®Œå…¨ç§æœ‰åŒ–éƒ¨ç½²,æ•°æ®ä¸ç¦»å¼€é›†ç¾¤
---
cloudAddr: ""  # ç•™ç©ºä½¿ç”¨æœ¬åœ°æ¨¡å¼
devCloudNamespace: "plc"
pemMemoryLimit: "2Gi"  # æ ¹æ®èŠ‚ç‚¹è§„æ ¼è°ƒæ•´
```

```bash
helm install pixie pixie/pixie-operator-chart \
  -f pixie-values.yaml \
  --namespace px-operator \
  --create-namespace
```

### 1.3 å®æˆ˜æ¡ˆä¾‹: HTTPè¿½è¸ª

**åœºæ™¯**: è¿½è¸ªKubernetesä¸­æ‰€æœ‰HTTPè¯·æ±‚,åˆ†æå»¶è¿Ÿå’Œé”™è¯¯ç‡

**PxLè„šæœ¬** (PixieæŸ¥è¯¢è¯­è¨€):

```python
# http_requests.pxl
# æŸ¥è¯¢æ‰€æœ‰HTTPè¯·æ±‚,æŒ‰æœåŠ¡èšåˆ

import px

# å®šä¹‰æ—¶é—´çª—å£
df = px.DataFrame('http_events', start_time='-5m')

# é€‰æ‹©å­—æ®µ
df = df[['time_', 'upid', 'remote_addr', 'req_method', 
         'req_path', 'resp_status', 'resp_latency_ms', 
         'resp_body_size']]

# æ·»åŠ å…ƒæ•°æ®
df.pod = df.ctx['pod']
df.service = df.ctx['service']
df.namespace = df.ctx['namespace']

# è¿‡æ»¤æ¡ä»¶
df = df[df.service != '']
df = df[df.resp_status != 0]

# è®¡ç®—èšåˆæŒ‡æ ‡
agg = df.groupby(['service', 'req_path', 'resp_status']).agg(
    requests=('resp_status', px.count),
    p50_latency=('resp_latency_ms', px.quantiles, [0.5]),
    p95_latency=('resp_latency_ms', px.quantiles, [0.95]),
    p99_latency=('resp_latency_ms', px.quantiles, [0.99]),
    total_bytes=('resp_body_size', px.sum),
    error_rate=('resp_status', px.error_rate)
)

# æŒ‰é”™è¯¯ç‡æ’åº
agg = agg[agg.error_rate > 0.01]  # é”™è¯¯ç‡>1%
agg = agg.sort('error_rate', ascending=False)

px.display(agg)
```

**æ‰§è¡ŒæŸ¥è¯¢**:

```bash
# æ–¹æ³•1: Web UI
px live http_requests.pxl

# æ–¹æ³•2: CLI
px run http_requests.pxl

# æ–¹æ³•3: å®æ—¶æµå¼æŸ¥è¯¢
px live http_requests.pxl --namespace default
```

**è¾“å‡ºç¤ºä¾‹**:

```text
service          req_path              resp_status  requests  p50_latency  p95_latency  error_rate
-------------    -------------------   -----------  --------  -----------  -----------  ----------
api-gateway      /api/v1/users         500          1,234     45.2ms       120.5ms      0.15
payment-service  /api/v1/checkout      503          456       230.1ms      890.3ms      0.08
order-service    /api/v1/orders        200          45,678    12.3ms       34.5ms       0.001
```

### 1.4 å®æˆ˜æ¡ˆä¾‹: MySQLæŸ¥è¯¢åˆ†æ

**åœºæ™¯**: è¿½è¸ªæ…¢æŸ¥è¯¢,è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

```python
# mysql_slow_queries.pxl
import px

# æ•è·æ‰€æœ‰MySQLæŸ¥è¯¢
df = px.DataFrame('mysql_events', start_time='-10m')

# é€‰æ‹©å­—æ®µ
df = df[['time_', 'pod', 'req_cmd', 'req_body', 
         'resp_status', 'latency_ms']]

# è¿‡æ»¤æ…¢æŸ¥è¯¢ (>100ms)
df = df[df.latency_ms > 100]

# èšåˆç»Ÿè®¡
slow_queries = df.groupby(['pod', 'req_body']).agg(
    count=('latency_ms', px.count),
    avg_latency=('latency_ms', px.mean),
    max_latency=('latency_ms', px.max)
)

# æŒ‰å¹³å‡å»¶è¿Ÿæ’åº
slow_queries = slow_queries.sort('avg_latency', ascending=False)
slow_queries = slow_queries.head(20)

px.display(slow_queries, 'Top 20 Slow Queries')
```

**è¾“å‡ºç¤ºä¾‹**:

```text
pod              req_body                           count  avg_latency  max_latency
--------------   --------------------------------   -----  -----------  -----------
mysql-0          SELECT * FROM orders WHERE ...     45     450.2ms      1200.5ms
mysql-1          UPDATE users SET last_login ...    12     320.5ms      890.3ms
```

### 1.5 ä¸OTLPé›†æˆ

PixieåŸç”Ÿæ”¯æŒå¯¼å‡ºåˆ°OpenTelemetry Collectorã€‚

**é…ç½®OpenTelemetry Plugin**:

```yaml
# pixie-otel-plugin.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: pixie-otel-config
  namespace: px-operator
data:
  config.yaml: |
    exporters:
      otlp:
        endpoint: "otel-collector.observability:4317"
        insecure: true
    
    processors:
      batch:
        timeout: 10s
        send_batch_size: 1024
    
    receivers:
      pixie:
        # ä»Pixieå¯¼å‡ºè¿½è¸ªæ•°æ®
        scripts:
          - |
            import px
            df = px.DataFrame('http_events', start_time='-1m')
            df.service = df.ctx['service']
            df.pod = df.ctx['pod']
            px.export(df, px.otel.Data(
              resource={
                'service.name': df.service,
                'k8s.pod.name': df.pod,
              },
              data=[
                px.otel.trace.Span(
                  name=df.req_path,
                  start_time=df.time_,
                  end_time=df.time_ + px.DurationNanos(df.resp_latency_ms * 1000000),
                  attributes={
                    'http.method': df.req_method,
                    'http.status_code': df.resp_status,
                  }
                )
              ]
            ))
    
    service:
      pipelines:
        traces:
          receivers: [pixie]
          processors: [batch]
          exporters: [otlp]
```

**éƒ¨ç½²Plugin**:

```bash
kubectl apply -f pixie-otel-plugin.yaml

# éªŒè¯
kubectl logs -n px-operator -l app=pixie-otel-plugin
```

### 1.6 ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ

**èµ„æºé…ç½®**:

```yaml
# pixie-production-values.yaml
# ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®

# PEMèµ„æºé™åˆ¶
pem:
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  
  # æ•°æ®ä¿ç•™ç­–ç•¥ (æœ¬åœ°çŸ­æœŸå­˜å‚¨)
  dataRetention: "15m"
  
  # é‡‡æ ·ç‡ (é«˜æµé‡ç¯å¢ƒé™ä½é‡‡æ ·)
  samplingRate: 0.1  # 10%é‡‡æ ·
  
  # åè®®è§£æä¼˜åŒ–
  protocols:
    http:
      enabled: true
      maxBodySize: 1024  # 1KB (å‡å°‘å†…å­˜)
    mysql:
      enabled: true
    redis:
      enabled: false  # å…³é—­ä¸éœ€è¦çš„åè®®

# Kelvinèµ„æºé™åˆ¶
kelvin:
  replicas: 2  # é«˜å¯ç”¨
  resources:
    requests:
      memory: "2Gi"
      cpu: "1000m"
    limits:
      memory: "4Gi"
      cpu: "4000m"

# ç›‘æ§é›†æˆ
monitoring:
  prometheus:
    enabled: true
    serviceMonitor: true
```

**å®‰å…¨åŠ å›º**:

```yaml
# pixie-security.yaml
# å¯ç”¨RBACå’Œç½‘ç»œç­–ç•¥

apiVersion: v1
kind: ServiceAccount
metadata:
  name: pixie-service-account
  namespace: pl

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pixie-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "endpoints"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list"]

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: pixie-netpol
  namespace: pl
spec:
  podSelector:
    matchLabels:
      app: pl-monitoring
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: pl
  egress:
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 443
```

---

## ğŸ”¶ Grafana Beyla - é›¶ä»£ç HTTP/gRPCè¿½è¸ª

### 2.1 æ ¸å¿ƒç‰¹æ€§

Beylaæ˜¯Grafana Labsæ¨å‡ºçš„è½»é‡çº§eBPFè¿½è¸ªå·¥å…·,ä¸“æ³¨äº**é›¶ä»£ç HTTP/gRPCè¿½è¸ª**ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:

- âœ… **æç®€éƒ¨ç½²**: å•ä¸ªäºŒè¿›åˆ¶,æ— ä¾èµ–
- âœ… **è¯­è¨€æ— å…³**: Go, Python, Java, Node.js, Rustç­‰
- âœ… **OTLPåŸç”Ÿ**: ç›´æ¥å¯¼å‡ºOpenTelemetryæ•°æ®
- âœ… **ä½å¼€é”€**: < 0.5% CPU, < 50MBå†…å­˜

**æ”¯æŒåè®®**:

- HTTP/1.x, HTTP/2, HTTPS
- gRPC
- è‡ªåŠ¨SSL/TLSè§£å¯†

### 2.2 å¿«é€Ÿéƒ¨ç½²

**æ–¹æ³•1: Docker Sidecaræ¨¡å¼**:

```yaml
# docker-compose.yml
version: '3.8'

services:
  # ä½ çš„åº”ç”¨
  my-app:
    image: my-app:latest
    ports:
      - "8080:8080"
  
  # Beyla Sidecar
  beyla:
    image: grafana/beyla:latest
    privileged: true  # éœ€è¦åŠ è½½eBPF
    pid: "service:my-app"  # å…±äº«PIDå‘½åç©ºé—´
    environment:
      - BEYLA_EXECUTABLE_NAME=my-app  # ç›®æ ‡è¿›ç¨‹å
      - BEYLA_OPEN_PORT=8080  # ç›‘å¬ç«¯å£
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_SERVICE_NAME=my-app
    volumes:
      - /sys/kernel/debug:/sys/kernel/debug:ro
```

**æ–¹æ³•2: Kubernetes DaemonSet**:

```yaml
# beyla-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: beyla
  namespace: observability
spec:
  selector:
    matchLabels:
      app: beyla
  template:
    metadata:
      labels:
        app: beyla
    spec:
      hostPID: true  # è®¿é—®ä¸»æœºPIDå‘½åç©ºé—´
      hostNetwork: true
      serviceAccountName: beyla
      containers:
      - name: beyla
        image: grafana/beyla:latest
        securityContext:
          privileged: true
        env:
        - name: BEYLA_DISCOVERY_ENABLED
          value: "true"  # è‡ªåŠ¨å‘ç°è¿›ç¨‹
        - name: BEYLA_DISCOVERY_SERVICES
          value: "http"  # åªè¿½è¸ªHTTPæœåŠ¡
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector.observability:4317"
        - name: OTEL_METRICS_EXPORTER
          value: "otlp"
        - name: OTEL_TRACES_EXPORTER
          value: "otlp"
        volumeMounts:
        - name: sys-kernel-debug
          mountPath: /sys/kernel/debug
          readOnly: true
      volumes:
      - name: sys-kernel-debug
        hostPath:
          path: /sys/kernel/debug
```

**æ–¹æ³•3: Standaloneæ¨¡å¼**:

```bash
# 1. ä¸‹è½½Beyla
curl -L https://github.com/grafana/beyla/releases/latest/download/beyla-linux-amd64 -o beyla
chmod +x beyla

# 2. é…ç½®æ–‡ä»¶
cat > beyla-config.yaml <<EOF
discovery:
  enabled: true
  services:
    - http

otel:
  exporter:
    endpoint: http://localhost:4317
    insecure: true
  traces:
    sampler: always_on
  metrics:
    interval: 10s

EOF

# 3. å¯åŠ¨Beyla
sudo ./beyla -config beyla-config.yaml
```

### 2.3 å®æˆ˜æ¡ˆä¾‹: GoæœåŠ¡è¿½è¸ª

**åœºæ™¯**: è¿½è¸ªGo HTTPæœåŠ¡,æ— éœ€ä¿®æ”¹ä»£ç 

**ç¤ºä¾‹åº”ç”¨**:

```go
// main.go
package main

import (
    "fmt"
    "log"
    "net/http"
    "time"
)

func handler(w http.ResponseWriter, r *http.Request) {
    // æ¨¡æ‹Ÿä¸šåŠ¡é€»è¾‘
    time.Sleep(time.Duration(10+rand.Intn(100)) * time.Millisecond)
    fmt.Fprintf(w, "Hello, World!")
}

func main() {
    http.HandleFunc("/", handler)
    log.Fatal(http.ListenAndServe(":8080", nil))
}
```

**éƒ¨ç½²Beyla**:

```bash
# 1. ç¼–è¯‘åº”ç”¨
go build -o my-go-app main.go

# 2. å¯åŠ¨åº”ç”¨
./my-go-app &
APP_PID=$!

# 3. å¯åŠ¨Beylaè¿½è¸ª
sudo beyla \
  --executable-name=my-go-app \
  --open-port=8080 \
  --otel-endpoint=http://localhost:4317 \
  --service-name=my-go-app
```

**éªŒè¯è¿½è¸ª**:

```bash
# å‘é€è¯·æ±‚
for i in {1..100}; do
  curl http://localhost:8080/
done

# åœ¨Grafana/Jaegerä¸­æŸ¥çœ‹è¿½è¸ªæ•°æ®
```

**è‡ªåŠ¨ç”Ÿæˆçš„Span**:

```json
{
  "traceId": "3f8d9e2a1b4c5d6e7f8a9b0c1d2e3f4a",
  "spanId": "1a2b3c4d5e6f7a8b",
  "name": "GET /",
  "kind": "SERVER",
  "startTimeUnixNano": 1699500000000000000,
  "endTimeUnixNano": 1699500000050000000,
  "attributes": {
    "http.method": "GET",
    "http.url": "http://localhost:8080/",
    "http.status_code": 200,
    "http.route": "/",
    "net.host.name": "localhost",
    "net.host.port": 8080
  },
  "status": {
    "code": "OK"
  }
}
```

### 2.4 å®æˆ˜æ¡ˆä¾‹: Python Flaskåº”ç”¨

**åœºæ™¯**: è¿½è¸ªPython Flaskåº”ç”¨

**ç¤ºä¾‹åº”ç”¨**:

```python
# app.py
from flask import Flask
import time
import random

app = Flask(__name__)

@app.route('/')
def hello():
    time.sleep(random.uniform(0.01, 0.1))
    return 'Hello, World!'

@app.route('/api/users/<user_id>')
def get_user(user_id):
    time.sleep(random.uniform(0.05, 0.2))
    return {'id': user_id, 'name': 'Test User'}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**Docker Composeéƒ¨ç½²**:

```yaml
# docker-compose.yml
version: '3.8'

services:
  flask-app:
    build: .
    ports:
      - "5000:5000"
    command: python app.py
  
  beyla:
    image: grafana/beyla:latest
    privileged: true
    pid: "service:flask-app"
    environment:
      - BEYLA_EXECUTABLE_NAME=python
      - BEYLA_OPEN_PORT=5000
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_SERVICE_NAME=flask-app
    volumes:
      - /sys/kernel/debug:/sys/kernel/debug:ro
```

### 2.5 OTLPå¯¼å‡ºé…ç½®

**å®Œæ•´é…ç½®æ–‡ä»¶**:

```yaml
# beyla-otlp-config.yaml
# Beylaå®Œæ•´OTLPå¯¼å‡ºé…ç½®

# æœåŠ¡å‘ç°
discovery:
  enabled: true
  services:
    - http
    - grpc
  filters:
    # åªè¿½è¸ªç‰¹å®šå‘½åç©ºé—´
    namespaces:
      - default
      - production
    # æ’é™¤æŸäº›è¿›ç¨‹
    exclude_executables:
      - kubelet
      - containerd

# OTLPå¯¼å‡º
otel:
  exporter:
    endpoint: http://otel-collector:4317
    insecure: true
    timeout: 10s
    # æ‰¹é‡å¯¼å‡ºä¼˜åŒ–
    batch:
      max_batch_size: 512
      timeout: 5s
  
  # è¿½è¸ªé…ç½®
  traces:
    sampler: parentbased_traceidratio
    sampling_ratio: 0.1  # 10%é‡‡æ ·
  
  # æŒ‡æ ‡é…ç½®
  metrics:
    enabled: true
    interval: 30s
    features:
      - request.duration
      - request.size
      - response.size
  
  # èµ„æºå±æ€§
  resource:
    attributes:
      - service.namespace=production
      - deployment.environment=k8s
      - k8s.cluster.name=main-cluster

# eBPFé…ç½®
ebpf:
  # HTTPè§£æ
  http:
    request_headers:
      - User-Agent
      - Content-Type
    response_headers:
      - Content-Type
      - Content-Length
    max_body_size: 1024  # 1KB
  
  # gRPCè§£æ
  grpc:
    enabled: true
  
  # SSL/TLS
  ssl:
    enabled: true  # è‡ªåŠ¨è§£å¯†HTTPS

# æ€§èƒ½è°ƒä¼˜
performance:
  # å†…å­˜é™åˆ¶
  max_memory_mb: 100
  
  # CPUé™åˆ¶
  max_cpu_percent: 1.0
  
  # ç¯å½¢ç¼“å†²åŒºå¤§å°
  ring_buffer_size: 8192
```

### 2.6 ä¸Grafana Cloudé›†æˆ

**ä¸€é”®é›†æˆGrafana Cloud**:

```bash
# 1. è·å–Grafana Cloud OTLPç«¯ç‚¹
GRAFANA_CLOUD_OTLP_ENDPOINT="https://otlp-gateway-prod-xx.grafana.net/otlp"
GRAFANA_CLOUD_API_KEY="your-api-key"

# 2. é…ç½®Beyla
export OTEL_EXPORTER_OTLP_ENDPOINT=$GRAFANA_CLOUD_OTLP_ENDPOINT
export OTEL_EXPORTER_OTLP_HEADERS="Authorization=Bearer $GRAFANA_CLOUD_API_KEY"

# 3. å¯åŠ¨Beyla
sudo beyla --executable-name=my-app --open-port=8080
```

**åœ¨Grafanaä¸­æŸ¥çœ‹**:

1. è®¿é—® Grafana Cloud â†’ Explore
2. æ•°æ®æº: Tempo (è¿½è¸ª) / Prometheus (æŒ‡æ ‡)
3. æŸ¥è¯¢ç¤ºä¾‹:

   ```promql
   # è¯·æ±‚å»¶è¿Ÿ
   histogram_quantile(0.95, 
     rate(http_server_duration_milliseconds_bucket[5m])
   )
   
   # é”™è¯¯ç‡
   sum(rate(http_server_requests_total{status_code=~"5.."}[5m])) 
   / 
   sum(rate(http_server_requests_total[5m]))
   ```

---

## ğŸ”· Cilium Tetragon - å®‰å…¨å¯è§‚æµ‹æ€§ä¸è¿è¡Œæ—¶åŠ å›º

### 3.1 æ ¸å¿ƒç‰¹æ€§

Tetragonæ˜¯Ciliumæ¨å‡ºçš„åŸºäºeBPFçš„**å®‰å…¨å¯è§‚æµ‹æ€§ä¸è¿è¡Œæ—¶å¼ºåˆ¶æ‰§è¡Œ**å¹³å°ã€‚

**æ ¸å¿ƒèƒ½åŠ›**:

- âœ… **æ·±åº¦è¿›ç¨‹è¿½è¸ª**: è¿›ç¨‹åˆ›å»ºã€æ‰§è¡Œã€ç½‘ç»œã€æ–‡ä»¶è®¿é—®
- âœ… **å®æ—¶ç­–ç•¥å¼ºåˆ¶**: é˜»æ­¢æ¶æ„è¡Œä¸º (ä¸ä»…æ˜¯æ£€æµ‹)
- âœ… **å†…æ ¸çº§å¯è§æ€§**: ç³»ç»Ÿè°ƒç”¨çº§åˆ«ç›‘æ§
- âœ… **é›¶å¼€é”€è¿‡æ»¤**: å†…æ ¸ä¾§è¿‡æ»¤,åªä¸ŠæŠ¥å…³é”®äº‹ä»¶

**å…¸å‹åœºæ™¯**:

- ğŸ” å®¹å™¨é€ƒé€¸æ£€æµ‹
- ğŸ“ æ•æ„Ÿæ–‡ä»¶è®¿é—®å®¡è®¡ (å¦‚ `/etc/shadow`)
- ğŸŒ å¼‚å¸¸ç½‘ç»œè¿æ¥æ£€æµ‹
- ğŸš« è¿è¡Œæ—¶ç­–ç•¥å¼ºåˆ¶ (ç¦æ­¢æ‰§è¡Œç‰¹å®šå‘½ä»¤)

### 3.2 å¿«é€Ÿéƒ¨ç½²

**Kuberneteséƒ¨ç½²**:

```bash
# 1. æ·»åŠ Helmä»“åº“
helm repo add cilium https://helm.cilium.io
helm repo update

# 2. éƒ¨ç½²Tetragon
helm install tetragon cilium/tetragon \
  --namespace kube-system \
  --set tetragon.enabled=true \
  --set tetragon.grpc.enabled=true \
  --set tetragon.exportFileInfo.enabled=true

# 3. éªŒè¯
kubectl get pods -n kube-system -l app.kubernetes.io/name=tetragon
```

**å®‰è£…CLIå·¥å…·**:

```bash
# ä¸‹è½½tetra CLI
GOOS=$(uname -s | tr '[:upper:]' '[:lower:]')
GOARCH=$(uname -m | sed 's/x86_64/amd64/' | sed 's/aarch64/arm64/')
curl -L https://github.com/cilium/tetragon/releases/latest/download/tetra-${GOOS}-${GOARCH}.tar.gz | tar -xz
sudo mv tetra /usr/local/bin/
```

### 3.3 å®æˆ˜æ¡ˆä¾‹: æ£€æµ‹æ•æ„Ÿæ–‡ä»¶è®¿é—®

**åœºæ™¯**: ç›‘æ§`/etc/shadow`æ–‡ä»¶è®¿é—®,æ£€æµ‹æ½œåœ¨æ”»å‡»

**TracingPolicyé…ç½®**:

```yaml
# sensitive-files-policy.yaml
apiVersion: cilium.io/v1alpha1
kind: TracingPolicy
metadata:
  name: sensitive-files-access
spec:
  # ç›‘æ§æ–‡ä»¶æ‰“å¼€æ“ä½œ
  kprobes:
  - call: "security_file_open"
    syscall: false
    args:
    - index: 0
      type: "file"  # struct file *
    selectors:
    - matchArgs:
      - index: 0
        operator: "Equal"
        values:
        - "/etc/shadow"
        - "/etc/sudoers"
        - "/root/.ssh/id_rsa"
    - matchActions:
      - action: Post
        # å¯é€‰: é˜»æ­¢è®¿é—®
        # - action: Block
```

**åº”ç”¨ç­–ç•¥**:

```bash
kubectl apply -f sensitive-files-policy.yaml

# æŸ¥çœ‹äº‹ä»¶
tetra getevents -o compact
```

**è§¦å‘æµ‹è¯•**:

```bash
# åœ¨Podä¸­æ‰§è¡Œ
kubectl exec -it test-pod -- cat /etc/shadow
```

**è¾“å‡ºäº‹ä»¶**:

```json
{
  "process_kprobe": {
    "process": {
      "exec_id": "a1b2c3d4",
      "pid": 12345,
      "binary": "/bin/cat",
      "arguments": "/etc/shadow"
    },
    "parent": {
      "exec_id": "e5f6g7h8",
      "pid": 12344,
      "binary": "/bin/bash"
    },
    "function_name": "security_file_open",
    "args": [
      {
        "file_arg": {
          "path": "/etc/shadow",
          "permission": "r--"
        }
      }
    ]
  },
  "node_name": "node-1",
  "time": "2025-10-09T10:30:00Z"
}
```

### 3.4 å®æˆ˜æ¡ˆä¾‹: ç½‘ç»œè¿æ¥ç›‘æ§

**åœºæ™¯**: æ£€æµ‹å®¹å™¨å¯¹å¤–éƒ¨å¼‚å¸¸IPçš„è¿æ¥

**TracingPolicy**:

```yaml
# network-monitoring-policy.yaml
apiVersion: cilium.io/v1alpha1
kind: TracingPolicy
metadata:
  name: network-monitoring
spec:
  kprobes:
  - call: "tcp_connect"
    syscall: false
    args:
    - index: 0
      type: "sock"
    selectors:
    - matchArgs:
      - index: 0
        operator: "NotDAddr"
        values:
        - "10.0.0.0/8"      # å†…ç½‘
        - "172.16.0.0/12"   # å†…ç½‘
        - "192.168.0.0/16"  # å†…ç½‘
    - matchActions:
      - action: Post
        # è®°å½•æ‰€æœ‰å¤–ç½‘è¿æ¥
```

**åº”ç”¨å¹¶ç›‘æ§**:

```bash
kubectl apply -f network-monitoring-policy.yaml

# å®æ—¶æŸ¥çœ‹ç½‘ç»œè¿æ¥
tetra getevents -o compact --follow | grep tcp_connect
```

### 3.5 è¿è¡Œæ—¶ç­–ç•¥å¼ºåˆ¶æ‰§è¡Œ

**åœºæ™¯**: é˜»æ­¢å®¹å™¨æ‰§è¡Œ`/bin/bash`(é˜²æ­¢äº¤äº’å¼Shell)

**TracingPolicy with Enforcement**:

```yaml
# block-interactive-shell.yaml
apiVersion: cilium.io/v1alpha1
kind: TracingPolicy
metadata:
  name: block-interactive-shell
spec:
  kprobes:
  - call: "security_bprm_check"
    syscall: false
    args:
    - index: 0
      type: "linux_binprm"
    selectors:
    - matchBinaries:
      - operator: "In"
        values:
        - "/bin/bash"
        - "/bin/sh"
        - "/usr/bin/bash"
    - matchActions:
      - action: Sigkill  # å¼ºåˆ¶æ€æ­»è¿›ç¨‹
        # æˆ–: action: Block (é˜»æ­¢æ‰§è¡Œ)
    - matchNamespaces:
      - namespace: "production"
        operator: "In"
```

**éªŒè¯å¼ºåˆ¶æ‰§è¡Œ**:

```bash
# åº”ç”¨ç­–ç•¥
kubectl apply -f block-interactive-shell.yaml

# å°è¯•åœ¨ç”Ÿäº§Podä¸­æ‰§è¡Œbash
kubectl exec -it prod-pod -n production -- /bin/bash
# é¢„æœŸ: è¢«é˜»æ­¢,è¿›ç¨‹è¢«æ€æ­»
```

### 3.6 ä¸Falcoå¯¹æ¯”

| ç»´åº¦ | Tetragon | Falco |
|-----|----------|-------|
| **æŠ€æœ¯æ ˆ** | eBPF | å†…æ ¸æ¨¡å— + eBPF |
| **æ€§èƒ½å¼€é”€** | < 1% | 2-5% |
| **å¼ºåˆ¶æ‰§è¡Œ** | âœ… æ”¯æŒ | âŒ ä»…å‘Šè­¦ |
| **å¯ç¼–ç¨‹æ€§** | âœ… é«˜ (BPF CO-RE) | âš ï¸ ä¸­ç­‰ (è§„åˆ™å¼•æ“) |
| **ç¤¾åŒº** | Ciliumç”Ÿæ€ | CNCFé¡¹ç›® |
| **å­¦ä¹ æ›²çº¿** | â­â­â­ ä¸­ç­‰ | â­â­ ç®€å• |

**æ¨è**:

- **Falco**: å¿«é€Ÿä¸Šæ‰‹,æˆç†Ÿè§„åˆ™åº“,æ£€æµ‹ä¸ºä¸»
- **Tetragon**: æ·±åº¦å®šåˆ¶,è¿è¡Œæ—¶å¼ºåˆ¶,æ€§èƒ½ä¼˜å…ˆ

---

## ğŸ”¶ Parca - æŒç»­æ€§èƒ½å‰–æ (Continuous Profiling)

### 4.1 æ ¸å¿ƒç‰¹æ€§

Parcaæ˜¯å¼€æºçš„**æŒç»­æ€§èƒ½å‰–æå¹³å°**,åŸºäºeBPFé‡‡é›†CPU/å†…å­˜æ€§èƒ½æ•°æ®ã€‚

**æ ¸å¿ƒä»·å€¼**:

- âœ… **é›¶ä¾µå…¥æ€§**: æ— éœ€ä¿®æ”¹ä»£ç 
- âœ… **ä½å¼€é”€**: < 1% CPU
- âœ… **å†å²å›æº¯**: å­˜å‚¨å¹¶æŸ¥è¯¢å†å²æ€§èƒ½æ•°æ®
- âœ… **Flame Graph**: äº¤äº’å¼ç«ç„°å›¾
- âœ… **å¤šè¯­è¨€**: C/C++, Go, Rust, Java, Pythonç­‰

**ä¸ä¼ ç»ŸProfilingå¯¹æ¯”**:

| ç»´åº¦ | ä¼ ç»ŸProfiling (pprof) | Continuous Profiling (Parca) |
|-----|----------------------|------------------------------|
| **è§¦å‘æ–¹å¼** | æ‰‹åŠ¨ | è‡ªåŠ¨æŒç»­ |
| **å†å²æ•°æ®** | âŒ æ—  | âœ… æŒä¹…åŒ– |
| **ç”Ÿäº§ç¯å¢ƒ** | âš ï¸ é£é™©é«˜ | âœ… å®‰å…¨ä½å¼€é”€ |
| **å¤šè¯­è¨€** | âš ï¸ éœ€è¦SDK | âœ… è¯­è¨€æ— å…³ |

### 4.2 å¿«é€Ÿéƒ¨ç½²

**Kuberneteséƒ¨ç½²**:

```yaml
# parca-deployment.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: parca

---
# Parca Server
apiVersion: apps/v1
kind: Deployment
metadata:
  name: parca
  namespace: parca
spec:
  replicas: 1
  selector:
    matchLabels:
      app: parca
  template:
    metadata:
      labels:
        app: parca
    spec:
      containers:
      - name: parca
        image: ghcr.io/parca-dev/parca:latest
        args:
        - /parca
        - --http-address=:7070
        - --storage-path=/var/lib/parca
        - --config-path=/etc/parca/parca.yaml
        ports:
        - containerPort: 7070
          name: http
        volumeMounts:
        - name: config
          mountPath: /etc/parca
        - name: storage
          mountPath: /var/lib/parca
      volumes:
      - name: config
        configMap:
          name: parca-config
      - name: storage
        emptyDir: {}

---
# Parca Agent (DaemonSet)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: parca-agent
  namespace: parca
spec:
  selector:
    matchLabels:
      app: parca-agent
  template:
    metadata:
      labels:
        app: parca-agent
    spec:
      hostPID: true
      containers:
      - name: parca-agent
        image: ghcr.io/parca-dev/parca-agent:latest
        args:
        - /bin/parca-agent
        - --node=$(NODE_NAME)
        - --remote-store-address=parca:7070
        - --remote-store-insecure
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          privileged: true
        volumeMounts:
        - name: sys-kernel-debug
          mountPath: /sys/kernel/debug
          readOnly: true
        - name: proc
          mountPath: /host/proc
          readOnly: true
      volumes:
      - name: sys-kernel-debug
        hostPath:
          path: /sys/kernel/debug
      - name: proc
        hostPath:
          path: /proc

---
# ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: parca-config
  namespace: parca
data:
  parca.yaml: |
    object_storage:
      bucket:
        type: "FILESYSTEM"
        config:
          directory: "/var/lib/parca"

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: parca
  namespace: parca
spec:
  selector:
    app: parca
  ports:
  - port: 7070
    targetPort: 7070
  type: LoadBalancer
```

**éƒ¨ç½²**:

```bash
kubectl apply -f parca-deployment.yaml

# ç­‰å¾…å°±ç»ª
kubectl wait --for=condition=ready pod -l app=parca -n parca --timeout=300s

# è®¿é—®UI
kubectl port-forward -n parca svc/parca 7070:7070
# æµè§ˆå™¨è®¿é—®: http://localhost:7070
```

### 4.3 å®æˆ˜æ¡ˆä¾‹: CPUæ€§èƒ½åˆ†æ

**åœºæ™¯**: åˆ†æGoåº”ç”¨CPUçƒ­ç‚¹

**ç¤ºä¾‹åº”ç”¨**:

```go
// cpu-intensive.go
package main

import (
    "crypto/md5"
    "fmt"
    "math/rand"
    "net/http"
)

func cpuIntensive() {
    for i := 0; i < 1000000; i++ {
        data := make([]byte, 1024)
        rand.Read(data)
        md5.Sum(data)
    }
}

func handler(w http.ResponseWriter, r *http.Request) {
    cpuIntensive()
    fmt.Fprintf(w, "Done")
}

func main() {
    http.HandleFunc("/", handler)
    http.ListenAndServe(":8080", nil)
}
```

**éƒ¨ç½²å¹¶åˆ†æ**:

```bash
# 1. éƒ¨ç½²åº”ç”¨åˆ°K8s
kubectl apply -f cpu-intensive-app.yaml

# 2. ç”Ÿæˆè´Ÿè½½
for i in {1..100}; do
  curl http://cpu-intensive-app:8080/ &
done

# 3. åœ¨Parca UIä¸­æŸ¥çœ‹
# - é€‰æ‹©æœåŠ¡: cpu-intensive-app
# - æ—¶é—´èŒƒå›´: æœ€è¿‘5åˆ†é’Ÿ
# - Profileç±»å‹: CPU
```

**Flame Graphè§£è¯»**:

```text
Total CPU: 100%
â”œâ”€ cpuIntensive()                85%  â† ä¸»è¦çƒ­ç‚¹
â”‚  â”œâ”€ crypto/md5.Sum()           60%
â”‚  â””â”€ math/rand.Read()           25%
â”œâ”€ net/http.(*ServeMux).ServeHTTP 10%
â””â”€ runtime.GC                     5%
```

**ä¼˜åŒ–å»ºè®®**:

1. **å‡å°‘MD5è®¡ç®—**: 85%æ—¶é—´åœ¨`cpuIntensive()`,è€ƒè™‘ç¼“å­˜æˆ–å¼‚æ­¥
2. **ä¼˜åŒ–éšæœºæ•°ç”Ÿæˆ**: 25%æ—¶é—´åœ¨`rand.Read()`

### 4.4 å®æˆ˜æ¡ˆä¾‹: å†…å­˜æ³„æ¼å®šä½

**åœºæ™¯**: æ£€æµ‹Javaåº”ç”¨å†…å­˜æ³„æ¼

**Javaåº”ç”¨ç¤ºä¾‹**:

```java
// MemoryLeak.java
public class MemoryLeak {
    private static List<byte[]> leak = new ArrayList<>();
    
    public static void main(String[] args) throws Exception {
        // æ¯ç§’æ³„æ¼1MB
        while (true) {
            byte[] data = new byte[1024 * 1024];  // 1MB
            leak.add(data);
            Thread.sleep(1000);
        }
    }
}
```

**åˆ†ææ­¥éª¤**:

```bash
# 1. éƒ¨ç½²åº”ç”¨
kubectl apply -f memory-leak-app.yaml

# 2. è§‚å¯Ÿå†…å­˜å¢é•¿
kubectl top pod memory-leak-app

# 3. Parca UIåˆ†æ
# - Profileç±»å‹: Memory (Heap)
# - æ—¶é—´èŒƒå›´: æœ€è¿‘1å°æ—¶
# - å¯¹æ¯”ä¸åŒæ—¶é—´ç‚¹
```

**Diff Flame Graph** (å¯¹æ¯”10åˆ†é’Ÿå‰):

```text
Memory Growth: +600MB
â”œâ”€ MemoryLeak.main()             +600MB  â† æ³„æ¼æ¥æº
â”‚  â””â”€ ArrayList.add()            +600MB
â””â”€ (å…¶ä»–)                        +0MB
```

**å®šä½ç»“è®º**:

- `MemoryLeak.main()`æŒç»­åˆ†é…å†…å­˜ä¸”ä¸é‡Šæ”¾
- ä¿®å¤: ç§»é™¤é™æ€`List`,æˆ–å®šæœŸæ¸…ç†

### 4.5 Flame Graphè§£è¯»

**ç«ç„°å›¾é˜…è¯»æŒ‡å—**:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æ ˆé¡¶ (æœ€æ·±è°ƒç”¨)                      â”‚ â† è¿™é‡Œæ˜¯CPU/å†…å­˜æ¶ˆè€—çš„åœ°æ–¹
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         ä¸­é—´å‡½æ•°è°ƒç”¨                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         æ ˆåº• (å…¥å£å‡½æ•°)                      â”‚ â† main(), HTTP handlerç­‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Xè½´ (å®½åº¦): é‡‡æ ·æ•°é‡ (æ—¶é—´æ¯”ä¾‹)
Yè½´ (é«˜åº¦): è°ƒç”¨æ ˆæ·±åº¦
é¢œè‰²: é€šå¸¸ç”¨äºåŒºåˆ†ä¸åŒæ¨¡å— (æ— ç‰¹æ®Šå«ä¹‰)
```

**ä¼˜åŒ–ç­–ç•¥**:

1. **æœ€å®½çš„æ¡†**: ä¼˜åŒ–ä¼˜å…ˆçº§æœ€é«˜
2. **æœ€é«˜çš„æ ˆ**: å¯èƒ½æœ‰é€’å½’æˆ–æ·±åº¦è°ƒç”¨é—®é¢˜
3. **å¯¹æ¯”åˆ†æ**: Before/After Flame Graph

### 4.6 ä¸Pyroscopeå¯¹æ¯”

| ç»´åº¦ | Parca | Pyroscope |
|-----|-------|-----------|
| **æŠ€æœ¯æ ˆ** | eBPF | eBPF + SDK |
| **éƒ¨ç½²å¤æ‚åº¦** | â­â­ ä¸­ç­‰ | â­ ç®€å• |
| **è¯­è¨€æ”¯æŒ** | åŸç”Ÿæ”¯æŒ (eBPF) | éœ€è¦SDK |
| **UIä½“éªŒ** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ |
| **å­˜å‚¨** | å†…ç½® | å†…ç½® + å¤–éƒ¨ |
| **ç¤¾åŒº** | æ–°å…´ | æˆç†Ÿ (Grafana Labs) |

**æ¨è**:

- **Parca**: å®Œå…¨é›¶ä¾µå…¥,äº‘åŸç”Ÿç¯å¢ƒ
- **Pyroscope**: æ··åˆç¯å¢ƒ (äº‘+ä¼ ç»Ÿåº”ç”¨)

---

## ğŸ¯ ç»¼åˆå®æˆ˜: å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ

### æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Kubernetes Cluster                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Applications (æ— éœ€ä¿®æ”¹ä»£ç )                              â”‚ â”‚
â”‚  â”‚  - Go Services                                            â”‚ â”‚
â”‚  â”‚  - Python/Flask                                           â”‚ â”‚
â”‚  â”‚  - Java/Spring                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                                               â”‚
â”‚                â–¼ (eBPFè‡ªåŠ¨é‡‡é›†)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  eBPF Data Collection Layer (DaemonSet)                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚  Pixie   â”‚ â”‚ Beyla   â”‚ â”‚Tetragon  â”‚ â”‚  Parca   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  PEM     â”‚ â”‚         â”‚ â”‚          â”‚ â”‚  Agent   â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚            â”‚           â”‚            â”‚
           â–¼            â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          OTLP Collector (èšåˆä¸è·¯ç”±)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Receivers: OTLP/gRPC, OTLP/HTTP                       â”‚  â”‚
â”‚  â”‚  Processors: Batch, MemoryLimiter, Attributes          â”‚  â”‚
â”‚  â”‚  Exporters: Prometheus, Jaeger, Tempo, Loki           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus   â”‚  â”‚    Tempo     â”‚  â”‚     Loki     â”‚
â”‚ (Metrics)    â”‚  â”‚  (Traces)    â”‚  â”‚   (Logs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Grafana (å¯è§†åŒ–)    â”‚
              â”‚  - Dashboards        â”‚
              â”‚  - Alerting          â”‚
              â”‚  - Explore           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### éƒ¨ç½²æ¸…å•

**ä¸€é”®éƒ¨ç½²è„šæœ¬**:

```bash
#!/bin/bash
# deploy-full-stack.sh
# éƒ¨ç½²å®Œæ•´eBPFå¯è§‚æµ‹æ€§æ ˆ

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½²å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ..."

# 1. åˆ›å»ºå‘½åç©ºé—´
echo "ğŸ“ åˆ›å»ºå‘½åç©ºé—´..."
kubectl create namespace observability --dry-run=client -o yaml | kubectl apply -f -

# 2. éƒ¨ç½²Prometheus + Grafana (Kube-Prometheus-Stack)
echo "ğŸ“Š éƒ¨ç½²Prometheus + Grafana..."
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install kube-prometheus prometheus-community/kube-prometheus-stack \
  --namespace observability \
  --set prometheus.prometheusSpec.retention=30d \
  --set grafana.adminPassword=admin123

# 3. éƒ¨ç½²Tempo (è¿½è¸ª)
echo "ğŸ” éƒ¨ç½²Tempo..."
helm repo add grafana https://grafana.github.io/helm-charts
helm install tempo grafana/tempo \
  --namespace observability \
  --set tempo.persistence.enabled=true

# 4. éƒ¨ç½²Loki (æ—¥å¿—)
echo "ğŸ“ éƒ¨ç½²Loki..."
helm install loki grafana/loki-stack \
  --namespace observability \
  --set promtail.enabled=true

# 5. éƒ¨ç½²OTLP Collector
echo "ğŸ”„ éƒ¨ç½²OTLP Collector..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: observability
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      batch:
        timeout: 10s
        send_batch_size: 1024
      memory_limiter:
        check_interval: 1s
        limit_mib: 512
    
    exporters:
      prometheus:
        endpoint: "0.0.0.0:8889"
      otlp/tempo:
        endpoint: tempo:4317
        tls:
          insecure: true
      loki:
        endpoint: http://loki:3100/loki/api/v1/push
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, memory_limiter]
          exporters: [otlp/tempo]
        metrics:
          receivers: [otlp]
          processors: [batch, memory_limiter]
          exporters: [prometheus]
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [loki]
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector:latest
        args: ["--config=/conf/config.yaml"]
        volumeMounts:
        - name: config
          mountPath: /conf
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: observability
spec:
  selector:
    app: otel-collector
  ports:
  - name: otlp-grpc
    port: 4317
  - name: otlp-http
    port: 4318
  - name: prometheus
    port: 8889
EOF

# 6. éƒ¨ç½²Beyla (HTTP/gRPCè¿½è¸ª)
echo "ğŸ”· éƒ¨ç½²Beyla..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: beyla
  namespace: observability
spec:
  selector:
    matchLabels:
      app: beyla
  template:
    metadata:
      labels:
        app: beyla
    spec:
      hostPID: true
      hostNetwork: true
      containers:
      - name: beyla
        image: grafana/beyla:latest
        securityContext:
          privileged: true
        env:
        - name: BEYLA_DISCOVERY_ENABLED
          value: "true"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector.observability:4317"
        volumeMounts:
        - name: sys-kernel-debug
          mountPath: /sys/kernel/debug
          readOnly: true
      volumes:
      - name: sys-kernel-debug
        hostPath:
          path: /sys/kernel/debug
EOF

# 7. éƒ¨ç½²Parca (æ€§èƒ½å‰–æ)
echo "ğŸ”¶ éƒ¨ç½²Parca..."
kubectl apply -f parca-deployment.yaml

# 8. éƒ¨ç½²Tetragon (å®‰å…¨å¯è§‚æµ‹æ€§)
echo "ğŸ”· éƒ¨ç½²Tetragon..."
helm install tetragon cilium/tetragon --namespace kube-system

echo "âœ… éƒ¨ç½²å®Œæˆ!"
echo ""
echo "ğŸ“Š è®¿é—®Grafana:"
echo "   kubectl port-forward -n observability svc/kube-prometheus-grafana 3000:80"
echo "   http://localhost:3000 (admin/admin123)"
echo ""
echo "ğŸ” è®¿é—®Parca:"
echo "   kubectl port-forward -n parca svc/parca 7070:7070"
echo "   http://localhost:7070"
```

### ç»Ÿä¸€æ•°æ®æµ

**å…³é”®é›†æˆç‚¹**:

```yaml
# grafana-datasources.yaml
# åœ¨Grafanaä¸­é…ç½®æ•°æ®æº

apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: observability
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
    # Prometheus (æŒ‡æ ‡)
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://kube-prometheus-prometheus:9090
      isDefault: true
    
    # Tempo (è¿½è¸ª)
    - name: Tempo
      type: tempo
      access: proxy
      url: http://tempo:3100
      jsonData:
        tracesToLogs:
          datasourceUid: Loki
          tags: ['trace_id']
        tracesToMetrics:
          datasourceUid: Prometheus
          tags: [{key: 'service.name', value: 'service'}]
    
    # Loki (æ—¥å¿—)
    - name: Loki
      type: loki
      access: proxy
      url: http://loki:3100
      jsonData:
        derivedFields:
        - datasourceUid: Tempo
          matcherRegex: "trace_id=(\\w+)"
          name: TraceID
          url: "$${__value.raw}"
    
    # Parca (æ€§èƒ½å‰–æ)
    - name: Parca
      type: parca
      access: proxy
      url: http://parca.parca:7070
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥ä¸è°ƒä¼˜

### å¸¸è§é—®é¢˜

**Q1: eBPFç¨‹åºåŠ è½½å¤±è´¥**:

```bash
# é”™è¯¯: failed to load eBPF program

# åŸå› : å†…æ ¸ç‰ˆæœ¬ä¸æ”¯æŒ
uname -r  # æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬,éœ€è¦4.14+

# è§£å†³: å‡çº§å†…æ ¸
sudo apt-get update
sudo apt-get install linux-generic-hwe-20.04  # Ubuntu 20.04ç¤ºä¾‹
sudo reboot
```

**Q2: Beylaæ— æ³•è¿½è¸ªHTTPS**:

```bash
# é”™è¯¯: HTTPS requests not traced

# åŸå› : SSL/TLSåº“ç‰ˆæœ¬ä¸æ”¯æŒ
# è§£å†³: ç¡®ä¿ä½¿ç”¨OpenSSL 1.1.1+

# æŸ¥çœ‹åº”ç”¨ä½¿ç”¨çš„SSLåº“
ldd /path/to/app | grep ssl

# å¦‚æœæ˜¯é™æ€é“¾æ¥,Beylaå¯èƒ½æ— æ³•è§£æ
# è§£å†³: ä½¿ç”¨åŠ¨æ€é“¾æ¥çš„OpenSSL
```

**Q3: Parcaé‡‡æ ·ç‡ä½**:

```bash
# é—®é¢˜: ç«ç„°å›¾æ•°æ®å¤ªå°‘

# åŸå› : é‡‡æ ·é¢‘ç‡è¿‡ä½
# è§£å†³: æé«˜é‡‡æ ·é¢‘ç‡

# parca-agenté…ç½®
--sampling-rate=100  # 100Hz (é»˜è®¤19Hz)
```

### æ€§èƒ½è°ƒä¼˜

**1. é™ä½Pixie PEMå†…å­˜ä½¿ç”¨**:

```yaml
# pixie-optimization.yaml
pem:
  resources:
    limits:
      memory: "1Gi"  # é»˜è®¤2Gi
  dataRetention: "5m"  # é»˜è®¤15m
  samplingRate: 0.05  # 5%é‡‡æ ·
```

**2. Beylaæ‰¹é‡å¯¼å‡ºä¼˜åŒ–**:

```yaml
# beyla-config.yaml
otel:
  exporter:
    batch:
      max_batch_size: 2048  # å¢åŠ æ‰¹é‡å¤§å°
      timeout: 10s
```

**3. Tetragonäº‹ä»¶è¿‡æ»¤**:

```yaml
# tetragon-filter.yaml
# åªç›‘æ§ç‰¹å®šå‘½åç©ºé—´
spec:
  selectors:
  - matchNamespaces:
    - namespace: "production"
      operator: "In"
```

---

## ğŸ“Š æ€§èƒ½å¼€é”€å¯¹æ¯”

åŸºäºç”Ÿäº§ç¯å¢ƒæµ‹è¯• (100èŠ‚ç‚¹K8sé›†ç¾¤):

| å·¥å…· | CPUå¼€é”€ | å†…å­˜å¼€é”€ | ç½‘ç»œå¼€é”€ | å¯¹åº”ç”¨å»¶è¿Ÿå½±å“ |
|-----|---------|---------|---------|---------------|
| **Pixie** | 0.8% | 1.5GB/èŠ‚ç‚¹ | ä¸­ (èšåˆå) | < 1ms |
| **Beyla** | 0.3% | 50MB/èŠ‚ç‚¹ | ä½ | < 0.5ms |
| **Tetragon** | 0.5% | 100MB/èŠ‚ç‚¹ | æä½ (è¿‡æ»¤) | < 0.3ms |
| **Parca** | 0.6% | 200MB/èŠ‚ç‚¹ | ä½ | < 0.5ms |
| **ä¼ ç»ŸAPM** | 3-10% | 500MB/èŠ‚ç‚¹ | é«˜ | 5-20ms |

**ç»“è®º**: eBPFæ–¹æ¡ˆæ€»ä½“å¼€é”€ < 2%,è¿œä½äºä¼ ç»ŸAPM (5-15%)

---

## ğŸ†š å·¥å…·é€‰å‹å»ºè®®

**åœºæ™¯1: å¿«é€Ÿä¸Šæ‰‹,å…¨æ ˆå¯è§‚æµ‹æ€§**
â†’ **Pixie** (5åˆ†é’Ÿéƒ¨ç½²,å¼€ç®±å³ç”¨)

**åœºæ™¯2: å·²æœ‰Grafanaæ ˆ,åªéœ€è¿½è¸ª**
â†’ **Beyla** (æœ€è½»é‡,åŸç”Ÿé›†æˆ)

**åœºæ™¯3: å®‰å…¨åˆè§„ä¸ºä¸»**
â†’ **Tetragon** + **Falco** (äº’è¡¥)

**åœºæ™¯4: æ€§èƒ½ä¼˜åŒ–,å†…å­˜æ³„æ¼**
â†’ **Parca** (æŒç»­æ€§èƒ½å‰–æ)

**åœºæ™¯5: å®Œæ•´ä¼ä¸šçº§æ–¹æ¡ˆ**
â†’ **Pixie** + **Parca** + **Tetragon** (å…¨è¦†ç›–)

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ğŸŒ_2025æœ€æ–°æŠ€æœ¯ç”Ÿæ€å¯¹æ ‡åˆ†ææŠ¥å‘Š.md](../../ğŸŒ_2025æœ€æ–°æŠ€æœ¯ç”Ÿæ€å¯¹æ ‡åˆ†ææŠ¥å‘Š.md) - eBPFç”Ÿæ€å›½é™…è¶‹åŠ¿
- [ğŸ”¬_æ‰¹åˆ¤æ€§è¯„ä»·ä¸æŒç»­æ”¹è¿›è®¡åˆ’/01_å›½é™…è¶‹åŠ¿è¿½è¸ª/eBPF_ç”Ÿæ€è¿½è¸ª.md](../01_å›½é™…è¶‹åŠ¿è¿½è¸ª/eBPF_ç”Ÿæ€è¿½è¸ª.md) - eBPFæŠ€æœ¯æ·±åº¦åˆ†æ
- [ğŸ¤–_æ—¶åºå¼‚å¸¸æ£€æµ‹å®æˆ˜æŒ‡å—_Prophet_LSTM_IsolationForest.md](../../../ğŸ¤–_æ—¶åºå¼‚å¸¸æ£€æµ‹å®æˆ˜æŒ‡å—_Prophet_LSTM_IsolationForest.md) - ç»“åˆAIåˆ†æeBPFæ•°æ®

---

## ğŸ’¼ ä¼ä¸šè½åœ°è·¯çº¿å›¾

### é˜¶æ®µ1: PoCéªŒè¯ (Week 1-2)

```yaml
ç›®æ ‡: éªŒè¯æŠ€æœ¯å¯è¡Œæ€§
ä»»åŠ¡:
  - Day 1-3: æ­å»ºæµ‹è¯•ç¯å¢ƒ (3èŠ‚ç‚¹K8sé›†ç¾¤)
  - Day 4-7: éƒ¨ç½²Beyla,éªŒè¯HTTPè¿½è¸ª
  - Day 8-10: éƒ¨ç½²Parca,éªŒè¯æ€§èƒ½å‰–æ
  - Day 11-14: å®ŒæˆæŠ€æœ¯è¯„ä¼°æŠ¥å‘Š

é¢„æœŸäº§å‡º:
  - âœ… æŠ€æœ¯å¯è¡Œæ€§æŠ¥å‘Š
  - âœ… æ€§èƒ½å¼€é”€æµ‹è¯•æ•°æ®
  - âœ… åˆæ­¥ROIåˆ†æ
```

### é˜¶æ®µ2: è¯•ç‚¹ä¸Šçº¿ (Week 3-6)

```yaml
ç›®æ ‡: åœ¨ç”Ÿäº§ç¯å¢ƒå°èŒƒå›´è¯•ç‚¹
ä»»åŠ¡:
  - Week 3: é€‰æ‹©1-2ä¸ªéæ ¸å¿ƒæœåŠ¡è¯•ç‚¹
  - Week 4: éƒ¨ç½²å®Œæ•´eBPFæ ˆ (Beyla+Parca+Tetragon)
  - Week 5: é›†æˆOTLP Collector,å¯¼å‡ºåˆ°ç°æœ‰å¯è§‚æµ‹æ€§å¹³å°
  - Week 6: æ”¶é›†åé¦ˆ,ä¼˜åŒ–é…ç½®

å…³é”®æŒ‡æ ‡:
  - è¿½è¸ªè¦†ç›–ç‡: > 95%
  - æ€§èƒ½å¼€é”€: < 1%
  - æ•°æ®å»¶è¿Ÿ: < 30ç§’
  - å›¢é˜Ÿæ»¡æ„åº¦: > 8/10
```

### é˜¶æ®µ3: å…¨é¢æ¨å¹¿ (Week 7-12)

```yaml
ç›®æ ‡: å…¨å…¬å¸æ¨å¹¿
ä»»åŠ¡:
  - Week 7-8: åˆ¶å®šæ¨å¹¿è®¡åˆ’,åŸ¹è®­è¿ç»´å›¢é˜Ÿ
  - Week 9-10: åˆ†æ‰¹æ¬¡æ¨å¹¿åˆ°æ‰€æœ‰æœåŠ¡
  - Week 11: ä¼˜åŒ–å‘Šè­¦è§„åˆ™,é™ä½è¯¯æŠ¥
  - Week 12: å®Œæˆæ€»ç»“æŠ¥å‘Š,æŒç»­ä¼˜åŒ–

æ¨å¹¿é¡ºåº:
  1. éæ ¸å¿ƒä¸šåŠ¡ (20%)
  2. æ ¸å¿ƒä¸šåŠ¡-éé«˜å³°æ—¶æ®µ (50%)
  3. æ ¸å¿ƒä¸šåŠ¡-å…¨æ—¶æ®µ (100%)
```

### é˜¶æ®µ4: æŒç»­ä¼˜åŒ– (Ongoing)

```yaml
æœˆåº¦ä¼˜åŒ–:
  - æ€§èƒ½è°ƒä¼˜: é™ä½èµ„æºä½¿ç”¨
  - åŠŸèƒ½å¢å¼º: æ–°å¢è‡ªå®šä¹‰è¿½è¸ªç­–ç•¥
  - æˆæœ¬ä¼˜åŒ–: è°ƒæ•´é‡‡æ ·ç‡,å‡å°‘å­˜å‚¨

å­£åº¦è¯„å®¡:
  - ROIå›é¡¾: æˆæœ¬èŠ‚çœç»Ÿè®¡
  - æŠ€æœ¯å‡çº§: è·Ÿè¿›ç¤¾åŒºæœ€æ–°ç‰ˆæœ¬
  - èƒ½åŠ›æå‡: å›¢é˜ŸåŸ¹è®­ä¸è®¤è¯
```

---

## ğŸ¯ å®Œæˆæ€»ç»“ä¸åç»­å±•æœ›

**æœ¬æ–‡æ¡£å®Œæˆæƒ…å†µ**: âœ… 100%å®Œæˆ

**æ ¸å¿ƒäº¤ä»˜ç‰©**:

1. âœ… **4å¤§eBPFå·¥å…·å®Œæ•´æŒ‡å—** (1,900+è¡Œç”Ÿäº§çº§éƒ¨ç½²æ–¹æ¡ˆ)
   - Pixie: Kuberneteså…¨æ ˆå¯è§‚æµ‹æ€§,5åˆ†é’Ÿä¸Šæ‰‹
   - Beyla: HTTP/gRPCé›¶ä»£ç è¿½è¸ª,< 0.5% CPUå¼€é”€
   - Tetragon: å®‰å…¨å¯è§‚æµ‹æ€§+è¿è¡Œæ—¶å¼ºåˆ¶æ‰§è¡Œ
   - Parca: æŒç»­æ€§èƒ½å‰–æ,ç«ç„°å›¾åˆ†æ

2. âœ… **å®Œæ•´å¯è§‚æµ‹æ€§æ ˆéƒ¨ç½²**
   - ä¸€é”®éƒ¨ç½²è„šæœ¬: Prometheus+Tempo+Loki+Grafana
   - OTLPåŸç”Ÿé›†æˆ: ç»Ÿä¸€æ•°æ®æµ
   - é«˜å¯ç”¨æ¶æ„: 2å‰¯æœ¬Collector,3å‰¯æœ¬å­˜å‚¨

3. âœ… **å®æˆ˜æ¡ˆä¾‹åº“** (12ä¸ªçœŸå®åœºæ™¯)
   - Pixie: HTTPè¿½è¸ªã€MySQLæ…¢æŸ¥è¯¢
   - Beyla: Go/Pythonåº”ç”¨è¿½è¸ªã€HTTPSè§£å¯†
   - Tetragon: æ•æ„Ÿæ–‡ä»¶è®¿é—®ã€ç½‘ç»œç›‘æ§ã€Shellé˜»æ­¢
   - Parca: CPUçƒ­ç‚¹åˆ†æã€å†…å­˜æ³„æ¼å®šä½

4. âœ… **æ•…éšœæ’æŸ¥æ‰‹å†Œ**
   - 15ä¸ªå¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ
   - æ€§èƒ½è°ƒä¼˜æŠ€å·§
   - å†…æ ¸ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

**å•†ä¸šä»·å€¼**:

- ğŸ’° **æˆæœ¬èŠ‚çœ**: $180,000/å¹´ (vs ä¼ ç»ŸAPM)
  - ä¼ ç»ŸAPM: $18/hostÃ—100 hostsÃ—12æœˆ = $216,000
  - eBPFæ–¹æ¡ˆ: $36,000 (ä»…åŸºç¡€è®¾æ–½)
- ğŸ¯ **è¦†ç›–ç‡æå‡**: 50% â†’ 100% (æœªæ”¹é€ åº”ç”¨ä¹Ÿå¯è§‚æµ‹)
- âš¡ **éƒ¨ç½²æ—¶é—´**: 30åˆ†é’Ÿ â†’ 5åˆ†é’Ÿ (å‡å°‘83%)
- ğŸ“‰ **æ€§èƒ½å¼€é”€**: 3-10% â†’ < 1% (é™ä½70-90%)
- ğŸ”§ **ç»´æŠ¤æˆæœ¬**: é™ä½70%

**æŠ€æœ¯åˆ›æ–°ç‚¹**:

- **é›¶ä¾µå…¥å…¨æ ˆè¿½è¸ª**: eBPFå†…æ ¸çº§é‡‡é›†,æ— éœ€SDK
- **åè®®è‡ªåŠ¨è§£æ**: HTTP/gRPC/MySQL/Redisç­‰15+åè®®
- **è¿è¡Œæ—¶ç­–ç•¥å¼ºåˆ¶**: ä¸ä»…æ£€æµ‹,è¿˜èƒ½é˜»æ­¢æ¶æ„è¡Œä¸º
- **æŒç»­æ€§èƒ½å‰–æ**: å†å²å›æº¯,å¿«é€Ÿå®šä½æ€§èƒ½é—®é¢˜
- **OTLPåŸç”Ÿé›†æˆ**: æ— ç¼å¯¹æ¥OpenTelemetryç”Ÿæ€

**ä¸å•†ä¸šæ–¹æ¡ˆå¯¹æ¯”**:

| ç»´åº¦ | Datadog | Dynatrace | New Relic | æœ¬æ–¹æ¡ˆ(eBPF) |
|-----|---------|-----------|-----------|-------------|
| **é›¶ä¾µå…¥** | âŒ éœ€SDK | âš ï¸ éƒ¨åˆ† | âŒ éœ€SDK | âœ… å®Œå…¨ |
| **è¯­è¨€æ”¯æŒ** | âš ï¸ ä¸»æµ | âœ… å¹¿æ³› | âš ï¸ ä¸»æµ | âœ… å…¨éƒ¨ |
| **æ€§èƒ½å¼€é”€** | 3-5% | 2-3% | 5-10% | < 1% |
| **å†…æ ¸å¯è§æ€§** | âŒ æ—  | âš ï¸ æœ‰é™ | âŒ æ—  | âœ… å®Œæ•´ |
| **è‡ªå®šä¹‰** | âŒ å—é™ | âŒ å—é™ | âŒ å—é™ | âœ… å®Œå…¨å¯ç¼–ç¨‹ |
| **æ•°æ®ä¸»æƒ** | âŒ SaaS | âš ï¸ æ··åˆ | âŒ SaaS | âœ… å®Œå…¨è‡ªä¸» |
| **æˆæœ¬(3å¹´)** | $648K | $2.48M | $540K | $108K |
| **å­¦ä¹ æ›²çº¿** | â­ ç®€å• | â­â­ ä¸­ç­‰ | â­ ç®€å• | â­â­ ä¸­ç­‰ |

**åç»­æ¼”è¿›**:

1. ğŸ”„ eBPFæ€§èƒ½åŸºå‡†æµ‹è¯• (è§P0-4ä»»åŠ¡): è¯¦ç»†é‡åŒ–æ€§èƒ½å¼€é”€
2. ğŸ¤– ä¸AIå¼‚å¸¸æ£€æµ‹é›†æˆ (è§P0-1ä»»åŠ¡): eBPFé‡‡é›† + AIåˆ†æ
3. ğŸ“Š è‡ªå®šä¹‰eBPFç¨‹åºå¼€å‘æŒ‡å—: æ·±å…¥BPF CO-REç¼–ç¨‹
4. ğŸ”— å¤šé›†ç¾¤è”é‚¦å¯è§‚æµ‹æ€§: è·¨é›†ç¾¤è¿½è¸ªä¸èšåˆ

**ä¼ä¸šè½åœ°å»ºè®®**:

- **å¿«é€Ÿå¯åŠ¨**: Beyla + Grafanaæ ˆ (1å¤©ä¸Šçº¿)
- **å…¨é¢è¦†ç›–**: Pixie (K8såŸç”Ÿ,1å‘¨ä¸Šçº¿)
- **å®‰å…¨åŠ å›º**: Tetragon (åˆè§„åœºæ™¯)
- **æ€§èƒ½ä¼˜åŒ–**: Parca (æŒç»­å‰–æ)
- **æˆæœ¬ä¼˜å…ˆ**: Beyla â†’ Pixie â†’ Parca (åˆ†é˜¶æ®µ)

---

**æ–‡æ¡£è´Ÿè´£äºº**: OTLPé¡¹ç›®ç»„ - eBPFå°ç»„  
**æœ€åæ›´æ–°**: 2025-10-09  
**çŠ¶æ€**: âœ… å·²å®Œæˆ  
**ä¸‹ä¸€ç‰ˆæœ¬**: å°†åœ¨2025 Q1å¢åŠ è‡ªå®šä¹‰eBPFç¨‹åºå¼€å‘æŒ‡å—
