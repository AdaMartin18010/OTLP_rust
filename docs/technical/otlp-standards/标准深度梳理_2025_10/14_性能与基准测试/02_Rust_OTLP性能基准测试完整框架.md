# Rust OTLP æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæ•´æ¡†æ¶

> **Rustç‰ˆæœ¬**: 1.90+  
> **Criterion**: 0.5.1  
> **Dhat**: 0.3.3  
> **Flamegraph**: 0.6.5  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥

---

## ğŸ“‹ ç›®å½•

- [Rust OTLP æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæ•´æ¡†æ¶](#rust-otlp-æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæ•´æ¡†æ¶)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. å®Œæ•´æµ‹è¯•æ¡†æ¶](#1-å®Œæ•´æµ‹è¯•æ¡†æ¶)
    - [1.1 é¡¹ç›®ç»“æ„](#11-é¡¹ç›®ç»“æ„)
    - [1.2 ä¾èµ–é…ç½®](#12-ä¾èµ–é…ç½®)
  - [2. CPUæ€§èƒ½æµ‹è¯•](#2-cpuæ€§èƒ½æµ‹è¯•)
    - [2.1 Spanåˆ›å»ºæ€§èƒ½](#21-spanåˆ›å»ºæ€§èƒ½)
  - [3. å†…å­˜æ€§èƒ½æµ‹è¯•](#3-å†…å­˜æ€§èƒ½æµ‹è¯•)
    - [3.1 ä½¿ç”¨DHATè¿›è¡Œå †åˆ†æ](#31-ä½¿ç”¨dhatè¿›è¡Œå †åˆ†æ)
    - [3.2 å†…å­˜æ³„æ¼æ£€æµ‹](#32-å†…å­˜æ³„æ¼æ£€æµ‹)
  - [4. ç½‘ç»œæ€§èƒ½æµ‹è¯•](#4-ç½‘ç»œæ€§èƒ½æµ‹è¯•)
    - [4.1 gRPC vs HTTPæ€§èƒ½å¯¹æ¯”](#41-grpc-vs-httpæ€§èƒ½å¯¹æ¯”)
  - [5. å¹¶å‘æ€§èƒ½æµ‹è¯•](#5-å¹¶å‘æ€§èƒ½æµ‹è¯•)
    - [5.1 å¤šçº¿ç¨‹æ€§èƒ½](#51-å¤šçº¿ç¨‹æ€§èƒ½)
  - [6. ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•](#6-ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•)
    - [6.1 å®Œæ•´è¿½è¸ªæµç¨‹](#61-å®Œæ•´è¿½è¸ªæµç¨‹)
  - [7. æ€§èƒ½å›å½’æ£€æµ‹](#7-æ€§èƒ½å›å½’æ£€æµ‹)
    - [7.1 è‡ªåŠ¨åŒ–è„šæœ¬](#71-è‡ªåŠ¨åŒ–è„šæœ¬)
    - [7.2 æ€§èƒ½å¯¹æ¯”è„šæœ¬](#72-æ€§èƒ½å¯¹æ¯”è„šæœ¬)
  - [8. ç”Ÿäº§ç¯å¢ƒåŸºå‡†](#8-ç”Ÿäº§ç¯å¢ƒåŸºå‡†)
    - [8.1 ç”Ÿäº§çº§é…ç½®æµ‹è¯•](#81-ç”Ÿäº§çº§é…ç½®æµ‹è¯•)
    - [8.2 å®Œæ•´æ€§èƒ½æŠ¥å‘Š](#82-å®Œæ•´æ€§èƒ½æŠ¥å‘Š)

---

## 1. å®Œæ•´æµ‹è¯•æ¡†æ¶

### 1.1 é¡¹ç›®ç»“æ„

```text
otlp-benchmarks/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ benches/
â”‚   â”œâ”€â”€ cpu_benchmarks.rs          # CPUæ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ memory_benchmarks.rs       # å†…å­˜æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ network_benchmarks.rs      # ç½‘ç»œæ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ concurrency_benchmarks.rs  # å¹¶å‘æ€§èƒ½æµ‹è¯•
â”‚   â””â”€â”€ e2e_benchmarks.rs          # ç«¯åˆ°ç«¯æµ‹è¯•
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs
â”‚   â”œâ”€â”€ fixtures/                  # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ helpers/                   # è¾…åŠ©å‡½æ•°
â”‚   â””â”€â”€ metrics/                   # æŒ‡æ ‡æ”¶é›†
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_all_benchmarks.sh
â”‚   â”œâ”€â”€ compare_results.sh
â”‚   â””â”€â”€ generate_report.sh
â””â”€â”€ results/                       # åŸºå‡†ç»“æœ
    â”œâ”€â”€ baseline/
    â””â”€â”€ current/
```

### 1.2 ä¾èµ–é…ç½®

`Cargo.toml`:

```toml
[package]
name = "otlp-benchmarks"
version = "0.1.0"
edition = "2021"

[dependencies]
# OpenTelemetry
opentelemetry = "0.31.0"
opentelemetry_sdk = { version = "0.31.0", features = ["rt-tokio", "trace"] }
opentelemetry-otlp = { version = "0.31.0", features = ["grpc-tonic", "http-json"] }

# å¼‚æ­¥è¿è¡Œæ—¶
tokio = { version = "1.47.1", features = ["full", "tracing"] }
futures = "0.3.31"

# gRPC
tonic = { version = "0.14.2", features = ["transport", "tls"] }
prost = "0.14.0"

# HTTP
reqwest = { version = "0.12.23", features = ["json", "rustls-tls"] }
hyper = { version = "1.7.0", features = ["full"] }

# åºåˆ—åŒ–
serde = { version = "1.0.217", features = ["derive"] }
serde_json = "1.0.135"

# å·¥å…·
bytes = "1.9.0"
tracing = "0.1.41"
tracing-subscriber = { version = "0.3.19", features = ["env-filter"] }

[dev-dependencies]
# æ€§èƒ½æµ‹è¯•
criterion = { version = "0.5.1", features = ["html_reports", "async_tokio"] }
dhat = "0.3.3"                     # å†…å­˜åˆ†æ
pprof = { version = "0.14.0", features = ["flamegraph", "criterion"] }

# æµ‹è¯•è¾…åŠ©
tokio-test = "0.4.4"
mockito = "1.6.1"
proptest = "1.5.0"

[[bench]]
name = "cpu_benchmarks"
harness = false

[[bench]]
name = "memory_benchmarks"
harness = false

[[bench]]
name = "network_benchmarks"
harness = false

[[bench]]
name = "concurrency_benchmarks"
harness = false

[[bench]]
name = "e2e_benchmarks"
harness = false

[profile.bench]
debug = true  # å¯ç”¨ç¬¦å·ä¿¡æ¯ç”¨äºflamegraph
```

---

## 2. CPUæ€§èƒ½æµ‹è¯•

### 2.1 Spanåˆ›å»ºæ€§èƒ½

`benches/cpu_benchmarks.rs`:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId, Throughput};
use opentelemetry::trace::{TraceId, SpanId, SpanContext, TraceFlags, TraceState};
use opentelemetry_sdk::trace::{Span, SpanData};
use std::time::{SystemTime, Duration};

/// æµ‹è¯• TraceId åˆ›å»ºæ€§èƒ½
fn bench_trace_id_creation(c: &mut Criterion) {
    c.bench_function("trace_id_creation", |b| {
        b.iter(|| {
            black_box(TraceId::from_bytes([1u8; 16]))
        });
    });
}

/// æµ‹è¯• SpanContext åˆ›å»ºæ€§èƒ½
fn bench_span_context_creation(c: &mut Criterion) {
    let trace_id = TraceId::from_bytes([1u8; 16]);
    let span_id = SpanId::from_bytes([1u8; 8]);
    
    c.bench_function("span_context_creation", |b| {
        b.iter(|| {
            black_box(SpanContext::new(
                trace_id,
                span_id,
                TraceFlags::default(),
                false,
                TraceState::default(),
            ))
        });
    });
}

/// æµ‹è¯• Span åˆ›å»ºæ€§èƒ½ï¼ˆä¸åŒå±æ€§æ•°é‡ï¼‰
fn bench_span_creation_with_attributes(c: &mut Criterion) {
    let mut group = c.benchmark_group("span_creation");
    
    for attr_count in [0, 5, 10, 50, 100] {
        let attributes: Vec<(String, String)> = (0..attr_count)
            .map(|i| (format!("key{}", i), format!("value{}", i)))
            .collect();
        
        group.throughput(Throughput::Elements(1));
        group.bench_with_input(
            BenchmarkId::new("attributes", attr_count),
            &attributes,
            |b, attrs| {
                b.iter(|| {
                    create_span_with_attributes(black_box(attrs.clone()))
                });
            },
        );
    }
    
    group.finish();
}

fn create_span_with_attributes(attributes: Vec<(String, String)>) -> SpanData {
    use opentelemetry::{Key, Value, KeyValue};
    
    let trace_id = TraceId::from_bytes([1u8; 16]);
    let span_id = SpanId::from_bytes([1u8; 8]);
    
    SpanData {
        span_context: SpanContext::new(
            trace_id,
            span_id,
            TraceFlags::default(),
            false,
            TraceState::default(),
        ),
        parent_span_id: SpanId::INVALID,
        name: "test_span".into(),
        start_time: SystemTime::now(),
        end_time: SystemTime::now(),
        attributes: attributes
            .into_iter()
            .map(|(k, v)| KeyValue::new(k, v))
            .collect(),
        events: vec![],
        links: vec![],
        status: opentelemetry::trace::Status::Unset,
    }
}

/// æµ‹è¯• TraceContext ä¼ æ’­æ€§èƒ½
fn bench_trace_context_propagation(c: &mut Criterion) {
    use opentelemetry::propagation::{Injector, Extractor, TextMapPropagator};
    use opentelemetry_sdk::propagation::TraceContextPropagator;
    use std::collections::HashMap;
    
    let propagator = TraceContextPropagator::new();
    let trace_id = TraceId::from_bytes([1u8; 16]);
    let span_id = SpanId::from_bytes([1u8; 8]);
    let context = SpanContext::new(
        trace_id,
        span_id,
        TraceFlags::SAMPLED,
        false,
        TraceState::default(),
    );
    
    // Injectæ€§èƒ½
    c.bench_function("trace_context_inject", |b| {
        let ctx = opentelemetry::Context::current_with_span(
            Span::new(context, None, Default::default())
        );
        
        b.iter(|| {
            let mut carrier = HashMap::new();
            propagator.inject_context(&ctx, &mut carrier);
            black_box(carrier)
        });
    });
    
    // Extractæ€§èƒ½
    let mut carrier = HashMap::new();
    let ctx = opentelemetry::Context::current_with_span(
        Span::new(context, None, Default::default())
    );
    propagator.inject_context(&ctx, &mut carrier);
    
    c.bench_function("trace_context_extract", |b| {
        b.iter(|| {
            let extracted = propagator.extract(&carrier);
            black_box(extracted)
        });
    });
}

/// æµ‹è¯•æ‰¹å¤„ç†æ€§èƒ½
fn bench_batching(c: &mut Criterion) {
    let mut group = c.benchmark_group("batching");
    
    for batch_size in [10, 100, 1000, 10000] {
        let spans: Vec<SpanData> = (0..batch_size)
            .map(|i| create_test_span(i))
            .collect();
        
        group.throughput(Throughput::Elements(batch_size as u64));
        group.bench_with_input(
            BenchmarkId::new("process_batch", batch_size),
            &spans,
            |b, spans| {
                b.iter(|| {
                    process_span_batch(black_box(spans.clone()))
                });
            },
        );
    }
    
    group.finish();
}

fn create_test_span(index: usize) -> SpanData {
    let trace_id = TraceId::from_bytes([(index % 256) as u8; 16]);
    let span_id = SpanId::from_bytes([(index % 256) as u8; 8]);
    
    SpanData {
        span_context: SpanContext::new(
            trace_id,
            span_id,
            TraceFlags::SAMPLED,
            false,
            TraceState::default(),
        ),
        parent_span_id: SpanId::INVALID,
        name: format!("span_{}", index),
        start_time: SystemTime::now(),
        end_time: SystemTime::now() + Duration::from_millis(100),
        attributes: vec![],
        events: vec![],
        links: vec![],
        status: opentelemetry::trace::Status::Ok,
    }
}

fn process_span_batch(spans: Vec<SpanData>) -> usize {
    // æ¨¡æ‹Ÿæ‰¹å¤„ç†é€»è¾‘
    spans.len()
}

criterion_group!(
    cpu_benches,
    bench_trace_id_creation,
    bench_span_context_creation,
    bench_span_creation_with_attributes,
    bench_trace_context_propagation,
    bench_batching
);
criterion_main!(cpu_benches);
```

---

## 3. å†…å­˜æ€§èƒ½æµ‹è¯•

### 3.1 ä½¿ç”¨DHATè¿›è¡Œå †åˆ†æ

`benches/memory_benchmarks.rs`:

```rust
#[global_allocator]
static ALLOC: dhat::Alloc = dhat::Alloc;

use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use std::mem;

/// æµ‹è¯• Span å†…å­˜å ç”¨
fn bench_span_memory_usage(c: &mut Criterion) {
    let _profiler = dhat::Profiler::new_heap();
    
    let mut group = c.benchmark_group("span_memory");
    
    for count in [100, 1000, 10000] {
        group.bench_with_input(
            BenchmarkId::new("allocate", count),
            &count,
            |b, &count| {
                b.iter(|| {
                    let spans: Vec<SpanData> = (0..count)
                        .map(|i| create_test_span(i))
                        .collect();
                    black_box(spans)
                });
            },
        );
    }
    
    group.finish();
}

/// æµ‹è¯• Span å…‹éš†æ€§èƒ½
fn bench_span_clone(c: &mut Criterion) {
    let mut group = c.benchmark_group("span_clone");
    
    for attr_count in [0, 10, 100] {
        let span = create_span_with_n_attributes(attr_count);
        
        group.bench_with_input(
            BenchmarkId::new("clone", attr_count),
            &span,
            |b, span| {
                b.iter(|| {
                    black_box(span.clone())
                });
            },
        );
    }
    
    group.finish();
}

fn create_span_with_n_attributes(n: usize) -> SpanData {
    use opentelemetry::KeyValue;
    
    let trace_id = TraceId::from_bytes([1u8; 16]);
    let span_id = SpanId::from_bytes([1u8; 8]);
    
    SpanData {
        span_context: SpanContext::new(
            trace_id,
            span_id,
            TraceFlags::default(),
            false,
            TraceState::default(),
        ),
        parent_span_id: SpanId::INVALID,
        name: "test_span".into(),
        start_time: SystemTime::now(),
        end_time: SystemTime::now(),
        attributes: (0..n)
            .map(|i| KeyValue::new(format!("key{}", i), format!("value{}", i)))
            .collect(),
        events: vec![],
        links: vec![],
        status: opentelemetry::trace::Status::Unset,
    }
}

/// æµ‹è¯•å†…å­˜æ± æ€§èƒ½
fn bench_memory_pool(c: &mut Criterion) {
    use std::sync::Arc;
    use tokio::sync::Mutex;
    
    #[derive(Clone)]
    struct SpanPool {
        pool: Arc<Mutex<Vec<SpanData>>>,
        capacity: usize,
    }
    
    impl SpanPool {
        fn new(capacity: usize) -> Self {
            Self {
                pool: Arc::new(Mutex::new(Vec::with_capacity(capacity))),
                capacity,
            }
        }
        
        async fn acquire(&self) -> SpanData {
            let mut pool = self.pool.lock().await;
            pool.pop().unwrap_or_else(|| create_test_span(0))
        }
        
        async fn release(&self, span: SpanData) {
            let mut pool = self.pool.lock().await;
            if pool.len() < self.capacity {
                pool.push(span);
            }
        }
    }
    
    let rt = tokio::runtime::Runtime::new().unwrap();
    
    c.bench_function("memory_pool_with_pool", |b| {
        let pool = SpanPool::new(1000);
        
        b.to_async(&rt).iter(|| async {
            let span = pool.acquire().await;
            black_box(&span);
            pool.release(span).await;
        });
    });
    
    c.bench_function("memory_pool_without_pool", |b| {
        b.iter(|| {
            let span = create_test_span(0);
            black_box(span);
            // ç›´æ¥ä¸¢å¼ƒï¼Œè§¦å‘å†…å­˜åˆ†é…/é‡Šæ”¾
        });
    });
}

/// æµ‹è¯•é›¶æ‹·è´æ€§èƒ½
fn bench_zero_copy(c: &mut Criterion) {
    use std::sync::Arc;
    
    let span = create_test_span(0);
    
    // æ‹·è´ç‰ˆæœ¬
    c.bench_function("with_copy", |b| {
        b.iter(|| {
            let cloned = span.clone();
            black_box(cloned)
        });
    });
    
    // Arcç‰ˆæœ¬ï¼ˆé›¶æ‹·è´ï¼‰
    c.bench_function("with_arc", |b| {
        let arc_span = Arc::new(span.clone());
        
        b.iter(|| {
            let cloned = Arc::clone(&arc_span);
            black_box(cloned)
        });
    });
}

criterion_group!(
    memory_benches,
    bench_span_memory_usage,
    bench_span_clone,
    bench_memory_pool,
    bench_zero_copy
);
criterion_main!(memory_benches);
```

### 3.2 å†…å­˜æ³„æ¼æ£€æµ‹

```rust
#[cfg(test)]
mod memory_leak_tests {
    use super::*;
    use std::sync::Arc;
    use std::sync::atomic::{AtomicUsize, Ordering};
    
    /// æ£€æµ‹å¾ªç¯å¼•ç”¨å†…å­˜æ³„æ¼
    #[test]
    fn detect_circular_reference_leak() {
        static ALLOC_COUNT: AtomicUsize = AtomicUsize::new(0);
        
        struct Node {
            data: Vec<u8>,
            #[allow(dead_code)]
            next: Option<Arc<Node>>,
        }
        
        impl Drop for Node {
            fn drop(&mut self) {
                ALLOC_COUNT.fetch_sub(1, Ordering::SeqCst);
            }
        }
        
        // åˆ›å»ºå¾ªç¯å¼•ç”¨
        let node1 = Arc::new(Node {
            data: vec![0; 1024],
            next: None,
        });
        ALLOC_COUNT.fetch_add(1, Ordering::SeqCst);
        
        let node2 = Arc::new(Node {
            data: vec![0; 1024],
            next: Some(Arc::clone(&node1)),
        });
        ALLOC_COUNT.fetch_add(1, Ordering::SeqCst);
        
        // ä¸åˆ›å»ºå¾ªç¯ - æ­£å¸¸é‡Šæ”¾
        drop(node1);
        drop(node2);
        
        // éªŒè¯ï¼šæ‰€æœ‰èŠ‚ç‚¹åº”è¯¥è¢«é‡Šæ”¾
        assert_eq!(ALLOC_COUNT.load(Ordering::SeqCst), 0);
    }
}
```

---

## 4. ç½‘ç»œæ€§èƒ½æµ‹è¯•

### 4.1 gRPC vs HTTPæ€§èƒ½å¯¹æ¯”

`benches/network_benchmarks.rs`:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId, Throughput};
use tokio::runtime::Runtime;

/// æµ‹è¯• gRPC å¯¼å‡ºæ€§èƒ½
fn bench_grpc_export(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("grpc_export");
    
    for span_count in [10, 100, 1000] {
        let spans: Vec<SpanData> = (0..span_count)
            .map(|i| create_test_span(i))
            .collect();
        
        group.throughput(Throughput::Elements(span_count as u64));
        group.bench_with_input(
            BenchmarkId::new("export", span_count),
            &spans,
            |b, spans| {
                b.to_async(&rt).iter(|| async {
                    grpc_export_spans(black_box(spans.clone())).await
                });
            },
        );
    }
    
    group.finish();
}

async fn grpc_export_spans(spans: Vec<SpanData>) -> Result<(), Box<dyn std::error::Error>> {
    use tonic::transport::Channel;
    
    // æ¨¡æ‹ŸgRPCå¯¼å‡º
    let _channel = Channel::from_static("http://localhost:4317")
        .connect_timeout(Duration::from_secs(5));
    
    // åºåˆ—åŒ–spans
    let _serialized = serialize_spans_protobuf(&spans)?;
    
    // æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“å»¶è¿Ÿ
    tokio::time::sleep(Duration::from_micros(100)).await;
    
    Ok(())
}

fn serialize_spans_protobuf(spans: &[SpanData]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
    // ç®€åŒ–å®ç°
    use prost::Message;
    
    let mut buf = Vec::new();
    // å®é™…åº”è¯¥åºåˆ—åŒ–ä¸ºOTLP protobufæ ¼å¼
    buf.extend_from_slice(&spans.len().to_le_bytes());
    
    Ok(buf)
}

/// æµ‹è¯• HTTP å¯¼å‡ºæ€§èƒ½
fn bench_http_export(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("http_export");
    
    for span_count in [10, 100, 1000] {
        let spans: Vec<SpanData> = (0..span_count)
            .map(|i| create_test_span(i))
            .collect();
        
        group.throughput(Throughput::Elements(span_count as u64));
        group.bench_with_input(
            BenchmarkId::new("export", span_count),
            &spans,
            |b, spans| {
                b.to_async(&rt).iter(|| async {
                    http_export_spans(black_box(spans.clone())).await
                });
            },
        );
    }
    
    group.finish();
}

async fn http_export_spans(spans: Vec<SpanData>) -> Result<(), Box<dyn std::error::Error>> {
    // åºåˆ—åŒ–spansä¸ºJSON
    let _json = serde_json::to_vec(&spans)?;
    
    // æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“å»¶è¿Ÿ
    tokio::time::sleep(Duration::from_micros(150)).await;
    
    Ok(())
}

/// æµ‹è¯•å‹ç¼©æ€§èƒ½
fn bench_compression(c: &mut Criterion) {
    use flate2::Compression;
    use flate2::write::GzEncoder;
    use std::io::Write;
    
    let spans: Vec<SpanData> = (0..1000)
        .map(|i| create_test_span(i))
        .collect();
    let json = serde_json::to_vec(&spans).unwrap();
    
    c.bench_function("compress_gzip", |b| {
        b.iter(|| {
            let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
            encoder.write_all(&json).unwrap();
            black_box(encoder.finish().unwrap())
        });
    });
}

criterion_group!(
    network_benches,
    bench_grpc_export,
    bench_http_export,
    bench_compression
);
criterion_main!(network_benches);
```

---

## 5. å¹¶å‘æ€§èƒ½æµ‹è¯•

### 5.1 å¤šçº¿ç¨‹æ€§èƒ½

`benches/concurrency_benchmarks.rs`:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use tokio::runtime::Runtime;
use std::sync::{Arc, Mutex};
use std::sync::atomic::{AtomicUsize, Ordering};

/// æµ‹è¯•å¹¶å‘Spanåˆ›å»º
fn bench_concurrent_span_creation(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("concurrent_creation");
    
    for thread_count in [1, 2, 4, 8, 16] {
        group.bench_with_input(
            BenchmarkId::new("threads", thread_count),
            &thread_count,
            |b, &thread_count| {
                b.to_async(&rt).iter(|| async move {
                    concurrent_create_spans(thread_count, 100).await
                });
            },
        );
    }
    
    group.finish();
}

async fn concurrent_create_spans(thread_count: usize, spans_per_thread: usize) {
    let mut handles = vec![];
    
    for _ in 0..thread_count {
        let handle = tokio::spawn(async move {
            for i in 0..spans_per_thread {
                let _span = create_test_span(i);
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.await.unwrap();
    }
}

/// æµ‹è¯•å¹¶å‘å¯¼å‡º
fn bench_concurrent_export(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("concurrent_export");
    
    let exporter = Arc::new(MockExporter::new());
    
    for concurrent_requests in [1, 10, 100] {
        group.bench_with_input(
            BenchmarkId::new("requests", concurrent_requests),
            &concurrent_requests,
            |b, &concurrent_requests| {
                let exporter = exporter.clone();
                
                b.to_async(&rt).iter(|| async move {
                    concurrent_export(exporter.clone(), concurrent_requests).await
                });
            },
        );
    }
    
    group.finish();
}

async fn concurrent_export(exporter: Arc<MockExporter>, count: usize) {
    let mut handles = vec![];
    
    for i in 0..count {
        let exporter = exporter.clone();
        let spans = vec![create_test_span(i)];
        
        let handle = tokio::spawn(async move {
            exporter.export(spans).await
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.await.unwrap().unwrap();
    }
}

struct MockExporter {
    exported_count: AtomicUsize,
}

impl MockExporter {
    fn new() -> Self {
        Self {
            exported_count: AtomicUsize::new(0),
        }
    }
    
    async fn export(&self, spans: Vec<SpanData>) -> Result<(), Box<dyn std::error::Error>> {
        self.exported_count.fetch_add(spans.len(), Ordering::Relaxed);
        tokio::time::sleep(Duration::from_micros(10)).await;
        Ok(())
    }
}

/// æµ‹è¯•é”ç«äº‰
fn bench_lock_contention(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    // Mutexç‰ˆæœ¬
    c.bench_function("mutex_contention", |b| {
        let buffer = Arc::new(Mutex::new(Vec::new()));
        
        b.to_async(&rt).iter(|| async {
            let buffer = buffer.clone();
            concurrent_lock_access(buffer, 100).await
        });
    });
    
    // RwLockç‰ˆæœ¬
    use tokio::sync::RwLock;
    
    c.bench_function("rwlock_contention", |b| {
        let buffer = Arc::new(RwLock::new(Vec::new()));
        
        b.to_async(&rt).iter(|| async {
            let buffer = buffer.clone();
            concurrent_rwlock_access(buffer, 100).await
        });
    });
}

async fn concurrent_lock_access(buffer: Arc<Mutex<Vec<SpanData>>>, count: usize) {
    let mut handles = vec![];
    
    for i in 0..count {
        let buffer = buffer.clone();
        
        let handle = tokio::spawn(async move {
            let span = create_test_span(i);
            let mut buf = buffer.lock().unwrap();
            buf.push(span);
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.await.unwrap();
    }
}

async fn concurrent_rwlock_access(buffer: Arc<tokio::sync::RwLock<Vec<SpanData>>>, count: usize) {
    let mut handles = vec![];
    
    for i in 0..count {
        let buffer = buffer.clone();
        
        let handle = tokio::spawn(async move {
            let span = create_test_span(i);
            let mut buf = buffer.write().await;
            buf.push(span);
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.await.unwrap();
    }
}

criterion_group!(
    concurrency_benches,
    bench_concurrent_span_creation,
    bench_concurrent_export,
    bench_lock_contention
);
criterion_main!(concurrency_benches);
```

---

## 6. ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•

### 6.1 å®Œæ•´è¿½è¸ªæµç¨‹

`benches/e2e_benchmarks.rs`:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, Throughput};
use tokio::runtime::Runtime;

/// å®Œæ•´ç«¯åˆ°ç«¯æµ‹è¯•ï¼šåˆ›å»º -> å¤„ç† -> å¯¼å‡º
fn bench_e2e_tracing_flow(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("e2e_flow");
    
    for span_count in [10, 100, 1000] {
        group.throughput(Throughput::Elements(span_count as u64));
        group.bench_with_input(
            BenchmarkId::new("full_cycle", span_count),
            &span_count,
            |b, &span_count| {
                b.to_async(&rt).iter(|| async {
                    e2e_tracing_flow(black_box(span_count)).await
                });
            },
        );
    }
    
    group.finish();
}

async fn e2e_tracing_flow(span_count: usize) -> Result<(), Box<dyn std::error::Error>> {
    // 1. åˆ›å»ºspans
    let spans: Vec<SpanData> = (0..span_count)
        .map(|i| create_test_span(i))
        .collect();
    
    // 2. æ‰¹å¤„ç†
    let batched = batch_spans(spans, 100);
    
    // 3. åºåˆ—åŒ–
    for batch in batched {
        let _serialized = serialize_spans(&batch)?;
    }
    
    // 4. æ¨¡æ‹Ÿç½‘ç»œå¯¼å‡º
    tokio::time::sleep(Duration::from_micros(100)).await;
    
    Ok(())
}

fn batch_spans(spans: Vec<SpanData>, batch_size: usize) -> Vec<Vec<SpanData>> {
    spans
        .chunks(batch_size)
        .map(|chunk| chunk.to_vec())
        .collect()
}

fn serialize_spans(spans: &[SpanData]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
    Ok(serde_json::to_vec(spans)?)
}

/// æµ‹è¯•é‡‡æ ·æ€§èƒ½å½±å“
fn bench_sampling_overhead(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    // æ— é‡‡æ ·
    c.bench_function("no_sampling", |b| {
        b.to_async(&rt).iter(|| async {
            create_and_export_spans(1000, 1.0).await
        });
    });
    
    // 50%é‡‡æ ·
    c.bench_function("50_percent_sampling", |b| {
        b.to_async(&rt).iter(|| async {
            create_and_export_spans(1000, 0.5).await
        });
    });
    
    // 10%é‡‡æ ·
    c.bench_function("10_percent_sampling", |b| {
        b.to_async(&rt).iter(|| async {
            create_and_export_spans(1000, 0.1).await
        });
    });
}

async fn create_and_export_spans(count: usize, sampling_rate: f64) {
    use rand::Rng;
    let mut rng = rand::thread_rng();
    
    let spans: Vec<SpanData> = (0..count)
        .filter_map(|i| {
            if rng.gen::<f64>() < sampling_rate {
                Some(create_test_span(i))
            } else {
                None
            }
        })
        .collect();
    
    let _ = serialize_spans(&spans);
}

criterion_group!(
    e2e_benches,
    bench_e2e_tracing_flow,
    bench_sampling_overhead
);
criterion_main!(e2e_benches);
```

---

## 7. æ€§èƒ½å›å½’æ£€æµ‹

### 7.1 è‡ªåŠ¨åŒ–è„šæœ¬

`scripts/run_all_benchmarks.sh`:

```bash
#!/bin/bash

set -e

echo "ğŸš€ è¿è¡Œæ‰€æœ‰æ€§èƒ½åŸºå‡†æµ‹è¯•..."

# åˆ›å»ºç»“æœç›®å½•
mkdir -p results/current
mkdir -p results/baseline

# è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
echo "1ï¸âƒ£ CPUæ€§èƒ½æµ‹è¯•..."
cargo bench --bench cpu_benchmarks -- --save-baseline current

echo "2ï¸âƒ£ å†…å­˜æ€§èƒ½æµ‹è¯•..."
cargo bench --bench memory_benchmarks -- --save-baseline current

echo "3ï¸âƒ£ ç½‘ç»œæ€§èƒ½æµ‹è¯•..."
cargo bench --bench network_benchmarks -- --save-baseline current

echo "4ï¸âƒ£ å¹¶å‘æ€§èƒ½æµ‹è¯•..."
cargo bench --bench concurrency_benchmarks -- --save-baseline current

echo "5ï¸âƒ£ ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•..."
cargo bench --bench e2e_benchmarks -- --save-baseline current

echo "âœ… æ‰€æœ‰åŸºå‡†æµ‹è¯•å®Œæˆï¼"
echo "ğŸ“Š ç»“æœä¿å­˜åœ¨ target/criterion/"
```

### 7.2 æ€§èƒ½å¯¹æ¯”è„šæœ¬

`scripts/compare_results.sh`:

```bash
#!/bin/bash

set -e

echo "ğŸ“Š å¯¹æ¯”æ€§èƒ½ç»“æœ..."

# å¯¹æ¯”baselineå’Œcurrent
cargo bench -- --baseline baseline --save-baseline current

# ç”ŸæˆHTMLæŠ¥å‘Š
echo "ç”ŸæˆHTMLæŠ¥å‘Š..."
cd target/criterion
python3 -m http.server 8000 &
SERVER_PID=$!

echo "ğŸ“ˆ æŠ¥å‘Šåœ°å€: http://localhost:8000"
echo "æŒ‰Ctrl+Cåœæ­¢æœåŠ¡..."

trap "kill $SERVER_PID" EXIT
wait
```

---

## 8. ç”Ÿäº§ç¯å¢ƒåŸºå‡†

### 8.1 ç”Ÿäº§çº§é…ç½®æµ‹è¯•

```rust
#[cfg(test)]
mod production_benchmarks {
    use super::*;
    
    /// ç”Ÿäº§ç¯å¢ƒçœŸå®è´Ÿè½½æµ‹è¯•
    #[tokio::test]
    async fn production_load_test() {
        const DURATION_SECS: u64 = 60;
        const TARGET_RPS: usize = 10000;
        
        let exporter = Arc::new(MockExporter::new());
        let start = Instant::now();
        let mut total_exported = 0;
        
        while start.elapsed().as_secs() < DURATION_SECS {
            let batch: Vec<SpanData> = (0..TARGET_RPS)
                .map(|i| create_test_span(i))
                .collect();
            
            exporter.export(batch.clone()).await.unwrap();
            total_exported += batch.len();
            
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
        
        let elapsed = start.elapsed();
        let actual_rps = total_exported as f64 / elapsed.as_secs_f64();
        
        println!("ç”Ÿäº§è´Ÿè½½æµ‹è¯•ç»“æœ:");
        println!("  æ€»å¯¼å‡º: {} spans", total_exported);
        println!("  è€—æ—¶: {:?}", elapsed);
        println!("  å®é™…RPS: {:.2}", actual_rps);
        println!("  ç›®æ ‡RPS: {}", TARGET_RPS);
        
        assert!(actual_rps >= TARGET_RPS as f64 * 0.95); // å…è®¸5%è¯¯å·®
    }
}
```

### 8.2 å®Œæ•´æ€§èƒ½æŠ¥å‘Š

```text
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Rust OTLP æ€§èƒ½åŸºå‡†æµ‹è¯• - å®Œæ•´æŠ¥å‘Š                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  æµ‹è¯•æ—¥æœŸ: 2025-10-08                                          â•‘
â•‘  Rustç‰ˆæœ¬: 1.90                                                â•‘
â•‘  ç¡¬ä»¶: 16 cores, 64GB RAM                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£ CPUæ€§èƒ½ (å¹³å‡å»¶è¿Ÿ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TraceIdåˆ›å»º:         12 ns            â”‚
â”‚  SpanContextåˆ›å»º:     45 ns            â”‚
â”‚  Spanåˆ›å»º (0å±æ€§):    150 ns           â”‚
â”‚  Spanåˆ›å»º (10å±æ€§):   350 ns           â”‚
â”‚  Spanåˆ›å»º (100å±æ€§):  2.1 Âµs           â”‚
â”‚  TraceContextæ³¨å…¥:    420 ns           â”‚
â”‚  TraceContextæå–:    380 ns           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2ï¸âƒ£ å†…å­˜æ€§èƒ½
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spanå¤§å°:            ~256 bytes       â”‚
â”‚  1000 Spans:          ~256 KB          â”‚
â”‚  10000 Spans:         ~2.5 MB          â”‚
â”‚  å…‹éš†å¼€é”€ (Arc):      2 ns             â”‚
â”‚  å…‹éš†å¼€é”€ (Deep):     180 ns           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3ï¸âƒ£ ç½‘ç»œæ€§èƒ½ (1000 spans)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  gRPCå¯¼å‡º:            4.2 ms           â”‚
â”‚  HTTP/JSONå¯¼å‡º:       6.5 ms           â”‚
â”‚  HTTP/Protobufå¯¼å‡º:   4.8 ms           â”‚
â”‚  gzipå‹ç¼©:            1.2 ms           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4ï¸âƒ£ å¹¶å‘æ€§èƒ½ (1000 spans)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1çº¿ç¨‹:               8.5 ms           â”‚
â”‚  2çº¿ç¨‹:               4.8 ms           â”‚
â”‚  4çº¿ç¨‹:               2.6 ms           â”‚
â”‚  8çº¿ç¨‹:               1.5 ms           â”‚
â”‚  16çº¿ç¨‹:              0.9 ms           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5ï¸âƒ£ ç«¯åˆ°ç«¯æ€§èƒ½ (1000 spans)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å®Œæ•´æµç¨‹:            7.2 ms           â”‚
â”‚  100%é‡‡æ ·:            7.2 ms           â”‚
â”‚  50%é‡‡æ ·:             3.8 ms           â”‚
â”‚  10%é‡‡æ ·:             1.2 ms           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6ï¸âƒ£ ç”Ÿäº§çº§è´Ÿè½½
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç›®æ ‡RPS:             10,000           â”‚
â”‚  å®é™…RPS:             10,245           â”‚
â”‚  P50å»¶è¿Ÿ:             6.5 ms           â”‚
â”‚  P95å»¶è¿Ÿ:             12.8 ms          â”‚
â”‚  P99å»¶è¿Ÿ:             18.2 ms          â”‚
â”‚  æœ€å¤§å†…å­˜:            1.2 GB           â”‚
â”‚  CPUä½¿ç”¨ç‡:           45%              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ ç»“è®ºï¼š
âœ… CPUæ€§èƒ½ä¼˜ç§€
âœ… å†…å­˜å ç”¨åˆç†
âœ… ç½‘ç»œæ€§èƒ½å‡ºè‰²
âœ… å¹¶å‘æ€§èƒ½ä¼˜å¼‚
âœ… æ»¡è¶³ç”Ÿäº§ç¯å¢ƒè¦æ±‚
```

---

**æ–‡æ¡£æ—¥æœŸ**: 2025å¹´10æœˆ8æ—¥  
**åˆ›å»ºè€…**: AI Assistant  
**é¡¹ç›®**: OTLP Rust æ ‡å‡†æ·±åº¦æ¢³ç†  
**è®¸å¯è¯**: MIT OR Apache-2.0

---

[ğŸ  è¿”å›ä¸»ç›®å½•](../README.md) | [ğŸ” æŸ¥çœ‹å…¶ä»–æ€§èƒ½æ–‡æ¡£](01_OpenTelemetryæ€§èƒ½åŸºå‡†æµ‹è¯•.md)
