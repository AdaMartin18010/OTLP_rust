# Rust OTLP Kubernetes å®Œæ•´éƒ¨ç½²æŒ‡å—

> **Rustç‰ˆæœ¬**: 1.90+  
> **Kubernetes**: 1.30+  
> **Helm**: 3.16+  
> **Kustomize**: 5.5+  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ8æ—¥

---

## ğŸ“‹ ç›®å½•

- [Rust OTLP Kubernetes å®Œæ•´éƒ¨ç½²æŒ‡å—](#rust-otlp-kubernetes-å®Œæ•´éƒ¨ç½²æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. å®¹å™¨åŒ–åŸºç¡€](#1-å®¹å™¨åŒ–åŸºç¡€)
    - [1.1 å¤šé˜¶æ®µDockerfileä¼˜åŒ–](#11-å¤šé˜¶æ®µdockerfileä¼˜åŒ–)
    - [1.2 .dockerignoreä¼˜åŒ–](#12-dockerignoreä¼˜åŒ–)
    - [1.3 æ„å»ºè„šæœ¬](#13-æ„å»ºè„šæœ¬)
  - [2. KubernetesåŸºç¡€éƒ¨ç½²](#2-kubernetesåŸºç¡€éƒ¨ç½²)
    - [2.1 Namespaceé…ç½®](#21-namespaceé…ç½®)
    - [2.2 ConfigMapé…ç½®](#22-configmapé…ç½®)
    - [2.3 Secreté…ç½®](#23-secreté…ç½®)
    - [2.4 Deploymenté…ç½®](#24-deploymenté…ç½®)
    - [2.5 Serviceé…ç½®](#25-serviceé…ç½®)
    - [2.6 Ingressé…ç½®](#26-ingressé…ç½®)
  - [3. Helm Chartå®Œæ•´å®ç°](#3-helm-chartå®Œæ•´å®ç°)
    - [3.1 Chart.yaml](#31-chartyaml)
    - [3.2 values.yaml](#32-valuesyaml)
    - [3.3 éƒ¨ç½²æ¨¡æ¿](#33-éƒ¨ç½²æ¨¡æ¿)
    - [3.4 å®‰è£…è„šæœ¬](#34-å®‰è£…è„šæœ¬)
  - [4. è‡ªåŠ¨ä¼¸ç¼©é…ç½®](#4-è‡ªåŠ¨ä¼¸ç¼©é…ç½®)
    - [4.1 HPAé…ç½®](#41-hpaé…ç½®)
    - [4.2 VPAé…ç½®](#42-vpaé…ç½®)
  - [5. æœåŠ¡ç½‘æ ¼é›†æˆ](#5-æœåŠ¡ç½‘æ ¼é›†æˆ)
    - [5.1 Istioé…ç½®](#51-istioé…ç½®)

---

## 1. å®¹å™¨åŒ–åŸºç¡€

### 1.1 å¤šé˜¶æ®µDockerfileä¼˜åŒ–

`Dockerfile`:

```dockerfile
# ================================
# Stage 1: Builder
# ================================
FROM rust:1.90-slim AS builder

WORKDIR /build

# å®‰è£…ç¼–è¯‘ä¾èµ–
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    protobuf-compiler \
    && rm -rf /var/lib/apt/lists/*

# ç¼“å­˜ä¾èµ–å±‚
COPY Cargo.toml Cargo.lock ./
RUN mkdir src && \
    echo "fn main() {}" > src/main.rs && \
    cargo build --release && \
    rm -rf src

# å¤åˆ¶æºä»£ç å¹¶æ„å»º
COPY src ./src
COPY build.rs ./
RUN touch src/main.rs && \
    cargo build --release --bin otlp-service

# ä¼˜åŒ–äºŒè¿›åˆ¶å¤§å°
RUN strip target/release/otlp-service

# ================================
# Stage 2: Runtime
# ================================
FROM debian:bookworm-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 otlp && \
    mkdir -p /app /data && \
    chown -R otlp:otlp /app /data

WORKDIR /app

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /build/target/release/otlp-service /usr/local/bin/

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY config/ /app/config/

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER otlp

# ç¯å¢ƒå˜é‡
ENV RUST_LOG=info \
    RUST_BACKTRACE=1 \
    CONFIG_PATH=/app/config/production.yaml

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
    CMD ["/usr/local/bin/otlp-service", "health"]

EXPOSE 8080 9090

CMD ["/usr/local/bin/otlp-service"]
```

### 1.2 .dockerignoreä¼˜åŒ–

`.dockerignore`:

```plaintext
# Git
.git/
.gitignore

# æ„å»ºäº§ç‰©
target/
**/*.rs.bk
**/*.pdb

# IDE
.vscode/
.idea/
*.swp
*.swo

# æ–‡æ¡£
*.md
docs/
examples/

# æµ‹è¯•
tests/
benches/
fixtures/

# CI/CD
.github/
.gitlab-ci.yml

# æœ¬åœ°é…ç½®
.env
.env.local
config/local.yaml
```

### 1.3 æ„å»ºè„šæœ¬

`scripts/build-docker.sh`:

```bash
#!/bin/bash

set -e

VERSION=${1:-latest}
REGISTRY=${REGISTRY:-ghcr.io/your-org}
IMAGE_NAME=otlp-service

echo "ğŸ³ æ„å»ºDockeré•œåƒ..."
echo "  ç‰ˆæœ¬: $VERSION"
echo "  ä»“åº“: $REGISTRY"

# æ„å»ºé•œåƒ
docker build \
    --build-arg RUST_VERSION=1.90 \
    --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
    --build-arg VCS_REF=$(git rev-parse --short HEAD) \
    --tag ${REGISTRY}/${IMAGE_NAME}:${VERSION} \
    --tag ${REGISTRY}/${IMAGE_NAME}:latest \
    --platform linux/amd64,linux/arm64 \
    .

echo "âœ… é•œåƒæ„å»ºå®Œæˆ"

# æ¨é€é•œåƒ
if [ "$PUSH" = "true" ]; then
    echo "ğŸ“¤ æ¨é€é•œåƒåˆ°ä»“åº“..."
    docker push ${REGISTRY}/${IMAGE_NAME}:${VERSION}
    docker push ${REGISTRY}/${IMAGE_NAME}:latest
    echo "âœ… é•œåƒæ¨é€å®Œæˆ"
fi

# é•œåƒä¿¡æ¯
echo "ğŸ“Š é•œåƒä¿¡æ¯:"
docker images ${REGISTRY}/${IMAGE_NAME}:${VERSION}
```

---

## 2. KubernetesåŸºç¡€éƒ¨ç½²

### 2.1 Namespaceé…ç½®

`k8s/base/namespace.yaml`:

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: otlp-system
  labels:
    name: otlp-system
    environment: production
    managed-by: kubectl
```

### 2.2 ConfigMapé…ç½®

`k8s/base/configmap.yaml`:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otlp-config
  namespace: otlp-system
data:
  production.yaml: |
    server:
      host: "0.0.0.0"
      port: 8080
      grpc_port: 4317
      
    exporter:
      endpoint: "http://otel-collector:4318"
      timeout: 30s
      batch_size: 1000
      
    tracing:
      service_name: "otlp-service"
      sampling_rate: 1.0
      
    logging:
      level: "info"
      format: "json"
      
    metrics:
      enabled: true
      port: 9090
      path: "/metrics"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otlp-env
  namespace: otlp-system
data:
  RUST_LOG: "info,otlp_service=debug"
  RUST_BACKTRACE: "1"
  OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4318"
```

### 2.3 Secreté…ç½®

`k8s/base/secret.yaml`:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: otlp-secrets
  namespace: otlp-system
type: Opaque
stringData:
  # TLSè¯ä¹¦
  tls.crt: |
    -----BEGIN CERTIFICATE-----
    ...
    -----END CERTIFICATE-----
  
  tls.key: |
    -----BEGIN PRIVATE KEY-----
    ...
    -----END PRIVATE KEY-----
  
  # APIå¯†é’¥
  api-key: "your-secret-api-key"
  
  # æ•°æ®åº“è¿æ¥
  database-url: "postgresql://user:pass@postgres:5432/otlp"
```

### 2.4 Deploymenté…ç½®

`k8s/base/deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otlp-service
  namespace: otlp-system
  labels:
    app: otlp-service
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  selector:
    matchLabels:
      app: otlp-service
  
  template:
    metadata:
      labels:
        app: otlp-service
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    
    spec:
      serviceAccountName: otlp-service
      
      # å®‰å…¨ä¸Šä¸‹æ–‡
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      
      # Initå®¹å™¨
      initContainers:
      - name: check-dependencies
        image: busybox:1.36
        command: 
        - sh
        - -c
        - |
          until nc -z otel-collector 4318; do
            echo "ç­‰å¾…otel-collectorå°±ç»ª..."
            sleep 2
          done
      
      containers:
      - name: otlp-service
        image: ghcr.io/your-org/otlp-service:latest
        imagePullPolicy: IfNotPresent
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: grpc
          containerPort: 4317
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        
        env:
        - name: CONFIG_PATH
          value: /app/config/production.yaml
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        
        envFrom:
        - configMapRef:
            name: otlp-env
        - secretRef:
            name: otlp-secrets
        
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        
        # å­˜æ´»æ¢é’ˆ
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        
        # å°±ç»ªæ¢é’ˆ
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        
        # å¯åŠ¨æ¢é’ˆ
        startupProbe:
          httpGet:
            path: /health/startup
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 30
        
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: tls
          mountPath: /app/tls
          readOnly: true
        - name: data
          mountPath: /data
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
      
      volumes:
      - name: config
        configMap:
          name: otlp-config
      - name: tls
        secret:
          secretName: otlp-secrets
          items:
          - key: tls.crt
            path: tls.crt
          - key: tls.key
            path: tls.key
      - name: data
        emptyDir:
          sizeLimit: 1Gi
      
      # äº²å’Œæ€§é…ç½®
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - otlp-service
              topologyKey: kubernetes.io/hostname
```

### 2.5 Serviceé…ç½®

`k8s/base/service.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: otlp-service
  namespace: otlp-system
  labels:
    app: otlp-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  type: ClusterIP
  selector:
    app: otlp-service
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
  - name: grpc
    protocol: TCP
    port: 4317
    targetPort: 4317
  - name: metrics
    protocol: TCP
    port: 9090
    targetPort: 9090
  
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800

---
# Headless Service for StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: otlp-service-headless
  namespace: otlp-system
  labels:
    app: otlp-service
spec:
  clusterIP: None
  selector:
    app: otlp-service
  ports:
  - name: http
    port: 8080
  - name: grpc
    port: 4317
```

### 2.6 Ingressé…ç½®

`k8s/base/ingress.yaml`:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: otlp-service
  namespace: otlp-system
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/grpc-backend: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - otlp.example.com
    secretName: otlp-tls
  rules:
  - host: otlp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: otlp-service
            port:
              number: 8080
      - path: /v1/traces
        pathType: Prefix
        backend:
          service:
            name: otlp-service
            port:
              number: 4317
```

---

## 3. Helm Chartå®Œæ•´å®ç°

### 3.1 Chart.yaml

`helm/otlp-service/Chart.yaml`:

```yaml
apiVersion: v2
name: otlp-service
description: Rust OTLP Service Helm Chart
type: application
version: 1.0.0
appVersion: "1.0.0"
keywords:
  - opentelemetry
  - otlp
  - observability
  - rust
home: https://github.com/your-org/otlp-service
sources:
  - https://github.com/your-org/otlp-service
maintainers:
  - name: Your Team
    email: team@example.com
dependencies:
  - name: opentelemetry-collector
    version: "0.111.0"
    repository: "https://open-telemetry.github.io/opentelemetry-helm-charts"
    condition: collector.enabled
```

### 3.2 values.yaml

`helm/otlp-service/values.yaml`:

```yaml
# é•œåƒé…ç½®
image:
  repository: ghcr.io/your-org/otlp-service
  pullPolicy: IfNotPresent
  tag: "latest"

imagePullSecrets: []

# å‰¯æœ¬æ•°
replicaCount: 3

# æœåŠ¡é…ç½®
service:
  type: ClusterIP
  http:
    port: 8080
    targetPort: 8080
  grpc:
    port: 4317
    targetPort: 4317
  metrics:
    port: 9090
    targetPort: 9090

# Ingressé…ç½®
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: otlp.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: otlp-tls
      hosts:
        - otlp.example.com

# èµ„æºé…ç½®
resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 1Gi

# è‡ªåŠ¨ä¼¸ç¼©
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# é…ç½®
config:
  server:
    host: "0.0.0.0"
    port: 8080
    grpc_port: 4317
  
  exporter:
    endpoint: "http://otel-collector:4318"
    timeout: 30s
    batch_size: 1000
  
  tracing:
    service_name: "otlp-service"
    sampling_rate: 1.0

# ç¯å¢ƒå˜é‡
env:
  - name: RUST_LOG
    value: "info"
  - name: RUST_BACKTRACE
    value: "1"

# å¥åº·æ£€æŸ¥
livenessProbe:
  httpGet:
    path: /health/live
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /health/ready
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5

startupProbe:
  httpGet:
    path: /health/startup
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 5
  failureThreshold: 30

# å®‰å…¨ä¸Šä¸‹æ–‡
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL

# æŒä¹…åŒ–å­˜å‚¨
persistence:
  enabled: false
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 10Gi

# ServiceMonitor (Prometheus Operator)
serviceMonitor:
  enabled: true
  interval: 30s
  scrapeTimeout: 10s

# PodDisruptionBudget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# NetworkPolicy
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress

# OpenTelemetry Collector
collector:
  enabled: true
  mode: deployment
```

### 3.3 éƒ¨ç½²æ¨¡æ¿

`helm/otlp-service/templates/deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "otlp-service.fullname" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "otlp-service.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  selector:
    matchLabels:
      {{- include "otlp-service.selectorLabels" . | nindent 6 }}
  
  template:
    metadata:
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        {{- with .Values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      labels:
        {{- include "otlp-service.selectorLabels" . | nindent 8 }}
    
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      
      serviceAccountName: {{ include "otlp-service.serviceAccountName" . }}
      
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        
        ports:
        - name: http
          containerPort: {{ .Values.service.http.targetPort }}
          protocol: TCP
        - name: grpc
          containerPort: {{ .Values.service.grpc.targetPort }}
          protocol: TCP
        - name: metrics
          containerPort: {{ .Values.service.metrics.targetPort }}
          protocol: TCP
        
        env:
        {{- range .Values.env }}
        - name: {{ .name }}
          value: {{ .value | quote }}
        {{- end }}
        
        livenessProbe:
          {{- toYaml .Values.livenessProbe | nindent 10 }}
        
        readinessProbe:
          {{- toYaml .Values.readinessProbe | nindent 10 }}
        
        startupProbe:
          {{- toYaml .Values.startupProbe | nindent 10 }}
        
        resources:
          {{- toYaml .Values.resources | nindent 10 }}
        
        securityContext:
          {{- toYaml .Values.securityContext | nindent 10 }}
        
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        {{- if .Values.persistence.enabled }}
        - name: data
          mountPath: /data
        {{- end }}
      
      volumes:
      - name: config
        configMap:
          name: {{ include "otlp-service.fullname" . }}
      {{- if .Values.persistence.enabled }}
      - name: data
        persistentVolumeClaim:
          claimName: {{ include "otlp-service.fullname" . }}
      {{- end }}
```

### 3.4 å®‰è£…è„šæœ¬

`scripts/helm-install.sh`:

```bash
#!/bin/bash

set -e

NAMESPACE=${NAMESPACE:-otlp-system}
RELEASE_NAME=${RELEASE_NAME:-otlp-service}
CHART_PATH=${CHART_PATH:-./helm/otlp-service}

echo "ğŸ“¦ å®‰è£… Helm Chart..."
echo "  Namespace: $NAMESPACE"
echo "  Release: $RELEASE_NAME"

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# æ·»åŠ ä¾èµ–ä»“åº“
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
helm repo update

# å®‰è£…Chart
helm upgrade --install $RELEASE_NAME $CHART_PATH \
    --namespace $NAMESPACE \
    --create-namespace \
    --wait \
    --timeout 10m \
    --values ${CHART_PATH}/values.yaml

echo "âœ… Helm Chartå®‰è£…å®Œæˆ"

# éªŒè¯éƒ¨ç½²
echo "ğŸ” éªŒè¯éƒ¨ç½²..."
kubectl wait --for=condition=available --timeout=5m \
    deployment/$RELEASE_NAME -n $NAMESPACE

kubectl get all -n $NAMESPACE

echo "ğŸ‰ éƒ¨ç½²æˆåŠŸï¼"
```

---

## 4. è‡ªåŠ¨ä¼¸ç¼©é…ç½®

### 4.1 HPAé…ç½®

`k8s/base/hpa.yaml`:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: otlp-service-hpa
  namespace: otlp-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: otlp-service
  
  minReplicas: 3
  maxReplicas: 20
  
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30
      selectPolicy: Max
  
  metrics:
  # CPUåˆ©ç”¨ç‡
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  # å†…å­˜åˆ©ç”¨ç‡
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # è‡ªå®šä¹‰æŒ‡æ ‡ï¼šè¯·æ±‚æ•°
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1k"
```

### 4.2 VPAé…ç½®

`k8s/base/vpa.yaml`:

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: otlp-service-vpa
  namespace: otlp-system
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: otlp-service
  
  updatePolicy:
    updateMode: "Auto"
  
  resourcePolicy:
    containerPolicies:
    - containerName: otlp-service
      minAllowed:
        cpu: 250m
        memory: 512Mi
      maxAllowed:
        cpu: 2000m
        memory: 4Gi
      controlledResources:
        - cpu
        - memory
```

---

## 5. æœåŠ¡ç½‘æ ¼é›†æˆ

### 5.1 Istioé…ç½®

`k8s/istio/virtual-service.yaml`:

```yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: otlp-service
  namespace: otlp-system
spec:
  hosts:
  - otlp-service
  - otlp.example.com
  
  http:
  - match:
    - uri:
        prefix: "/v1/traces"
    route:
    - destination:
        host: otlp-service
        port:
          number: 8080
      weight: 100
    retries:
      attempts: 3
      perTryTimeout: 5s
      retryOn: 5xx,reset,connect-failure,refused-stream
    timeout: 30s
    
  - match:
    - uri:
        prefix: "/"
    route:
    - destination:
        host: otlp-service
        port:
          number: 8080
      weight: 100

---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: otlp-service
  namespace: otlp-system
spec:
  host: otlp-service
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 1000
      http:
        http1MaxPendingRequests: 1000
        http2MaxRequests: 1000
        maxRequestsPerConnection: 2
    loadBalancer:
      simple: LEAST_REQUEST
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      minHealthPercent: 40
```

---

**æ–‡æ¡£æœªå®Œå¾…ç»­ï¼Œç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¯·æŸ¥çœ‹å®Œæ•´ç‰ˆæœ¬...**

---

**æ–‡æ¡£æ—¥æœŸ**: 2025å¹´10æœˆ8æ—¥  
**åˆ›å»ºè€…**: AI Assistant  
**é¡¹ç›®**: OTLP Rust æ ‡å‡†æ·±åº¦æ¢³ç†  
**è®¸å¯è¯**: MIT OR Apache-2.0

---

[ğŸ  è¿”å›ä¸»ç›®å½•](../README.md) | [ğŸ“Š ç›‘æ§ä¸å‘Šè­¦](../20_ç›‘æ§ä¸å‘Šè­¦/01_Prometheus_Grafanaå®Œæ•´é›†æˆæŒ‡å—.md)
