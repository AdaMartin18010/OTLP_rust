# Tracing Appenderæ—¥å¿—ç®¡ç†ï¼šæ—¥å¿—è½®è½¬å½’æ¡£ä¸OTLPé›†æˆæŒ‡å— (Rust 1.90)

## ç›®å½•

- [Tracing Appenderæ—¥å¿—ç®¡ç†ï¼šæ—¥å¿—è½®è½¬å½’æ¡£ä¸OTLPé›†æˆæŒ‡å— (Rust 1.90)](#tracing-appenderæ—¥å¿—ç®¡ç†æ—¥å¿—è½®è½¬å½’æ¡£ä¸otlpé›†æˆæŒ‡å—-rust-190)
  - [ç›®å½•](#ç›®å½•)
  - [ä¸€ã€æ—¥å¿—ç®¡ç†æ ¸å¿ƒæ¦‚å¿µ](#ä¸€æ—¥å¿—ç®¡ç†æ ¸å¿ƒæ¦‚å¿µ)
    - [1.1 æ—¥å¿—çº§åˆ«](#11-æ—¥å¿—çº§åˆ«)
    - [1.2 æ—¥å¿—è½®è½¬ç­–ç•¥](#12-æ—¥å¿—è½®è½¬ç­–ç•¥)
    - [1.3 æ—¥å¿—å½’æ¡£](#13-æ—¥å¿—å½’æ¡£)
  - [äºŒã€Rustæ—¥å¿—ç”Ÿæ€](#äºŒrustæ—¥å¿—ç”Ÿæ€)
    - [2.1 æ ¸å¿ƒä¾èµ–](#21-æ ¸å¿ƒä¾èµ–)
    - [2.2 é¡¹ç›®é…ç½®](#22-é¡¹ç›®é…ç½®)
  - [ä¸‰ã€åŸºç¡€æ—¥å¿—è¾“å‡º](#ä¸‰åŸºç¡€æ—¥å¿—è¾“å‡º)
    - [3.1 æ–‡ä»¶Appender](#31-æ–‡ä»¶appender)
    - [3.2 éé˜»å¡Appender](#32-éé˜»å¡appender)
    - [3.3 å¤šç›®æ ‡è¾“å‡º](#33-å¤šç›®æ ‡è¾“å‡º)
  - [å››ã€æ—¥å¿—è½®è½¬å®ç°](#å››æ—¥å¿—è½®è½¬å®ç°)
    - [4.1 åŸºäºæ—¶é—´çš„è½®è½¬](#41-åŸºäºæ—¶é—´çš„è½®è½¬)
    - [4.2 åŸºäºæ–‡ä»¶å¤§å°çš„è½®è½¬](#42-åŸºäºæ–‡ä»¶å¤§å°çš„è½®è½¬)
    - [4.3 è‡ªå®šä¹‰è½®è½¬ç­–ç•¥](#43-è‡ªå®šä¹‰è½®è½¬ç­–ç•¥)
  - [äº”ã€æ—¥å¿—å½’æ¡£](#äº”æ—¥å¿—å½’æ¡£)
    - [5.1 å‹ç¼©å½’æ¡£](#51-å‹ç¼©å½’æ¡£)
    - [5.2 è¿œç¨‹å½’æ¡£ï¼ˆS3ï¼‰](#52-è¿œç¨‹å½’æ¡£s3)
    - [5.3 è‡ªåŠ¨æ¸…ç†](#53-è‡ªåŠ¨æ¸…ç†)
  - [å…­ã€ç»“æ„åŒ–æ—¥å¿—](#å…­ç»“æ„åŒ–æ—¥å¿—)
    - [6.1 JSONæ ¼å¼](#61-jsonæ ¼å¼)
    - [6.2 è‡ªå®šä¹‰å­—æ®µ](#62-è‡ªå®šä¹‰å­—æ®µ)
    - [6.3 ä¸Šä¸‹æ–‡ä¼ æ’­](#63-ä¸Šä¸‹æ–‡ä¼ æ’­)
  - [ä¸ƒã€OTLPæ—¥å¿—é›†æˆ](#ä¸ƒotlpæ—¥å¿—é›†æˆ)
    - [7.1 OpenTelemetry Logså¯¼å‡º](#71-opentelemetry-logså¯¼å‡º)
    - [7.2 æ—¥å¿—ä¸è¿½è¸ªå…³è”](#72-æ—¥å¿—ä¸è¿½è¸ªå…³è”)
    - [7.3 å¤šåç«¯å¯¼å‡º](#73-å¤šåç«¯å¯¼å‡º)
  - [å…«ã€æ€§èƒ½ä¼˜åŒ–](#å…«æ€§èƒ½ä¼˜åŒ–)
    - [8.1 å¼‚æ­¥æ‰¹é‡å†™å…¥](#81-å¼‚æ­¥æ‰¹é‡å†™å…¥)
    - [8.2 ç¼“å†²åŒºä¼˜åŒ–](#82-ç¼“å†²åŒºä¼˜åŒ–)
    - [8.3 æ€§èƒ½åŸºå‡†æµ‹è¯•](#83-æ€§èƒ½åŸºå‡†æµ‹è¯•)
  - [ä¹ã€ç”Ÿäº§çº§é…ç½®](#ä¹ç”Ÿäº§çº§é…ç½®)
    - [9.1 åˆ†çº§æ—¥å¿—ç®¡ç†](#91-åˆ†çº§æ—¥å¿—ç®¡ç†)
    - [9.2 åŠ¨æ€æ—¥å¿—çº§åˆ«](#92-åŠ¨æ€æ—¥å¿—çº§åˆ«)
    - [9.3 æ—¥å¿—é‡‡æ ·](#93-æ—¥å¿—é‡‡æ ·)
  - [åã€ç›‘æ§ä¸å‘Šè­¦](#åç›‘æ§ä¸å‘Šè­¦)
    - [10.1 æ—¥å¿—æŒ‡æ ‡](#101-æ—¥å¿—æŒ‡æ ‡)
    - [10.2 é”™è¯¯æ—¥å¿—å‘Šè­¦](#102-é”™è¯¯æ—¥å¿—å‘Šè­¦)
    - [10.3 æ—¥å¿—å¥åº·æ£€æŸ¥](#103-æ—¥å¿—å¥åº·æ£€æŸ¥)
  - [åä¸€ã€Dockeréƒ¨ç½²](#åä¸€dockeréƒ¨ç½²)
  - [åäºŒã€å‚è€ƒèµ„æº](#åäºŒå‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [å›½é™…æ ‡å‡†](#å›½é™…æ ‡å‡†)
    - [å·¥å…·](#å·¥å…·)
  - [æ€»ç»“](#æ€»ç»“)

---

## ä¸€ã€æ—¥å¿—ç®¡ç†æ ¸å¿ƒæ¦‚å¿µ

### 1.1 æ—¥å¿—çº§åˆ«

æ ‡å‡†æ—¥å¿—çº§åˆ«ï¼ˆä»ä½åˆ°é«˜ï¼‰ï¼š

| çº§åˆ«    | ç”¨é€”                           | ç”Ÿäº§ç¯å¢ƒ  |
|---------|-------------------------------|----------|
| TRACE   | è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼ˆå‡½æ•°è¿›å‡ºï¼‰         | âŒ       |
| DEBUG   | è°ƒè¯•ä¿¡æ¯ï¼ˆå˜é‡å€¼ã€çŠ¶æ€ï¼‰         | âŒ       |
| INFO    | ä¸šåŠ¡æµç¨‹ï¼ˆç”¨æˆ·æ“ä½œã€å…³é”®äº‹ä»¶ï¼‰    | âœ…       |
| WARN    | è­¦å‘Šï¼ˆéè‡´å‘½é”™è¯¯ã€é™çº§ï¼‰         | âœ…       |
| ERROR   | é”™è¯¯ï¼ˆéœ€è¦å…³æ³¨ï¼‰                | âœ…       |

**æœ€ä½³å®è·µ**ï¼š

- å¼€å‘ç¯å¢ƒï¼šDEBUG
- æµ‹è¯•ç¯å¢ƒï¼šINFO
- ç”Ÿäº§ç¯å¢ƒï¼šINFOï¼ˆå…³é”®æœåŠ¡ï¼‰æˆ– WARNï¼ˆé«˜ååæœåŠ¡ï¼‰

### 1.2 æ—¥å¿—è½®è½¬ç­–ç•¥

**åŸºäºæ—¶é—´**ï¼š

- **Hourly**ï¼šæ¯å°æ—¶ç”Ÿæˆæ–°æ–‡ä»¶ï¼ˆé«˜æµé‡æœåŠ¡ï¼‰
- **Daily**ï¼šæ¯å¤©ç”Ÿæˆæ–°æ–‡ä»¶ï¼ˆæ ‡å‡†ï¼‰
- **Never**ï¼šå•æ–‡ä»¶ï¼ˆä»…æµ‹è¯•ï¼‰

**åŸºäºå¤§å°**ï¼š

- æ–‡ä»¶è¾¾åˆ°æŒ‡å®šå¤§å°ï¼ˆå¦‚100MBï¼‰æ—¶è½®è½¬
- é€‚ç”¨äºæµé‡ä¸å‡åŒ€çš„æœåŠ¡

**æ··åˆç­–ç•¥**ï¼š

- æ¯å¤©è½®è½¬ + å•æ–‡ä»¶æœ€å¤§100MB

### 1.3 æ—¥å¿—å½’æ¡£

**ä¿ç•™ç­–ç•¥**ï¼š

- **çƒ­æ•°æ®**ï¼šæœ€è¿‘7å¤©ï¼Œå­˜å‚¨åœ¨æœ¬åœ°SSD
- **æ¸©æ•°æ®**ï¼š8-30å¤©ï¼Œå‹ç¼©åå­˜å‚¨
- **å†·æ•°æ®**ï¼š31-365å¤©ï¼Œå½’æ¡£åˆ°S3
- **åˆ é™¤**ï¼šè¶…è¿‡365å¤©

**å‹ç¼©ç®—æ³•**ï¼š

- **gzip**ï¼šé€šç”¨ï¼Œå‹ç¼©ç‡70-80%
- **zstd**ï¼šé«˜æ€§èƒ½ï¼Œå‹ç¼©ç‡80-85%

---

## äºŒã€Rustæ—¥å¿—ç”Ÿæ€

### 2.1 æ ¸å¿ƒä¾èµ–

```toml
[dependencies]
# Tracingæ ¸å¿ƒ
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json", "ansi"] }
tracing-appender = "0.2"

# OpenTelemetryé›†æˆ
opentelemetry = { version = "0.31", features = ["logs"] }
opentelemetry_sdk = { version = "0.31", features = ["rt-tokio", "logs"] }
opentelemetry-otlp = { version = "0.31", features = ["logs", "grpc-tonic"] }
opentelemetry-appender-tracing = "0.31"
tracing-opentelemetry = "0.28"

# æ—¥å¿—å‹ç¼©
flate2 = "1.0"          # gzip
zstd = "0.13"           # zstd

# AWS S3
aws-config = "1.5"
aws-sdk-s3 = "1.72"

# æ—¶é—´å¤„ç†
chrono = "0.4"

# å¼‚æ­¥è¿è¡Œæ—¶
tokio = { version = "1.42", features = ["full"] }

# åºåˆ—åŒ–
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# é”™è¯¯å¤„ç†
anyhow = "1.0"
thiserror = "2.0"

[dev-dependencies]
tempfile = "3"
```

### 2.2 é¡¹ç›®é…ç½®

```bash
mkdir -p log-demo/src/{appender,rotation,archive,otel}
cd log-demo
cargo init
```

---

## ä¸‰ã€åŸºç¡€æ—¥å¿—è¾“å‡º

### 3.1 æ–‡ä»¶Appender

åˆ›å»ºåŸºç¡€æ–‡ä»¶æ—¥å¿—è¾“å‡ºï¼š

```rust
// src/appender/file.rs
use tracing_appender::{non_blocking, rolling};
use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

/// åˆå§‹åŒ–æ–‡ä»¶æ—¥å¿—
pub fn init_file_logging(log_dir: &str) {
    let file_appender = rolling::daily(log_dir, "app.log");
    let (non_blocking_appender, _guard) = non_blocking(file_appender);

    tracing_subscriber::registry()
        .with(EnvFilter::try_from_default_env().unwrap_or_else(|_| "info".into()))
        .with(
            fmt::layer()
                .with_writer(non_blocking_appender)
                .with_ansi(false) // æ–‡ä»¶è¾“å‡ºç¦ç”¨ANSIé¢œè‰²
                .with_target(true)
                .with_thread_ids(true)
                .with_file(true)
                .with_line_number(true),
        )
        .init();

    tracing::info!("File logging initialized: {}", log_dir);
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_file_logging() {
        let temp_dir = tempdir().unwrap();
        let log_path = temp_dir.path().to_str().unwrap();

        init_file_logging(log_path);

        tracing::info!("Test log message");
        tracing::error!(error_code = 500, "Test error");

        // éªŒè¯æ—¥å¿—æ–‡ä»¶å­˜åœ¨
        let log_files: Vec<_> = std::fs::read_dir(log_path)
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert!(!log_files.is_empty());
    }
}
```

### 3.2 éé˜»å¡Appender

ä½¿ç”¨éé˜»å¡I/Oæå‡æ€§èƒ½ï¼š

```rust
// src/appender/non_blocking.rs
use tracing_appender::non_blocking::{NonBlocking, WorkerGuard};
use tracing_appender::rolling::RollingFileAppender;

/// åˆ›å»ºéé˜»å¡Appender
pub fn create_non_blocking_appender(
    appender: RollingFileAppender,
) -> (NonBlocking, WorkerGuard) {
    tracing_appender::non_blocking(appender)
}

/// é…ç½®éé˜»å¡Appenderï¼ˆå¸¦ç¼“å†²åŒºå¤§å°ï¼‰
pub fn create_buffered_appender(
    appender: RollingFileAppender,
    buffer_size: usize,
) -> (NonBlocking, WorkerGuard) {
    tracing_appender::non_blocking::NonBlockingBuilder::default()
        .lossy(false) // ä¸ä¸¢å¼ƒæ—¥å¿—
        .buffered_lines_limit(buffer_size)
        .finish(appender)
}

#[cfg(test)]
mod tests {
    use super::*;
    use tracing_appender::rolling;
    use tempfile::tempdir;

    #[test]
    fn test_non_blocking_appender() {
        let temp_dir = tempdir().unwrap();
        let file_appender = rolling::daily(temp_dir.path(), "test.log");

        let (_non_blocking, _guard) = create_non_blocking_appender(file_appender);

        // Guardåœ¨æµ‹è¯•ç»“æŸæ—¶è‡ªåŠ¨åˆ·æ–°ç¼“å†²åŒº
    }

    #[test]
    fn test_buffered_appender() {
        let temp_dir = tempdir().unwrap();
        let file_appender = rolling::daily(temp_dir.path(), "test.log");

        let (_non_blocking, _guard) = create_buffered_appender(file_appender, 10_000);

        println!("Buffered appender created with 10,000 lines buffer");
    }
}
```

### 3.3 å¤šç›®æ ‡è¾“å‡º

åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼š

```rust
// src/appender/multi_target.rs
use tracing_appender::rolling;
use tracing_subscriber::{
    fmt,
    layer::SubscriberExt,
    util::SubscriberInitExt,
    EnvFilter,
};

pub fn init_multi_target_logging(log_dir: &str) {
    let file_appender = rolling::daily(log_dir, "app.log");
    let (non_blocking_file, _guard) = tracing_appender::non_blocking(file_appender);

    tracing_subscriber::registry()
        .with(EnvFilter::try_from_default_env().unwrap_or_else(|_| "info".into()))
        // æ§åˆ¶å°è¾“å‡ºï¼ˆå¸¦é¢œè‰²ï¼‰
        .with(
            fmt::layer()
                .with_writer(std::io::stdout)
                .with_ansi(true)
                .with_target(false)
                .compact(),
        )
        // æ–‡ä»¶è¾“å‡ºï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
        .with(
            fmt::layer()
                .with_writer(non_blocking_file)
                .with_ansi(false)
                .with_target(true)
                .with_thread_ids(true)
                .with_file(true)
                .with_line_number(true),
        )
        .init();

    tracing::info!("Multi-target logging initialized");
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_multi_target() {
        let temp_dir = tempdir().unwrap();
        init_multi_target_logging(temp_dir.path().to_str().unwrap());

        tracing::info!("This appears in both console and file");
        tracing::warn!(user_id = 123, "Warning message");
    }
}
```

---

## å››ã€æ—¥å¿—è½®è½¬å®ç°

### 4.1 åŸºäºæ—¶é—´çš„è½®è½¬

å®ç°å°æ—¶ã€å¤©ã€å‘¨è½®è½¬ï¼š

```rust
// src/rotation/time_based.rs
use tracing_appender::rolling::{RollingFileAppender, Rotation};
use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub enum RotationStrategy {
    Hourly,
    Daily,
    Weekly,
}

impl RotationStrategy {
    fn to_rotation(&self) -> Rotation {
        match self {
            Self::Hourly => Rotation::HOURLY,
            Self::Daily => Rotation::DAILY,
            Self::Weekly => Rotation::NEVER, // tracing-appenderä¸æ”¯æŒWEEKLYï¼Œéœ€è‡ªå®šä¹‰
        }
    }
}

pub fn init_time_based_rotation(log_dir: &str, strategy: RotationStrategy) {
    let file_appender = RollingFileAppender::new(
        strategy.to_rotation(),
        log_dir,
        "app.log",
    );

    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);

    tracing_subscriber::registry()
        .with(EnvFilter::new("info"))
        .with(
            fmt::layer()
                .with_writer(non_blocking)
                .with_ansi(false),
        )
        .init();

    tracing::info!("Time-based rotation initialized: {:?}", strategy);
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_daily_rotation() {
        let temp_dir = tempdir().unwrap();
        init_time_based_rotation(temp_dir.path().to_str().unwrap(), RotationStrategy::Daily);

        for i in 0..100 {
            tracing::info!(iteration = i, "Log entry");
        }

        // éªŒè¯æ—¥å¿—æ–‡ä»¶å‘½åæ ¼å¼ï¼šapp.log.2025-10-11
        let log_files: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert!(!log_files.is_empty());
    }
}
```

### 4.2 åŸºäºæ–‡ä»¶å¤§å°çš„è½®è½¬

è‡ªå®šä¹‰åŸºäºå¤§å°çš„è½®è½¬ï¼š

```rust
// src/rotation/size_based.rs
use std::fs::{File, OpenOptions};
use std::io::{self, Write};
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};

pub struct SizeBasedRotation {
    log_dir: PathBuf,
    file_prefix: String,
    max_size_bytes: u64,
    current_file: Arc<Mutex<Option<File>>>,
    current_size: Arc<Mutex<u64>>,
}

impl SizeBasedRotation {
    pub fn new(log_dir: &Path, file_prefix: &str, max_size_mb: u64) -> Self {
        std::fs::create_dir_all(log_dir).unwrap();

        Self {
            log_dir: log_dir.to_path_buf(),
            file_prefix: file_prefix.to_string(),
            max_size_bytes: max_size_mb * 1024 * 1024,
            current_file: Arc::new(Mutex::new(None)),
            current_size: Arc::new(Mutex::new(0)),
        }
    }

    pub fn write(&self, data: &[u8]) -> io::Result<()> {
        let mut file_lock = self.current_file.lock().unwrap();
        let mut size_lock = self.current_size.lock().unwrap();

        // æ£€æŸ¥æ˜¯å¦éœ€è¦è½®è½¬
        if *size_lock + data.len() as u64 > self.max_size_bytes {
            self.rotate(&mut file_lock)?;
            *size_lock = 0;
        }

        // æ‰“å¼€æ–‡ä»¶ï¼ˆå¦‚æœæœªæ‰“å¼€ï¼‰
        if file_lock.is_none() {
            let path = self.current_log_path();
            *file_lock = Some(
                OpenOptions::new()
                    .create(true)
                    .append(true)
                    .open(path)?,
            );
        }

        // å†™å…¥æ•°æ®
        if let Some(ref mut file) = *file_lock {
            file.write_all(data)?;
            file.flush()?;
            *size_lock += data.len() as u64;
        }

        Ok(())
    }

    fn rotate(&self, file_lock: &mut Option<File>) -> io::Result<()> {
        // å…³é—­å½“å‰æ–‡ä»¶
        *file_lock = None;

        // é‡å‘½åå½“å‰æ–‡ä»¶
        let current_path = self.current_log_path();
        if current_path.exists() {
            let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
            let rotated_path = self
                .log_dir
                .join(format!("{}_{}.log", self.file_prefix, timestamp));
            std::fs::rename(&current_path, &rotated_path)?;
            tracing::info!("Rotated log file: {:?}", rotated_path);
        }

        Ok(())
    }

    fn current_log_path(&self) -> PathBuf {
        self.log_dir.join(format!("{}.log", self.file_prefix))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_size_based_rotation() {
        let temp_dir = tempdir().unwrap();
        let rotation = SizeBasedRotation::new(temp_dir.path(), "app", 1); // 1MB

        // å†™å…¥2MBæ•°æ®ï¼Œè§¦å‘è½®è½¬
        for _ in 0..2048 {
            let data = vec![b'A'; 1024]; // 1KB per write
            rotation.write(&data).unwrap();
        }

        // éªŒè¯è½®è½¬æ–‡ä»¶å­˜åœ¨
        let log_files: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert!(log_files.len() >= 2); // è‡³å°‘æœ‰å½“å‰æ–‡ä»¶å’Œä¸€ä¸ªè½®è½¬æ–‡ä»¶
    }
}
```

### 4.3 è‡ªå®šä¹‰è½®è½¬ç­–ç•¥

ç»“åˆæ—¶é—´å’Œå¤§å°çš„æ··åˆè½®è½¬ï¼š

```rust
// src/rotation/custom.rs
use std::path::Path;
use tracing_appender::rolling::{RollingFileAppender, Rotation};

pub struct CustomRotation {
    time_rotation: Rotation,
    max_size_mb: u64,
}

impl CustomRotation {
    pub fn new(time_rotation: Rotation, max_size_mb: u64) -> Self {
        Self {
            time_rotation,
            max_size_mb,
        }
    }

    pub fn create_appender(&self, log_dir: &Path, file_prefix: &str) -> RollingFileAppender {
        // ä½¿ç”¨tracing_appenderçš„æ—¶é—´è½®è½¬
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç»“åˆsize_basedæ¨¡å—å®ç°æ··åˆè½®è½¬
        RollingFileAppender::new(self.time_rotation, log_dir, file_prefix)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_custom_rotation() {
        let temp_dir = tempdir().unwrap();
        let custom = CustomRotation::new(Rotation::DAILY, 100);

        let _appender = custom.create_appender(temp_dir.path(), "app.log");

        println!("Custom rotation: daily + 100MB limit");
    }
}
```

---

## äº”ã€æ—¥å¿—å½’æ¡£

### 5.1 å‹ç¼©å½’æ¡£

ä½¿ç”¨gzipå‹ç¼©æ—§æ—¥å¿—ï¼š

```rust
// src/archive/compression.rs
use flate2::write::GzEncoder;
use flate2::Compression;
use std::fs::File;
use std::io::{self, Read, Write};
use std::path::{Path, PathBuf};

pub fn compress_log_file(src: &Path, dest: &Path) -> io::Result<()> {
    let mut input = File::open(src)?;
    let output = File::create(dest)?;
    let mut encoder = GzEncoder::new(output, Compression::default());

    let mut buffer = Vec::new();
    input.read_to_end(&mut buffer)?;
    encoder.write_all(&buffer)?;
    encoder.finish()?;

    tracing::info!("Compressed: {:?} -> {:?}", src, dest);

    Ok(())
}

pub fn compress_old_logs(log_dir: &Path, days_old: u64) -> io::Result<()> {
    let cutoff = chrono::Utc::now() - chrono::Duration::days(days_old as i64);

    for entry in std::fs::read_dir(log_dir)? {
        let entry = entry?;
        let path = entry.path();

        if path.extension().and_then(|s| s.to_str()) == Some("log") {
            let metadata = entry.metadata()?;
            if let Ok(modified) = metadata.modified() {
                let modified_time: chrono::DateTime<chrono::Utc> = modified.into();

                if modified_time < cutoff {
                    let gz_path = path.with_extension("log.gz");
                    compress_log_file(&path, &gz_path)?;
                    std::fs::remove_file(&path)?; // åˆ é™¤åŸæ–‡ä»¶
                }
            }
        }
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::tempdir;

    #[test]
    fn test_compress_log() {
        let temp_dir = tempdir().unwrap();

        // åˆ›å»ºæµ‹è¯•æ—¥å¿—æ–‡ä»¶
        let log_path = temp_dir.path().join("test.log");
        let mut file = File::create(&log_path).unwrap();
        writeln!(file, "Log entry 1").unwrap();
        writeln!(file, "Log entry 2").unwrap();

        // å‹ç¼©
        let gz_path = temp_dir.path().join("test.log.gz");
        compress_log_file(&log_path, &gz_path).unwrap();

        assert!(gz_path.exists());

        // éªŒè¯å‹ç¼©ç‡
        let original_size = log_path.metadata().unwrap().len();
        let compressed_size = gz_path.metadata().unwrap().len();
        println!("Compression ratio: {:.2}%", (compressed_size as f64 / original_size as f64) * 100.0);
    }

    #[test]
    fn test_compress_old_logs() {
        let temp_dir = tempdir().unwrap();

        // åˆ›å»ºå¤šä¸ªæ—¥å¿—æ–‡ä»¶
        for i in 0..5 {
            let log_path = temp_dir.path().join(format!("app_{}.log", i));
            let mut file = File::create(&log_path).unwrap();
            writeln!(file, "Log data {}", i).unwrap();
        }

        // å‹ç¼©7å¤©å‰çš„æ—¥å¿—ï¼ˆæµ‹è¯•ä¸­ç«‹å³å‹ç¼©ï¼‰
        compress_old_logs(temp_dir.path(), 0).unwrap();

        // éªŒè¯.gzæ–‡ä»¶å­˜åœ¨
        let gz_files: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .filter(|e| e.path().extension().and_then(|s| s.to_str()) == Some("gz"))
            .collect();

        assert!(!gz_files.is_empty());
    }
}
```

### 5.2 è¿œç¨‹å½’æ¡£ï¼ˆS3ï¼‰

å°†å‹ç¼©æ—¥å¿—ä¸Šä¼ åˆ°AWS S3ï¼š

```rust
// src/archive/s3_upload.rs
use aws_config::BehaviorVersion;
use aws_sdk_s3::primitives::ByteStream;
use aws_sdk_s3::Client;
use std::path::Path;

pub struct S3Archiver {
    client: Client,
    bucket: String,
}

impl S3Archiver {
    pub async fn new(bucket: String) -> Self {
        let config = aws_config::load_defaults(BehaviorVersion::latest()).await;
        let client = Client::new(&config);

        Self { client, bucket }
    }

    pub async fn upload_log(&self, local_path: &Path, s3_key: &str) -> anyhow::Result<()> {
        let body = ByteStream::from_path(local_path).await?;

        self.client
            .put_object()
            .bucket(&self.bucket)
            .key(s3_key)
            .body(body)
            .send()
            .await?;

        tracing::info!(
            local_path = %local_path.display(),
            s3_key = s3_key,
            "Log uploaded to S3"
        );

        Ok(())
    }

    pub async fn archive_old_logs(&self, log_dir: &Path, days_old: u64) -> anyhow::Result<()> {
        let cutoff = chrono::Utc::now() - chrono::Duration::days(days_old as i64);

        for entry in std::fs::read_dir(log_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) == Some("gz") {
                let metadata = entry.metadata()?;
                if let Ok(modified) = metadata.modified() {
                    let modified_time: chrono::DateTime<chrono::Utc> = modified.into();

                    if modified_time < cutoff {
                        let filename = path.file_name().unwrap().to_str().unwrap();
                        let s3_key = format!("logs/{}", filename);

                        self.upload_log(&path, &s3_key).await?;

                        // ä¸Šä¼ æˆåŠŸååˆ é™¤æœ¬åœ°æ–‡ä»¶
                        std::fs::remove_file(&path)?;
                    }
                }
            }
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[tokio::test]
    #[ignore] // éœ€è¦AWSå‡­è¯
    async fn test_s3_upload() {
        let temp_dir = tempdir().unwrap();
        let log_path = temp_dir.path().join("test.log.gz");
        std::fs::write(&log_path, b"compressed log data").unwrap();

        let archiver = S3Archiver::new("my-log-bucket".to_string()).await;
        archiver.upload_log(&log_path, "logs/test.log.gz").await.unwrap();
    }
}
```

### 5.3 è‡ªåŠ¨æ¸…ç†

å®šæœŸæ¸…ç†è¿‡æœŸæ—¥å¿—ï¼š

```rust
// src/archive/cleanup.rs
use std::path::Path;
use std::time::Duration;
use tokio::time;

pub async fn start_log_cleanup_task(log_dir: &Path, retention_days: u64) {
    let log_dir = log_dir.to_path_buf();
    let mut interval = time::interval(Duration::from_secs(3600)); // æ¯å°æ—¶æ£€æŸ¥

    tokio::spawn(async move {
        loop {
            interval.tick().await;

            if let Err(e) = cleanup_expired_logs(&log_dir, retention_days) {
                tracing::error!(error = %e, "Failed to cleanup logs");
            }
        }
    });
}

fn cleanup_expired_logs(log_dir: &Path, retention_days: u64) -> std::io::Result<()> {
    let cutoff = chrono::Utc::now() - chrono::Duration::days(retention_days as i64);

    for entry in std::fs::read_dir(log_dir)? {
        let entry = entry?;
        let path = entry.path();

        let metadata = entry.metadata()?;
        if let Ok(modified) = metadata.modified() {
            let modified_time: chrono::DateTime<chrono::Utc> = modified.into();

            if modified_time < cutoff {
                std::fs::remove_file(&path)?;
                tracing::info!(file = %path.display(), "Deleted expired log");
            }
        }
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_cleanup_expired_logs() {
        let temp_dir = tempdir().unwrap();

        // åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        for i in 0..5 {
            let path = temp_dir.path().join(format!("old_{}.log", i));
            std::fs::write(&path, b"old data").unwrap();
        }

        // ç«‹å³æ¸…ç†ï¼ˆretention_days = 0ï¼‰
        cleanup_expired_logs(temp_dir.path(), 0).unwrap();

        // éªŒè¯æ–‡ä»¶è¢«åˆ é™¤
        let remaining: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert_eq!(remaining.len(), 0);
    }
}
```

---

## å…­ã€ç»“æ„åŒ–æ—¥å¿—

### 6.1 JSONæ ¼å¼

è¾“å‡ºJSONæ ¼å¼æ—¥å¿—ï¼š

```rust
// src/structured/json_format.rs
use tracing_appender::rolling;
use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_json_logging(log_dir: &str) {
    let file_appender = rolling::daily(log_dir, "app.json");
    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);

    tracing_subscriber::registry()
        .with(EnvFilter::new("info"))
        .with(
            fmt::layer()
                .json() // JSONæ ¼å¼
                .with_writer(non_blocking)
                .with_current_span(true)
                .with_span_list(true)
                .with_target(true)
                .with_thread_ids(true),
        )
        .init();

    tracing::info!("JSON logging initialized");
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_json_logging() {
        let temp_dir = tempdir().unwrap();
        init_json_logging(temp_dir.path().to_str().unwrap());

        tracing::info!(user_id = 123, action = "login", "User logged in");
        tracing::error!(error_code = 500, "Internal server error");

        // è¯»å–JSONæ—¥å¿—
        let log_files: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert!(!log_files.is_empty());

        // éªŒè¯JSONæ ¼å¼
        if let Some(log_file) = log_files.first() {
            let content = std::fs::read_to_string(log_file.path()).unwrap();
            assert!(content.contains("\"user_id\":123"));
        }
    }
}
```

**JSONæ—¥å¿—ç¤ºä¾‹**ï¼š

```json
{
  "timestamp": "2025-10-11T12:34:56.789Z",
  "level": "INFO",
  "target": "app::handlers::user",
  "fields": {
    "user_id": 123,
    "action": "login",
    "message": "User logged in"
  },
  "span": {
    "name": "process_request",
    "request_id": "550e8400-e29b-41d4-a716-446655440000"
  }
}
```

### 6.2 è‡ªå®šä¹‰å­—æ®µ

æ·»åŠ å…¨å±€ä¸Šä¸‹æ–‡å­—æ®µï¼š

```rust
// src/structured/custom_fields.rs
use tracing::{info_span, Span};
use tracing_subscriber::{layer::Context, Layer};

pub struct GlobalContextLayer {
    service_name: String,
    environment: String,
}

impl GlobalContextLayer {
    pub fn new(service_name: &str, environment: &str) -> Self {
        Self {
            service_name: service_name.to_string(),
            environment: environment.to_string(),
        }
    }
}

impl<S> Layer<S> for GlobalContextLayer
where
    S: tracing::Subscriber,
{
    fn on_new_span(
        &self,
        attrs: &tracing::span::Attributes<'_>,
        id: &tracing::span::Id,
        ctx: Context<'_, S>,
    ) {
        let span = ctx.span(id).unwrap();

        // æ·»åŠ å…¨å±€å­—æ®µ
        span.extensions_mut().insert(GlobalContext {
            service_name: self.service_name.clone(),
            environment: self.environment.clone(),
        });
    }
}

#[derive(Clone)]
struct GlobalContext {
    service_name: String,
    environment: String,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_global_context() {
        let span = info_span!("operation", user_id = 123);
        let _enter = span.enter();

        tracing::info!("This log includes global context");
    }
}
```

### 6.3 ä¸Šä¸‹æ–‡ä¼ æ’­

åœ¨Spanä¸­ä¼ æ’­ä¸Šä¸‹æ–‡ï¼š

```rust
// src/structured/context_propagation.rs
use tracing::{info_span, instrument};

#[instrument(fields(user_id, request_id))]
pub async fn process_user_request(user_id: u64, request_id: &str) {
    tracing::info!("Processing user request");

    // ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¼ æ’­åˆ°å­å‡½æ•°
    fetch_user_data(user_id).await;
    update_user_profile(user_id).await;

    tracing::info!("Request completed");
}

#[instrument]
async fn fetch_user_data(user_id: u64) {
    tracing::debug!(user_id, "Fetching user data");
    tokio::time::sleep(std::time::Duration::from_millis(10)).await;
}

#[instrument]
async fn update_user_profile(user_id: u64) {
    tracing::debug!(user_id, "Updating user profile");
    tokio::time::sleep(std::time::Duration::from_millis(5)).await;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_context_propagation() {
        process_user_request(123, "req-001").await;
    }
}
```

---

## ä¸ƒã€OTLPæ—¥å¿—é›†æˆ

### 7.1 OpenTelemetry Logså¯¼å‡º

å°†æ—¥å¿—å¯¼å‡ºåˆ°OTLPï¼š

```rust
// src/otel/logs_exporter.rs
use opentelemetry::logs::LoggerProvider;
use opentelemetry_appender_tracing::layer::OpenTelemetryTracingBridge;
use opentelemetry_otlp::{LogExporter, WithExportConfig};
use opentelemetry_sdk::{logs::LoggerProvider as SdkLoggerProvider, Resource, runtime};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_otlp_logging(service_name: &str, otlp_endpoint: &str) {
    let exporter = LogExporter::builder()
        .with_tonic()
        .with_endpoint(otlp_endpoint)
        .build()
        .expect("Failed to create OTLP log exporter");

    let logger_provider = SdkLoggerProvider::builder()
        .with_batch_exporter(exporter, runtime::Tokio)
        .with_resource(Resource::new(vec![
            opentelemetry::KeyValue::new("service.name", service_name.to_string()),
        ]))
        .build();

    let otel_layer = OpenTelemetryTracingBridge::new(&logger_provider);

    tracing_subscriber::registry()
        .with(EnvFilter::new("info"))
        .with(otel_layer)
        .init();

    tracing::info!("OTLP logging initialized: {}", otlp_endpoint);
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    #[ignore] // éœ€è¦OTLP Collectorè¿è¡Œ
    async fn test_otlp_logging() {
        init_otlp_logging("test-service", "http://localhost:4317");

        tracing::info!(user_id = 123, "Test log to OTLP");

        tokio::time::sleep(std::time::Duration::from_secs(2)).await; // ç­‰å¾…æ‰¹é‡å¯¼å‡º
    }
}
```

### 7.2 æ—¥å¿—ä¸è¿½è¸ªå…³è”

å°†æ—¥å¿—å…³è”åˆ°Traceï¼š

```rust
// src/otel/tracing_correlation.rs
use opentelemetry::trace::{TraceContextExt, Tracer};
use tracing::{info_span, Span};
use tracing_opentelemetry::OpenTelemetrySpanExt;

pub async fn traced_operation_with_logs() {
    let span = info_span!("traced_operation");
    let _enter = span.enter();

    // æ—¥å¿—è‡ªåŠ¨åŒ…å«Trace IDå’ŒSpan ID
    tracing::info!("This log is correlated with the trace");

    expensive_computation().await;

    tracing::info!("Operation completed");
}

async fn expensive_computation() {
    tracing::debug!("Starting computation");
    tokio::time::sleep(std::time::Duration::from_millis(100)).await;
    tracing::debug!("Computation done");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_correlated_logs() {
        traced_operation_with_logs().await;
    }
}
```

### 7.3 å¤šåç«¯å¯¼å‡º

åŒæ—¶å¯¼å‡ºåˆ°æ–‡ä»¶å’ŒOTLPï¼š

```rust
// src/otel/multi_backend.rs
use opentelemetry_appender_tracing::layer::OpenTelemetryTracingBridge;
use opentelemetry_sdk::logs::LoggerProvider;
use tracing_appender::rolling;
use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_multi_backend_logging(
    log_dir: &str,
    logger_provider: &LoggerProvider,
) {
    let file_appender = rolling::daily(log_dir, "app.log");
    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);

    let otel_layer = OpenTelemetryTracingBridge::new(logger_provider);

    tracing_subscriber::registry()
        .with(EnvFilter::new("info"))
        // æ–‡ä»¶è¾“å‡º
        .with(
            fmt::layer()
                .with_writer(non_blocking)
                .with_ansi(false)
                .json(),
        )
        // OTLPè¾“å‡º
        .with(otel_layer)
        .init();

    tracing::info!("Multi-backend logging initialized");
}
```

---

## å…«ã€æ€§èƒ½ä¼˜åŒ–

### 8.1 å¼‚æ­¥æ‰¹é‡å†™å…¥

ä½¿ç”¨éé˜»å¡I/Oæå‡æ€§èƒ½ï¼š

```rust
// src/performance/async_batch.rs
use tracing_appender::non_blocking::NonBlockingBuilder;
use tracing_appender::rolling;

pub fn init_optimized_logging(log_dir: &str) {
    let file_appender = rolling::daily(log_dir, "app.log");

    let (non_blocking, _guard) = NonBlockingBuilder::default()
        .lossy(false) // ä¸ä¸¢å¼ƒæ—¥å¿—
        .buffered_lines_limit(10_000) // 10,000è¡Œç¼“å†²
        .finish(file_appender);

    tracing_subscriber::fmt()
        .with_writer(non_blocking)
        .with_ansi(false)
        .init();

    tracing::info!("Optimized logging initialized");
}
```

### 8.2 ç¼“å†²åŒºä¼˜åŒ–

è°ƒæ•´ç¼“å†²åŒºå¤§å°ä»¥å¹³è¡¡å†…å­˜å’Œæ€§èƒ½ï¼š

```rust
// src/performance/buffer_tuning.rs
use tracing_appender::non_blocking::NonBlockingBuilder;
use tracing_appender::rolling::RollingFileAppender;

pub struct LoggingConfig {
    pub buffer_size: usize,
    pub lossy: bool,
}

impl Default for LoggingConfig {
    fn default() -> Self {
        Self {
            buffer_size: 8192, // 8KBç¼“å†²
            lossy: false,
        }
    }
}

pub fn create_optimized_appender(
    appender: RollingFileAppender,
    config: LoggingConfig,
) -> (tracing_appender::non_blocking::NonBlocking, tracing_appender::non_blocking::WorkerGuard) {
    NonBlockingBuilder::default()
        .lossy(config.lossy)
        .buffered_lines_limit(config.buffer_size)
        .finish(appender)
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;
    use tracing_appender::rolling;

    #[test]
    fn test_buffer_tuning() {
        let temp_dir = tempdir().unwrap();
        let file_appender = rolling::daily(temp_dir.path(), "test.log");

        let config = LoggingConfig {
            buffer_size: 16384, // 16KB
            lossy: false,
        };

        let (_non_blocking, _guard) = create_optimized_appender(file_appender, config);

        println!("Optimized appender with 16KB buffer");
    }
}
```

### 8.3 æ€§èƒ½åŸºå‡†æµ‹è¯•

è¯„ä¼°æ—¥å¿—æ€§èƒ½å½±å“ï¼š

```rust
// benches/logging_benchmark.rs (éœ€è¦æ”¾åœ¨benchesç›®å½•)
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tracing::{info, instrument};

#[instrument]
fn log_intensive_operation() {
    for i in 0..1000 {
        info!(iteration = i, "Processing");
    }
}

fn benchmark_logging(c: &mut Criterion) {
    // åˆå§‹åŒ–æ—¥å¿—ï¼ˆè¾“å‡ºåˆ°/dev/nullï¼‰
    tracing_subscriber::fmt()
        .with_writer(std::io::sink)
        .init();

    c.bench_function("log_1000_messages", |b| {
        b.iter(|| {
            log_intensive_operation();
        });
    });
}

criterion_group!(benches, benchmark_logging);
criterion_main!(benches);
```

**è¿è¡ŒåŸºå‡†æµ‹è¯•**ï¼š

```bash
cargo bench

# é¢„æœŸç»“æœ
# log_1000_messages  time:   [2.5 ms 2.6 ms 2.7 ms]
```

---

## ä¹ã€ç”Ÿäº§çº§é…ç½®

### 9.1 åˆ†çº§æ—¥å¿—ç®¡ç†

ä¸åŒçº§åˆ«æ—¥å¿—è¾“å‡ºåˆ°ä¸åŒæ–‡ä»¶ï¼š

```rust
// src/production/tiered_logging.rs
use tracing_appender::rolling;
use tracing_subscriber::{
    filter::LevelFilter, fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter,
};

pub fn init_tiered_logging(log_dir: &str) {
    // INFOçº§åˆ«æ—¥å¿—
    let info_appender = rolling::daily(log_dir, "info.log");
    let (info_writer, _info_guard) = tracing_appender::non_blocking(info_appender);

    // ERRORçº§åˆ«æ—¥å¿—
    let error_appender = rolling::daily(log_dir, "error.log");
    let (error_writer, _error_guard) = tracing_appender::non_blocking(error_appender);

    tracing_subscriber::registry()
        // INFOåŠä»¥ä¸Šçº§åˆ« -> info.log
        .with(
            fmt::layer()
                .with_writer(info_writer)
                .with_ansi(false)
                .json()
                .with_filter(LevelFilter::INFO),
        )
        // ERRORåŠä»¥ä¸Šçº§åˆ« -> error.log
        .with(
            fmt::layer()
                .with_writer(error_writer)
                .with_ansi(false)
                .json()
                .with_filter(LevelFilter::ERROR),
        )
        .init();

    tracing::info!("Tiered logging initialized");
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_tiered_logging() {
        let temp_dir = tempdir().unwrap();
        init_tiered_logging(temp_dir.path().to_str().unwrap());

        tracing::info!("This goes to info.log");
        tracing::error!("This goes to both info.log and error.log");

        // éªŒè¯ä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨
        let files: Vec<_> = std::fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(Result::ok)
            .collect();

        assert!(files.len() >= 2);
    }
}
```

### 9.2 åŠ¨æ€æ—¥å¿—çº§åˆ«

è¿è¡Œæ—¶è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼š

```rust
// src/production/dynamic_level.rs
use std::sync::Arc;
use tracing::Level;
use tracing_subscriber::{reload, EnvFilter, Registry};

pub struct DynamicLogger {
    reload_handle: reload::Handle<EnvFilter, Registry>,
}

impl DynamicLogger {
    pub fn new() -> (Self, reload::Layer<EnvFilter, Registry>) {
        let (filter, reload_handle) = reload::Layer::new(EnvFilter::new("info"));

        (Self { reload_handle }, filter)
    }

    pub fn set_level(&self, level: Level) -> Result<(), reload::Error> {
        let new_filter = EnvFilter::new(level.to_string());
        self.reload_handle.reload(new_filter)
    }

    pub fn set_module_level(&self, module: &str, level: Level) -> Result<(), reload::Error> {
        let new_filter = EnvFilter::new(format!("{}={}", module, level));
        self.reload_handle.reload(new_filter)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

    #[test]
    fn test_dynamic_level() {
        let (logger, reload_layer) = DynamicLogger::new();

        tracing_subscriber::registry()
            .with(reload_layer)
            .with(tracing_subscriber::fmt::layer())
            .init();

        tracing::info!("Info level (visible)");
        tracing::debug!("Debug level (not visible)");

        // åŠ¨æ€åˆ‡æ¢åˆ°DEBUG
        logger.set_level(Level::DEBUG).unwrap();

        tracing::debug!("Debug level (now visible)");
    }
}
```

### 9.3 æ—¥å¿—é‡‡æ ·

é«˜æµé‡åœºæ™¯ä¸‹é‡‡æ ·æ—¥å¿—ï¼š

```rust
// src/production/sampling.rs
use std::sync::atomic::{AtomicU64, Ordering};

pub struct LogSampler {
    counter: AtomicU64,
    sample_rate: u64, // æ¯Næ¡æ—¥å¿—è®°å½•1æ¡
}

impl LogSampler {
    pub fn new(sample_rate: u64) -> Self {
        Self {
            counter: AtomicU64::new(0),
            sample_rate,
        }
    }

    pub fn should_log(&self) -> bool {
        let count = self.counter.fetch_add(1, Ordering::Relaxed);
        count % self.sample_rate == 0
    }
}

#[macro_export]
macro_rules! sampled_log {
    ($sampler:expr, $level:ident, $($arg:tt)+) => {
        if $sampler.should_log() {
            tracing::$level!($($arg)+);
        }
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sampling() {
        let sampler = LogSampler::new(10); // é‡‡æ ·ç‡1/10

        let mut logged = 0;
        for _ in 0..100 {
            if sampler.should_log() {
                logged += 1;
            }
        }

        assert_eq!(logged, 10); // æ­£å¥½10æ¡
    }
}
```

---

## åã€ç›‘æ§ä¸å‘Šè­¦

### 10.1 æ—¥å¿—æŒ‡æ ‡

å°†æ—¥å¿—ç»Ÿè®¡å¯¼å‡ºä¸ºæŒ‡æ ‡ï¼š

```rust
// src/monitoring/log_metrics.rs
use metrics::{counter, gauge};
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use tracing::{Event, Subscriber};
use tracing_subscriber::layer::Context;
use tracing_subscriber::Layer;

pub struct LogMetricsLayer {
    error_count: Arc<AtomicU64>,
    warn_count: Arc<AtomicU64>,
}

impl LogMetricsLayer {
    pub fn new() -> Self {
        Self {
            error_count: Arc::new(AtomicU64::new(0)),
            warn_count: Arc::new(AtomicU64::new(0)),
        }
    }

    pub fn start_metrics_export(self: Arc<Self>) {
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(std::time::Duration::from_secs(10));

            loop {
                interval.tick().await;

                let errors = self.error_count.swap(0, Ordering::Relaxed);
                let warns = self.warn_count.swap(0, Ordering::Relaxed);

                counter!("log_errors_total").increment(errors);
                counter!("log_warnings_total").increment(warns);
            }
        });
    }
}

impl<S> Layer<S> for LogMetricsLayer
where
    S: Subscriber,
{
    fn on_event(&self, event: &Event<'_>, _ctx: Context<'_, S>) {
        let metadata = event.metadata();

        match *metadata.level() {
            tracing::Level::ERROR => {
                self.error_count.fetch_add(1, Ordering::Relaxed);
            }
            tracing::Level::WARN => {
                self.warn_count.fetch_add(1, Ordering::Relaxed);
            }
            _ => {}
        }
    }
}
```

### 10.2 é”™è¯¯æ—¥å¿—å‘Šè­¦

è‡ªåŠ¨å‘Šè­¦é”™è¯¯æ—¥å¿—ï¼š

```rust
// src/monitoring/alerting.rs
use tracing::{Event, Subscriber};
use tracing_subscriber::layer::Context;
use tracing_subscriber::Layer;

pub struct AlertingLayer {
    alert_threshold: usize,
    error_buffer: std::sync::Mutex<Vec<String>>,
}

impl AlertingLayer {
    pub fn new(alert_threshold: usize) -> Self {
        Self {
            alert_threshold,
            error_buffer: std::sync::Mutex::new(Vec::new()),
        }
    }

    fn send_alert(&self, errors: &[String]) {
        // å®é™…åœºæ™¯ä¸­ï¼Œå‘é€åˆ°PagerDutyã€Slackç­‰
        tracing::warn!(
            error_count = errors.len(),
            "ğŸš¨ Alert: High error rate detected"
        );

        for error in errors.iter().take(5) {
            tracing::warn!("  - {}", error);
        }
    }
}

impl<S> Layer<S> for AlertingLayer
where
    S: Subscriber,
{
    fn on_event(&self, event: &Event<'_>, _ctx: Context<'_, S>) {
        if *event.metadata().level() == tracing::Level::ERROR {
            let mut buffer = self.error_buffer.lock().unwrap();
            buffer.push(format!("{:?}", event));

            if buffer.len() >= self.alert_threshold {
                self.send_alert(&buffer);
                buffer.clear();
            }
        }
    }
}
```

### 10.3 æ—¥å¿—å¥åº·æ£€æŸ¥

ç›‘æ§æ—¥å¿—ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼š

```rust
// src/monitoring/health_check.rs
use std::time::{Duration, Instant};
use tokio::time;

pub struct LogHealthChecker {
    last_log_time: std::sync::Mutex<Instant>,
}

impl LogHealthChecker {
    pub fn new() -> Self {
        Self {
            last_log_time: std::sync::Mutex::new(Instant::now()),
        }
    }

    pub fn record_log(&self) {
        *self.last_log_time.lock().unwrap() = Instant::now();
    }

    pub fn is_healthy(&self, timeout: Duration) -> bool {
        let last_log = *self.last_log_time.lock().unwrap();
        last_log.elapsed() < timeout
    }

    pub async fn start_health_check(self: std::sync::Arc<Self>) {
        let mut interval = time::interval(Duration::from_secs(60));

        loop {
            interval.tick().await;

            if !self.is_healthy(Duration::from_secs(300)) {
                tracing::error!("âš ï¸  Log system appears unhealthy: no logs in 5 minutes");
            }
        }
    }
}
```

---

## åä¸€ã€Dockeréƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - RUST_LOG=info
      - LOG_DIR=/app/logs
      - OTLP_ENDPOINT=http://otel-collector:4317
    volumes:
      - app_logs:/app/logs

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.114.0
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"

  loki:
    image: grafana/loki:3.3.2
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml

  grafana:
    image: grafana/grafana:11.4.0
    ports:
      - "3001:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  app_logs:
  grafana_data:
```

---

## åäºŒã€å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

1. **tracing-appender**: <https://docs.rs/tracing-appender/>
2. **tracing-subscriber**: <https://docs.rs/tracing-subscriber/>
3. **OpenTelemetry Logs**: <https://opentelemetry.io/docs/specs/otel/logs/>

### å›½é™…æ ‡å‡†

1. **Log Management Best Practices** (CNCF): <https://www.cncf.io/blog/2021/10/18/log-management-best-practices/>
2. **Structured Logging** (Google SRE): <https://sre.google/sre-book/monitoring-distributed-systems/>

### å·¥å…·

1. **Loki**: <https://grafana.com/oss/loki/>
2. **Fluentd**: <https://www.fluentd.org/>
3. **Vector**: <https://vector.dev/>

---

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†Rust 1.90ä¸­æ—¥å¿—ç®¡ç†çš„å®Œæ•´æŒ‡å—ï¼Œæ¶µç›–ï¼š

âœ… **æ—¥å¿—è½®è½¬**ï¼šæ—¶é—´ã€å¤§å°ã€è‡ªå®šä¹‰ç­–ç•¥  
âœ… **æ—¥å¿—å½’æ¡£**ï¼šå‹ç¼©ã€S3ä¸Šä¼ ã€è‡ªåŠ¨æ¸…ç†  
âœ… **ç»“æ„åŒ–æ—¥å¿—**ï¼šJSONæ ¼å¼ã€è‡ªå®šä¹‰å­—æ®µã€ä¸Šä¸‹æ–‡ä¼ æ’­  
âœ… **OTLPé›†æˆ**ï¼šæ—¥å¿—å¯¼å‡ºã€è¿½è¸ªå…³è”ã€å¤šåç«¯  
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå¼‚æ­¥æ‰¹é‡å†™å…¥ã€ç¼“å†²åŒºè°ƒä¼˜  
âœ… **ç”Ÿäº§é…ç½®**ï¼šåˆ†çº§ç®¡ç†ã€åŠ¨æ€çº§åˆ«ã€æ—¥å¿—é‡‡æ ·  
âœ… **ç›‘æ§å‘Šè­¦**ï¼šæ—¥å¿—æŒ‡æ ‡ã€é”™è¯¯å‘Šè­¦ã€å¥åº·æ£€æŸ¥  

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

- éµå¾ªOpenTelemetry Logsæ ‡å‡†
- ç”Ÿäº§çº§æ€§èƒ½ï¼ˆéé˜»å¡I/Oã€æ‰¹é‡å†™å…¥ï¼‰
- å®Œæ•´çš„æ—¥å¿—ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆè½®è½¬ã€å‹ç¼©ã€å½’æ¡£ã€æ¸…ç†ï¼‰
- æ·±åº¦é›†æˆOpenTelemetryå¯è§‚æµ‹æ€§æ ˆ

**ä¸‹ä¸€æ­¥**ï¼š

- æ¢ç´¢`opentelemetry-rust`é«˜çº§ç‰¹æ€§
- é›†æˆLokiã€Elasticsearchç­‰æ—¥å¿—åç«¯
- å­¦ä¹ åˆ†å¸ƒå¼è¿½è¸ªæœ€ä½³å®è·µ
