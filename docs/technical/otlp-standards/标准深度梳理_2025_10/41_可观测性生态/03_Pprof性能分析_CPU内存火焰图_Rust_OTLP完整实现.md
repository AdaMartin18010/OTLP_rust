# Pprofæ€§èƒ½åˆ†æï¼šCPU/å†…å­˜ç«ç„°å›¾ä¸OTLPé›†æˆæŒ‡å— (Rust 1.90)

## ç›®å½•

- [Pprofæ€§èƒ½åˆ†æï¼šCPU/å†…å­˜ç«ç„°å›¾ä¸OTLPé›†æˆæŒ‡å— (Rust 1.90)](#pprofæ€§èƒ½åˆ†æcpuå†…å­˜ç«ç„°å›¾ä¸otlpé›†æˆæŒ‡å—-rust-190)
  - [ç›®å½•](#ç›®å½•)
  - [ä¸€ã€æ€§èƒ½åˆ†ææ ¸å¿ƒæ¦‚å¿µ](#ä¸€æ€§èƒ½åˆ†ææ ¸å¿ƒæ¦‚å¿µ)
    - [1.1 CPU Profiling](#11-cpu-profiling)
    - [1.2 Memory Profiling](#12-memory-profiling)
    - [1.3 ç«ç„°å›¾å¯è§†åŒ–](#13-ç«ç„°å›¾å¯è§†åŒ–)
  - [äºŒã€Rustæ€§èƒ½åˆ†æç”Ÿæ€](#äºŒrustæ€§èƒ½åˆ†æç”Ÿæ€)
    - [2.1 æ ¸å¿ƒä¾èµ–](#21-æ ¸å¿ƒä¾èµ–)
    - [2.2 é¡¹ç›®é…ç½®](#22-é¡¹ç›®é…ç½®)
  - [ä¸‰ã€CPUæ€§èƒ½åˆ†æ](#ä¸‰cpuæ€§èƒ½åˆ†æ)
    - [3.1 åŸºç¡€CPU Profiling](#31-åŸºç¡€cpu-profiling)
    - [3.2 é‡‡æ ·é¢‘ç‡æ§åˆ¶](#32-é‡‡æ ·é¢‘ç‡æ§åˆ¶)
    - [3.3 çƒ­ç‚¹å‡½æ•°è¯†åˆ«](#33-çƒ­ç‚¹å‡½æ•°è¯†åˆ«)
  - [å››ã€å†…å­˜æ€§èƒ½åˆ†æ](#å››å†…å­˜æ€§èƒ½åˆ†æ)
    - [4.1 å †å†…å­˜åˆ†æ](#41-å †å†…å­˜åˆ†æ)
    - [4.2 å†…å­˜æ³„æ¼æ£€æµ‹](#42-å†…å­˜æ³„æ¼æ£€æµ‹)
    - [4.3 åˆ†é…è¿½è¸ª](#43-åˆ†é…è¿½è¸ª)
  - [äº”ã€ç«ç„°å›¾ç”Ÿæˆ](#äº”ç«ç„°å›¾ç”Ÿæˆ)
    - [5.1 CPUç«ç„°å›¾](#51-cpuç«ç„°å›¾)
    - [5.2 å†…å­˜ç«ç„°å›¾](#52-å†…å­˜ç«ç„°å›¾)
    - [5.3 å·®å¼‚ç«ç„°å›¾](#53-å·®å¼‚ç«ç„°å›¾)
  - [å…­ã€HTTPç«¯ç‚¹é›†æˆ](#å…­httpç«¯ç‚¹é›†æˆ)
    - [6.1 Pprof HTTPæœåŠ¡å™¨](#61-pprof-httpæœåŠ¡å™¨)
    - [6.2 ä¸Axumé›†æˆ](#62-ä¸axumé›†æˆ)
    - [6.3 åŠ¨æ€é‡‡æ ·æ§åˆ¶](#63-åŠ¨æ€é‡‡æ ·æ§åˆ¶)
  - [ä¸ƒã€OTLPé›†æˆ](#ä¸ƒotlpé›†æˆ)
    - [7.1 æ€§èƒ½æŒ‡æ ‡å¯¼å‡º](#71-æ€§èƒ½æŒ‡æ ‡å¯¼å‡º)
    - [7.2 è¿½è¸ªä¸æ€§èƒ½å…³è”](#72-è¿½è¸ªä¸æ€§èƒ½å…³è”)
    - [7.3 åˆ†å¸ƒå¼æ€§èƒ½åˆ†æ](#73-åˆ†å¸ƒå¼æ€§èƒ½åˆ†æ)
  - [å…«ã€ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–](#å…«ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–)
    - [8.1 ä½å¼€é”€é‡‡æ ·](#81-ä½å¼€é”€é‡‡æ ·)
    - [8.2 æŒ‰éœ€å¯ç”¨](#82-æŒ‰éœ€å¯ç”¨)
    - [8.3 æ€§èƒ½å½±å“è¯„ä¼°](#83-æ€§èƒ½å½±å“è¯„ä¼°)
  - [ä¹ã€å®æˆ˜æ¡ˆä¾‹](#ä¹å®æˆ˜æ¡ˆä¾‹)
    - [9.1 å®šä½CPUçƒ­ç‚¹](#91-å®šä½cpuçƒ­ç‚¹)
    - [9.2 æ’æŸ¥å†…å­˜æ³„æ¼](#92-æ’æŸ¥å†…å­˜æ³„æ¼)
    - [9.3 ä¼˜åŒ–å‰åå¯¹æ¯”](#93-ä¼˜åŒ–å‰åå¯¹æ¯”)
  - [åã€å¯è§†åŒ–å·¥å…·é›†æˆ](#åå¯è§†åŒ–å·¥å…·é›†æˆ)
    - [10.1 Speedscopeé›†æˆ](#101-speedscopeé›†æˆ)
    - [10.2 Grafana Pyroscopeé›†æˆ](#102-grafana-pyroscopeé›†æˆ)
    - [10.3 Google Perftoolsé›†æˆ](#103-google-perftoolsé›†æˆ)
  - [åä¸€ã€Dockeréƒ¨ç½²](#åä¸€dockeréƒ¨ç½²)
  - [åäºŒã€å‚è€ƒèµ„æº](#åäºŒå‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [å›½é™…æ ‡å‡†](#å›½é™…æ ‡å‡†)
    - [å·¥å…·](#å·¥å…·)
    - [åšå®¢](#åšå®¢)
  - [æ€»ç»“](#æ€»ç»“)

---

## ä¸€ã€æ€§èƒ½åˆ†ææ ¸å¿ƒæ¦‚å¿µ

### 1.1 CPU Profiling

**åŸç†**ï¼šé€šè¿‡å®šæœŸé‡‡æ ·ï¼ˆå¦‚100Hzï¼‰è®°å½•ç¨‹åºè°ƒç”¨æ ˆï¼Œç»Ÿè®¡æ¯ä¸ªå‡½æ•°çš„CPUæ—¶é—´å æ¯”ã€‚

**é‡‡æ ·æ–¹å¼**ï¼š

- **On-CPU Profiling**ï¼šé‡‡æ ·æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹ï¼ˆ99%åœºæ™¯ï¼‰
- **Off-CPU Profiling**ï¼šé‡‡æ ·é˜»å¡çš„çº¿ç¨‹ï¼ˆI/Oå¯†é›†å‹åœºæ™¯ï¼‰

**æŒ‡æ ‡**ï¼š

- **Self Time**ï¼šå‡½æ•°è‡ªèº«æ‰§è¡Œæ—¶é—´ï¼ˆä¸åŒ…æ‹¬è°ƒç”¨çš„å­å‡½æ•°ï¼‰
- **Total Time**ï¼šå‡½æ•°æ€»æ—¶é—´ï¼ˆåŒ…æ‹¬å­å‡½æ•°ï¼‰

**åº”ç”¨åœºæ™¯**ï¼š

- è¯†åˆ«CPUå¯†é›†å‹çƒ­ç‚¹å‡½æ•°
- ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦
- å‘ç°ä¸å¿…è¦çš„è®¡ç®—

### 1.2 Memory Profiling

**åŸç†**ï¼šè·Ÿè¸ªå†…å­˜åˆ†é…å’Œé‡Šæ”¾ï¼Œç»Ÿè®¡å†…å­˜ä½¿ç”¨æƒ…å†µã€‚

**åˆ†æç»´åº¦**ï¼š

- **Allocated Memory**ï¼šå·²åˆ†é…å†…å­˜æ€»é‡
- **In-Use Memory**ï¼šå½“å‰ä½¿ç”¨ä¸­çš„å†…å­˜
- **Allocation Count**ï¼šåˆ†é…æ¬¡æ•°ï¼ˆé¢‘ç¹åˆ†é…å½±å“æ€§èƒ½ï¼‰

**åº”ç”¨åœºæ™¯**ï¼š

- æ£€æµ‹å†…å­˜æ³„æ¼ï¼ˆæœªé‡Šæ”¾çš„å†…å­˜æŒç»­å¢é•¿ï¼‰
- ä¼˜åŒ–å†…å­˜åˆ†é…ç­–ç•¥
- å‡å°‘å †ç¢ç‰‡åŒ–

### 1.3 ç«ç„°å›¾å¯è§†åŒ–

**ç«ç„°å›¾ç‰¹ç‚¹**ï¼š

- **Xè½´**ï¼šæŒ‰å­—æ¯æ’åºï¼ˆä¸ä»£è¡¨æ—¶é—´é¡ºåºï¼‰
- **Yè½´**ï¼šè°ƒç”¨æ ˆæ·±åº¦
- **å®½åº¦**ï¼šCPUæ—¶é—´æˆ–å†…å­˜å æ¯”
- **é¢œè‰²**ï¼šéšæœºæˆ–æ ¹æ®æ¨¡å—åˆ†ç±»

**è§£è¯»æŠ€å·§**ï¼š

- **å¹³é¡¶å±±**ï¼šCPUçƒ­ç‚¹ï¼ˆéœ€ä¼˜åŒ–ï¼‰
- **é«˜å¡”**ï¼šæ·±å±‚è°ƒç”¨æ ˆï¼ˆå¯èƒ½è¿‡åº¦è®¾è®¡ï¼‰
- **å®½åŸº**ï¼šå…¬å…±åŸºç¡€å‡½æ•°

---

## äºŒã€Rustæ€§èƒ½åˆ†æç”Ÿæ€

### 2.1 æ ¸å¿ƒä¾èµ–

```toml
[dependencies]
# CPU Profiling
pprof = { version = "0.14", features = ["flamegraph", "protobuf-codec", "criterion"] }

# HTTPæœåŠ¡å™¨
axum = "0.7"
tokio = { version = "1.42", features = ["full"] }
tower = "0.5"
tower-http = { version = "0.6", features = ["trace"] }

# OpenTelemetryé›†æˆ
opentelemetry = { version = "0.31", features = ["metrics"] }
opentelemetry_sdk = { version = "0.31", features = ["rt-tokio", "metrics"] }
opentelemetry-otlp = { version = "0.31", features = ["metrics", "grpc-tonic"] }
tracing = "0.1"
tracing-subscriber = "0.3"
tracing-opentelemetry = "0.28"

# åºåˆ—åŒ–
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# é”™è¯¯å¤„ç†
anyhow = "1.0"
thiserror = "2.0"

[dev-dependencies]
criterion = { version = "0.6", features = ["html_reports"] }

[profile.release]
debug = true  # ç”Ÿæˆè°ƒè¯•ç¬¦å·ï¼Œç”¨äºæ€§èƒ½åˆ†æ
```

### 2.2 é¡¹ç›®é…ç½®

```bash
mkdir -p pprof-demo/src/{cpu,memory,flamegraph,http}
cd pprof-demo
cargo init
```

**æ³¨æ„**ï¼šç”Ÿäº§ç¯å¢ƒéœ€è¦ä¿ç•™è°ƒè¯•ç¬¦å·ï¼Œä½†å¯ä»¥ä½¿ç”¨`strip = "symbols"`åˆ é™¤ä¸å¿…è¦çš„ç¬¦å·ä»¥å‡å°äºŒè¿›åˆ¶å¤§å°ã€‚

---

## ä¸‰ã€CPUæ€§èƒ½åˆ†æ

### 3.1 åŸºç¡€CPU Profiling

ä½¿ç”¨`pprof`åº“è¿›è¡ŒCPUé‡‡æ ·ï¼š

```rust
// src/cpu/basic.rs
use pprof::ProfilerGuard;
use std::fs::File;
use std::io::Write;

/// æ‰§è¡ŒCPUæ€§èƒ½åˆ†æ
pub fn run_cpu_profiling<F>(sample_frequency: i32, duration_secs: u64, workload: F) -> anyhow::Result<()>
where
    F: FnOnce(),
{
    // å¯åŠ¨é‡‡æ ·å™¨ï¼ˆ100Hz = æ¯10msé‡‡æ ·ä¸€æ¬¡ï¼‰
    let guard = ProfilerGuard::new(sample_frequency)?;

    // æ‰§è¡Œå·¥ä½œè´Ÿè½½
    workload();

    // ç”ŸæˆæŠ¥å‘Š
    if let Ok(report) = guard.report().build() {
        // 1. è¾“å‡ºç«ç„°å›¾SVG
        let file = File::create("flamegraph.svg")?;
        report.flamegraph(file)?;

        // 2. è¾“å‡ºprotobufæ ¼å¼ï¼ˆå…¼å®¹Google Pprofï¼‰
        let mut file = File::create("profile.pb")?;
        let profile = report.pprof()?;
        let mut content = Vec::new();
        profile.write_to_vec(&mut content)?;
        file.write_all(&content)?;

        println!("âœ… CPU profile saved: flamegraph.svg, profile.pb");
    }

    Ok(())
}

/// æ¨¡æ‹ŸCPUå¯†é›†å‹ä»»åŠ¡
fn cpu_intensive_task() {
    let mut sum: u64 = 0;
    for i in 0..10_000_000 {
        sum = sum.wrapping_add(fibonacci(i % 30));
    }
    println!("Sum: {}", sum);
}

fn fibonacci(n: u64) -> u64 {
    match n {
        0 => 0,
        1 => 1,
        _ => fibonacci(n - 1) + fibonacci(n - 2),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cpu_profiling() {
        run_cpu_profiling(100, 10, || {
            cpu_intensive_task();
        })
        .unwrap();
    }
}
```

**ç”Ÿæˆçš„ç«ç„°å›¾ç¤ºä¾‹**ï¼š

```text
                    [main]
                      |
            [cpu_intensive_task]
                      |
         +------------+------------+
         |                         |
    [fibonacci]              [wrapping_add]
      (80%)                      (20%)
```

### 3.2 é‡‡æ ·é¢‘ç‡æ§åˆ¶

ä¸åŒåœºæ™¯é€‰æ‹©ä¸åŒé‡‡æ ·é¢‘ç‡ï¼š

```rust
// src/cpu/sampling_control.rs
use pprof::ProfilerGuardBuilder;
use std::time::Duration;

pub enum SamplingMode {
    /// ä½å¼€é”€æ¨¡å¼ï¼ˆ10Hzï¼Œç”Ÿäº§ç¯å¢ƒï¼‰
    LowOverhead,
    /// æ ‡å‡†æ¨¡å¼ï¼ˆ100Hzï¼Œæµ‹è¯•ç¯å¢ƒï¼‰
    Standard,
    /// é«˜ç²¾åº¦æ¨¡å¼ï¼ˆ1000Hzï¼Œå¼€å‘ç¯å¢ƒï¼‰
    HighPrecision,
}

impl SamplingMode {
    fn frequency(&self) -> i32 {
        match self {
            Self::LowOverhead => 10,
            Self::Standard => 100,
            Self::HighPrecision => 1000,
        }
    }
}

pub fn profile_with_mode<F>(mode: SamplingMode, workload: F) -> anyhow::Result<pprof::Report>
where
    F: FnOnce(),
{
    let guard = ProfilerGuardBuilder::default()
        .frequency(mode.frequency())
        .blocklist(&["libc", "libpthread"]) // å¿½ç•¥ç³»ç»Ÿåº“
        .build()?;

    workload();

    guard.report().build().map_err(|e| anyhow::anyhow!(e))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sampling_modes() {
        // ä½å¼€é”€æ¨¡å¼
        let report = profile_with_mode(SamplingMode::LowOverhead, || {
            std::thread::sleep(Duration::from_secs(1));
        })
        .unwrap();

        println!("Low overhead report: {} samples", report.data.len());

        // é«˜ç²¾åº¦æ¨¡å¼
        let report = profile_with_mode(SamplingMode::HighPrecision, || {
            std::thread::sleep(Duration::from_secs(1));
        })
        .unwrap();

        println!("High precision report: {} samples", report.data.len());
    }
}
```

**æ€§èƒ½å½±å“**ï¼š

- **10Hz**ï¼š< 1% CPUå¼€é”€
- **100Hz**ï¼š< 5% CPUå¼€é”€
- **1000Hz**ï¼š10-20% CPUå¼€é”€

### 3.3 çƒ­ç‚¹å‡½æ•°è¯†åˆ«

åˆ†ææŠ¥å‘Šæ‰¾å‡ºçƒ­ç‚¹å‡½æ•°ï¼š

```rust
// src/cpu/hotspot_analysis.rs
use pprof::Report;
use std::collections::HashMap;

/// åˆ†æçƒ­ç‚¹å‡½æ•°
pub fn analyze_hotspots(report: &Report) -> Vec<(String, u64)> {
    let mut function_times: HashMap<String, u64> = HashMap::new();

    for (frames, count) in &report.data {
        for frame in frames {
            for symbol in &frame.symbols {
                let name = symbol.name().unwrap_or("unknown");
                *function_times.entry(name.to_string()).or_insert(0) += count;
            }
        }
    }

    let mut sorted: Vec<_> = function_times.into_iter().collect();
    sorted.sort_by(|a, b| b.1.cmp(&a.1));

    // è¿”å›Top 10çƒ­ç‚¹
    sorted.into_iter().take(10).collect()
}

pub fn print_hotspots(hotspots: &[(String, u64)]) {
    println!("\nğŸ”¥ Top 10 CPU Hotspots:");
    println!("{:<50} {:<15} {}", "Function", "Samples", "Percentage");
    println!("{:-<80}", "");

    let total_samples: u64 = hotspots.iter().map(|(_, count)| count).sum();

    for (func, count) in hotspots {
        let percentage = (*count as f64 / total_samples as f64) * 100.0;
        println!("{:<50} {:<15} {:.2}%", func, count, percentage);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cpu::sampling_control::{profile_with_mode, SamplingMode};

    #[test]
    fn test_hotspot_analysis() {
        let report = profile_with_mode(SamplingMode::Standard, || {
            // æ¨¡æ‹Ÿä¸åŒå‡½æ•°è°ƒç”¨
            expensive_function_a();
            cheap_function_b();
        })
        .unwrap();

        let hotspots = analyze_hotspots(&report);
        print_hotspots(&hotspots);

        assert!(!hotspots.is_empty());
    }

    fn expensive_function_a() {
        for _ in 0..1_000_000 {
            std::hint::black_box(compute());
        }
    }

    fn cheap_function_b() {
        for _ in 0..100 {
            std::hint::black_box(compute());
        }
    }

    fn compute() -> u64 {
        (0..100).sum()
    }
}
```

---

## å››ã€å†…å­˜æ€§èƒ½åˆ†æ

### 4.1 å †å†…å­˜åˆ†æ

Rustä½¿ç”¨`jemalloc`æˆ–`mimalloc`åˆ†é…å™¨é…åˆ`pprof`ï¼š

```rust
// src/memory/heap_profiling.rs
use pprof::ProfilerGuard;
use std::collections::HashMap;

/// æ¨¡æ‹Ÿå†…å­˜å¯†é›†å‹ä»»åŠ¡
pub fn memory_intensive_task() {
    let mut data: Vec<HashMap<String, Vec<u8>>> = Vec::new();

    // åˆ†é…å¤§é‡å°å¯¹è±¡
    for i in 0..10_000 {
        let mut map = HashMap::new();
        map.insert(
            format!("key_{}", i),
            vec![0u8; 1024], // 1KB per entry
        );
        data.push(map);
    }

    println!("Allocated {} maps", data.len());

    // ä¿æŒå†…å­˜å ç”¨
    std::thread::sleep(std::time::Duration::from_secs(2));
}

/// æ‰§è¡Œå†…å­˜æ€§èƒ½åˆ†æ
pub fn profile_memory<F>(workload: F) -> anyhow::Result<()>
where
    F: FnOnce(),
{
    let guard = ProfilerGuard::new(100)?;

    workload();

    if let Ok(report) = guard.report().build() {
        let file = std::fs::File::create("memory_flamegraph.svg")?;
        report.flamegraph(file)?;

        println!("âœ… Memory profile saved: memory_flamegraph.svg");
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_memory_profiling() {
        profile_memory(|| {
            memory_intensive_task();
        })
        .unwrap();
    }
}
```

**ä½¿ç”¨jemalloc**ï¼ˆæ¨èç”¨äºå†…å­˜åˆ†æï¼‰ï¼š

```toml
# Cargo.toml
[dependencies]
jemallocator = "0.6"

[target.'cfg(not(target_env = "msvc"))'.dependencies]
tikv-jemallocator = "0.6"
```

```rust
// src/main.rs
#[cfg(not(target_env = "msvc"))]
use tikv_jemallocator::Jemalloc;

#[cfg(not(target_env = "msvc"))]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;
```

### 4.2 å†…å­˜æ³„æ¼æ£€æµ‹

æ¨¡æ‹Ÿå†…å­˜æ³„æ¼å¹¶æ£€æµ‹ï¼š

```rust
// src/memory/leak_detection.rs
use std::sync::{Arc, Mutex};

lazy_static::lazy_static! {
    /// å…¨å±€ç¼“å­˜ï¼ˆå¯èƒ½å¯¼è‡´æ³„æ¼ï¼‰
    static ref GLOBAL_CACHE: Arc<Mutex<Vec<Vec<u8>>>> = Arc::new(Mutex::new(Vec::new()));
}

/// æ¨¡æ‹Ÿå†…å­˜æ³„æ¼
pub fn simulate_memory_leak() {
    for _ in 0..1000 {
        let data = vec![0u8; 10_240]; // 10KB
        GLOBAL_CACHE.lock().unwrap().push(data);
    }

    println!(
        "Global cache size: {} entries",
        GLOBAL_CACHE.lock().unwrap().len()
    );
}

/// æ£€æµ‹å†…å­˜æ³„æ¼
pub fn detect_leaks() {
    let initial_size = GLOBAL_CACHE.lock().unwrap().len();

    // æ‰§è¡Œå¤šæ¬¡åˆ†é…
    for _ in 0..5 {
        simulate_memory_leak();
        std::thread::sleep(std::time::Duration::from_secs(1));
    }

    let final_size = GLOBAL_CACHE.lock().unwrap().len();

    if final_size > initial_size {
        println!("âš ï¸  Potential memory leak detected!");
        println!("  Initial: {} entries", initial_size);
        println!("  Final: {} entries", final_size);
        println!("  Growth: {} entries", final_size - initial_size);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_leak_detection() {
        detect_leaks();
    }
}
```

### 4.3 åˆ†é…è¿½è¸ª

è¿½è¸ªå†…å­˜åˆ†é…çƒ­ç‚¹ï¼š

```rust
// src/memory/allocation_tracking.rs
use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicU64, Ordering};

pub struct TrackingAllocator;

static ALLOCATED: AtomicU64 = AtomicU64::new(0);
static DEALLOCATED: AtomicU64 = AtomicU64::new(0);
static ALLOCATION_COUNT: AtomicU64 = AtomicU64::new(0);

unsafe impl GlobalAlloc for TrackingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ptr = System.alloc(layout);
        if !ptr.is_null() {
            ALLOCATED.fetch_add(layout.size() as u64, Ordering::Relaxed);
            ALLOCATION_COUNT.fetch_add(1, Ordering::Relaxed);
        }
        ptr
    }

    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        System.dealloc(ptr, layout);
        DEALLOCATED.fetch_add(layout.size() as u64, Ordering::Relaxed);
    }
}

#[global_allocator]
static ALLOCATOR: TrackingAllocator = TrackingAllocator;

pub fn print_allocation_stats() {
    let allocated = ALLOCATED.load(Ordering::Relaxed);
    let deallocated = DEALLOCATED.load(Ordering::Relaxed);
    let count = ALLOCATION_COUNT.load(Ordering::Relaxed);
    let net = allocated.saturating_sub(deallocated);

    println!("\nğŸ“Š Allocation Statistics:");
    println!("  Total allocated: {} bytes", allocated);
    println!("  Total deallocated: {} bytes", deallocated);
    println!("  Net allocated: {} bytes", net);
    println!("  Allocation count: {}", count);
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_allocation_tracking() {
        let before_count = ALLOCATION_COUNT.load(Ordering::Relaxed);

        // åˆ†é…ä¸€äº›å†…å­˜
        let vec: Vec<u8> = vec![0; 1024];
        drop(vec);

        let after_count = ALLOCATION_COUNT.load(Ordering::Relaxed);

        print_allocation_stats();

        assert!(after_count > before_count);
    }
}
```

---

## äº”ã€ç«ç„°å›¾ç”Ÿæˆ

### 5.1 CPUç«ç„°å›¾

ç”Ÿæˆäº¤äº’å¼ç«ç„°å›¾ï¼š

```rust
// src/flamegraph/cpu_flamegraph.rs
use pprof::protos::Message;
use pprof::Report;
use std::fs::File;
use std::io::Write;

pub fn generate_cpu_flamegraph(report: &Report, output_path: &str) -> anyhow::Result<()> {
    let file = File::create(output_path)?;
    report.flamegraph(file)?;

    println!("âœ… CPU flamegraph saved: {}", output_path);
    Ok(())
}

pub fn generate_pprof_protobuf(report: &Report, output_path: &str) -> anyhow::Result<()> {
    let profile = report.pprof()?;

    let mut buffer = Vec::new();
    profile.write_to_vec(&mut buffer)?;

    let mut file = File::create(output_path)?;
    file.write_all(&buffer)?;

    println!("âœ… Pprof protobuf saved: {}", output_path);
    println!("  View with: go tool pprof -http=:8080 {}", output_path);

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cpu::sampling_control::{profile_with_mode, SamplingMode};

    #[test]
    fn test_generate_flamegraphs() {
        let report = profile_with_mode(SamplingMode::Standard, || {
            expensive_computation();
        })
        .unwrap();

        generate_cpu_flamegraph(&report, "test_cpu.svg").unwrap();
        generate_pprof_protobuf(&report, "test_cpu.pb").unwrap();
    }

    fn expensive_computation() {
        let mut sum = 0u64;
        for i in 0..5_000_000 {
            sum = sum.wrapping_add(i * 2);
        }
        std::hint::black_box(sum);
    }
}
```

### 5.2 å†…å­˜ç«ç„°å›¾

ç”Ÿæˆå†…å­˜åˆ†é…ç«ç„°å›¾ï¼š

```rust
// src/flamegraph/memory_flamegraph.rs
use pprof::Report;
use std::fs::File;

pub fn generate_memory_flamegraph(report: &Report, output_path: &str) -> anyhow::Result<()> {
    let file = File::create(output_path)?;

    // ä½¿ç”¨åå‘ç«ç„°å›¾ï¼ˆä»åˆ†é…ç‚¹å‘ä¸Šå±•ç¤ºè°ƒç”¨æ ˆï¼‰
    report.flamegraph(file)?;

    println!("âœ… Memory flamegraph saved: {}", output_path);
    println!("  Red areas = high memory allocation");

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cpu::sampling_control::{profile_with_mode, SamplingMode};

    #[test]
    fn test_memory_flamegraph() {
        let report = profile_with_mode(SamplingMode::Standard, || {
            allocate_heavy();
            allocate_light();
        })
        .unwrap();

        generate_memory_flamegraph(&report, "test_memory.svg").unwrap();
    }

    fn allocate_heavy() {
        let _data: Vec<Vec<u8>> = (0..1000).map(|_| vec![0u8; 10_240]).collect();
    }

    fn allocate_light() {
        let _data: Vec<u8> = vec![0u8; 1024];
    }
}
```

### 5.3 å·®å¼‚ç«ç„°å›¾

å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ€§èƒ½å·®å¼‚ï¼š

```rust
// src/flamegraph/diff_flamegraph.rs
use pprof::Report;

pub fn generate_diff_report(
    before: &Report,
    after: &Report,
) -> anyhow::Result<()> {
    // æå–æ ·æœ¬æ•°æ®
    let before_samples: u64 = before.data.values().sum();
    let after_samples: u64 = after.data.values().sum();

    let improvement = (before_samples as f64 - after_samples as f64) / before_samples as f64 * 100.0;

    println!("\nğŸ“Š Performance Comparison:");
    println!("  Before: {} samples", before_samples);
    println!("  After: {} samples", after_samples);
    println!("  Improvement: {:.2}%", improvement);

    // ç”Ÿæˆç‹¬ç«‹ç«ç„°å›¾
    let before_file = std::fs::File::create("before.svg")?;
    before.flamegraph(before_file)?;

    let after_file = std::fs::File::create("after.svg")?;
    after.flamegraph(after_file)?;

    println!("âœ… Diff flamegraphs saved: before.svg, after.svg");

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cpu::sampling_control::{profile_with_mode, SamplingMode};

    #[test]
    fn test_diff_flamegraph() {
        // ä¼˜åŒ–å‰
        let before = profile_with_mode(SamplingMode::Standard, || {
            slow_function();
        })
        .unwrap();

        // ä¼˜åŒ–å
        let after = profile_with_mode(SamplingMode::Standard, || {
            optimized_function();
        })
        .unwrap();

        generate_diff_report(&before, &after).unwrap();
    }

    fn slow_function() {
        for _ in 0..1_000_000 {
            std::hint::black_box(expensive_operation());
        }
    }

    fn optimized_function() {
        for _ in 0..1_000_000 {
            std::hint::black_box(cheap_operation());
        }
    }

    fn expensive_operation() -> u64 {
        (0..100).sum()
    }

    fn cheap_operation() -> u64 {
        42
    }
}
```

---

## å…­ã€HTTPç«¯ç‚¹é›†æˆ

### 6.1 Pprof HTTPæœåŠ¡å™¨

åˆ›å»ºHTTPç«¯ç‚¹æš´éœ²æ€§èƒ½æ•°æ®ï¼š

```rust
// src/http/pprof_server.rs
use axum::{
    extract::Query,
    http::StatusCode,
    response::{IntoResponse, Response},
    routing::get,
    Router,
};
use pprof::ProfilerGuardBuilder;
use serde::Deserialize;
use std::net::SocketAddr;
use std::time::Duration;

#[derive(Debug, Deserialize)]
struct ProfileParams {
    #[serde(default = "default_duration")]
    seconds: u64,
    #[serde(default = "default_frequency")]
    frequency: i32,
}

fn default_duration() -> u64 {
    30
}

fn default_frequency() -> i32 {
    100
}

/// CPU Profileç«¯ç‚¹
async fn cpu_profile_handler(Query(params): Query<ProfileParams>) -> Response {
    let guard = match ProfilerGuardBuilder::default()
        .frequency(params.frequency)
        .blocklist(&["libc", "libpthread"])
        .build()
    {
        Ok(g) => g,
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("Failed to start profiler: {}", e),
            )
                .into_response()
        }
    };

    // é‡‡æ ·æŒ‡å®šæ—¶é—´
    tokio::time::sleep(Duration::from_secs(params.seconds)).await;

    match guard.report().build() {
        Ok(report) => {
            let mut buffer = Vec::new();
            if let Ok(profile) = report.pprof() {
                use pprof::protos::Message;
                if profile.write_to_vec(&mut buffer).is_ok() {
                    return (
                        StatusCode::OK,
                        [("Content-Type", "application/octet-stream")],
                        buffer,
                    )
                        .into_response();
                }
            }

            (
                StatusCode::INTERNAL_SERVER_ERROR,
                "Failed to generate profile",
            )
                .into_response()
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("Failed to build report: {}", e),
        )
            .into_response(),
    }
}

/// ç«ç„°å›¾ç«¯ç‚¹
async fn flamegraph_handler(Query(params): Query<ProfileParams>) -> Response {
    let guard = match ProfilerGuardBuilder::default()
        .frequency(params.frequency)
        .build()
    {
        Ok(g) => g,
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("Failed to start profiler: {}", e),
            )
                .into_response()
        }
    };

    tokio::time::sleep(Duration::from_secs(params.seconds)).await;

    match guard.report().build() {
        Ok(report) => {
            let mut buffer = Vec::new();
            if report.flamegraph(&mut buffer).is_ok() {
                return (StatusCode::OK, [("Content-Type", "image/svg+xml")], buffer)
                    .into_response();
            }

            (
                StatusCode::INTERNAL_SERVER_ERROR,
                "Failed to generate flamegraph",
            )
                .into_response()
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("Failed to build report: {}", e),
        )
            .into_response(),
    }
}

/// å¯åŠ¨Pprof HTTPæœåŠ¡å™¨
pub async fn start_pprof_server(addr: SocketAddr) {
    let app = Router::new()
        .route("/debug/pprof/profile", get(cpu_profile_handler))
        .route("/debug/pprof/flamegraph", get(flamegraph_handler));

    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    tracing::info!("Pprof server listening on {}", addr);
    tracing::info!("  CPU Profile: http://{}/debug/pprof/profile?seconds=30", addr);
    tracing::info!("  Flamegraph: http://{}/debug/pprof/flamegraph?seconds=10", addr);

    axum::serve(listener, app).await.unwrap();
}
```

### 6.2 ä¸Axumé›†æˆ

å°†Pprofé›†æˆåˆ°ç°æœ‰Axumåº”ç”¨ï¼š

```rust
// src/http/axum_integration.rs
use axum::{
    extract::State,
    http::StatusCode,
    response::IntoResponse,
    routing::{get, post},
    Json, Router,
};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::sync::Arc;

#[derive(Clone)]
struct AppState {
    // åº”ç”¨çŠ¶æ€
}

#[derive(Debug, Serialize, Deserialize)]
struct CreateOrderRequest {
    product_id: u64,
    quantity: u32,
}

#[derive(Debug, Serialize)]
struct CreateOrderResponse {
    order_id: u64,
}

async fn create_order(
    State(_state): State<Arc<AppState>>,
    Json(payload): Json<CreateOrderRequest>,
) -> Result<Json<CreateOrderResponse>, StatusCode> {
    // æ¨¡æ‹Ÿä¸šåŠ¡é€»è¾‘
    tokio::time::sleep(std::time::Duration::from_millis(50)).await;

    Ok(Json(CreateOrderResponse { order_id: 12345 }))
}

async fn list_orders() -> impl IntoResponse {
    Json(vec!["order1", "order2"])
}

pub async fn start_app_with_pprof(addr: SocketAddr, pprof_addr: SocketAddr) {
    let state = Arc::new(AppState {});

    // ä¸šåŠ¡è·¯ç”±
    let app = Router::new()
        .route("/api/orders", post(create_order).get(list_orders))
        .with_state(state);

    // å¯åŠ¨ä¸šåŠ¡æœåŠ¡å™¨
    let app_listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    tracing::info!("App server listening on {}", addr);

    tokio::spawn(async move {
        axum::serve(app_listener, app).await.unwrap();
    });

    // å¯åŠ¨PprofæœåŠ¡å™¨ï¼ˆç‹¬ç«‹ç«¯å£ï¼‰
    crate::http::pprof_server::start_pprof_server(pprof_addr).await;
}
```

### 6.3 åŠ¨æ€é‡‡æ ·æ§åˆ¶

é€šè¿‡HTTP APIåŠ¨æ€å¯åŠ¨/åœæ­¢é‡‡æ ·ï¼š

```rust
// src/http/dynamic_sampling.rs
use axum::{
    extract::State,
    http::StatusCode,
    response::IntoResponse,
    routing::{get, post},
    Json, Router,
};
use pprof::ProfilerGuard;
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};

#[derive(Clone)]
struct SamplingState {
    guard: Arc<Mutex<Option<ProfilerGuard<'static>>>>,
}

#[derive(Debug, Deserialize)]
struct StartSamplingRequest {
    frequency: i32,
}

#[derive(Debug, Serialize)]
struct SamplingResponse {
    status: String,
    message: String,
}

async fn start_sampling(
    State(state): State<SamplingState>,
    Json(payload): Json<StartSamplingRequest>,
) -> impl IntoResponse {
    let mut guard_lock = state.guard.lock().unwrap();

    if guard_lock.is_some() {
        return (
            StatusCode::CONFLICT,
            Json(SamplingResponse {
                status: "error".to_string(),
                message: "Sampling already in progress".to_string(),
            }),
        );
    }

    match ProfilerGuard::new(payload.frequency) {
        Ok(guard) => {
            *guard_lock = Some(guard);
            (
                StatusCode::OK,
                Json(SamplingResponse {
                    status: "success".to_string(),
                    message: format!("Sampling started at {}Hz", payload.frequency),
                }),
            )
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(SamplingResponse {
                status: "error".to_string(),
                message: format!("Failed to start sampling: {}", e),
            }),
        ),
    }
}

async fn stop_sampling(State(state): State<SamplingState>) -> impl IntoResponse {
    let mut guard_lock = state.guard.lock().unwrap();

    if let Some(guard) = guard_lock.take() {
        match guard.report().build() {
            Ok(report) => {
                let mut buffer = Vec::new();
                if report.flamegraph(&mut buffer).is_ok() {
                    return (StatusCode::OK, [("Content-Type", "image/svg+xml")], buffer)
                        .into_response();
                }
            }
            Err(e) => {
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    format!("Failed to build report: {}", e),
                )
                    .into_response()
            }
        }
    }

    (StatusCode::NOT_FOUND, "No active sampling").into_response()
}

pub fn create_router() -> Router {
    let state = SamplingState {
        guard: Arc::new(Mutex::new(None)),
    };

    Router::new()
        .route("/sampling/start", post(start_sampling))
        .route("/sampling/stop", get(stop_sampling))
        .with_state(state)
}
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```bash
# å¯åŠ¨é‡‡æ ·
curl -X POST http://localhost:8080/sampling/start \
  -H "Content-Type: application/json" \
  -d '{"frequency": 100}'

# æ‰§è¡Œä¸šåŠ¡æ“ä½œ...

# åœæ­¢é‡‡æ ·å¹¶è·å–ç«ç„°å›¾
curl http://localhost:8080/sampling/stop > flamegraph.svg
```

---

## ä¸ƒã€OTLPé›†æˆ

### 7.1 æ€§èƒ½æŒ‡æ ‡å¯¼å‡º

å°†æ€§èƒ½åˆ†æç»“æœä½œä¸ºæŒ‡æ ‡å¯¼å‡ºåˆ°OTLPï¼š

```rust
// src/otel/metrics_export.rs
use opentelemetry::{global, KeyValue};
use pprof::Report;

pub fn export_profiling_metrics(report: &Report) {
    let meter = global::meter("profiling-metrics");

    // é‡‡æ ·æ€»æ•°
    let total_samples: u64 = report.data.values().sum();
    let sample_counter = meter
        .u64_counter("profiling_samples_total")
        .with_description("Total profiling samples collected")
        .build();

    sample_counter.add(total_samples, &[]);

    // Topå‡½æ•°CPUæ—¶é—´
    let cpu_time_gauge = meter
        .f64_observable_gauge("profiling_function_cpu_time_ratio")
        .with_description("CPU time ratio by function")
        .with_callback(move |observer| {
            // è¿™é‡Œåº”è¯¥ä»reportä¸­æå–Topå‡½æ•°æ•°æ®
            observer.observe(0.35, &[KeyValue::new("function", "hot_function")]);
        })
        .build();

    tracing::info!("Exported profiling metrics to OTLP");
}
```

### 7.2 è¿½è¸ªä¸æ€§èƒ½å…³è”

åœ¨è¿½è¸ªSpanä¸­åµŒå…¥æ€§èƒ½æ•°æ®ï¼š

```rust
// src/otel/tracing_correlation.rs
use opentelemetry::trace::TraceContextExt;
use pprof::ProfilerGuard;
use tracing::{info_span, Span};
use tracing_opentelemetry::OpenTelemetrySpanExt;

pub async fn traced_expensive_operation() {
    let span = info_span!("expensive_operation");
    let _enter = span.enter();

    // åœ¨Spanå†…å¯åŠ¨æ€§èƒ½åˆ†æ
    let guard = ProfilerGuard::new(100).unwrap();

    // æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    expensive_computation();

    // ç”ŸæˆæŠ¥å‘Š
    if let Ok(report) = guard.report().build() {
        let total_samples: u64 = report.data.values().sum();

        // å°†æ€§èƒ½æ•°æ®æ·»åŠ åˆ°Spanå±æ€§
        Span::current().set_attribute("profiling.samples", total_samples as i64);
        Span::current().set_attribute("profiling.hotspot", "expensive_computation");

        tracing::info!(samples = total_samples, "Performance profiling completed");
    }
}

fn expensive_computation() {
    std::thread::sleep(std::time::Duration::from_millis(500));
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_traced_profiling() {
        traced_expensive_operation().await;
    }
}
```

### 7.3 åˆ†å¸ƒå¼æ€§èƒ½åˆ†æ

è·¨æœåŠ¡å…³è”æ€§èƒ½æ•°æ®ï¼š

```rust
// src/otel/distributed_profiling.rs
use opentelemetry::{global, trace::{Span, Tracer}, KeyValue};
use pprof::Report;

pub fn profile_distributed_request(service_name: &str, operation: &str, report: &Report) {
    let tracer = global::tracer("distributed-profiling");

    let mut span = tracer
        .span_builder(format!("profile:{}", operation))
        .with_attributes(vec![
            KeyValue::new("service.name", service_name.to_string()),
            KeyValue::new("profiling.operation", operation.to_string()),
        ])
        .start(&tracer);

    // æ·»åŠ æ€§èƒ½æŒ‡æ ‡
    let total_samples: u64 = report.data.values().sum();
    span.set_attribute("profiling.samples", total_samples as i64);

    // å¯¼å‡ºåˆ°OTLP
    span.end();

    tracing::info!(
        service = service_name,
        operation = operation,
        samples = total_samples,
        "Distributed profiling data exported"
    );
}
```

---

## å…«ã€ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

### 8.1 ä½å¼€é”€é‡‡æ ·

ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ä½é¢‘é‡‡æ ·ï¼š

```rust
// src/production/low_overhead.rs
use pprof::ProfilerGuardBuilder;
use std::time::Duration;

pub struct ProductionProfiler {
    frequency: i32,
    duration: Duration,
}

impl ProductionProfiler {
    pub fn new() -> Self {
        Self {
            frequency: 10,  // 10Hzï¼Œ< 1% CPU overhead
            duration: Duration::from_secs(60),
        }
    }

    pub async fn profile_periodically<F>(&self, workload: F)
    where
        F: Fn() + Send + 'static,
    {
        loop {
            tracing::info!("Starting periodic profiling");

            let guard = ProfilerGuardBuilder::default()
                .frequency(self.frequency)
                .blocklist(&["libc", "libpthread", "ld-linux"])
                .build()
                .unwrap();

            tokio::time::sleep(self.duration).await;

            if let Ok(report) = guard.report().build() {
                // å¼‚æ­¥ä¿å­˜åˆ°S3æˆ–æœ¬åœ°
                self.save_report(&report).await;
            }

            // é—´éš”5åˆ†é’Ÿå†æ¬¡é‡‡æ ·
            tokio::time::sleep(Duration::from_secs(300)).await;
        }
    }

    async fn save_report(&self, report: &pprof::Report) {
        let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
        let filename = format!("profile_{}.svg", timestamp);

        if let Ok(file) = std::fs::File::create(&filename) {
            let _ = report.flamegraph(file);
            tracing::info!(file = %filename, "Profile saved");
        }
    }
}
```

### 8.2 æŒ‰éœ€å¯ç”¨

é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ§åˆ¶ï¼š

```rust
// src/production/conditional_profiling.rs
use std::env;

pub fn is_profiling_enabled() -> bool {
    env::var("ENABLE_PROFILING")
        .unwrap_or_else(|_| "false".to_string())
        .parse()
        .unwrap_or(false)
}

pub async fn maybe_profile<F, T>(name: &str, f: F) -> T
where
    F: FnOnce() -> T,
{
    if is_profiling_enabled() {
        tracing::info!(operation = name, "Profiling enabled");

        let guard = pprof::ProfilerGuard::new(10).ok();

        let result = f();

        if let Some(g) = guard {
            if let Ok(report) = g.report().build() {
                let filename = format!("{}_profile.svg", name);
                if let Ok(file) = std::fs::File::create(&filename) {
                    let _ = report.flamegraph(file);
                }
            }
        }

        result
    } else {
        f()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_conditional_profiling() {
        env::set_var("ENABLE_PROFILING", "true");

        let result = maybe_profile("test_operation", || {
            std::thread::sleep(std::time::Duration::from_millis(100));
            42
        }).await;

        assert_eq!(result, 42);
    }
}
```

### 8.3 æ€§èƒ½å½±å“è¯„ä¼°

è¯„ä¼°æ€§èƒ½åˆ†æå¯¹åº”ç”¨çš„å½±å“ï¼š

```rust
// src/production/overhead_measurement.rs
use std::time::Instant;

pub fn measure_profiling_overhead<F>(f: F) -> (std::time::Duration, std::time::Duration)
where
    F: Fn(),
{
    // æ— æ€§èƒ½åˆ†æåŸºå‡†
    let start_baseline = Instant::now();
    f();
    let baseline_duration = start_baseline.elapsed();

    // æœ‰æ€§èƒ½åˆ†æ
    let guard = pprof::ProfilerGuard::new(100).unwrap();
    let start_profiled = Instant::now();
    f();
    let profiled_duration = start_profiled.elapsed();
    drop(guard);

    let overhead = profiled_duration.saturating_sub(baseline_duration);
    let overhead_percent = (overhead.as_secs_f64() / baseline_duration.as_secs_f64()) * 100.0;

    println!("\nğŸ“Š Profiling Overhead:");
    println!("  Baseline: {:?}", baseline_duration);
    println!("  With profiling: {:?}", profiled_duration);
    println!("  Overhead: {:?} ({:.2}%)", overhead, overhead_percent);

    (baseline_duration, profiled_duration)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_overhead_measurement() {
        measure_profiling_overhead(|| {
            std::thread::sleep(std::time::Duration::from_secs(1));
        });
    }
}
```

---

## ä¹ã€å®æˆ˜æ¡ˆä¾‹

### 9.1 å®šä½CPUçƒ­ç‚¹

å®Œæ•´æ¡ˆä¾‹ï¼šä¼˜åŒ–JSONåºåˆ—åŒ–ï¼š

```rust
// src/cases/cpu_hotspot.rs
use serde::{Deserialize, Serialize};
use pprof::ProfilerGuard;

#[derive(Debug, Serialize, Deserialize)]
struct User {
    id: u64,
    name: String,
    email: String,
    tags: Vec<String>,
}

/// æ…¢ç‰ˆæœ¬ï¼šé¢‘ç¹åºåˆ—åŒ–
fn slow_json_processing() {
    for i in 0..10_000 {
        let user = User {
            id: i,
            name: format!("user_{}", i),
            email: format!("user{}@example.com", i),
            tags: vec!["tag1".to_string(), "tag2".to_string()],
        };

        let _json = serde_json::to_string(&user).unwrap();
        let _: User = serde_json::from_str(&_json).unwrap();
    }
}

/// å¿«ç‰ˆæœ¬ï¼šæ‰¹é‡åºåˆ—åŒ–
fn fast_json_processing() {
    let users: Vec<User> = (0..10_000)
        .map(|i| User {
            id: i,
            name: format!("user_{}", i),
            email: format!("user{}@example.com", i),
            tags: vec!["tag1".to_string(), "tag2".to_string()],
        })
        .collect();

    let _json = serde_json::to_string(&users).unwrap();
    let _: Vec<User> = serde_json::from_str(&_json).unwrap();
}

pub fn compare_json_performance() {
    // Profileæ…¢ç‰ˆæœ¬
    let guard = ProfilerGuard::new(100).unwrap();
    slow_json_processing();
    let slow_report = guard.report().build().unwrap();

    let slow_file = std::fs::File::create("slow_json.svg").unwrap();
    slow_report.flamegraph(slow_file).unwrap();

    // Profileå¿«ç‰ˆæœ¬
    let guard = ProfilerGuard::new(100).unwrap();
    fast_json_processing();
    let fast_report = guard.report().build().unwrap();

    let fast_file = std::fs::File::create("fast_json.svg").unwrap();
    fast_report.flamegraph(fast_file).unwrap();

    println!("âœ… Comparison complete: slow_json.svg vs fast_json.svg");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_json_optimization() {
        compare_json_performance();
    }
}
```

### 9.2 æ’æŸ¥å†…å­˜æ³„æ¼

æ¨¡æ‹Ÿå¹¶æ£€æµ‹å†…å­˜æ³„æ¼ï¼š

```rust
// src/cases/memory_leak.rs
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

lazy_static::lazy_static! {
    static ref SESSION_CACHE: Arc<Mutex<HashMap<String, Vec<u8>>>> =
        Arc::new(Mutex::new(HashMap::new()));
}

/// æœ‰æ³„æ¼çš„ä¼šè¯ç®¡ç†
fn leaky_session_manager() {
    for i in 0..1_000 {
        let session_id = format!("session_{}", i);
        let session_data = vec![0u8; 10_240]; // 10KB per session

        // æ·»åŠ åˆ°ç¼“å­˜ï¼Œä½†ä»ä¸æ¸…ç†
        SESSION_CACHE.lock().unwrap().insert(session_id, session_data);
    }

    println!("Session cache size: {}", SESSION_CACHE.lock().unwrap().len());
}

/// ä¿®å¤åçš„ç‰ˆæœ¬ï¼ˆLRUç¼“å­˜ï¼‰
struct LruSessionCache {
    cache: lru::LruCache<String, Vec<u8>>,
}

impl LruSessionCache {
    fn new(capacity: usize) -> Self {
        Self {
            cache: lru::LruCache::new(std::num::NonZeroUsize::new(capacity).unwrap()),
        }
    }

    fn insert(&mut self, key: String, value: Vec<u8>) {
        self.cache.put(key, value);
    }
}

pub fn detect_and_fix_leak() {
    println!("\nğŸ” Detecting memory leak...");

    // æ³„æ¼ç‰ˆæœ¬
    let guard = pprof::ProfilerGuard::new(100).unwrap();
    leaky_session_manager();
    let leak_report = guard.report().build().unwrap();

    let leak_file = std::fs::File::create("leak_memory.svg").unwrap();
    leak_report.flamegraph(leak_file).unwrap();

    println!("âœ… Leak profile saved: leak_memory.svg");

    // ä¿®å¤å
    let mut fixed_cache = LruSessionCache::new(100); // é™åˆ¶100ä¸ªsession
    for i in 0..1_000 {
        let session_id = format!("session_{}", i);
        let session_data = vec![0u8; 10_240];
        fixed_cache.insert(session_id, session_data);
    }

    println!("âœ… Fixed: LRU cache limits memory usage");
}
```

### 9.3 ä¼˜åŒ–å‰åå¯¹æ¯”

æ ‡å‡†åŒ–æ€§èƒ½ä¼˜åŒ–æµç¨‹ï¼š

```rust
// src/cases/optimization_workflow.rs
use std::time::{Duration, Instant};
use pprof::Report;

pub struct OptimizationResult {
    pub before_duration: Duration,
    pub after_duration: Duration,
    pub improvement_percent: f64,
}

pub fn benchmark_optimization<F1, F2>(
    name: &str,
    before: F1,
    after: F2,
) -> OptimizationResult
where
    F1: Fn(),
    F2: Fn(),
{
    println!("\nğŸš€ Optimizing: {}", name);

    // ä¼˜åŒ–å‰
    let start = Instant::now();
    before();
    let before_duration = start.elapsed();

    let guard = pprof::ProfilerGuard::new(100).unwrap();
    before();
    let before_report = guard.report().build().unwrap();
    save_report(&before_report, &format!("{}_before.svg", name));

    // ä¼˜åŒ–å
    let start = Instant::now();
    after();
    let after_duration = start.elapsed();

    let guard = pprof::ProfilerGuard::new(100).unwrap();
    after();
    let after_report = guard.report().build().unwrap();
    save_report(&after_report, &format!("{}_after.svg", name));

    let improvement_percent =
        (before_duration.as_secs_f64() - after_duration.as_secs_f64())
            / before_duration.as_secs_f64()
            * 100.0;

    println!("  Before: {:?}", before_duration);
    println!("  After: {:?}", after_duration);
    println!("  Improvement: {:.2}%", improvement_percent);

    OptimizationResult {
        before_duration,
        after_duration,
        improvement_percent,
    }
}

fn save_report(report: &Report, filename: &str) {
    if let Ok(file) = std::fs::File::create(filename) {
        let _ = report.flamegraph(file);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_optimization_workflow() {
        let result = benchmark_optimization(
            "string_concatenation",
            || {
                // æ…¢ç‰ˆæœ¬
                let mut s = String::new();
                for i in 0..10_000 {
                    s = format!("{}{}", s, i);
                }
            },
            || {
                // å¿«ç‰ˆæœ¬
                let mut s = String::with_capacity(50_000);
                for i in 0..10_000 {
                    use std::fmt::Write;
                    write!(&mut s, "{}", i).unwrap();
                }
            },
        );

        assert!(result.improvement_percent > 50.0);
    }
}
```

---

## åã€å¯è§†åŒ–å·¥å…·é›†æˆ

### 10.1 Speedscopeé›†æˆ

ç”ŸæˆSpeedscopeå…¼å®¹æ ¼å¼ï¼š

```rust
// src/visualization/speedscope.rs
use pprof::Report;
use std::fs::File;
use std::io::Write;

pub fn export_to_speedscope(report: &Report, output_path: &str) -> anyhow::Result<()> {
    let profile = report.pprof()?;

    let mut buffer = Vec::new();
    use pprof::protos::Message;
    profile.write_to_vec(&mut buffer)?;

    let mut file = File::create(output_path)?;
    file.write_all(&buffer)?;

    println!("âœ… Speedscope profile saved: {}", output_path);
    println!("  View at: https://www.speedscope.app/");
    println!("  Or: speedscope {}", output_path);

    Ok(())
}
```

### 10.2 Grafana Pyroscopeé›†æˆ

é›†æˆPyroscopeè¿›è¡Œè¿ç»­æ€§èƒ½åˆ†æï¼š

```rust
// src/visualization/pyroscope.rs
use pprof::Report;
use reqwest::Client;

pub async fn push_to_pyroscope(
    report: &Report,
    pyroscope_url: &str,
    app_name: &str,
) -> anyhow::Result<()> {
    let profile = report.pprof()?;

    let mut buffer = Vec::new();
    use pprof::protos::Message;
    profile.write_to_vec(&mut buffer)?;

    let client = Client::new();
    let url = format!("{}/ingest", pyroscope_url);

    client
        .post(&url)
        .header("Content-Type", "application/octet-stream")
        .query(&[("name", app_name)])
        .body(buffer)
        .send()
        .await?;

    tracing::info!("âœ… Profile pushed to Pyroscope: {}", pyroscope_url);

    Ok(())
}
```

### 10.3 Google Perftoolsé›†æˆ

ä½¿ç”¨`go tool pprof`åˆ†æï¼š

```bash
# ç”Ÿæˆprotobufæ ¼å¼
cargo test --release

# ä½¿ç”¨Goå·¥å…·åˆ†æ
go tool pprof -http=:8080 profile.pb

# æˆ–å‘½ä»¤è¡Œåˆ†æ
go tool pprof profile.pb
> top10
> list hot_function
> web  # ç”Ÿæˆè°ƒç”¨å›¾
```

---

## åä¸€ã€Dockeréƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"    # åº”ç”¨ç«¯å£
      - "8080:8080"    # Pprofç«¯å£
    environment:
      - RUST_LOG=info
      - ENABLE_PROFILING=true
    volumes:
      - ./profiles:/app/profiles  # ä¿å­˜æ€§èƒ½æ•°æ®

  pyroscope:
    image: grafana/pyroscope:latest
    ports:
      - "4040:4040"
    environment:
      - PYROSCOPE_LOG_LEVEL=debug

  grafana:
    image: grafana/grafana:11.4.0
    ports:
      - "3001:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  grafana_data:
```

**Dockerfile**ï¼š

```dockerfile
FROM rust:1.90 AS builder

WORKDIR /app
COPY Cargo.toml Cargo.lock ./
COPY src ./src

# ä¿ç•™è°ƒè¯•ç¬¦å·
RUN cargo build --release

FROM ubuntu:24.04

RUN apt-get update && apt-get install -y \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY --from=builder /app/target/release/pprof-demo .

EXPOSE 3000 8080

CMD ["./pprof-demo"]
```

---

## åäºŒã€å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

1. **pprofåº“æ–‡æ¡£**: <https://docs.rs/pprof/>
2. **Google Pprof**: <https://github.com/google/pprof>
3. **Flame Graphs**: <https://www.brendangregg.com/flamegraphs.html>

### å›½é™…æ ‡å‡†

1. **Continuous Profiling**: <https://www.cncf.io/blog/2022/05/31/what-is-continuous-profiling/>
2. **Profiling Best Practices** (Google): <https://cloud.google.com/profiler/docs/best-practices>

### å·¥å…·

1. **Speedscope**: <https://www.speedscope.app/>
2. **Grafana Pyroscope**: <https://grafana.com/oss/pyroscope/>
3. **Criterion.rs**: <https://github.com/bheisler/criterion.rs>

### åšå®¢

1. **Profiling Rust Applications** (Datadog): <https://www.datadoghq.com/blog/rust-profiling/>
2. **Rust Performance Book**: <https://nnethercote.github.io/perf-book/>

---

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†Rust 1.90ä¸­Pprofæ€§èƒ½åˆ†æçš„å®Œæ•´æŒ‡å—ï¼Œæ¶µç›–ï¼š

âœ… **CPU/å†…å­˜åˆ†æ**ï¼šé‡‡æ ·ã€çƒ­ç‚¹è¯†åˆ«ã€å†…å­˜æ³„æ¼æ£€æµ‹  
âœ… **ç«ç„°å›¾ç”Ÿæˆ**ï¼šSVGã€Protobufã€å·®å¼‚ç«ç„°å›¾  
âœ… **HTTPç«¯ç‚¹**ï¼šåŠ¨æ€é‡‡æ ·ã€Axumé›†æˆ  
âœ… **OTLPé›†æˆ**ï¼šæŒ‡æ ‡å¯¼å‡ºã€è¿½è¸ªå…³è”  
âœ… **ç”Ÿäº§ä¼˜åŒ–**ï¼šä½å¼€é”€é‡‡æ ·ã€æŒ‰éœ€å¯ç”¨ã€æ€§èƒ½å½±å“è¯„ä¼°  
âœ… **å®æˆ˜æ¡ˆä¾‹**ï¼šCPUçƒ­ç‚¹ä¼˜åŒ–ã€å†…å­˜æ³„æ¼æ’æŸ¥  
âœ… **å¯è§†åŒ–å·¥å…·**ï¼šSpeedscopeã€Pyroscopeã€Google Pprof  

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

- éµå¾ªGoogle Pprofæ ‡å‡†ï¼Œå…¼å®¹ç”Ÿæ€å·¥å…·
- ç”Ÿäº§ç¯å¢ƒå‹å¥½ï¼ˆ< 1% CPUå¼€é”€@10Hzï¼‰
- å®Œæ•´çš„å¯è§†åŒ–å’Œåˆ†æå·¥å…·é“¾
- ä¸OpenTelemetryæ·±åº¦é›†æˆ

**ä¸‹ä¸€æ­¥**ï¼š

- æ¢ç´¢`tracing-appender`è¿›è¡Œæ—¥å¿—ç®¡ç†
- å­¦ä¹ `opentelemetry-rust`é«˜çº§ç‰¹æ€§
- é›†æˆAPMå¹³å°ï¼ˆDatadogã€New Relicï¼‰
