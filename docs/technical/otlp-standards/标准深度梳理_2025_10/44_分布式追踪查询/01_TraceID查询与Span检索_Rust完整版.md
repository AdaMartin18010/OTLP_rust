# TraceID æŸ¥è¯¢ä¸ Span æ£€ç´¢ - Rust å®Œæ•´å®ç°

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **Rust ç‰ˆæœ¬**: 1.90+  
> **æœ€åæ›´æ–°**: 2025-10-10

---

## ğŸ“‹ ç›®å½•

- [TraceID æŸ¥è¯¢ä¸ Span æ£€ç´¢ - Rust å®Œæ•´å®ç°](#traceid-æŸ¥è¯¢ä¸-span-æ£€ç´¢---rust-å®Œæ•´å®ç°)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ¯ æ¦‚è¿°](#-æ¦‚è¿°)
    - [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
    - [æŠ€æœ¯æŒ‘æˆ˜](#æŠ€æœ¯æŒ‘æˆ˜)
  - [ğŸ” TraceID ç²¾ç¡®æŸ¥è¯¢](#-traceid-ç²¾ç¡®æŸ¥è¯¢)
    - [1. TraceID æŸ¥è¯¢å™¨](#1-traceid-æŸ¥è¯¢å™¨)
    - [2. åˆ†åŒºå®šä½å™¨](#2-åˆ†åŒºå®šä½å™¨)
    - [3. å¹¶è¡ŒæŸ¥è¯¢æ‰§è¡Œå™¨](#3-å¹¶è¡ŒæŸ¥è¯¢æ‰§è¡Œå™¨)
  - [ğŸ“Š Span å±æ€§æ£€ç´¢](#-span-å±æ€§æ£€ç´¢)
    - [1. Span è¿‡æ»¤å™¨](#1-span-è¿‡æ»¤å™¨)
    - [2. å±æ€§ç´¢å¼•æŸ¥è¯¢](#2-å±æ€§ç´¢å¼•æŸ¥è¯¢)
    - [3. å¤åˆæ¡ä»¶æŸ¥è¯¢](#3-å¤åˆæ¡ä»¶æŸ¥è¯¢)
  - [ğŸ”— Span å…³è”æŸ¥è¯¢](#-span-å…³è”æŸ¥è¯¢)
    - [1. çˆ¶å­å…³ç³»æŸ¥è¯¢](#1-çˆ¶å­å…³ç³»æŸ¥è¯¢)
    - [2. Trace é‡å»ºå™¨](#2-trace-é‡å»ºå™¨)
    - [3. ä¾èµ–å›¾æ„å»º](#3-ä¾èµ–å›¾æ„å»º)
  - [âš¡ æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
    - [1. æŸ¥è¯¢ç¼“å­˜](#1-æŸ¥è¯¢ç¼“å­˜)
    - [2. é¢„å–ç­–ç•¥](#2-é¢„å–ç­–ç•¥)
    - [3. æ‰¹é‡æŸ¥è¯¢](#3-æ‰¹é‡æŸ¥è¯¢)
  - [ğŸ“ˆ èšåˆç»Ÿè®¡](#-èšåˆç»Ÿè®¡)
    - [1. Span ç»Ÿè®¡å™¨](#1-span-ç»Ÿè®¡å™¨)
    - [2. æ—¶é—´èŒƒå›´èšåˆ](#2-æ—¶é—´èŒƒå›´èšåˆ)
  - [ğŸ”„ æµå¼æŸ¥è¯¢](#-æµå¼æŸ¥è¯¢)
    - [1. æµå¼ TraceID æŸ¥è¯¢](#1-æµå¼-traceid-æŸ¥è¯¢)
    - [2. åˆ†é¡µæŸ¥è¯¢](#2-åˆ†é¡µæŸ¥è¯¢)
  - [ğŸ“Š å®Œæ•´ç¤ºä¾‹ï¼šåˆ†å¸ƒå¼ Trace æŸ¥è¯¢ç³»ç»Ÿ](#-å®Œæ•´ç¤ºä¾‹åˆ†å¸ƒå¼-trace-æŸ¥è¯¢ç³»ç»Ÿ)
  - [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [æŸ¥è¯¢ä¼˜åŒ–](#æŸ¥è¯¢ä¼˜åŒ–)
    - [ç¼“å­˜ç­–ç•¥](#ç¼“å­˜ç­–ç•¥)
    - [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)

---

## ğŸ¯ æ¦‚è¿°

åˆ†å¸ƒå¼è¿½è¸ªæŸ¥è¯¢æ˜¯ OTLP ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œéœ€è¦é«˜æ•ˆåœ°ä»æµ·é‡æ•°æ®ä¸­ç²¾ç¡®å®šä½ TraceIDã€æ£€ç´¢ç›¸å…³ Span å¹¶é‡å»ºå®Œæ•´çš„è°ƒç”¨é“¾è·¯ã€‚

### æ ¸å¿ƒåŠŸèƒ½

- âœ… **TraceID ç²¾ç¡®æŸ¥è¯¢** - å¿«é€Ÿå®šä½ç‰¹å®š Trace
- âœ… **Span å±æ€§æ£€ç´¢** - åŸºäºå±æ€§è¿‡æ»¤ Span
- âœ… **å…³è”æŸ¥è¯¢** - çˆ¶å­å…³ç³»ã€ä¾èµ–å›¾æ„å»º
- âœ… **æ€§èƒ½ä¼˜åŒ–** - ç¼“å­˜ã€é¢„å–ã€æ‰¹é‡æŸ¥è¯¢
- âœ… **æµå¼æŸ¥è¯¢** - å¤§ç»“æœé›†åˆ†é¡µå¤„ç†
- âœ… **èšåˆç»Ÿè®¡** - Trace çº§åˆ«çš„ç»Ÿè®¡åˆ†æ

### æŠ€æœ¯æŒ‘æˆ˜

- ğŸ”§ **æ•°æ®åˆ†æ•£** - Trace æ•°æ®åˆ†å¸ƒåœ¨å¤šä¸ªåˆ†åŒº/èŠ‚ç‚¹
- ğŸ”§ **å…³è”å¤æ‚** - Span ä¹‹é—´çš„çˆ¶å­å…³ç³»éœ€è¦é‡å»º
- ğŸ”§ **æ€§èƒ½è¦æ±‚** - æ¯«ç§’çº§æŸ¥è¯¢å“åº”
- ğŸ”§ **æ•°æ®é‡å¤§** - PB çº§æ•°æ®å­˜å‚¨

---

## ğŸ” TraceID ç²¾ç¡®æŸ¥è¯¢

### 1. TraceID æŸ¥è¯¢å™¨

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;
use chrono::{DateTime, Utc};

/// TraceID æŸ¥è¯¢å™¨
pub struct TraceIdQueryEngine {
    shard_manager: Arc<ShardManager>,
    bloom_index: Arc<BloomIndex>,
    lsm_index: Arc<LsmIndex>,
    cache: Arc<TraceCache>,
}

impl TraceIdQueryEngine {
    pub fn new(
        shard_manager: Arc<ShardManager>,
        bloom_index: Arc<BloomIndex>,
        lsm_index: Arc<LsmIndex>,
        cache: Arc<TraceCache>,
    ) -> Self {
        Self {
            shard_manager,
            bloom_index,
            lsm_index,
            cache,
        }
    }
    
    /// æŸ¥è¯¢å•ä¸ª TraceID
    pub async fn query_trace(
        &self,
        trace_id: &TraceId,
    ) -> Result<Option<CompleteTrace>, QueryError> {
        // 1. æ£€æŸ¥ç¼“å­˜
        if let Some(cached_trace) = self.cache.get(trace_id).await {
            tracing::debug!("TraceID {} found in cache", trace_id);
            return Ok(Some(cached_trace));
        }
        
        // 2. ç¡®å®šå¯èƒ½çš„åˆ†åŒº
        let partitions = self.shard_manager.get_partitions_for_trace(trace_id).await?;
        
        tracing::debug!("TraceID {} may be in {} partitions", trace_id, partitions.len());
        
        // 3. å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„åˆ†åŒº
        let mut handles = Vec::new();
        
        for partition in partitions {
            let trace_id = trace_id.clone();
            let bloom_index = self.bloom_index.clone();
            let lsm_index = self.lsm_index.clone();
            
            let handle = tokio::spawn(async move {
                // ä½¿ç”¨ Bloom Filter å¿«é€Ÿæ’é™¤
                if !bloom_index.might_contain(&partition, &trace_id).await {
                    return None;
                }
                
                // ä» LSM-Tree æŸ¥è¯¢
                lsm_index.get_trace(&partition, &trace_id).await
            });
            
            handles.push(handle);
        }
        
        // 4. ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆ
        for handle in handles {
            if let Ok(Some(trace)) = handle.await {
                // æ‰¾åˆ° Traceï¼Œæ”¾å…¥ç¼“å­˜
                self.cache.put(trace_id.clone(), trace.clone()).await;
                return Ok(Some(trace));
            }
        }
        
        Ok(None)
    }
    
    /// æ‰¹é‡æŸ¥è¯¢å¤šä¸ª TraceID
    pub async fn query_traces_batch(
        &self,
        trace_ids: Vec<TraceId>,
    ) -> Result<Vec<(TraceId, Option<CompleteTrace>)>, QueryError> {
        let mut results = Vec::new();
        
        // åˆ†ç»„ï¼šæŒ‰åˆ†åŒºèšåˆ TraceID
        let mut partition_groups: HashMap<String, Vec<TraceId>> = HashMap::new();
        
        for trace_id in trace_ids {
            let partitions = self.shard_manager.get_partitions_for_trace(&trace_id).await?;
            
            for partition in partitions {
                partition_groups
                    .entry(partition.clone())
                    .or_insert_with(Vec::new)
                    .push(trace_id.clone());
            }
        }
        
        // å¹¶è¡ŒæŸ¥è¯¢æ¯ä¸ªåˆ†åŒº
        let mut handles = Vec::new();
        
        for (partition, trace_ids) in partition_groups {
            let bloom_index = self.bloom_index.clone();
            let lsm_index = self.lsm_index.clone();
            
            let handle = tokio::spawn(async move {
                let mut batch_results = Vec::new();
                
                for trace_id in trace_ids {
                    if bloom_index.might_contain(&partition, &trace_id).await {
                        let trace = lsm_index.get_trace(&partition, &trace_id).await;
                        batch_results.push((trace_id, trace));
                    } else {
                        batch_results.push((trace_id, None));
                    }
                }
                
                batch_results
            });
            
            handles.push(handle);
        }
        
        // æ”¶é›†ç»“æœ
        for handle in handles {
            if let Ok(batch_results) = handle.await {
                results.extend(batch_results);
            }
        }
        
        Ok(results)
    }
}

/// å®Œæ•´çš„ Trace
#[derive(Debug, Clone)]
pub struct CompleteTrace {
    pub trace_id: TraceId,
    pub spans: Vec<SpanRecord>,
    pub start_time: DateTime<Utc>,
    pub end_time: DateTime<Utc>,
    pub duration_ms: i64,
    pub service_count: usize,
    pub span_count: usize,
}

#[derive(Debug, Clone)]
pub struct SpanRecord {
    pub span_id: SpanId,
    pub parent_span_id: Option<SpanId>,
    pub trace_id: TraceId,
    pub name: String,
    pub start_time: DateTime<Utc>,
    pub end_time: DateTime<Utc>,
    pub duration_ms: i64,
    pub service_name: String,
    pub attributes: HashMap<String, String>,
    pub status: SpanStatus,
}

#[derive(Debug, Clone)]
pub enum SpanStatus {
    Ok,
    Error { message: String },
}

pub type TraceId = [u8; 16];
pub type SpanId = [u8; 8];

#[derive(Debug)]
pub enum QueryError {
    NotFound,
    PartitionError(String),
    IndexError(String),
    NetworkError(String),
}
```

---

### 2. åˆ†åŒºå®šä½å™¨

```rust
/// åˆ†åŒºå®šä½å™¨
pub struct PartitionLocator {
    time_partitioner: Arc<TimeRangePartitioner>,
    hash_partitioner: Arc<HashPartitioner>,
}

impl PartitionLocator {
    pub fn new(
        time_partitioner: Arc<TimeRangePartitioner>,
        hash_partitioner: Arc<HashPartitioner>,
    ) -> Self {
        Self {
            time_partitioner,
            hash_partitioner,
        }
    }
    
    /// æ ¹æ® TraceID å®šä½åˆ†åŒº
    pub async fn locate_partitions(
        &self,
        trace_id: &TraceId,
        time_hint: Option<DateTime<Utc>>,
    ) -> Result<Vec<String>, String> {
        let mut partitions = Vec::new();
        
        if let Some(timestamp) = time_hint {
            // æœ‰æ—¶é—´æç¤ºï¼Œç²¾ç¡®å®šä½
            let time_partition = self.time_partitioner.get_partition(timestamp);
            let hash_key = self.hash_partitioner.hash_trace_id(trace_id);
            
            partitions.push(format!("{}-{}", time_partition, hash_key));
        } else {
            // æ— æ—¶é—´æç¤ºï¼Œéœ€è¦æŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„æ—¶é—´åˆ†åŒº
            let all_time_partitions = self.time_partitioner.get_all_active_partitions().await?;
            
            let hash_key = self.hash_partitioner.hash_trace_id(trace_id);
            
            for time_partition in all_time_partitions {
                partitions.push(format!("{}-{}", time_partition, hash_key));
            }
        }
        
        Ok(partitions)
    }
    
    /// æ ¹æ®æ—¶é—´èŒƒå›´è·å–åˆ†åŒº
    pub async fn locate_partitions_by_time_range(
        &self,
        start_time: DateTime<Utc>,
        end_time: DateTime<Utc>,
    ) -> Result<Vec<String>, String> {
        let time_partitions = self.time_partitioner
            .get_partitions_in_range(start_time, end_time);
        
        let mut all_partitions = Vec::new();
        
        for time_partition in time_partitions {
            // æ¯ä¸ªæ—¶é—´åˆ†åŒºåŒ…å«å¤šä¸ªå“ˆå¸Œåˆ†åŒº
            let hash_partitions = self.hash_partitioner.get_all_partitions();
            
            for hash_key in hash_partitions {
                all_partitions.push(format!("{}-{}", time_partition, hash_key));
            }
        }
        
        Ok(all_partitions)
    }
}
```

---

### 3. å¹¶è¡ŒæŸ¥è¯¢æ‰§è¡Œå™¨

```rust
/// å¹¶è¡ŒæŸ¥è¯¢æ‰§è¡Œå™¨
pub struct ParallelTraceQueryExecutor {
    query_engine: Arc<TraceIdQueryEngine>,
    worker_pool_size: usize,
}

impl ParallelTraceQueryExecutor {
    pub fn new(query_engine: Arc<TraceIdQueryEngine>, worker_pool_size: usize) -> Self {
        Self {
            query_engine,
            worker_pool_size,
        }
    }
    
    /// å¹¶è¡ŒæŸ¥è¯¢å¤šä¸ª TraceID
    pub async fn execute_parallel_query(
        &self,
        trace_ids: Vec<TraceId>,
    ) -> Result<Vec<(TraceId, Option<CompleteTrace>)>, QueryError> {
        let chunk_size = (trace_ids.len() + self.worker_pool_size - 1) / self.worker_pool_size;
        
        let mut handles = Vec::new();
        
        for chunk in trace_ids.chunks(chunk_size) {
            let query_engine = self.query_engine.clone();
            let chunk = chunk.to_vec();
            
            let handle = tokio::spawn(async move {
                let mut results = Vec::new();
                
                for trace_id in chunk {
                    match query_engine.query_trace(&trace_id).await {
                        Ok(trace) => results.push((trace_id, trace)),
                        Err(e) => {
                            tracing::error!("Failed to query TraceID {:?}: {:?}", trace_id, e);
                            results.push((trace_id, None));
                        }
                    }
                }
                
                results
            });
            
            handles.push(handle);
        }
        
        let mut all_results = Vec::new();
        
        for handle in handles {
            if let Ok(results) = handle.await {
                all_results.extend(results);
            }
        }
        
        Ok(all_results)
    }
}
```

---

## ğŸ“Š Span å±æ€§æ£€ç´¢

### 1. Span è¿‡æ»¤å™¨

```rust
/// Span è¿‡æ»¤å™¨
pub struct SpanFilter {
    inverted_index: Arc<InvertedIndex>,
}

impl SpanFilter {
    pub fn new(inverted_index: Arc<InvertedIndex>) -> Self {
        Self { inverted_index }
    }
    
    /// æ ¹æ®å±æ€§è¿‡æ»¤ Span
    pub async fn filter_spans_by_attributes(
        &self,
        conditions: Vec<AttributeCondition>,
    ) -> Result<Vec<TraceId>, QueryError> {
        if conditions.is_empty() {
            return Ok(Vec::new());
        }
        
        // å°†æ¡ä»¶è½¬æ¢ä¸ºå€’æ’ç´¢å¼•æŸ¥è¯¢
        let attribute_queries: Vec<(String, String)> = conditions
            .into_iter()
            .map(|c| (c.key, c.value))
            .collect();
        
        // ä½¿ç”¨å€’æ’ç´¢å¼•æŸ¥è¯¢
        let trace_ids = self.inverted_index.query_and(attribute_queries).await;
        
        Ok(trace_ids)
    }
    
    /// æ ¹æ®æœåŠ¡åè¿‡æ»¤
    pub async fn filter_by_service(
        &self,
        service_name: &str,
    ) -> Result<Vec<TraceId>, QueryError> {
        let trace_ids = self.inverted_index
            .query("service.name", service_name)
            .await;
        
        Ok(trace_ids)
    }
    
    /// æ ¹æ® Span åç§°å‰ç¼€è¿‡æ»¤
    pub async fn filter_by_span_name_prefix(
        &self,
        prefix: &str,
    ) -> Result<Vec<TraceId>, QueryError> {
        // ä½¿ç”¨ Trie ç´¢å¼•æŸ¥æ‰¾åŒ¹é…çš„ Span åç§°
        let span_names = self.inverted_index
            .trie_index
            .starts_with(prefix)
            .await;
        
        let mut all_trace_ids = Vec::new();
        
        for span_name in span_names {
            let trace_ids = self.inverted_index
                .query("span.name", &span_name)
                .await;
            
            all_trace_ids.extend(trace_ids);
        }
        
        // å»é‡
        all_trace_ids.sort();
        all_trace_ids.dedup();
        
        Ok(all_trace_ids)
    }
}

#[derive(Debug, Clone)]
pub struct AttributeCondition {
    pub key: String,
    pub value: String,
}
```

---

### 2. å±æ€§ç´¢å¼•æŸ¥è¯¢

```rust
/// å±æ€§ç´¢å¼•æŸ¥è¯¢å™¨
pub struct AttributeIndexQuery {
    inverted_index: Arc<RwLock<HashMap<(String, String), Vec<TraceId>>>>,
}

impl AttributeIndexQuery {
    pub fn new() -> Self {
        Self {
            inverted_index: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// æ’å…¥ Span å±æ€§åˆ°ç´¢å¼•
    pub async fn index_span(
        &self,
        trace_id: TraceId,
        attributes: HashMap<String, String>,
    ) {
        let mut index = self.inverted_index.write().await;
        
        for (key, value) in attributes {
            index
                .entry((key, value))
                .or_insert_with(Vec::new)
                .push(trace_id);
        }
    }
    
    /// æŸ¥è¯¢å±æ€§
    pub async fn query_attribute(
        &self,
        key: &str,
        value: &str,
    ) -> Vec<TraceId> {
        let index = self.inverted_index.read().await;
        
        index
            .get(&(key.to_string(), value.to_string()))
            .cloned()
            .unwrap_or_default()
    }
    
    /// AND æŸ¥è¯¢ï¼ˆæ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼‰
    pub async fn query_and(
        &self,
        conditions: Vec<(String, String)>,
    ) -> Vec<TraceId> {
        if conditions.is_empty() {
            return Vec::new();
        }
        
        let index = self.inverted_index.read().await;
        
        // è·å–ç¬¬ä¸€ä¸ªæ¡ä»¶çš„ç»“æœ
        let mut result_set: Vec<TraceId> = index
            .get(&conditions[0])
            .cloned()
            .unwrap_or_default();
        
        result_set.sort();
        
        // å¯¹æ¯ä¸ªåç»­æ¡ä»¶è¿›è¡Œäº¤é›†
        for condition in conditions.iter().skip(1) {
            let mut condition_set = index
                .get(condition)
                .cloned()
                .unwrap_or_default();
            
            condition_set.sort();
            
            // è®¡ç®—äº¤é›†
            result_set = result_set
                .into_iter()
                .filter(|id| condition_set.binary_search(id).is_ok())
                .collect();
            
            if result_set.is_empty() {
                break;
            }
        }
        
        result_set
    }
    
    /// OR æŸ¥è¯¢ï¼ˆä»»ä¸€æ¡ä»¶æ»¡è¶³ï¼‰
    pub async fn query_or(
        &self,
        conditions: Vec<(String, String)>,
    ) -> Vec<TraceId> {
        if conditions.is_empty() {
            return Vec::new();
        }
        
        let index = self.inverted_index.read().await;
        
        let mut result_set = Vec::new();
        
        for condition in conditions {
            if let Some(ids) = index.get(&condition) {
                result_set.extend_from_slice(ids);
            }
        }
        
        // å»é‡
        result_set.sort();
        result_set.dedup();
        
        result_set
    }
}
```

---

### 3. å¤åˆæ¡ä»¶æŸ¥è¯¢

```rust
/// å¤åˆæ¡ä»¶æŸ¥è¯¢å™¨
pub struct CompositeQueryEngine {
    span_filter: Arc<SpanFilter>,
    time_range_index: Arc<TimeRangeIndex>,
}

impl CompositeQueryEngine {
    pub fn new(
        span_filter: Arc<SpanFilter>,
        time_range_index: Arc<TimeRangeIndex>,
    ) -> Self {
        Self {
            span_filter,
            time_range_index,
        }
    }
    
    /// æ‰§è¡Œå¤åˆæŸ¥è¯¢
    pub async fn execute_composite_query(
        &self,
        query: CompositeQuery,
    ) -> Result<Vec<TraceId>, QueryError> {
        let mut candidate_trace_ids: Option<Vec<TraceId>> = None;
        
        // 1. æ—¶é—´èŒƒå›´è¿‡æ»¤ï¼ˆæœ€é«˜é€‰æ‹©æ€§ï¼‰
        if let Some(time_range) = query.time_range {
            let time_filtered = self.time_range_index
                .query_range(time_range.start, time_range.end)
                .await;
            
            candidate_trace_ids = Some(time_filtered);
        }
        
        // 2. å±æ€§è¿‡æ»¤
        if !query.attributes.is_empty() {
            let attribute_filtered = self.span_filter
                .filter_spans_by_attributes(query.attributes)
                .await?;
            
            candidate_trace_ids = match candidate_trace_ids {
                Some(existing) => {
                    // è®¡ç®—äº¤é›†
                    let intersection = Self::intersect(existing, attribute_filtered);
                    Some(intersection)
                }
                None => Some(attribute_filtered),
            };
        }
        
        // 3. æœåŠ¡åè¿‡æ»¤
        if let Some(service_name) = query.service_name {
            let service_filtered = self.span_filter
                .filter_by_service(&service_name)
                .await?;
            
            candidate_trace_ids = match candidate_trace_ids {
                Some(existing) => {
                    let intersection = Self::intersect(existing, service_filtered);
                    Some(intersection)
                }
                None => Some(service_filtered),
            };
        }
        
        Ok(candidate_trace_ids.unwrap_or_default())
    }
    
    /// è®¡ç®—ä¸¤ä¸ªæœ‰åºåˆ—è¡¨çš„äº¤é›†
    fn intersect(mut a: Vec<TraceId>, mut b: Vec<TraceId>) -> Vec<TraceId> {
        a.sort();
        b.sort();
        
        let mut result = Vec::new();
        let mut i = 0;
        let mut j = 0;
        
        while i < a.len() && j < b.len() {
            match a[i].cmp(&b[j]) {
                std::cmp::Ordering::Equal => {
                    result.push(a[i]);
                    i += 1;
                    j += 1;
                }
                std::cmp::Ordering::Less => i += 1,
                std::cmp::Ordering::Greater => j += 1,
            }
        }
        
        result
    }
}

#[derive(Debug, Clone)]
pub struct CompositeQuery {
    pub time_range: Option<TimeRange>,
    pub service_name: Option<String>,
    pub attributes: Vec<AttributeCondition>,
}

#[derive(Debug, Clone)]
pub struct TimeRange {
    pub start: DateTime<Utc>,
    pub end: DateTime<Utc>,
}
```

---

## ğŸ”— Span å…³è”æŸ¥è¯¢

### 1. çˆ¶å­å…³ç³»æŸ¥è¯¢

```rust
/// Span å…³è”æŸ¥è¯¢å™¨
pub struct SpanRelationshipQuery {
    trace_query_engine: Arc<TraceIdQueryEngine>,
}

impl SpanRelationshipQuery {
    pub fn new(trace_query_engine: Arc<TraceIdQueryEngine>) -> Self {
        Self { trace_query_engine }
    }
    
    /// æŸ¥è¯¢ Span çš„æ‰€æœ‰å­ Span
    pub async fn get_children(
        &self,
        trace_id: &TraceId,
        parent_span_id: &SpanId,
    ) -> Result<Vec<SpanRecord>, QueryError> {
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        let children: Vec<SpanRecord> = trace
            .spans
            .into_iter()
            .filter(|span| {
                span.parent_span_id.as_ref() == Some(parent_span_id)
            })
            .collect();
        
        Ok(children)
    }
    
    /// æŸ¥è¯¢ Span çš„çˆ¶ Span
    pub async fn get_parent(
        &self,
        trace_id: &TraceId,
        span_id: &SpanId,
    ) -> Result<Option<SpanRecord>, QueryError> {
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        // æ‰¾åˆ°å½“å‰ Span
        let current_span = trace
            .spans
            .iter()
            .find(|span| &span.span_id == span_id)
            .ok_or(QueryError::NotFound)?;
        
        // æŸ¥æ‰¾çˆ¶ Span
        if let Some(parent_id) = &current_span.parent_span_id {
            let parent = trace
                .spans
                .into_iter()
                .find(|span| &span.span_id == parent_id);
            
            Ok(parent)
        } else {
            Ok(None)
        }
    }
    
    /// æŸ¥è¯¢ Span çš„æ‰€æœ‰ç¥–å…ˆ
    pub async fn get_ancestors(
        &self,
        trace_id: &TraceId,
        span_id: &SpanId,
    ) -> Result<Vec<SpanRecord>, QueryError> {
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        let mut ancestors = Vec::new();
        let mut current_span_id = *span_id;
        
        loop {
            // æŸ¥æ‰¾å½“å‰ Span
            let current_span = trace
                .spans
                .iter()
                .find(|span| span.span_id == current_span_id);
            
            match current_span {
                Some(span) => {
                    if let Some(parent_id) = span.parent_span_id {
                        // æ‰¾åˆ°çˆ¶ Span
                        if let Some(parent_span) = trace.spans.iter().find(|s| s.span_id == parent_id) {
                            ancestors.push(parent_span.clone());
                            current_span_id = parent_id;
                        } else {
                            break;
                        }
                    } else {
                        // æ²¡æœ‰çˆ¶ Spanï¼Œç»“æŸ
                        break;
                    }
                }
                None => break,
            }
        }
        
        Ok(ancestors)
    }
}
```

---

### 2. Trace é‡å»ºå™¨

```rust
/// Trace é‡å»ºå™¨
pub struct TraceReconstructor {
    trace_query_engine: Arc<TraceIdQueryEngine>,
}

impl TraceReconstructor {
    pub fn new(trace_query_engine: Arc<TraceIdQueryEngine>) -> Self {
        Self { trace_query_engine }
    }
    
    /// é‡å»ºå®Œæ•´çš„ Trace æ ‘
    pub async fn reconstruct_trace_tree(
        &self,
        trace_id: &TraceId,
    ) -> Result<TraceTree, QueryError> {
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        // æ„å»º Span æ˜ å°„
        let mut span_map: HashMap<SpanId, SpanRecord> = trace
            .spans
            .into_iter()
            .map(|span| (span.span_id, span))
            .collect();
        
        // æ‰¾åˆ°æ ¹ Spanï¼ˆæ²¡æœ‰çˆ¶ Span çš„ï¼‰
        let root_spans: Vec<SpanRecord> = span_map
            .values()
            .filter(|span| span.parent_span_id.is_none())
            .cloned()
            .collect();
        
        // æ„å»ºæ ‘
        let mut root_nodes = Vec::new();
        
        for root_span in root_spans {
            let root_node = self.build_tree_node(root_span, &span_map);
            root_nodes.push(root_node);
        }
        
        Ok(TraceTree {
            trace_id: *trace_id,
            root_nodes,
        })
    }
    
    /// é€’å½’æ„å»ºæ ‘èŠ‚ç‚¹
    fn build_tree_node(
        &self,
        span: SpanRecord,
        span_map: &HashMap<SpanId, SpanRecord>,
    ) -> TraceTreeNode {
        // æŸ¥æ‰¾å­ Span
        let children: Vec<SpanRecord> = span_map
            .values()
            .filter(|child| child.parent_span_id == Some(span.span_id))
            .cloned()
            .collect();
        
        let child_nodes: Vec<TraceTreeNode> = children
            .into_iter()
            .map(|child| self.build_tree_node(child, span_map))
            .collect();
        
        TraceTreeNode {
            span,
            children: child_nodes,
        }
    }
}

#[derive(Debug, Clone)]
pub struct TraceTree {
    pub trace_id: TraceId,
    pub root_nodes: Vec<TraceTreeNode>,
}

#[derive(Debug, Clone)]
pub struct TraceTreeNode {
    pub span: SpanRecord,
    pub children: Vec<TraceTreeNode>,
}
```

---

### 3. ä¾èµ–å›¾æ„å»º

```rust
/// ä¾èµ–å›¾æ„å»ºå™¨
pub struct DependencyGraphBuilder {
    trace_reconstructor: Arc<TraceReconstructor>,
}

impl DependencyGraphBuilder {
    pub fn new(trace_reconstructor: Arc<TraceReconstructor>) -> Self {
        Self { trace_reconstructor }
    }
    
    /// æ„å»ºæœåŠ¡ä¾èµ–å›¾
    pub async fn build_service_dependency_graph(
        &self,
        trace_id: &TraceId,
    ) -> Result<ServiceDependencyGraph, QueryError> {
        let trace_tree = self.trace_reconstructor
            .reconstruct_trace_tree(trace_id)
            .await?;
        
        let mut graph = ServiceDependencyGraph {
            nodes: HashMap::new(),
            edges: Vec::new(),
        };
        
        // éå†æ ‘ï¼Œæ„å»ºä¾èµ–å…³ç³»
        for root in trace_tree.root_nodes {
            self.traverse_and_build_graph(None, &root, &mut graph);
        }
        
        Ok(graph)
    }
    
    /// éå†å¹¶æ„å»ºå›¾
    fn traverse_and_build_graph(
        &self,
        parent_service: Option<String>,
        node: &TraceTreeNode,
        graph: &mut ServiceDependencyGraph,
    ) {
        let current_service = node.span.service_name.clone();
        
        // æ·»åŠ èŠ‚ç‚¹
        graph.nodes
            .entry(current_service.clone())
            .or_insert_with(|| ServiceNode {
                service_name: current_service.clone(),
                span_count: 0,
                total_duration_ms: 0,
            })
            .span_count += 1;
        
        graph.nodes
            .get_mut(&current_service)
            .unwrap()
            .total_duration_ms += node.span.duration_ms;
        
        // æ·»åŠ è¾¹
        if let Some(parent) = parent_service {
            if parent != current_service {
                graph.edges.push(ServiceDependencyEdge {
                    from: parent,
                    to: current_service.clone(),
                    call_count: 1,
                });
            }
        }
        
        // é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in &node.children {
            self.traverse_and_build_graph(Some(current_service.clone()), child, graph);
        }
    }
}

#[derive(Debug, Clone)]
pub struct ServiceDependencyGraph {
    pub nodes: HashMap<String, ServiceNode>,
    pub edges: Vec<ServiceDependencyEdge>,
}

#[derive(Debug, Clone)]
pub struct ServiceNode {
    pub service_name: String,
    pub span_count: usize,
    pub total_duration_ms: i64,
}

#[derive(Debug, Clone)]
pub struct ServiceDependencyEdge {
    pub from: String,
    pub to: String,
    pub call_count: usize,
}
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. æŸ¥è¯¢ç¼“å­˜

```rust
use lru::LruCache;
use std::num::NonZeroUsize;

/// Trace ç¼“å­˜
pub struct TraceCache {
    cache: Arc<tokio::sync::Mutex<LruCache<TraceId, CompleteTrace>>>,
}

impl TraceCache {
    pub fn new(capacity: usize) -> Self {
        Self {
            cache: Arc::new(tokio::sync::Mutex::new(
                LruCache::new(NonZeroUsize::new(capacity).unwrap())
            )),
        }
    }
    
    /// è·å–ç¼“å­˜
    pub async fn get(&self, trace_id: &TraceId) -> Option<CompleteTrace> {
        let mut cache = self.cache.lock().await;
        cache.get(trace_id).cloned()
    }
    
    /// æ”¾å…¥ç¼“å­˜
    pub async fn put(&self, trace_id: TraceId, trace: CompleteTrace) {
        let mut cache = self.cache.lock().await;
        cache.put(trace_id, trace);
    }
    
    /// æ¸…é™¤ç¼“å­˜
    pub async fn invalidate(&self, trace_id: &TraceId) {
        let mut cache = self.cache.lock().await;
        cache.pop(trace_id);
    }
    
    /// è·å–ç¼“å­˜ç»Ÿè®¡
    pub async fn get_stats(&self) -> CacheStats {
        let cache = self.cache.lock().await;
        
        CacheStats {
            size: cache.len(),
            capacity: cache.cap().get(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct CacheStats {
    pub size: usize,
    pub capacity: usize,
}
```

---

### 2. é¢„å–ç­–ç•¥

```rust
/// é¢„å–ç®¡ç†å™¨
pub struct PrefetchManager {
    trace_query_engine: Arc<TraceIdQueryEngine>,
    cache: Arc<TraceCache>,
}

impl PrefetchManager {
    pub fn new(
        trace_query_engine: Arc<TraceIdQueryEngine>,
        cache: Arc<TraceCache>,
    ) -> Self {
        Self {
            trace_query_engine,
            cache,
        }
    }
    
    /// é¢„å–ç›¸å…³çš„ Trace
    pub async fn prefetch_related_traces(
        &self,
        trace_id: &TraceId,
    ) -> Result<(), QueryError> {
        // æŸ¥è¯¢å½“å‰ Trace
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        // æå–ç›¸å…³çš„ TraceIDï¼ˆä¾‹å¦‚ï¼Œä»å±æ€§ä¸­ï¼‰
        let related_trace_ids = self.extract_related_trace_ids(&trace);
        
        // å¼‚æ­¥é¢„å–
        for related_id in related_trace_ids {
            let query_engine = self.trace_query_engine.clone();
            let cache = self.cache.clone();
            
            tokio::spawn(async move {
                if let Ok(Some(related_trace)) = query_engine.query_trace(&related_id).await {
                    cache.put(related_id, related_trace).await;
                }
            });
        }
        
        Ok(())
    }
    
    fn extract_related_trace_ids(&self, trace: &CompleteTrace) -> Vec<TraceId> {
        let mut related_ids = Vec::new();
        
        for span in &trace.spans {
            // ä»å±æ€§ä¸­æå–ç›¸å…³çš„ TraceID
            if let Some(related_trace_str) = span.attributes.get("related.trace_id") {
                // è§£æ TraceID
                if let Ok(related_id) = Self::parse_trace_id(related_trace_str) {
                    related_ids.push(related_id);
                }
            }
        }
        
        related_ids
    }
    
    fn parse_trace_id(s: &str) -> Result<TraceId, ()> {
        let bytes = hex::decode(s).map_err(|_| ())?;
        
        if bytes.len() != 16 {
            return Err(());
        }
        
        let mut trace_id = [0u8; 16];
        trace_id.copy_from_slice(&bytes);
        
        Ok(trace_id)
    }
}
```

---

### 3. æ‰¹é‡æŸ¥è¯¢

```rust
/// æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–å™¨
pub struct BatchQueryOptimizer {
    query_engine: Arc<TraceIdQueryEngine>,
}

impl BatchQueryOptimizer {
    pub fn new(query_engine: Arc<TraceIdQueryEngine>) -> Self {
        Self { query_engine }
    }
    
    /// æ‰¹é‡æŸ¥è¯¢ï¼ˆåˆ†ç»„ä¼˜åŒ–ï¼‰
    pub async fn batch_query_optimized(
        &self,
        trace_ids: Vec<TraceId>,
        batch_size: usize,
    ) -> Result<Vec<(TraceId, Option<CompleteTrace>)>, QueryError> {
        let mut all_results = Vec::new();
        
        for chunk in trace_ids.chunks(batch_size) {
            let results = self.query_engine
                .query_traces_batch(chunk.to_vec())
                .await?;
            
            all_results.extend(results);
        }
        
        Ok(all_results)
    }
}
```

---

## ğŸ“ˆ èšåˆç»Ÿè®¡

### 1. Span ç»Ÿè®¡å™¨

```rust
/// Span ç»Ÿè®¡å™¨
pub struct SpanAggregator {
    trace_query_engine: Arc<TraceIdQueryEngine>,
}

impl SpanAggregator {
    pub fn new(trace_query_engine: Arc<TraceIdQueryEngine>) -> Self {
        Self { trace_query_engine }
    }
    
    /// è®¡ç®— Trace ç»Ÿè®¡ä¿¡æ¯
    pub async fn aggregate_trace_stats(
        &self,
        trace_id: &TraceId,
    ) -> Result<TraceStats, QueryError> {
        let trace = self.trace_query_engine
            .query_trace(trace_id)
            .await?
            .ok_or(QueryError::NotFound)?;
        
        let total_duration = trace.duration_ms;
        let span_count = trace.spans.len();
        
        // ç»Ÿè®¡æ¯ä¸ªæœåŠ¡çš„ Span æ•°é‡å’Œè€—æ—¶
        let mut service_stats: HashMap<String, ServiceStats> = HashMap::new();
        
        for span in &trace.spans {
            let stats = service_stats
                .entry(span.service_name.clone())
                .or_insert_with(|| ServiceStats {
                    service_name: span.service_name.clone(),
                    span_count: 0,
                    total_duration_ms: 0,
                    error_count: 0,
                });
            
            stats.span_count += 1;
            stats.total_duration_ms += span.duration_ms;
            
            if matches!(span.status, SpanStatus::Error { .. }) {
                stats.error_count += 1;
            }
        }
        
        // æ‰¾åˆ°æœ€æ…¢çš„ Span
        let slowest_span = trace
            .spans
            .iter()
            .max_by_key(|span| span.duration_ms)
            .cloned();
        
        Ok(TraceStats {
            trace_id: *trace_id,
            total_duration_ms: total_duration,
            span_count,
            service_stats: service_stats.into_values().collect(),
            slowest_span,
        })
    }
}

#[derive(Debug, Clone)]
pub struct TraceStats {
    pub trace_id: TraceId,
    pub total_duration_ms: i64,
    pub span_count: usize,
    pub service_stats: Vec<ServiceStats>,
    pub slowest_span: Option<SpanRecord>,
}

#[derive(Debug, Clone)]
pub struct ServiceStats {
    pub service_name: String,
    pub span_count: usize,
    pub total_duration_ms: i64,
    pub error_count: usize,
}
```

---

### 2. æ—¶é—´èŒƒå›´èšåˆ

```rust
/// æ—¶é—´èŒƒå›´èšåˆå™¨
pub struct TimeRangeAggregator {
    trace_query_engine: Arc<TraceIdQueryEngine>,
    span_filter: Arc<SpanFilter>,
}

impl TimeRangeAggregator {
    pub fn new(
        trace_query_engine: Arc<TraceIdQueryEngine>,
        span_filter: Arc<SpanFilter>,
    ) -> Self {
        Self {
            trace_query_engine,
            span_filter,
        }
    }
    
    /// èšåˆæ—¶é—´èŒƒå›´å†…çš„ Trace ç»Ÿè®¡
    pub async fn aggregate_time_range(
        &self,
        start_time: DateTime<Utc>,
        end_time: DateTime<Utc>,
        service_name: Option<String>,
    ) -> Result<TimeRangeStats, QueryError> {
        // 1. æ ¹æ®æ—¶é—´èŒƒå›´å’ŒæœåŠ¡åè¿‡æ»¤ TraceID
        let query = CompositeQuery {
            time_range: Some(TimeRange {
                start: start_time,
                end: end_time,
            }),
            service_name,
            attributes: Vec::new(),
        };
        
        // è¿™é‡Œéœ€è¦å®ç°æŸ¥è¯¢å¼•æ“...
        let trace_ids: Vec<TraceId> = Vec::new(); // ç®€åŒ–
        
        // 2. ç»Ÿè®¡
        let mut total_traces = 0;
        let mut total_spans = 0;
        let mut total_duration_ms = 0i64;
        let mut error_count = 0;
        
        for trace_id in trace_ids {
            if let Ok(Some(trace)) = self.trace_query_engine.query_trace(&trace_id).await {
                total_traces += 1;
                total_spans += trace.span_count;
                total_duration_ms += trace.duration_ms;
                
                // ç»Ÿè®¡é”™è¯¯
                error_count += trace
                    .spans
                    .iter()
                    .filter(|span| matches!(span.status, SpanStatus::Error { .. }))
                    .count();
            }
        }
        
        Ok(TimeRangeStats {
            start_time,
            end_time,
            total_traces,
            total_spans,
            avg_duration_ms: if total_traces > 0 {
                total_duration_ms / total_traces as i64
            } else {
                0
            },
            error_count,
        })
    }
}

#[derive(Debug, Clone)]
pub struct TimeRangeStats {
    pub start_time: DateTime<Utc>,
    pub end_time: DateTime<Utc>,
    pub total_traces: usize,
    pub total_spans: usize,
    pub avg_duration_ms: i64,
    pub error_count: usize,
}
```

---

## ğŸ”„ æµå¼æŸ¥è¯¢

### 1. æµå¼ TraceID æŸ¥è¯¢

```rust
use futures::stream::{Stream, StreamExt};
use std::pin::Pin;

/// æµå¼æŸ¥è¯¢å¤„ç†å™¨
pub struct StreamingQueryProcessor {
    query_engine: Arc<TraceIdQueryEngine>,
}

impl StreamingQueryProcessor {
    pub fn new(query_engine: Arc<TraceIdQueryEngine>) -> Self {
        Self { query_engine }
    }
    
    /// æµå¼æŸ¥è¯¢å¤šä¸ª TraceID
    pub fn stream_traces(
        &self,
        trace_ids: Vec<TraceId>,
    ) -> Pin<Box<dyn Stream<Item = (TraceId, Option<CompleteTrace>)> + Send>> {
        let query_engine = self.query_engine.clone();
        
        Box::pin(futures::stream::iter(trace_ids).then(move |trace_id| {
            let query_engine = query_engine.clone();
            
            async move {
                let trace = query_engine.query_trace(&trace_id).await.ok().flatten();
                (trace_id, trace)
            }
        }))
    }
}
```

---

### 2. åˆ†é¡µæŸ¥è¯¢

```rust
/// åˆ†é¡µæŸ¥è¯¢å™¨
pub struct PaginatedQueryEngine {
    composite_query: Arc<CompositeQueryEngine>,
    trace_query_engine: Arc<TraceIdQueryEngine>,
}

impl PaginatedQueryEngine {
    pub fn new(
        composite_query: Arc<CompositeQueryEngine>,
        trace_query_engine: Arc<TraceIdQueryEngine>,
    ) -> Self {
        Self {
            composite_query,
            trace_query_engine,
        }
    }
    
    /// åˆ†é¡µæŸ¥è¯¢
    pub async fn query_paginated(
        &self,
        query: CompositeQuery,
        page: usize,
        page_size: usize,
    ) -> Result<PaginatedResult, QueryError> {
        // 1. æ‰§è¡Œå¤åˆæŸ¥è¯¢ï¼Œè·å–æ‰€æœ‰åŒ¹é…çš„ TraceID
        let all_trace_ids = self.composite_query
            .execute_composite_query(query)
            .await?;
        
        let total_count = all_trace_ids.len();
        
        // 2. è®¡ç®—åˆ†é¡µ
        let start_idx = page * page_size;
        let end_idx = std::cmp::min(start_idx + page_size, total_count);
        
        if start_idx >= total_count {
            return Ok(PaginatedResult {
                page,
                page_size,
                total_count,
                traces: Vec::new(),
            });
        }
        
        let page_trace_ids = &all_trace_ids[start_idx..end_idx];
        
        // 3. æŸ¥è¯¢è¯¥é¡µçš„å®Œæ•´ Trace æ•°æ®
        let mut traces = Vec::new();
        
        for trace_id in page_trace_ids {
            if let Ok(Some(trace)) = self.trace_query_engine.query_trace(trace_id).await {
                traces.push(trace);
            }
        }
        
        Ok(PaginatedResult {
            page,
            page_size,
            total_count,
            traces,
        })
    }
}

#[derive(Debug, Clone)]
pub struct PaginatedResult {
    pub page: usize,
    pub page_size: usize,
    pub total_count: usize,
    pub traces: Vec<CompleteTrace>,
}
```

---

## ğŸ“Š å®Œæ•´ç¤ºä¾‹ï¼šåˆ†å¸ƒå¼ Trace æŸ¥è¯¢ç³»ç»Ÿ

```rust
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt::init();
    
    // åˆå§‹åŒ–å„ä¸ªç»„ä»¶
    let shard_manager = Arc::new(ShardManager::new());
    let bloom_index = Arc::new(BloomIndex::new());
    let lsm_index = Arc::new(LsmIndex::new());
    let cache = Arc::new(TraceCache::new(1000));
    
    // åˆ›å»ºæŸ¥è¯¢å¼•æ“
    let trace_query_engine = Arc::new(TraceIdQueryEngine::new(
        shard_manager.clone(),
        bloom_index.clone(),
        lsm_index.clone(),
        cache.clone(),
    ));
    
    // åˆ›å»º Span è¿‡æ»¤å™¨
    let inverted_index = Arc::new(InvertedIndex::new());
    let span_filter = Arc::new(SpanFilter::new(inverted_index.clone()));
    
    // åˆ›å»ºå¤åˆæŸ¥è¯¢å¼•æ“
    let time_range_index = Arc::new(TimeRangeIndex::new());
    let composite_query = Arc::new(CompositeQueryEngine::new(
        span_filter.clone(),
        time_range_index.clone(),
    ));
    
    // åˆ›å»ºåˆ†é¡µæŸ¥è¯¢å™¨
    let paginated_query = Arc::new(PaginatedQueryEngine::new(
        composite_query.clone(),
        trace_query_engine.clone(),
    ));
    
    println!("ğŸ¯ åˆ†å¸ƒå¼ Trace æŸ¥è¯¢ç³»ç»Ÿå·²å¯åŠ¨ï¼");
    
    // ç¤ºä¾‹1ï¼šæŸ¥è¯¢å•ä¸ª TraceID
    let trace_id = [1u8; 16];
    
    match trace_query_engine.query_trace(&trace_id).await {
        Ok(Some(trace)) => {
            println!("\nâœ… æ‰¾åˆ° Trace:");
            println!("  TraceID: {:?}", trace.trace_id);
            println!("  Span æ•°é‡: {}", trace.span_count);
            println!("  æŒç»­æ—¶é—´: {}ms", trace.duration_ms);
        }
        Ok(None) => println!("\nâŒ Trace æœªæ‰¾åˆ°"),
        Err(e) => println!("\nâš ï¸ æŸ¥è¯¢å¤±è´¥: {:?}", e),
    }
    
    // ç¤ºä¾‹2ï¼šå¤åˆæ¡ä»¶æŸ¥è¯¢
    let query = CompositeQuery {
        time_range: Some(TimeRange {
            start: Utc::now() - chrono::Duration::hours(1),
            end: Utc::now(),
        }),
        service_name: Some("my-service".to_string()),
        attributes: vec![
            AttributeCondition {
                key: "http.status_code".to_string(),
                value: "500".to_string(),
            },
        ],
    };
    
    let trace_ids = composite_query.execute_composite_query(query).await?;
    
    println!("\nğŸ” å¤åˆæŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {} ä¸ª Trace", trace_ids.len());
    
    // ç¤ºä¾‹3ï¼šåˆ†é¡µæŸ¥è¯¢
    let page_result = paginated_query
        .query_paginated(
            CompositeQuery {
                time_range: Some(TimeRange {
                    start: Utc::now() - chrono::Duration::hours(1),
                    end: Utc::now(),
                }),
                service_name: None,
                attributes: Vec::new(),
            },
            0,
            10,
        )
        .await?;
    
    println!("\nğŸ“„ åˆ†é¡µæŸ¥è¯¢ç»“æœ:");
    println!("  é¡µç : {}", page_result.page);
    println!("  æ¯é¡µå¤§å°: {}", page_result.page_size);
    println!("  æ€»æ•°: {}", page_result.total_count);
    println!("  å½“å‰é¡µ Trace æ•°: {}", page_result.traces.len());
    
    // ç¤ºä¾‹4ï¼šé‡å»º Trace æ ‘
    let reconstructor = Arc::new(TraceReconstructor::new(trace_query_engine.clone()));
    
    if let Ok(tree) = reconstructor.reconstruct_trace_tree(&trace_id).await {
        println!("\nğŸŒ² Trace æ ‘:");
        println!("  æ ¹èŠ‚ç‚¹æ•°: {}", tree.root_nodes.len());
        
        for root in &tree.root_nodes {
            print_tree_node(root, 0);
        }
    }
    
    // ç¤ºä¾‹5ï¼šæ„å»ºæœåŠ¡ä¾èµ–å›¾
    let dependency_builder = Arc::new(DependencyGraphBuilder::new(reconstructor.clone()));
    
    if let Ok(graph) = dependency_builder.build_service_dependency_graph(&trace_id).await {
        println!("\nğŸ”— æœåŠ¡ä¾èµ–å›¾:");
        println!("  æœåŠ¡æ•°: {}", graph.nodes.len());
        println!("  ä¾èµ–è¾¹æ•°: {}", graph.edges.len());
        
        for edge in &graph.edges {
            println!("  {} â†’ {}", edge.from, edge.to);
        }
    }
    
    Ok(())
}

fn print_tree_node(node: &TraceTreeNode, depth: usize) {
    let indent = "  ".repeat(depth);
    
    println!(
        "{}â”œâ”€ {} ({}ms)",
        indent,
        node.span.name,
        node.span.duration_ms
    );
    
    for child in &node.children {
        print_tree_node(child, depth + 1);
    }
}

// å ä½å®ç°
pub struct ShardManager {}
impl ShardManager {
    pub fn new() -> Self { Self {} }
    pub async fn get_partitions_for_trace(&self, _trace_id: &TraceId) -> Result<Vec<String>, QueryError> {
        Ok(vec!["partition_1".to_string()])
    }
}

pub struct BloomIndex {}
impl BloomIndex {
    pub fn new() -> Self { Self {} }
    pub async fn might_contain(&self, _partition: &str, _trace_id: &TraceId) -> bool {
        true
    }
}

pub struct LsmIndex {}
impl LsmIndex {
    pub fn new() -> Self { Self {} }
    pub async fn get_trace(&self, _partition: &str, _trace_id: &TraceId) -> Option<CompleteTrace> {
        None
    }
}

pub struct InvertedIndex {}
impl InvertedIndex {
    pub fn new() -> Self { Self {} }
    pub async fn query_and(&self, _conditions: Vec<(String, String)>) -> Vec<TraceId> {
        Vec::new()
    }
    pub async fn query(&self, _key: &str, _value: &str) -> Vec<TraceId> {
        Vec::new()
    }
    pub trie_index: TrieIndexPlaceholder = TrieIndexPlaceholder {};
}

pub struct TrieIndexPlaceholder {}
impl TrieIndexPlaceholder {
    pub async fn starts_with(&self, _prefix: &str) -> Vec<String> {
        Vec::new()
    }
}

pub struct TimeRangeIndex {}
impl TimeRangeIndex {
    pub fn new() -> Self { Self {} }
    pub async fn query_range(&self, _start: DateTime<Utc>, _end: DateTime<Utc>) -> Vec<TraceId> {
        Vec::new()
    }
}
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### æŸ¥è¯¢ä¼˜åŒ–

1. **æ—¶é—´èŒƒå›´ä¼˜å…ˆ** - å…ˆæŒ‰æ—¶é—´è¿‡æ»¤ï¼Œå‡å°‘æ•°æ®é‡
2. **Bloom Filter é¢„è¿‡æ»¤** - é¿å…æ— æ•ˆçš„ LSM-Tree æŸ¥è¯¢
3. **æ‰¹é‡æŸ¥è¯¢** - å‡å°‘ç½‘ç»œå¼€é”€

### ç¼“å­˜ç­–ç•¥

1. **çƒ­ç‚¹ Trace ç¼“å­˜** - LRU ç­–ç•¥
2. **é¢„å–ç›¸å…³ Trace** - æ ¹æ®ä¾èµ–å…³ç³»
3. **å®šæœŸæ¸…ç†** - é¿å…ç¼“å­˜è†¨èƒ€

### é”™è¯¯å¤„ç†

1. **è¶…æ—¶æ§åˆ¶** - é¿å…é•¿æ—¶é—´ç­‰å¾…
2. **é™çº§ç­–ç•¥** - éƒ¨åˆ†å¤±è´¥æ—¶è¿”å›éƒ¨åˆ†ç»“æœ
3. **é‡è¯•æœºåˆ¶** - ç½‘ç»œé”™è¯¯è‡ªåŠ¨é‡è¯•

---

## ğŸ“š å‚è€ƒèµ„æº

- [Jaeger Query Service](https://www.jaegertracing.io/docs/latest/apis/)
- [Zipkin API](https://zipkin.io/zipkin-api/)
- [OpenTelemetry Trace Query](https://opentelemetry.io/docs/specs/otel/trace/api/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**æœ€åæ›´æ–°**: 2025-10-10  
**ä½œè€…**: OTLP Rust é¡¹ç›®ç»„
